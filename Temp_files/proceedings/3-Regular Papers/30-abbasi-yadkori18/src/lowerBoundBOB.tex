% !TEX root = Main.tex
%
%\subsection{Lower Bound for the Stochastic \& Adversarial Rewards}
%\label{s:LowBOB}
\paragraph{Why is the best of both worlds unachievable?}
% 
We define a new notion of complexity, $\complexityBoth$ as
%
\[
%
\complexityBoth 
\triangleq
\frac{1}{
\gap_{(1)}}
\max_{k\in\setArms}\frac{k}{\gap_{(k)}}\cdot
%
\]
%
$\complexityBoth $ is a complexity for
the stochastic case.
As we detail  in Remark~\ref{rem:LOWbobCOMP}, 
$	\complexitySR\leq\complexityBoth\leq\complexityUnif.$
%Let $\mathcal S$ be the set of stochastic problem such that
%The upcoming Theorem~\ref{th:lowBOB} shows that
%for any $\nArms$ specified gaps, $0<\gap_1=\gap_2\leq\gap_3\leq \ldots\leq \gap_\nArms\leq 1/8$, 
%a stochastic problem can be built with a very similar gap landscape 
%and a complexity changed by at most a factor of $2$ such that on this problem
% it is not possible to have a probability of error 
%smaller than 
%$	\frac{1}{64}\exp\left(-512\frac{\timeHorizon}{\complexityBoth}\right)$
% %on any stochastic problem
%  without  having 
%  a probability of error  not converging to $0$ with large $\timeHorizon$
%   on some adversarial problem with
%  again a similar gap landscape.
%
\begin{restatable}[\textcolor{titleTh}{Lower bound for the BOB challenge}]{theorem}{thi}\label{th:lowBOB}
     For any class problem $\Gaps_{4}$, for any learner, 
     there exists an i.i.d.\,stochastic problem $\stoPro\in\Gaps_{4}$ with complexity $\complexityBoth$,
     such that  for any~$\timeHorizon$ satisfying  	$\nArms\exp\left(-\gap^2_1\timeHorizon\right/32)\leq 1/32$,  if
	the probability of error of the learner
	 on  \stoPro{}   
	satisfies
%	
	\[	
\ProErr_{\stoPro}(\timeHorizon)
	\leq
	\frac{1}{64}\exp\left(-\frac{2048\timeHorizon}{\complexityBoth}\right)\!\CommaBin
	\]	
%
	then there exists an adversarial problem $\gainVector\in\Gaps_{4}$
	   that  makes the learner suffer a 
	constant error,
	%
	\[	
	\ProErr_{\advPro(\gainVector)}(\timeHorizon)
	\geq
	 \frac{1}{16}\cdot
	\]
	%
      \end{restatable}    
%
\begin{remark}\label{rem:LOWbobCOMP}
	In general, we have
	%
	\[
	\complexitySR\leq\complexityBoth\leq\complexityUnif.
	\]
	%
%We first compare the complexities in a general regime. Then we spell out three different regimes to intuitively explore when the inequalities in the previous equation are strict or not.
Below, we compare the three  complexities in 
three specific gap regimes in order to intuitively explore   whether
the inequalities in the previous equation are strict or not. 
Interestingly, while in two regimes  $\complexitySR=\complexityBoth$, in the third regime, called the `square-root gaps', we can obtain $\complexityBoth=\sqrt{\nArms/2}\complexitySR$.  
This equality shows that on some problems and for large values of $\nArms$,
% 	\todovout{actually really large value on K , like millions !!! :(, i am not sure we want to comment on that no?those numerical constants!}
 our lower bound on 
the complexity of the BOB problem is 
significantly larger than the complexity of the strictly stochastic case.
This ultimately shows that no  learner can guarantee the BOB in general   and that any learner  that is optimal in all strict stochastic problems is then inconsistent against
worst-case adversaries.
	\end{remark}
%\begin{description}
%	\item[General Regime:] Let the set $S$ of pairs $(k,\alpha)$, be $S=\{k\in\setArmsmo,\alpha\geq 0 : \gap^{\alpha}_{(1)}=\frac{\gap^{\alpha}_{(k)}}{k}\}$. This set is not empty as for each $k$ it contains the pair $\left(k,\alpha=\frac{\log k}{\log\left(\frac{\gap{(k)}}{\gap_{(1)}}\right)}\right)$
%	Let us denote $\kappa=\max_{k,\alpha\in S} k^{\frac{1}{\alpha}}$
	%
	\paragraph{\raisebox{.04cm}{\textcolor{bull}{$\blacktriangleright$}}~Flat regime}  We assume all the gaps are equal, 
$k\in\setArms,~ \gap_k=\gap_{1}$. Then, 
$\complexitySR=\complexityBoth=\complexityUnif$. Having $\complexitySR=\complexityBoth$  shows that our  
stochastic BOB lower bound for robust learners (Theorem~\ref{th:lowBOB}) using $\complexityBoth$ is of the same order as the one in the 
strict stochastic setting~\citep{Audibert10BA} using $\complexitySR$.   
In this stochastic regime, \RULE{} is optimal while being robust to an adversary.
%
\paragraph{\raisebox{.04cm}{\textcolor{bull}{$\blacktriangleright$}}~Super-linear gaps} Let $(2)\in\argmin_{k\in\setArms} (\gap_{(k)}/k).$ 
This holds if 
$\forall k\in[3:\nArms],$ we have that $\gap_{(k)}=k\gap_{(1)}$, $\gap_{(1)}\leq 1/\nArms$. Then, 
$\complexitySR=\complexityBoth=(2/\nArms) \complexityUnif$. 
Again, our BOB lower bound is of the same order as in 
the strict stochastic setting. This seems to indicate that in this case, BOB is achievable. However, it is not achieved by the uniform 
learner that is clearly suboptimal. This observation demands a new robust learner. Intuitively,  the learner can  
identify bad arms quickly
and  start focusing early on the best arms without incurring 
high variance on its estimates for them.
%
%\todov{think more about the right 2s!}
\paragraph{\raisebox{.04cm}{\textcolor{bull}{$\blacktriangleright$}}~Square-root gaps}   We assume $(2)\!\in\!\argmin_{k\in\setArms} (\gap^2_{(k)}/k).$ 
%This means that for all $k\in\setArms$, $\gap_{(1)}\leq \frac{\gap{(k)}}{\sqrt{k}}$. 
Let us denote arm $j$ for which  $j\in\argmin_{k\in\setArms} (\gap_{(k)}/k)$. 
For some constant $c$, let $\gap_{(1)}=c\gap_{(j)}/j$. We have 
$c\leq \sqrt{2j}$ because  $\gap^2_{(1)}/2 \leq \gap^2_{(j)}/j$ 
as  $(2)\in\argmin_{k\in\setArms} (\gap^2_{(k)}/k)$.
Therefore,  \[\complexitySR=\frac{2}{\gap^2_{(2)}}=\frac{2}{\gap^2_{(1)}}= \frac{2}{\gap_{(1)}} \frac{j}{c\gap_{(j)}}=\frac{2\complexityBoth}{c}=\frac{2\complexityUnif}{\nArms}\cdot\]	
We can get $c=\sqrt{2j}=\sqrt{2\nArms}$.
This happens if 
$\sqrt{\nArms/2}\gap_{(1)}=\gap_{(\nArms)}$ and
$\sqrt{k/2}\gap_{(1)}\geq\gap_{(k)}$ for $k\in[3:\nArms-1]$. 
Then,  we get  $\sqrt{\nArms/2}\complexitySR=\complexityBoth$.
$\complexityBoth$ is $\sqrt{\nArms/2}$ larger than the complexity of
the strictly stochastic setting.
Intuitively,  the learner needs to spend some time to 
identify the `square-root gaps' suboptimal arms before starting 
to focus on the best arms. This makes it suffer an additional amount
of variance on its estimates for the best arms.
%\vspace{.1cm}
%
%\textbullet~ If all the gaps are such that for all $i$ , $\gap_i/i$ are
% equal (or more generally if, which means
% $\gap_1$ is quite small comparatively to the other gaps, the gaps in the example are increasing rapidly : linearly), we have the lowerbound 
%  $\complexitySR=\complexityBoth=\frac{1}{\nArms}\complexityUnif	$
%   the normal lowerbound again
%
%\textbullet~ If all the gaps are such that for all $i$ , $\gap^2_i/i$ are
% equal (or, more generally, If $1=\argmin_k \gap^2_k/k$, which 
% means arm 1 is quite small comparatively but as small as in
%  the previous case!, the gaps are increasing in a square root fashion ), in this case we have  $K=\argmin_k \gap_k/k$ we have the lowerbound 
%  $\complexitySR=\frac{1}{\sqrt{\nArms}}\complexityBoth=\frac{1}{\nArms}\complexityUnif	$ 
%  which is a new lowerbound larger than in the traditional case so 
%  thats cool. Indeed note that this is a case where the definition of the 
%  classical complexity is $\exp(-N\gap^2_1)$
%  
%  \todovout{\textbullet~ Think about other examples, what can we say in general? We can add something bout general geometric setting where all $\frac{i}{\gap^\alpha_i}$ are the same.}

%
%\begin{remark}
%The assumption $\nArms\exp\left(-\frac{1}{32}\gap^2_{(1)}\timeHorizon\right)\leq 1/32$ is mild. 
%Essentially, at most, it  asks for $\timeHorizon$ to be large 
%enough so that the stochastic problem is solvable within the budget $\timeHorizon$.
%% $\timeHorizon$ is required to be large enough here.
%\end{remark}%
%

\vspace{.5cm}
\noindent\textbf{Sketch of the proof} 
\textit{(full proof in 
	Appendix~\ref{app:prooflowBOB})}:
Our proof of the lower bound uses some arguments of purely stochastic best-arm identification 
lower bounds of~\cite{Audibert10BA} and~\cite{Carpentier16TB}.
We have been also inspired by the lower bound of~\cite{Auer16AA} 
for the BOB question for the cumulative regret. However, 
our specific construction is new.
%\todov{thats a long sketch! should we shortening it or remove it? or no}

Consider a fixed learner. 
%To maximize 
%the bound we will set $i=\argmax_{k\in\setArmsmo} \frac{k}{\gap_{k}}\cdot$
%Let $n_i=n\dividefac_i$, with $\dividefac_i=\gap_1/\gap_i\leq 1$ be a number of early rounds in the game.
%\todov{woops do we have an extra condition here!?}
%As in the proof of Theorem~\ref{th:LOWadPRO} discussed in 
%Section~\ref{s:ULGenAd}, 
%We construct two similar bandit 
%problems, one stochastic and one adversarial.
We construct a stochastic and an adversarial problem.
Between the two problems, only one arm differs.
% by a change in the mean 
%of order $\gap_{i}$. Also this arm that will be observed by the learner only $\timeHorizon_i/i$ times. 
We bound the number of pulls from the learner on this arm.
Using a change-of-measure argument,  
 with a probability  $\cO\left(\exp\left(-\timeHorizon/\complexityBoth\right)\right)$ 
 the two problems are impossible to discriminate. 
However, the two problems have different best arms. 
Therefore the learner makes a mistake $\cO\left(\exp\left(-\timeHorizon/\complexityBoth\right)\right)$ 
on at least one of the two problems.

Let us define $K$ base Bernoulli distributions with  
means $\mean_1 \triangleq 1/2$ and for all remaining $k\in[2:\nArms], \mean_k\triangleq/2-\gap_k$. 
 % that we call $\earlyPhase_i$.
Let $i\in\setArmsmo$ be  an arbitrary arm.
Let $n_i\triangleq n\dividefac_i$, where $\dividefac_i \triangleq \gap_1/\gap_i\leq 1$, is a number of early rounds in the game.
Because the total number of pulls by the learner is 
limited by $\timeHorizon_i$ 
during this phase, by Dirichlet's box principle,  there exists at least $K-i+1$  arms included in $[2:\nArms]$ %$\{(2),\ldots,(\nArms)\}$.
that are pulled  by the learner less than $\cO(\timeHorizon_i/i)$ times in 
expectation. 
Therefore, in this set of arms,  there is an arm, 
%($\refarm=1$ by construction),
 denoted $\refarm$, that 
 has a gap of order or smaller than $\gap_{i}$.
 This arm, with a small gap, that the learner does 
 not explore very much, is then used 
 to  construct the two similar bandit problems 
 that the learner has a hard time to differentiate.
%
The stochastic problem is made by only modifying the
original Bernoulli distribution of arm $\refarm$  
by setting it  to 
$\mu_{\refarm} \triangleq 1/2 + \gap_1/2$. 
The adversarial problem samples  $\gainVector$ randomly: 
 It is mimicking the stochastic 
problem  for all rounds and all arms with the exception 
of the $\refarm$ during the first  $\timeHorizon_i$ 
rounds of the game where the gains are from 
the base Bernoulli distribution (with mean $1-\gap_{\refarm}$).
%distributions until the end of phase $A_i$ and then switch to the same distributions as problem 1.




If  $\dividefac_i\geq \gap_1/\gap_i$--- 
fixing a large enough phase at the beginning to 
modify the identity of the best arm---then  the best 
arms in both problems are different. The event on which the 
two problems are impossible to discriminate has a probability of~$\cO\left(\exp(-\timeHorizon_i(\gap_i)^2/i\right)$. %\leq\exp(-\timeHorizon_ia_i\gap^2_1/i)\right)$.
To maximize this probability, we minimize $\dividefac_i$ 
while still ensuring  to  have the change of best arm 
between the two problems, by setting $\dividefac_i  \triangleq\gap_1/\gap_i$.
Therefore, the probability is now   
$\cO\left(\exp(-\timeHorizon\gap_{1}\gap_i/i)\right)$.
Again to maximize  it, we choose 
$i \triangleq \argmin_k (\gap_k/k)$ and obtain the claimed result for some fixed $\gainVector$.
%