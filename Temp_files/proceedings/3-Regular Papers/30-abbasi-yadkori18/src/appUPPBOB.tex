% !TEX root = Main.tex
%
\section{Upper bound in best of both worlds} %Setting (Theorem~\ref{th:UpBOB}) }
\label{app:proofupBOB}
%
%
%	 
%\todom{again $p$ vs $j$}
\begin{lemma}\label{l:errTwoArms}
	%
	    Let $\eventbob_p$  be the events defined in Equation~\ref{eq:eventbob} for all $p\in[2:\nArms]$.
	On the conjunction of events $\cap_{p=i+1}^{\nArms+1}
	\eventbob_{p}$ and for
$i\in[2:\nArms]$,	in an i.i.d.\,stochastic 
environment, and complexity $\complexityProOne$, playing~\Pone{},
	given two distinct  arms  $ j \in [i:\nArms] $, $k\in[\nArms]$   and 
	a round $t\geq \phaseTime_{i}$ such that $\mean_1-\mean_k< \gap_{i}/2,$
	we have
	%
	\[
	%
\Pro\left(\estCumulGainVector_{k,t}\leq  \estCumulGainVector_{j,t} \right)
	\leq
 2\exp\left(-\frac{\timeHorizon}{128\complexityProOne}\right)\!\cdot
%
	\]
	%
\end{lemma}
%  
\begin{proof}
	We  prove that for any  proportions of rounds $\propTimeVec$, we have
		\[
	%
	\Pro\left(\estCumulGainVector_{k,t}\leq  \estCumulGainVector_{j,t} \right)
	\leq
	2\exp\left(-\frac{\timeHorizon}{128\complexityProOne(\propTimeVec)}\right)\!\cdot
	%
	\]
	Then, the claim of the Lemma~\ref{l:errTwoArms} comes from $\complexityProOne
	=
	\min_{\propTimeVec\in\propTimeVecSpa}
	\complexityProOne(\propTimeVec)$.	
%
First, notice that  %\todom{michal typesetchecked until here}
\[\mean_k-\mean_j= \mean_k-\mean_1+\mean_1-\mean_j
\stackrel{\textbf{(a)}}{>}
-\frac{\gap_{j}}{2}+\mean_1-\mean_j
=
\frac{\gap_{j}}{2}
%~=~
%\frac{\gap_{i+1}}{2}
>
0,
\] %\todom{we assume all the gaps are nonzero? \\ Victor : yes because there is a unique best arm}
where \textbf{(a)} is because by the assumption of the lemma,
$\mean_1-\mean_k<\gap_{i}/2\leq \gap_{j}/2$.
%and  \textbf{(b)} is because as $ j \geq i+1 $
%$\gap_{j}\geq\gap_{i+1}$.
We decompose
%
%\todomi{shouldn't this be on $i$ instead of $k$? how else you can have $\mean_k-\mean_j>0$}
\begin{align}
\Pro\left(\estCumulGainVector_{k,t}\leq  
\estCumulGainVector_{j,t} \right)
&\stackrel{\textbf{(c)}}{\leq}
\Pro\left(t\mu_k-\estCumulGainVector_{k,t}  
\geq  t\frac{\mu_k-\mu_j}{2} \right)
+
\Pro\left(\estCumulGainVector_{j,t} - t\mu_j 
\geq  t\frac{\mu_k-\mu_j}{2} \right) \nonumber\\
&\stackrel{\textbf{(d)}}{\leq}
\Pro\left(t\mu_k-\estCumulGainVector_{k,t} > 
\frac{t\gap_{j}}{4} \right)
+
\Pro\left(\estCumulGainVector_{j,t} - t\mu_j > 
 \frac{t\gap_{j}}{4} \right) \label{eq13}\!\CommaBin
\end{align}
%
where \textbf{(c)} is because $\mean_k-\mean_j>0$ %\todom{maybe $\geq$?}
and \textbf{(d)} is because $\mean_k-\mean_j> \gap_{j}/2.$

We  now bound the two terms in Equation~\ref{eq13}.
To bound the \emph{second term} in Equation~\ref{eq13} we have
for all $t'\in[\timeHorizon]$,
$|\estGainVector_{j,t'}-\gainVector_{j,t'}|\leq 
\nArms\bar\log \nArms$ as $\learnerDist_{j,t'}
\geq 1/(\nArms\bar\log\nArms).$
We define  arm $j^+$ so that 
$j^+ +1$  is the arm with the largest mean among the ones that have the at least twice the gap of the gap of $j$,  %$j^+=\argmax_{p\in\{\nArms\}\cup\left\{p':\mean_1-\mean_j<\gap_{p'+1}/2\right\}}\mean_p$.
%\todom{say with words: it the arm with the largest mean among the ones that have the at least twice the gap of the gap of $j$}
$j^+  +1 \triangleq \mathop{\arg\max}\limits_{p':\mean_1-\mean_j<\gap_{p'}/2}
\mean_{p'}$. Note that as $j\geq i>1$, we have $j^++1> j
$ and therefore $j^+\geq j\geq i$.
We now bound the cumulative variance $\sum_{t'=1}^t \var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}$ for the mean estimator of arm $j$ at round~$t'$, 
%
\begin{align*}
%
\sum_{t'=1}^t \var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}
%&\leq
%\sum_{l=2}^{\nArms}
%\sum_{t'=\phaseTime_{l+1}}^{\phaseTime_{l}}
% \var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}\\
&\stackrel{\textbf{(e')}}{=}
\sum_{\ell=j^+}^{\nArms}
\sum_{t'=\phaseTime_{\ell+1}+1}^{\phaseTime_{\ell}}
\var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}
+
\sum_{t'=\phaseTime_{j^+ }+1}^{t}
\var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}\\
&\stackrel{\textbf{(e)}}{\leq}
\sum_{\ell=j^+}^{\nArms}
\sum_{t'=\phaseTime_{\ell+1}+1}^{\phaseTime_{\ell}}
\ell\bar\log\nArms
+
\sum_{t'=\phaseTime_{j^+}+1}^{t}
j^+\bar\log\nArms\\
&=
\sum_{\ell=j^+}^{\nArms}
(\phaseTime_{\ell}-\phaseTime_{\ell+1})
\ell\bar\log\nArms
+
(t-\phaseTime_{j^+})
j^+\bar\log\nArms,
%
 \end{align*}
 %\todomi{perhaps say what $\var$ is variance? or use $\operatorname{Var}(X)$?}
 %\todomi{$l$ is hard to read, change to $\ell$ or a different letter}
  %\todomi{this and next lemma is not very self-contained, it uses the variables from all over the paper}
 %
 where \textbf{(e')} is because   $t\geq \phaseTime_i\geq 
  \phaseTime_{j^+ }$ and \textbf{(e)} is because we are on 
  the conjunction of events  $\cap_{p=i+1}^{\nArms+1}
   \eventbob_{p}$. Therefore, as for each round $t'$ in the
    round interval $[\phaseTime_{\ell+1}+1:\phaseTime_{\ell}]$  
    with $\ell\in [j^+:\nArms]$, we verify $\mean_1-\mean_j
    <\gap_{j^+ +1}/2\leq\gap_{\ell+1}/2$, then we have $\tilde{\langle j \rangle}_{t'}
    \leq \ell$. For $t'\in [\phaseTime_{j^+}+1:t ]$, we use the 
    fact that  event $ \eventbob_{j^++1}$   holds for arm $j$ by 
    construction  of the events $\{\xi_i\}_i$ and therefore $\forall t'> \phaseTime_{j^+}
    \geq \phaseTime_{j^++1}$, $\tilde{\langle j \rangle}_{t'}<j^+ \leq j^+ +1$ and we 
    can bound the variance.
%

\smallskip \noindent
By applying the Bernstein inequality for martingale  differences  we have
%\todomi{let's discuss $\var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}$, this is not a typical form of this inequality}
%
\begin{align*}
%
\Pro&\left(\estCumulGainVector_{j,t} - t\mu_j >  
\frac{t\gap_{j}}{4} \right)
\stackrel{\textbf{(f)}}{\leq}
\Pro\left(\estCumulGainVector_{j,t} - t\mu_j >  
\frac{t\gap_{j^+}}{8} \right)\\
&\quad\quad\quad\quad\quad\leq
\exp\left(-
\frac{\left( t\gap_{j^+}/8\right)^2}{2\sum_{t'=1}^t 
	\var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}
+
\frac{2}{3}\nArms\bar\log(\nArms)\frac{t\gap_{j^+}}{8}
}
\right)\\
&\quad\quad\quad\quad\quad\leq
\exp\left(-
\frac{\left(t\gap_{j^+}\right)^2\!/64}{
	2\sum_{\ell=j^+}^{\nArms}
	(\phaseTime_{\ell}-\phaseTime_{\ell+1})
	\ell\bar\log\nArms
	+
	(t-\phaseTime_{j^+})
	j^+\bar\log\nArms
	+
	\frac{1}{12}\nArms\bar\log(\nArms) t\gap_{j^+}
}
\right)\\
&\quad\quad\quad\quad\quad\stackrel{\textbf{(g)}}{\leq}
\exp\left(-
\frac{\left(\phaseTime_{j^+}\gap_{j^+}\right)^2\!/64}{
2	\sum_{\ell=j^+}^{\nArms}
(\phaseTime_{\ell}-\phaseTime_{\ell+1})
	\ell\bar\log\nArms
	+
	\frac{1}{12}\nArms\bar\log(\nArms)\phaseTime_{j^+}\gap_{j^+}
}
\right)\!\CommaBin
%
\end{align*}
%
where \textbf{(f)} is because $\gap_{j^+}/2\!\leq\!\gap_j$ 
by construction
and \textbf{(g)} is because the exponential term is a 
decreasing function of $t$ and $t\geq \phaseTime_i\geq 
\phaseTime_{j^+ }$.

%\smallskip
%\noindent 
To bound the \emph{first term} of Equation~\ref{eq13} we use similar arguments. 
We have
for all $t'\!\in\![\timeHorizon]$,
$|\estGainVector_{k,t'}-\gainVector_{k,t'}|
\leq 
\nArms\bar\log\nArms$ as $\learnerDist_{j,t'}\geq 1/(\nArms\bar\log\nArms).$
%\smallskip \noindent 
We get
\begin{align*}
\sum_{t'=1}^t \var_{\estGainVector_{k,t'}-\gainVector_{k,t'}}
&=%\stackrel{(e')}{=}~
\sum_{\ell=i}^{\nArms}
\sum_{t'=\phaseTime_{\ell+1}+1}^{\phaseTime_{\ell}}
\var_{\estGainVector_{k,t'}-\gainVector_{k,t'}}
+
\sum_{t'=\phaseTime_{i }+1}^{t}
\var_{\estGainVector_{k,t'}-\gainVector_{k,t'}}\\
&\stackrel{\textbf{(e)}}{\leq}
\sum_{\ell=i}^{\nArms}
\sum_{t'=\phaseTime_{\ell+1}+1}^{\phaseTime_{\ell}}
\ell\bar\log\nArms
+
\sum_{t'=\phaseTime_{i}+1}^{t}
i\bar\log\nArms\\
&=
\sum_{\ell=i}^{\nArms}
(\phaseTime_{\ell}-\phaseTime_{\ell+1})
\ell\bar\log\nArms
+
(t-\phaseTime_{i})
i\bar\log\nArms,
%&\leq
%\sum_{l'=j^++1}^{\nArms}
%(\phaseTime_{l'-1}-\phaseTime_{l'})
%(l')\bar\log\nArms
%+
%(t-\phaseTime_{j^+})
%j^+\bar\log\nArms
\end{align*}
%where \textbf{(e')} is because  $t\geq \phaseTime_i\geq \phaseTime_{j^+ }$, 
where \textbf{(e)} is because we are on the conjunction of 
events  $\cap_{p=i+1}^{\nArms} \eventbob_{p}$. Therefore, 
as for each round $t'$ in the round interval 
$[\phaseTime_{\ell+1}+1:\phaseTime_\ell]$  with $\ell\in [i:\nArms]$, 
we verify $\mean_1-\mean_k<\gap_{i +1}/2\leq\gap_{\ell+1}/2$, 
then we have $\tilde{\langle k \rangle}_{t'}<\ell+1$. For 
$t'\in [\phaseTime_{i}+1:t ]$, we use the fact that  event 
$ \eventbob_{i+1}$ holds for arm $k$ by construction and 
therefore $\forall t'\geq \phaseTime_{i+1}\geq \phaseTime_{i}$, we have
$\tilde{\langle k \rangle}_{t'}\leq i$ and we can bound the variance.

\smallskip \noindent We apply the Bernstein inequality for martingale  differences  again to get
%
\begin{align*}
%
\Pro\left(\estCumulGainVector_{k,t} - t\mu_k >  \frac{t\gap_{j}}{4} \right)
&\stackrel{\textbf{(f)}}{\leq}
\Pro\left(\estCumulGainVector_{k,t} - t\mu_k >  \frac{t\gap_{i}}{4} \right)\\
&\leq
\exp\left(
\frac{-\left( t\gap_{i}/4\right)^2}{
	2\sum_{t'=1}^t \var_{\estGainVector_{j,t'}-\gainVector_{j,t'}}
	+
	\frac{2}{3}\nArms\bar\log(\nArms)\frac{t\gap_{i}}{4}
}
\right)\\
&\leq
\exp\left(
\frac{-\left(t\gap_{i}\right)^2\!/16}{
2	\sum_{\ell=i}^{\nArms}
	(\phaseTime_{\ell}-\phaseTime_{\ell+1})
	\ell\bar\log\nArms
	+
	(t-\phaseTime_{i})
	i\bar\log\nArms
	+
	\frac{1}{6}\nArms\bar\log(\nArms) t\gap_{i}
}
\right)\\
&\stackrel{\textbf{(g)}}{\leq}
\exp\left(
\frac{-\left(\phaseTime_{i}\gap_{i}\right)^2\!/16}{
	2\sum_{\ell=i}^{\nArms}
	(\phaseTime_{\ell}-\phaseTime_{\ell+1})
	\ell\bar\log\nArms
	+
	\frac{1}{6}\nArms\bar\log(\nArms)\phaseTime_{i}\gap_{i}
}
\right)\!\CommaBin
%
\end{align*}
%
where \textbf{(f)} is because $\gap_{i}\leq\gap_j$ by 
construction
and \textbf{(g)} is because the exponential term is a 
decreasing function of $t$ and $t\geq \phaseTime_i\geq \phaseTime_{j^+ }$.
%
\end{proof}			
\begin{lemma}\label{l:errPOGerrPO}
        Let $\eventbob_p$  be the events defined in Equation~\ref{eq:eventbob} for all $p\in[2:\nArms]$.
	In an i.i.d.\,stochastic environment and complexity $\complexityProOne$ playing \Pone{}, we have for all $i\in[2:\nArms]$, 
	%
	\[
\Pro
\left(
\eventbob^c_{i}\ \middle| \bigcap_{p=i+1}^{\nArms+1} \eventbob_{p}
\right)
\leq
 2\nArms^2\timeHorizon
 \exp\left(-\frac{\timeHorizon}{128\complexityProOne}\right)\!\cdot
	\]
	%
\end{lemma}
%\todomi{index in lemma is from $p$ and event while we defined event $K+1$, we say all over that $i$ goes only up to $K$}
% 
\begin{proof}
	%
Let us consider one arm  $k\in[\nArms]$ and a round  
$t> \phaseTime_{i}$ such that $\mean_1-\mean_k< \gap_{i}/2.$ 
We bound the probability that $\tilde{\langle k \rangle}_t\geq i$ as
%
\begin{align*}
\Pro\left(\tilde{\langle k \rangle}_t\geq i\right)
&\stackrel{\textbf{(a)}}{\leq}
\Pro\left( \exists j \in [i:\nArms],~ \estCumulGainVector_{k,t-1}
\leq  \estCumulGainVector_{j,t-1} \right)\\
&\leq
\sum_{j=i}^{\nArms}
\Pro\left(\estCumulGainVector_{k,t-1}\leq  \estCumulGainVector_{j,t-1} \right)\\
&\stackrel{\textbf{(b)}}{\leq}
\sum_{j=i}^{\nArms}  2\exp\left(-\frac{\timeHorizon}{128\complexityProOne}\right)\!\CommaBin  
\end{align*} 
%
%\todo{fix the constants!!} 
where \textbf{(a)} is because if $\forall j
 \in [i:\nArms],~\estCumulGainVector_{k,t}>  \estCumulGainVector_{j,t},$
  then we have $\tilde{\langle k \rangle}_t< i$,
 \textbf{(b)} is using  Lemma~\ref{l:errTwoArms} with $t'=t-1$ and we have $t'=t-1>\timeHorizon_i-1\geq\timeHorizon_i$.
%\todov{Wooops i forgot to write this part!! and this is link to an important choice of notation! I will guess we dont need the $G_{i,t}$ in general and suppress them and hope it works here at reread}
%
Using union bounds on the arms in  $k\in[\nArms]$ and the rounds $t$, 
 we get the claim of the lemma.
 %
\end{proof}%
%
	\setcounter{scratchcounter}{\value{theorem}}\setcounter{theorem}{\the\numexpr\getrefnumber{th:UpBOB}-1}
\lightres*
\setcounter{theorem}{\the\numexpr\value{scratchcounter}}
\begin{proof} %[Theorem~\ref{th:UpBOB}] 
We consider two cases separately.
	%Let us consider the $a^*_i$ that maximizes the proof quantity
	%
	%
	\paragraph{The i.i.d.~stochastic case}
	We place ourselves in the i.i.d.\,stochastic setting described 
	in Section~\ref{s:FormuBOB}.
	%
	%To avoid technicalities and ease the reading, we henceforth assume that
	%$\nArms$ is a power of $2$ $K=\log(\TphaseNumber)$. 
	To ease the notation and without loss of generality, we  assume that 
	the arms are sorted by their means so that arm $1$ is the best,
	$\mean_1>\mean_2\geq\ldots\geq\mean_{\nArms}$, and $\gap_1=\gap_2\leq\ldots\leq\gap_{\nArms}$.
	%
	
	Let us consider any %$1\geq a_2\geq\ldots\geq a_{\nArms-1}\geq 0$.
	%and the respective 
	rounds verifying 
	$\phaseTime_2=\timeHorizon\geq \phaseTime_3\geq\ldots\geq 
	\phaseTime_{\nArms+1} = 0 $.  Intuitively, $n_i$ is a round 
	after which, for $t\geq\phaseTime_i$, we expect \Pone{} to 
	have well ranked any arm $k$ with a 
	gap smaller than half the gap of arm $i$,  in the sense that $\tilde{\langle k \rangle}_t< i$, 
	if $ \mean_1-\mean_k\leq\gap_{i}/2.$
	%\todov{maybe the freedman inequality should be used more cleanly with some filtrations}
	For $i\in[2:\nArms+1]$, we define the following event $\eventbob_i$,
	%
	\begin{equation}\label{eq:eventbob}
	\eventbob_i
	\triangleq
	\left\{
	\forall t> \phaseTime_{i} , 
	\forall k\in[\nArms] : \mean_1-\mean_k<\frac{\gap_{i}}{2}\implies \tilde{\langle k \rangle}_t< i
	\right\}\!\cdot
	\end{equation}%\todov{clearer K+1}
	%\todomi{why don't we write $\mean_1-\mean_k$ using gap notation?\\ Victor because i think there is a subtlety for k=1}
	%\todomi{implication in the instead of comma above?}
	%
	Note that as the ranks $\tilde{\langle k \rangle}_t$ 
	are integers, $\tilde{\langle k \rangle}_t< i$ is 
	equivalent to $\tilde{\langle k \rangle}_t\leq i-1$.
	We initialize the sequence by defining $\gap_{\nArms+1}=3\gap_{\nArms}$ 
	and then we have that event $\eventbob_{\nArms+1}$ is always true.
	
	If $\eventbob_{2}$ holds, the algorithm \Pone{} makes 
	no mistake as
	$\tilde{\langle k \rangle}_{\timeHorizon+1} = 1$ and the 
	returned arm is $\recomArm_\timeHorizon=1$.
	More generally, we say for $i\in[2:\nArms]$, that 
	if $\eventbob_{i}$ does not hold, or equivalently 
	if its complement $\eventbob^c_{i}$ holds,  then 
	the algorithm makes a mistake at stage $i$. 
	%
	We now bound the probability of an event $A$ 
	%mistake at stage $i$, $\Pro\left(\eventbob^c_i\right)$  for $i\in[2:\nArms]$
	with respect to the probability of mistake 
	at a stage $j$, $\Pro(\eventbob^c_{j})$ as
	%
	\begin{align*}
	\Pro\left(A\right)
	&=
	\Pro\left(A \cap \eventbob^c_{j} \right) +\Pro\left(A \cap \eventbob_{j}\right)
	\leq
	\Pro\left(\eventbob^c_j \right) +\Pro\left(A \cap \eventbob_{j}\right).
	%\\
	%&~=~
	%\Pro\left(\eventbob^c_j \right) +\Pro\left(A \middle| \eventbob_{j}\right)\Pro\left(\eventbob_{j}\right)
	%~\leq~
	%\Pro\left(\eventbob^c_j \right)+\Pro\left(A \middle| \eventbob_{j}\right)
	\end{align*}
	%\begin{align*}
	%\Pro\left(\eventbob^c_i\right)
	%&~=~
	%\Pro\left(\eventbob^c_i \cap \eventbob^c_{j} \right) +\Pro\left(\eventbob^c_i \cap \eventbob_{j}\right)
	%~\leq~
	%\Pro\left(\eventbob^c_j \right) +\Pro\left(\eventbob^c_i \cap \eventbob_{j}\right)\\
	%&~=~
	%\Pro\left(\eventbob^c_j \right) +\Pro\left(\eventbob^c_i \middle| \eventbob_{j}\right)\Pro\left(\eventbob_{j}\right)
	%~\leq~
	%\Pro\left(\eventbob^c_j \right)+\Pro\left(\eventbob^c_i \middle| \eventbob_{j}\right)
	%\end{align*}
	Therefore, applying recursively the previous 
	inequality to bound the probability of error of 
	\Pone{} denoted $\ProErr_{\stoPro}(\timeHorizon)$, we write
	%
	\begin{align*}
	&\ProErr_{\stoPro}(\timeHorizon)
	=
	\Pro\left(\eventbob^c_2\right)
	%~\leq~
	%\Pro\left(\bigcup_{i=1}^{\nArms-1}\eventbob^c_i\right)
	%~=~
	%\Pro\left(
	%\bigcup_{i=1}^{\nArms-1}
	%\left(
	%\eventbob^c_{i}\cap\left(\bigcup_{j=i+1}^{\nArms} \eventbob_{j}\right)
	%\right)\right)\\
	%~\leq~
	%\sum_{i=1}^{\nArms+1}\Pro
	%\left(
	%\eventbob^c_{i}\cap\left(\bigcup_{j=i+1}^{\nArms} \eventbob_{j}\right)
	%\right)
	\leq
	\sum_{i=2}^{\nArms}
	\Pro
	\left(
	\eventbob^c_{i}\cap\left(\bigcap_{j=i+1}^{\nArms+1} \eventbob_{j}\right)
	\right)\!
	\leq
	\sum_{i=2}^{\nArms}
	\Pro
	\left(
	\eventbob^c_{i}~\middle| \bigcap_{j=i+1}^{\nArms+1} \eventbob_{j}
	\right)\!.
	%&~=~
	%\Pro\left(\eventbob^c_{\nArms+1}\cup \left( \eventbob^c_{\nArms}\cap\eventbob^_{\nArms+1}\right)
	%\cup \left( \eventbob^c_{\nArms-1}\cap\left(\eventbob_{\nArms+1}\cup\eventbob_{\nArms+1}\right)\right)
	%\cup\ldots
	%\cup
	%\eventbob^c_{2}\cap\left(\bigcup_{j=2}^{\nArms+1} \eventbob_{j}\right)\right)
	%\right)
	%~\leq~
	%\sum_{i=2}^{\nArms}\Pro\left(\eventbob^c_i \middle| \eventbob_{i+1}\right)
	\end{align*}
	Using Lemma~\ref{l:errPOGerrPO}; we get our claimed result in the stochastic case. 
	%Let us consider the event:
	%
	%
	%	\begin{equation*}
	%	\eventu
	%	~=~
	%	\left\{
	%	\forall k\in\setArms,
	%%	\forall t\in \{\timeHorizon/a_2,\ldots,\timeHorizon/a_{\nArms-1}\},
	%\forall t\in \{\phaseTime_2,\ldots,\phaseTime_{\nArms-1}\},
	%	\left|\estCumulGainVector_{k,t}-\mu_k \phaseTime_k\right| \leq \gap_k \phaseTime_k
	%	\right\}
	%\end{equation*}
	%2\exp\left(-\frac{ \epsilon^2/2}{\timeHorizon \nArms + \frac{1}{3}\nArms\epsilon} \right)
	
	%This event holds with probability
	%
	%
	%After $t=N/a^*_K$, all the arms have been pulled $N/K/a^*_K\log(K)$
	%therefore the upper half of the arms will be well ranked.
	%with probability $\exp(-\gap^2_K  N/K/a_K\log(K))$
	%
	%in the same way
	%After $t=N/a^*_i$, all the arms have been pulled $N/i/a^*_i\log(K)$
	%therefore the upper half of the arms will be well ranked.
	%with probability $\exp(-N \frac{\gap^2_i}{\sum_{j\geq i} j (a_j-a_{j+1})\log{K} })$
	%
	%
	\paragraph{The adversarial case}
	%
	Given the adversary gain vector $\gainVector$, 
	the random variables $\estGainVector_{k,t}$ can 
	be dependent of each other for all $k\in\setArms$ 
	and $t\in[\timeHorizon]$ as $\learnerDist_{k,t}$ 
	depends on previous observations at previous rounds. 
	Therefore, we use the Bernstein inequality for martingale  differences by~\citet{Freedman75OT}.
	
	For random variables $\estGainVector_{k,1}, \ldots, 
	\estGainVector_{k,n}$, we know that their variance is 
	the variance of the Bernoulli random variable with 
	parameter $1/\learnerDist_{k,t}$, scaled to the range $[0, \gainVector_{k,t}/\learnerDist_{k,t}]$.
	For all $k\in\setArms$ and $t\in[\timeHorizon]$, 
	having a lower bound on $\learnerDist_{k,t}\geq 1/(\nArms\bar\log\nArms),$ 
	we have 
	%$\estGainVector_{k,t}-\gainVector_{k,t} \in 
	%[-\nArms\gainVector_{k,t}, \nArms\gainVector_{k,t}]$, 
	%$\range_{\estGainVector_{k,t}-\gainVector_{k,t}}
	%\leq 2\nArms\bar\log\nArms\gainVector_{k,t}\leq  2\nArms\bar\log\nArms$ 
	$|\estGainVector_{k,t}-\gainVector_{k,t}| \leq  \nArms\bar\log\nArms$ 
	and  \[\var_{\estGainVector_{k,t}-\gainVector_{k,t}}
	=
	\var_{\estGainVector_{k,t}}=\frac{\learnerDist_{k,t}
	(1-\learnerDist_{k,t})\gainVector_{k,t}^2}{\learnerDist^2_{k,t}}\leq \nArms\bar\log \nArms.\]
	%\todov{no, not the Maurer with gap square!}
	Then, following the same reasoning as in the proof 
	of Theorem~\ref{th:UPARU}, but replacing the Bernstein inequality by the Bernstein inequality for martingale differences of~\cite{Freedman75OT} applied to the martingale 
	differences $\estGainVector_{k,t}-\gainVector_{k,t}$,  
	we obtain the claimed result for the adversarial case.
	%
\end{proof}
%
\section{On the complexities of $\complexityProOne$, $\complexitySR$, and 
	$\complexityBoth$}  %Proof of  Corollary~\ref{coco}}
\label{s:moreOnRem}
%\todomi{right reference to the remark in the title?}
%\todom{recheck the derivations below in detail}
%
%
 %\begin{remark} 
 We now show that in general, 
	$\complexityProOne = \cO\left(\complexityBoth\log^2\nArms\right)$. 
	This demonstrates that \Pone{} achieves the best 
	that can be wished for in the two worlds, up to log
	 factors.
	The extra $\log\nArms$ from the $\log^2\nArms$ is not always
	present  and we report an 
	even more detailed discussion on the three different regimes of the
	gaps used in 
	Remark~\ref{rem:LOWbobCOMP}  at the end of the section.
	%\todov{its not he right number for the corrolary numbering!}	
	\setcounter{scratchcounter}{\value{theorem}}\setcounter{theorem}{\the\numexpr\getrefnumber{coco}-1}
	\cocores*
	\setcounter{theorem}{\the\numexpr\value{scratchcounter}}
	\begin{proof}%[Proof of  Corollary~\ref{coco}
	To simplify the exposition, we assume, without 
	loss of generality,  that 
	$	\timeHorizon\propTime_i\in\Integer,~  \forall i \in[\nArms]$.
	%\todov{dont forget the extra log K!}
	%  
	%\todov{it look like we can write something directly for the general case, so we might remove the three specific examples or move to appendix, but i let them here for now at least for our own personal intuition because it would be nice to understand why it works this w
	We set $j\triangleq\argmin (\gap_{k}/k)$.
%	\todov{why this choice work, its the same as in the lower bound, we should try to understand more intuitibly}
	Let $\propTime_k \triangleq  \gap_{(1)}/\gap_{(k)},  \forall k \in\setArms$ and remember 
that $\propTime_{\nArms+1}=0$.  
	First note that the second term in $\complexityProOne(\propTimeVec)$, 
	taken for a fixed $k$, is of order  (not considering the numerical constants and the $\bar\log\nArms$) 
	%
	\[
	\frac{
		\nArms\propTime_{\langle k\rangle}\gap_{k}}
	{\propTime^2_{\langle k\rangle}\gap^2_{k}}
	=
	\frac{
		\nArms}{\gap_{(1)}}
	\leq
	\frac{
		\nArms}{\gap_{(K)}\gap_{(1)}}
	\leq
	\frac{
		j}{\gap_{j}\gap_{(1)}}
	=
	\complexityBoth.
	\]
	%   
	Similarly, we have the first term in $\complexityProOne(\propTimeVec)$  of order
	%
	\begin{align*}
	%
	\frac{
		\sum_{i=\langle k\rangle}^{\nArms}
		(\propTime_{i}-\propTime_{i+1})
		i
	}{\propTime^2_{\langle k\rangle}\gap^2_{k}}
	%
	&=
	%
	\frac{
		\sum_{i=\langle k\rangle}^{\nArms-1}
		\left(\frac{
			\gap_{(1)}
		}{\gap_{(i)}}-\frac{
			\gap_{(1)}
		}{\gap_{(i+1)}}\right)
		i
		+ \nArms \frac{		\gap_{(1)}	}{\gap_{(\nArms)}}
	}{\gap^2_{(1)}}\\
	&=
	%
	\frac{
		\sum_{i=\langle k\rangle}^{\nArms-1}
		\left(\frac{
			1
		}{\gap_{(i)}}-\frac{
			1
		}{\gap_{(i+1)}}\right)
		i 	+ \nArms \frac{	1}{\gap_{(\nArms)}}
	}{\gap_{(1)}}\\
	%
	&\stackrel{\textbf{(a)}}{\leq}
	%
	\frac{
		\sum_{i=\langle k\rangle}^{\nArms-1}
		\left(
		\frac{j}{i\gap_{(j)}}-\frac{j}{(i+1)\gap_{(j)}}\right)
		i	+ \nArms \frac{j}{\nArms\gap_{(j)}}
	}{\gap_{(1)}}\\
	%
&	=
	%
	\frac{j\left(
		\sum_{i=\langle k\rangle}^{\nArms}
		\left(	\frac{1}{i}-\frac{1}{i+1}\right)
		i +1\right)
	}{\gap_{(1)}\gap_{(j)}}\\
	&=
	%
	\frac{j\left(
		\sum_{i=\langle k\rangle}^{\nArms}
		\frac{1}{i+1}+1\right)
	}{\gap_{(1)}\gap_{(j)}}\\
	&   \leq
	\complexityBoth\left(\log\nArms+1\right)\!,
	\end{align*}
	%
	where \textbf{(a)} is because as  $j\triangleq\argmin_{k\in\setArms}
	(\gap_{(k)}/k),$ for all $i\in\setArms,$
	$1/\gap_{(i)}\leq j/(i\gap_{(j)}).$ More 
	precisely, to see \textbf{(a)}, we 
	unfold the sum and notice that actually there are no 
	negative signs anywhere therefore, the upper bound holds.
%\end{remark}%
\end{proof}
%

\subsection{Relation between 
	$\complexityProOne$, $\complexitySR$, and 
	$\complexityBoth$ for different regimes of the 
	gaps.}
We now study the relation between 
$\complexityProOne$, $\complexitySR$, and 
$\complexityBoth$ for different regimes of the 
gaps.
We use the same examples as the ones used in 
Remark~\ref{rem:LOWbobCOMP}.
We assume without 
loss of generality that 
$	\timeHorizon\propTime_i\in\Integer,~  \forall i \in[2:\nArms]$.
In these three regimes of interest we prove that at 
worst, $\complexityProOne=\cO(\complexityBoth\log^2\nArms)$. 
In the flat regime and the square-root gap regime, we have $\complexityProOne=\cO(\complexityBoth\log\nArms)$. 
%\end{remark}
%\todov{dont forget the extra log K!}
%  
%\todov{maybe remove the numerical constants?}
\paragraph{\raisebox{.04cm}{\textcolor{bull}{$\blacktriangleright$}}~Flat regime}  All the gaps are equal, that is,
$k\in\setArmsmo,$ we have that $\gap_k=\gap_{1}$. 

\smallskip
\noindent
We choose $\propTime_i = 1,~ \forall i \in[2:\nArms]$.
First note that in $\complexityProOne(\propTimeVec)$ the term
\[
\frac{
	\nArms\propTime_{\langle k \rangle }\gap_{k}}
{\propTime^2_{\langle k \rangle}\gap^2_{k}}
=
\frac{
	\nArms}{\gap_{(1)}}
\leq
\frac{
	\nArms}{\gap^2_{(1)}}
=
\complexitySR
=
\complexityBoth.
\]
%
Then we have the first term 
\[
\frac{
	\sum_{i=\langle k \rangle}^{\nArms}
	(\propTime_{i}-\propTime_{i+1})
	i
}{\propTime^2_{\langle k \rangle}\gap^2_{k}}
\leq
\frac{
	\nArms
}{\min_{k\in\setArms}\gap^2_{k}}
=
\complexitySR
=
\complexityBoth.
\]
%
%\todov{fix the 2 and make clear exactly which setting, do you fix the gap to  precise value?}
\paragraph{\raisebox{.04cm}{\textcolor{bull}{$\blacktriangleright$}}~Super-linear gaps}  Since $(2)\in\argmin_k(\gap_k/k)$, we get that $(2)\in\argmin_k (\gap^2_k/k)$.

\smallskip
\noindent Let $\propTime_i \triangleq 1/i,~ \forall i \in[2:\nArms]$. The two terms verify

%First note that in $\complexityProOne$ the term 	
%$\frac{
%	\frac{2}{3}\nArms\frac{\propTime_{k}\gap_{k}}{4}}
%{\propTime^2_{k}\gap^2_{k}/64}\bar\log\nArms$ verifies
\[
\frac{
	\nArms\propTime_{\langle k \rangle}\gap_{k}}
{\propTime^2_{\langle k \rangle}\gap^2_{k}}
=
\frac{
	\nArms}{\propTime_{\langle k \rangle}\gap_{k}}
=
\frac{
	\nArms k}{\gap_{k}}
=
\frac{
	2\nArms }{\gap_{(1)}}
\leq
\frac{
	2\nArms }{\gap_{(K)}\gap_{(1)}}
=
\frac{
	2}{\gap^2_{(1)}}
=
\complexitySR
=
\complexityBoth \quad \text{and}
\]
\begin{align*}
\frac{
	\sum_{i=\langle k\rangle}^{\nArms}
	(\propTime_{i}-\propTime_{i+1})
	i
}{\propTime^2_{\langle k\rangle}\gap^2_{k}}
&	=
\frac{
	\sum_{i=\langle k\rangle}^{\nArms}
	\left(\frac{1}{i}-\frac{1}{i+1}\right)
	i
}{\propTime^2_{\langle k \rangle}\gap^2_{k}}\\
&\leq
\frac{
	4	\sum_{i=1}^{\nArms}
	\left(\frac{1}{i}-\frac{1}{i+1}\right)
	i
}{\gap^2_{1}}\\
&	=
\frac{
	4	\sum_{i=1}^{\nArms}
	\left(\frac{1}{i}(i+1)\right)
	i
}{\gap^2_{1}}\\
&\leq
\frac{
	4	\log\nArms
}{\gap^2_{1}}\\
&=
2	\complexitySR	\log\nArms\\
&=
2	\complexityBoth	\log\nArms.
\end{align*}
%
\paragraph{\raisebox{.04cm}{\textcolor{bull}{$\blacktriangleright$}}~Square-root gaps} We have that $(2)\in\argmin_k (\gap^2_k/k),$
$\sqrt{\nArms/2}\gap_{(1)}=\gap_{(\nArms)}$, and also that
$\sqrt{k/2}\gap_{(1)}\geq\gap_{(k)}$ for $k\in[3:\nArms-1]$. 
Therefore, we have $K\in\argmin_{k\in\setArms} (\gap^2_{(k)}/k)$ and $K\in\argmin_{k\in\setArms} (\gap_{(k)}/k).$

\smallskip
\noindent 
Let $\propTime_i = 1/\sqrt{i},~ \forall i \in[2:\nArms]$.  The two terms verify
\[
\frac{
	\nArms\propTime_{\langle k\rangle}\gap_{k}}
{\propTime^2_{\langle k \rangle}\gap^2_{k}}
=
\frac{
	\nArms}{\propTime_{\langle k\rangle}\gap_{k}}
=
\frac{
	\nArms \sqrt{k}}{\gap_{k}}
=
\frac{
	\nArms \sqrt{2}}{\gap_{(1)}}
\leq
\frac{
	\nArms \sqrt{2}}{\gap_{(K)}\gap_{(1)}}
=
\sqrt{2}	\complexitySR\sqrt{\nArms}
=
\sqrt{2}	\complexityBoth \quad \text{and}
\] 
\begin{align*}		
\frac{
	\sum_{i=\langle k\rangle}^{\nArms}
	(\propTime_{i}-\propTime_{i+1})
	i
}{\propTime^2_{\langle k\rangle}\gap^2_{k}}
&	=
\frac{
	\sum_{i=\langle k\rangle}^{\nArms}
	\left(\frac{1}{\sqrt{i}}-\frac{1}{\sqrt{i+1}}\right)
	i
}{\propTime^2_{\langle k\rangle}\gap^2_{k}}\\
&\leq
\frac{
	2	\sum_{i=1}^{\nArms}
	\frac{\sqrt{i}}{\sqrt{i+1}}	\left(\sqrt{i+1}-\sqrt{i}\right)
}{\gap^2_{(1)}}\\
&	\leq
\frac{2
	\sum_{i=1}^{\nArms}
	(\sqrt{i+1}-\sqrt{i})	
}{\gap^2_{(1)}}\\
&\leq
\frac{
	2	\sqrt{\nArms+1}	
}{\gap^2_{(1)}}\\
&		=
\frac{
	2	\sqrt{\nArms+1}	
}{\gap^2_{(1)}}\\
&=
\complexitySR		\sqrt{\nArms+1}	
\leq
2\complexityBoth.
\end{align*}
%\todomi{gramarly it all in the end}
