% \documentclass[anon,12pt]{colt2018} % Anonymized submission
\documentclass[final]{colt2018} % Include author names

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{transparent}

% \usepackage{amsmath}
%\usepackage{amsthm}
% \usepackage{amssymb}
\usepackage{mathtools}
%\usepackage[usenames]{xcolor}

%\usepackage[ruled,linesnumbered]{algorithm2e}

\usepackage{enumitem}
\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}

\definecolor{darkblue}{rgb}{0.0,0.0,0.55}
\hypersetup{
	colorlinks = true,
	citecolor  = darkblue,
	linkcolor  = darkblue,
	citecolor  = darkblue,
	filecolor  = darkblue,
	urlcolor   = darkblue,
}


\usepackage{enumitem}
\usepackage{xspace}

\usepackage{wrapfig}

%\newtheorem{lemma}{Lemma}
%\newtheorem{theorem}{Theorem}
%\newtheorem{corollary}{Corollary}
%\newtheorem{proposition}{Proposition}
%\newtheorem{remark}{Remark}
%\newtheorem{definition}{Definition}
\newtheorem{claim}{Claim}
\newtheorem{assumption}{Assumption}

\newcommand{\Exp}{\mathrm{Exp}}
\newcommand{\arccosh}{\mathrm{arccosh}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\ragd}{\textsc{Ragd}}
\newcommand{\inj}{\mathrm{inj}}
\renewcommand{\nabla}{\mathrm{grad}}

\title[An Estimate Sequence for Geodesically Convex Optimization]{An Estimate Sequence for Geodesically Convex Optimization}
\usepackage{times}
 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
  % \coltauthor{\Name{Author Name1} \Email{abc@sample.com}\and
  %  \Name{Author Name2} \Email{xyz@sample.com}\\
  %  \addr Address}

 % Three or more authors with the same address:
 % \coltauthor{\Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \addr Address}


 % Authors with different addresses:
 \coltauthor{\Name{Hongyi Zhang} \Email{hongyiz@mit.edu}\\
 \addr BCS and LIDS, Massachusetts Institute of Technology
 \AND
 \Name{Suvrit Sra} \Email{suvrit@mit.edu}\\
 \addr EECS and LIDS, Massachusetts Institute of Technology
 }

\begin{document}

\maketitle

\begin{abstract}
We propose a Riemannian version of Nesterov's Accelerated Gradient algorithm (\ragd), and show that for \emph{geodesically} smooth and strongly convex problems, within a neighborhood of the minimizer whose radius depends on the condition number as well as the sectional curvature of the manifold, \ragd{} converges to the minimizer with acceleration. Unlike the algorithm in \citep{liu2017accelerated} that requires the exact solution to a nonlinear equation which in turn may be intractable, our algorithm is constructive and computationally tractable\footnote{ as long as Riemannian gradient, exponential map and its inverse are computationally tractable, which is the case for many matrix manifolds \citep{absil2009optimization}.}. Our proof exploits a new estimate sequence and a novel bound on the nonlinear metric distortion, both ideas may be of independent interest.
\end{abstract}

\begin{keywords}
	Riemannian optimization; geodesically convex optimization; Nesterov's accelerated gradient method; nonlinear optimization
\end{keywords}

\input{intro}
\input{background}
\input{algo}
\input{analysis}
\input{discussion}

\acks{The authors thank the anonymous reviewers for helpful feedback. This work was supported in part by NSF-IIS-1409802 and the DARPA Lagrange grant.}

\bibliographystyle{abbrvnat}

{\small
	\bibliography{main_agd17}
}

\newpage
\input{appendix}

\end{document}
