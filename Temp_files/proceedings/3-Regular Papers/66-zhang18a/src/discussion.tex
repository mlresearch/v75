\section{Discussion}
In this work, we proposed a Riemannian generalization of the accelerated gradient algorithm and developed its convergence and complexity analysis. For the first time (to the best of our knowledge), we show gradient based algorithms on Riemannian manifolds can be accelerated, at least in a neighborhood of the minimizer. Central to our analysis are the two main technical contributions of our work: a new estimate sequence (Lemma \ref{thm:estimate-sequence-lemma}), which relaxes the assumption of Nesterov's original construction and handles metric distortion on Riemannian manifolds; a tangent space distance comparison theorem (Theorem \ref{thm:squared-distance-ratio-bound}), which provides sufficient conditions for bounding the metric distortion and could be of interest for a broader range of problems on Riemannian manifolds.

Despite not matching the standard convex results, our result exposes the key difficulty of analyzing Nesterov-style algorithms on Riemannian manifolds, an aspect missing in previous work. Critically, the convergence analysis relies on bounding a new distortion term per each step. Furthermore, we observe that the side length sequence $d(y_k, v_{k+1})$ can grow much greater than $d(y_k, x^*)$, even if we reduce the ``step size'' $h_k$ in Algorithm 1, defeating any attempt to control the distortion globally by modifying the algorithm parameters. This is a benign feature in vector space analysis, since (\ref{eq:base-change-assumption}) trivially holds nonetheless; however it poses a great difficulty for analysis in nonlinear space. Note the stark contrast to (stochastic) gradient descent, where the step length can be effectively controlled by reducing the step size, hence bounding the distortion terms globally \citep{zhang2016first}.

%A surprising observation we make is that step size only controls the speed of growth of $b_{k+1}$, a key quantity we would like to bound, but not its limit (see Lemma \ref{thm:b-bound} and the discussion afterwards). Consequentially our result has a small radius of convergence. We hypothesize that this fact is fundamentally connected to the update rule of $v_{k+1}$ we use in Line \ref{eq:v-k+1} of Algorithm \ref{alg:riemannian-ag}. One could of course try to add damping terms in Line \ref{eq:v-k+1}. However, as the expression in Line \ref{eq:v-k+1} is a direct result of Lemma \ref{thm:complete-square}, any such modification may inevitably require a completely new kind of estimate sequence. Developing and analyzing algorithms with greater convergence radius, most likely via better control of $b_{k+1}$, is an important topic for future research.

A topic of future interest is to study whether assumption (\ref{eq:base-change-assumption}) can be further relaxed, while maintaining that overall the algorithm still converges. By bounding the squared distance distortion in every step, our analysis provides guarantee for the worst-case scenario, which seems unlikely to happen in practice. It would be interesting to conduct experiments to see how often (\ref{eq:base-change-assumption}) is violated versus how often it is loose. It would also be interesting to construct some adversarial problem case (if any) and study the complexity lower bound of gradient based Riemannian optimization, to see if geodesically convex optimization is strictly more difficult than convex optimization. Generalizing the current analysis to non-strongly g-convex functions is another interesting direction.
