\section{Introduction}
%The increasing access to data in virtually every realm has spawned  great interests in analysis and prediction.  , one can reasonably argue that nonlinear optimization algorithms
%Nonlinear optimization is the algorithmic backbone of machine learning where it is instrumental to estimation, classification, regression, reinforcement learning, deep learning, and other key applications. In parallel to its ubiquity in practice, nonlinear optimization has also witnessed great theoretical advances in the past few decades. The most fruitful area for such advances has been convex optimization in vector spaces. Indeed, starting with the seminal ellipsoid algorithm~\citep{khachiyan1980polynomial} a broader complexity theory of convex optimization emerged~\citep{nemirovsky1983problem}. Shortly thereafter, interior point methods~\citep{karmarkar1984new} were discovered, which spurred tremendous growth, culminating in the work~\citep{nesterov1994interior}. 

Convex optimization theory has been a fruitful area of research for decades, with classic work such as the ellipsoid algorithm \citep{khachiyan1980polynomial} and the interior point methods \citep{karmarkar1984new}. However, with the rise of machine learning and data science, growing problem sizes have shifted the community's focus to first-order methods such as gradient descent and stochastic gradient descent.  Over the years, impressive theoretical progress has also been made here, helping elucidate problem characteristics and bringing
insights that drive the discovery of provably faster algorithms, notably Nesterov's accelerated gradient descent~ \citep{nesterov1983method} and variance reduced incremental gradient methods \citep[e.g.,][]{johnson2013accelerating,schmidt2013minimizing,defazio2014saga}.

Outside convex optimization, however, despite some recent progress on nonconvex optimization our theoretical understanding remains limited. Nonetheless, nonconvexity pervades machine learning applications and  motivates identification and study of specialized structure that enables sharper theoretical analysis, e.g., optimality bounds, global complexity, or faster algorithms. Some examples include, problems with low-rank structure~\citep{boumal2016non,ge2017no,sun2017complete,kawaguchi2016deep}; local convergence rates~\citep{ghadimi2013stochastic,Reddi16,Agarwal16,Yair16}; growth conditions that enable fast convergence~\citep{Polyak1963,zhang2016riemannian,attouch2013convergence,shamir2015stochastic}; and nonlinear constraints based on Riemannian manifolds~\citep{boumal2016global,zhang2016first,zhang2016riemannian,mishra2016}, or more general metric spaces~\citep{ambrosio2014metric,bacak2014convex}.

%In practice, nonconvex problems abound in machine learning and data science applications. (Structure assumptions. Introduce Riemannian optimization problems and algorithms.)
%{\color{blue} Landmark result in convex optimization; first-order methods; global iteration complexity}

In this paper, we focus on nonconvexity from a Riemannian viewpoint and consider gradient based optimization. In particular, we are motivated by Nesterov's accelerated gradient method~\citep{nesterov1983method}, a landmark result in the theory of first-order optimization. By introducing an ingenious ``estimate sequence'' technique, \citet{nesterov1983method} devised a first-order algorithm that provably outperforms gradient descent, and is \emph{optimal} (in a first-order oracle model) up to constant factors. This result bridges the gap between the lower and upper complexity bounds in smooth first-order convex optimization~\citep{nemirovsky1983problem, nesterov2004introductory}. 

Following this seminal work, other researchers also developed different analyses to explain the phenomenon of  acceleration. However, both the original proof of Nesterov and all other existing analyses rely heavily on the linear structure of vector spaces. Therefore, our central question is: 
\begin{center}
  \emph{Is linear space structure necessary to achieve acceleration?}
\end{center}
Given that the iteration complexity theory of gradient descent generalizes to Riemannian manifolds~\citep{zhang2016first}, it is tempting to hypothesize that a Riemannian generalization of accelerated gradient methods also works. However, the nonlinear nature of Riemannian geometry poses significant obstructions to either verify or refute such a hypothesis. The aim of this paper is to study existence of accelerated gradient methods on Riemannian manifolds, while identifying and tackling key obstructions and obtaining new tools for global analysis of optimization on Riemannian manifolds as a byproduct.

It is important to note that in a recent work \citep{liu2017accelerated}, the authors claimed to have developed Nesterov-style methods on Riemannian manifolds and analyzed their convergence rates. Unfortunately, this is \emph{not} the case, since their algorithm requires the \emph{exact} solution to a nonlinear equation \cite[(4) and (5)]{liu2017accelerated} on the manifold at every iteration. In fact, solving this nonlinear equation itself can be as difficult as solving the original optimization problem.
%Introduce Riemannian optimization theory.

\subsection{Related work}
The first accelerated gradient method in vector space along with the concept of estimate sequence is proposed by \citet{nesterov1983method}; \citep[Chapter 2.2.1]{nesterov2004introductory} contains an expository introduction. In recent years, there has been a surging interest to either develop new analysis for Nesterov's algorithm or invent new accelerated gradient methods. In particular, \citet{su2014differential,flammarion2015averaging,wibisono2016variational} take a dynamical system viewpoint, modeling the continuous time limit of Nesterov's algorithm as a second-order ordinary differential equation. \citet{allen2014linear} reinterpret Nesterov's algorithm as the linear coupling of a gradient step and a mirror descent step, which also leads to accelerated gradient methods for smoothness defined with non-Euclidean norms. \citet{arjevani2015lower} reinvent Nesterov's algorithm by considering optimal methods for optimizing polynomials. \citet{bubeck2015geometric} develop an alternative accelerated method with a geometric explanation. \citet{lessard2016analysis} use theory from robust control to derive convergence rates for Nesterov's algorithm.

% A collection of accelerated gradient method papers, including \citet{allen2014linear, bubeck2015geometric, flammarion2015averaging, su2014differential, lessard2016analysis, wibisono2016variational, kim2016optimized, arjevani2015lower, ghadimi2016accelerated}.

The design and analysis of Riemannian optimization algorithms as well as some historical perspectives were covered in details in \citep{absil2009optimization}, although the analysis only focused on local convergence. The first global convergence result was derived in \citep{udriste1994convex} under the assumption that the Riemannian Hessian is positive definite. \citet{zhang2016first} established the globally convergence rate of Riemannian gradient descent algorithm for optimizing geodesically convex functions on Riemannian manifolds. Other nonlocal analyses of Riemannian optimization algorithms include stochastic gradient algorithm \citep{zhang2016first}, fast incremental algorithm \citep{zhang2016riemannian, kasai2016riemannian}, proximal point algorithm \citep{ferreira2002proximal} and trust-region algorithm \citep{boumal2016global}. \citet[Chapter 2]{absil2009optimization} also surveyed some important applications of Riemannian optimization.

%{EDIT: \color{blue} Most notably, it generalizes to \emph{geodesically convex} metric spaces~\citep{gromov1978manifolds,bridson1999metric,burago2001course}, through which it offers a much richer setting for developing mathematical models amenable to global optimization. Although Riemannian geometry provides tools that enable generalization of Euclidean algorithms~\citep{udriste1994convex,absil2009optimization}, to obtain iteration complexity bounds we must overcome some fundamental geometric hurdles. We introduce key results that overcome some of these hurdles, and pave the way to analyzing first-order g-convex optimization algorithms.}


%Standard references on Riemannian optimization are \citep{udriste1994convex,absil2009optimization}, but these primarily consider   problems on manifolds without necessarily assuming g-convexity. Consequently, their analysis is limited to asymptotic convergence (except for ~\cite[Theorem 4.2,][]{udriste1994convex} that proves linear convergence for  functions with positive-definite and bounded Riemannian Hessians). The recent monograph \citep{bacak2014convex} is devoted to g-convexity and g-convex optimization on geodesic metric spaces, though without any attention to global complexity analysis. \citet{bacak2014convex} also details a noteworthy application: averaging trees in the geodesic metric space of phylogenetic trees~\citep{billera2001geometry}.

%A collection of Riemannian optimization analysis, including \citet{absil2009optimization,zhang2016first,zhang2016riemannian,kasai2016riemannian,boumal2016global}


\subsection{Summary of results}
In this paper, we make the following contributions:
\begin{enumerate}
	\item We propose the first \emph{computationally tractable} accelerated gradient algorithm that, within a radius from the minimizer that depends on the condition number and sectional curvature bounds, is provably faster than gradient descent methods on Riemannian manifolds with bounded sectional curvatures. (Algorithm \ref{alg:constant-step}, Theorem \ref{thm:convergence-induction})
	\item We analyze the convergence of this algorithm using a new estimate sequence, which relaxes Nesterov's original assumption and also generalizes to Riemannian optimization. (Lemma \ref{thm:estimate-sequence-lemma})
	\item We develop a novel bound related to the bi-Lipschitz property of exponential maps on Riemannian manifolds. This fundamental geometric result is essential for our convergence analysis, but should also have other interesting applications. (Theorem \ref{thm:squared-distance-ratio-bound}) 
\end{enumerate}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "nips_2017"
%%% End:
