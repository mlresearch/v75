Testing goodness-of-fit for distributions has a long history in Statistics; for some old and more recent references see, e.g.,~\cite{Pearson00,Fisher35,RaoS81,Agresti11}. 
In this literature the emphasis has been on the asymptotic analysis of tests, pinning down their error exponents as the number of samples tends to infinity~\cite{Agresti11,TanAW10}. In 
the last two decades or so, distribution testing has also piqued the interest of theoretical computer scientists~\cite{BatuFFKRW01,Paninski08,LeviRR13,ValiantV14,ChanDVV14, AcharyaDK15,CanonneDGR15,DiakonikolasK16,DaskalakisDSVV13,CanonneRS14,Rubinfeld12,Goldreich11,Canonne15}, where the emphasis, in contrast, has been on minimizing the number of samples required to test hypotheses with a strong control for both type I and type II errors. A few recent works have identified tight upper and lower bounds on the sample complexities of various testing problems~\cite{Paninski08,ValiantV14,AcharyaDK15,DiakonikolasK16}. All of the papers in this vast body of literature assume access to i.i.d. samples from the underlying distribution. 

%Classically testing goodness-of-fit of distributions has a long history in statistics, since the early days; for some old and some more recent references see, e.g.,~\cite{Pearson00,Fisher35,RaoS81,Agresti11}. Traditionally, the emphasis has been on the asymptotic analysis of tests, pinning down their error exponents as the number of samples tends to infinity~\cite{Agresti11,TanAW10}. In the last two decades or so, distribution testing  has also piqued the interest of  theoretical computer scientists, where the emphasis has been different~\cite{BatuFFKRW01,Paninski08,LeviRR13,ValiantV14,ChanDVV14, AcharyaDK15,CanonneDGR15,DiakonikolasK16,DaskalakisDSVV13,CanonneRS14}. In contrast to much of the statistics literature, the goal has been to minimize the number of samples required for testing.
%This recent work has identified tight upper and lower bounds on the sample complexity of various testing problems~\cite{Paninski08,ValiantV14,AcharyaDK15,DiakonikolasK16,Paninski08}. However, all of this vast body of literature assumes access to independent and identically distributed samples from the underlying distribution. 

Some work in Statistics has considered the problem of testing with dependent samples. For instance, \cite{Bartlett51, Moore82, GleserM83, MolinaMPV02} and the references therein study goodness-of-fit testing under Markov dependences. These works study how the classical tests used to perform goodness-of-fit testing with independent samples, perform when there are Markovian dependencies among the samples. \cite{TavareA83} and more recently \cite{BarsottiPR16} study the problem of testing the stationary distribution of Markov chains. \cite{Kazakos78} studies the problem of asymptotically perfect detection (APD) between two Markov chains. All these works focus on the asymptotic regime where the length of the observed trajectories tends to infinity, and study the conditions under which hypothesis testing can be performed successfully or focus on pinning down the error exponents. In the computer science literature, \cite{BatuFRSW13} considered the problem of testing whether a Markov chain is fast mixing or not. They defined a notion of closeness between two random walks starting at different states of the \emph{same} chain, which is different in spirit to the distance notion we define in this work. In particular, their distance is based on the $L_1$ norm of the state distributions attained by starting at two different states $u$ and $v$ and running the chain for $t$ steps. This ignores any differences in trajectory seen along the way and it is apt for their setting as they focus on mixing time which is a trajectory independent property of the chain. Moreover, they assume the chain can be restarted any number of times making it fundamentally different from our setting.

%There has been some work in the statistics community which looked at testing from dependent samples. For instance, \cite{Bartlett51, Moore82, GleserM83, MolinaMPV02} and the references therein study goodness-of-fit testing for Markov chains; \cite{TavareA83} and more recently \cite{BarsottiPR16} study the problem of testing the stationary distribution of Markov chains. \cite{Kazakos78} studies the problem of detection of one of two Markov chains.  All these works focus on the asymptotic regime where the number of samples tends to infinity as opposed to the finite sample regime which is of interest to us here. Within the computer science community \cite{BatuFRSW13} have looked at the problem of testing whether a Markov chain is fast mixing. They define a notion of closeness between two random walks on a Markov chain which is ideologically similar to the distance notion we define in this work.


There is a large body of statistical literature on estimating properties and parameters of Markov chains. Mixing time is one such important and well studied parameter
(see, e.g.,~\cite{HsuKS15} and the references therein), as it is useful in designing MCMC algorithms. The question of mixing time estimation is related to but different than the goodness-of-fit 
kernel testing that we perform here. 

Our notion of distance is derived from Lemma~\ref{lemma:kazakos lemma} but the work of \cite{Kazakos78} or more recent works of \cite{DaskalakisP17} or \cite{DiakonikolasKS16} don't consider the spectral behavior as we do in this work.