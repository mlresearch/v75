%Given our formal notion of distance between symmetric Markov Chains (\ref{}), we get a well defined framework (e.g. \cite{BatuFFKRW01,Paninski08,LeviRR13}) for testing properties of distributions generated by Markov Chains.
After understanding the problem of distinguishing between two given distributions, a next fundamental question is the identity testing problem where the goal is to test whether an unknown distribution $p$ from which we see a stream of samples, coincides with a given hypothesis distribution $q$. 
In this section, we study identity testing of symmetric Markov chains and provide an efficient algorithm (Theorem~\ref{th:symmetric_ub}).  
%and information theoretic lower bounds (Theorem~\ref{thm:symm-lower-bound}). 
%\nishanth{More intro needed?}
%\corrected{In this section, we present our algorithm for testing identity of symmetric Markov chains. The precise problem definition is stated below:}
We begin by giving below a formal statement of the problem:\\
%\begin{description}
%\item[Input:] $\eps$; symmetric transition matrix $Q$; stream of $m$ consecutive samples from symmetric Markov Chain $P$.
%\item[Output:] $P=Q$, or $P\neq Q$ if $1-\specr{\srprod{P}{Q}}>\eps$. 
%\end{description}
%\noindent \textbf{Identity Testing of Markov Chains:}


\begin{algorithm}[H]
%\caption{Identity Testing for Symmetric Markov Chains}
	\label{def:mc-id-testing}
\KwIn{$\eps > 0$; explicit description of a symmetric Markov chain $Q$; a trajectory $s_1\cdots s_m$ of length $m$ from a symmetric Markov Chain $P$.}
\KwOut{$P=Q$, or $P\neq Q$ if $1-\specr{\srprod{P}{Q}}>\eps$.}
\end{algorithm}



\paragraph{Our approach.}
Identity testing problem with i.i.d. samples, is a well studied problem in the
distribution testing literature. The problem is quite non trivial\footnote{It is studied by a number of works. For instance, see~\cite{BatuFFKRW01,Paninski08,ValiantV14,AcharyaDK15,DiakonikolasK16} (This is not an exhaustive list).} 
and to achieve tight sample complexity one needs to do careful estimations of collisions in observed samples.
Markov chain identity testing appears to be at least as hard as the i.i.d. identity testing problem with the added complication of dependent samples.
To avoid involved analysis of collisions among dependent samples we will instead try to find a black-box reduction of the MC testing problem to identity testing with i.i.d. samples.
%Our idea is to exploit insights about symmetric Markov chains which will allow us to reduce to the classical problem of identity testing with i.i.d. samples.
A naive attempt at such a reduction proceeds by waiting for a period of mixing time $\mixt{Q}$ of the known Markov Chain $Q$ to get one (potential) i.i.d. sample from the 
stationary distribution of $P$ (in case $P$ has mixed). If the empirical distribution for the number of visits is far from the uniform distribution, we can 
immediately reject $P$ (since if $P=Q$, then $P$ is a symmetric chain and will have the uniform distribution as the stationary) and if it is not, then we would have attained multiple transitions from a sizeable set of nodes and one could hope they contain sufficient signal to distinguish $P$ from $Q$. 
It is non-trivial to extract this signal as the mere fact that we have seen multiple samples from a single node within a short length of the trajectory introduces dependencies in our samples. That is, two samples from the same node are not independent samples from the transition distribution of that node, if it took only a little time to return to this node. Moreover, this attempt, if it works, will incur a \emph{multiplicative loss} of $\mixt{Q}$ in the sample complexity.\\
%

\noindent We take a more subtle and involved approach to achieve a successful reduction to the classical setting with i.i.d. samples. Moreover, our reduction yields an algorithm that suffers only an {\em additive loss} of $\wO{\hitt{Q}\cdot\log\left(\hitt{Q}\right)}$ in sample complexity. We reduce the Markov chain problem to the classical identity testing problem with respect to squared Hellinger distance of distributions supported on a domain of size $n^2$. Our result is always as good as the naive approach. Indeed, for symmetric chains, the hitting time cannot be larger than mixing time by more than a $c.n$ factor (where $c$ is a constant), but usually it is much smaller (in fact hitting time can be even smaller than mixing time).  
We note that many broad classes of graphs and Markov chains have close to linear hitting times, e.g., expanders, $d$-dimensional grids (which are not expanders). Below we describe how we map samples from a Markov chain to i.i.d. samples from the appropriate distribution.\\
%\nishanth{Many commonly studied Markov chains have poly(n) hitting times and hence our tester is efficient.} Below we describe at a high-level our approach.\\

\noindent \textbf{A Mapping From Infinite Words.} Consider a mapping $\infmap{\vect{k}}$ from words of infinite length $w \in W_M^{\infty}$ of an irreducible Markov chain $M$ on the state space $[n]$ to $\prod_{i=1}^{n}
[n]^{k_i}$, where $\vect{k}=(k_1,\cdots,k_n)$ is a vector of $n$ non negative integers, as follows. For each infinite word $w=s_1s_2\cdots$ and each state 
$i\in[n]$ we look at the first $k_i$ visits to state $i$ (i.e., at times $t=t_1,\dots,t_{k_i}$ with $s_{t}=i$) and write down the corresponding 
transitions in $w$, i.e., $s_{t+1}$. We note that every state is visited almost surely in $w$, since $M$ is an irreducible finite-state Markov chain. 
Therefore, mapping $\infmap{\vect{k}}$ defines a probability distribution on $\prod_{i=1}^{n}[n]^{k_i}$. Now, crucially, this distribution is independent across all different states and/or independent for a particular state $i$ because of the Markov property of Markov chains. Furthermore, a specific transition from a copy of the state $i$ is distributed according to the $i$-th row of the transition matrix $M$.

In Lemma~\ref{lem:large_deviation_bound}, we show that even for a finite length trajectory with length $ m=\widetilde{O}\left(\hitt{Q}\log\left(\hitt{Q}\right)\right. \allowbreak +\left. \frac{n}{\eps}\right)$ \footnote{in this paper, $\widetilde{O}$ always hides poly $\log(n/\eps)$ factors, but not $\hitt{Q}$.} and 
$k_i=O(\Ex{\text{\# visits to } i})=O(\frac{m}{n})$ the mapping $\infmap{\vect{k}}$ is well defined for all 
but a small fraction (in probability) of the words from the distribution $\word{M}{m}$. This effectively allows us, with high probability, to generate a large number of independent samples from the following distribution supported over $[n]\times[n]$: pick uniformly at random a state $i\in[n]$ and then observe a transition from $i$ according to transition probabilities of row $P_i$.
Indeed, to this end, we first simulate $m'=\Theta\left(\frac{m}{\log^2 (n/\eps)}\right)$ i.i.d. samples from $[n]$. These samples describe how many visits an independent sampler would make to state $i \in [n]$. Let 
$\vect{k}$ be the histogram of these $m'$ samples (note that $\max_{i} k_i \le O(m'\log n /n)$ with high probability). 
We apply $\infmap{\vect{k}}$ mapping to our stream of $m$ consecutive samples of Markov chain $P$, which is well defined with high probability. 
Apart from some small probability events ($\max_{i} k_i$ is too large, or $\infmap{\vect{k}}$ is not defined for our choice of $m$) we obtain the desired $m'$ i.i.d. 
samples. 
%Large deviation bound
\begin{lemma}
	Given an irreducible Markov chain $M$ and the mapping from infinite words $\word{M}{\infty}$ described above, for $m=\wO{\log\left(\hitt{Q}\right)\hitt{Q}}$, then 
	$\Prx{\exists~\text{state}~i~\text{s.t.}~|\{t: i=s_t\in w\}|<\frac{m}{8e\cdot n}}\le\frac{\eps^2}{n}$ where the probability is over the sampling of $\vect{k}$ and word $w$. 
%If the number of steps $m=\wO{\log\left(\hitt{Q}\right)\hitt{Q}}$, then
%\[
%\Prx{\exists \text{ state }i: |\{t: i=s_t\in w\}|<\frac{m}{8e\cdot n}}\le\frac{\eps^2}{n}.
%\] 
\label{lem:large_deviation_bound}
\end{lemma}
The proof is deferred to Appendix~\ref{app:proofs_symm}.


In the following we present our algorithm for Markov Chain identity testing and provide an upper bound on its sampling complexity.

\begin{algorithm}[H]
\caption{Independent Edges Sampler.}
\label{alg:symmetric_MC}
\SetKwData{Histogram}{Histogram}\SetKwData{Samples}{Samples}\SetKwFunction{IdentityTest}{IdentityTestIID}
\SetKwFunction{Uniform}{Uniform}
%\KwIn{$\eps$; explicit symmetric Markov chain $Q$; $m$ consecutive samples $s_1\cdots s_m$ from a symmetric Markov Chain $P$.}
%\KwOut{$P=Q$, or $P\neq Q$ if $1-\specr{\srprod{P}{Q}}>\eps$.}
\BlankLine
$\vect{k}~\leftarrow$ \Histogram ($\Theta\left(\frac{m}{\log^2 (n/\eps)}\right)$ i.i.d. \Uniform[n] samples) \;
\For{$t\leftarrow 1$ \KwTo $m-1$}{
\lIf{$|\Samples[s_t]|<\vect{k}[s_t]$}{Add $(s_t\to s_{t+1})$ to $\Samples[s_t]$}
}
\eIf{$\exists i, \text{ s.t., } |\Samples[i]|<\vect{k}[i]$}{
\KwRet \textsc{Reject};
}
{
$\Samples\leftarrow\Samples[1]\cup\dots\cup\Samples[n]$\;
\KwRet \IdentityTest($\eps,$ $\{q_{ij}=\frac{1}{n}\cdot Q_{ij}\}_{i,j\in[n]}$, \Samples)\;
}
\end{algorithm}

Algorithm~\ref{alg:symmetric_MC} uses as a black-box the tester of Algorithm 1 of~\cite{DaskalakisKW17}. The following Lemma follows from Theorem 1 of~\cite{DaskalakisKW17}. %We state the sample complexity of this result here.
\begin{lemma}
\label{lem:hellinger_idtest}
Given a discrete distribution $q$ supported on $[n]$ and access to i.i.d. samples from a discrete distribution $p$ on the same support, there is a tester which can distinguish whether $p=q$ or $\hellinger{p}{q} \ge \eps$ with probability $\ge 2/3$ using $\Ocomplex{\frac{\sqrt{n}}{\eps^2}}$ samples.
\end{lemma}
As a corollary of Lemma~\ref{lem:hellinger_idtest}, we get a test that can distinguish whether $P=Q$, or $\hellingersq{\frac{1}{n}P}{\frac{1}{n}Q}\ge\eps$ using $m=\Ocomplex{\frac{n}{\eps}}$ i.i.d samples from $\frac{1}{n}P$, which can be viewed as a distribution on a support of size $n^2$. Lemma~\ref{lem:rho_l1_distances} shows that the required distance condition for the i.i.d. sampler is implied by our input guarantee. % (proof is deferred to Appendix~\ref{app:proofs_symm}).

\begin{lemma}
	Consider two symmetric Markov chains $P$ and $Q$ on a finite state space $[n]$. Denote by $\frac{1}{n}P$ the distribution over $n^2$ elements obtained by scaling down every entry of the transition matrix $P$ by a factor $1/n$. We have,
\begin{align}
\frac{1}{2}\sum\limits_{i,j\in[n]}\left(\sqrt{\frac{P_{ij}}{n}}-\sqrt{\frac{Q_{ij}}{n}}\right)^2=
\hellingersq{\frac{1}{n}P}{\frac{1}{n}Q}\ge\dist{P}{Q}\eqdef 1-\specr{\srprod{P}{Q}} .
\end{align}
\label{lem:rho_l1_distances}
\end{lemma}
The proof of Lemma~\ref{lem:rho_l1_distances} is given in Appendix~\ref{app:proofs_symm}.

Finally, the following Theorem~\ref{th:symmetric_ub} gives an upper bound on sampling complexity of Algorithm~\ref{alg:symmetric_MC}.
We note that $\wO{\hitt{Q}}$ samples are necessary for a reduction approach to work. Indeed, if we are to simulate
$n \log n$ i.i.d. samples ($v\to u$, where $v\sim \Uniform[n]$ and $u\sim P_v$), then we shall see all states
$v\in [n]$ at least once with high probability. I.e., the random walk must visit all the states, which would require at the very least 
$\hitt{Q}$ steps in the random walk. On the other hand, our bound of $\wO{\hitt{Q}\cdot\log\left(\hitt{Q}\right)+\frac{n}{\eps}}$ is always better than a naive
bound of $\mixt{Q}\cdot\frac{n}{\eps}$, since $\hitt{Q}< n\cdot\mixt{Q}$ and, in fact, for most of the reasonable MC $\hitt{Q}$ is much less than that.

%\begin{lemma}
%$\frac{1}{n}\onenorm{P-Q}\ge 2\eps.$
%\label{lem:rho_l1_distances}
%\end{lemma}
%\begin{proof}
%We note that, as $P$ and $Q$ are symmetric matrices, so is $\srprod{P}{Q}$. Thus we have
%\be
%\label{eq:sv_def}
%1-\eps = \specr{\srprod{P}{Q}} = \max_{\twonorm{\vev}=1} \vev\circ\srprod{P}{Q}\circ\vevt.
%\ee
%If we use a particular $\vev=\frac{1}{\sqrt{n}}\onev$ in \eqref{eq:sv_def}, then we get the following inequality.
%\begin{align*}
%1-\eps \ge & \frac{1}{\sqrt{n}}\onev\circ\srprod{P}{Q}\circ\frac{1}{\sqrt{n}}\onevt = \frac{1}{n}\sum\limits_{i,j} \sqrt{P_{ij}\cdot Q_{ij}}\\
       %=  &\frac{1}{2n}\sum\limits_{i,j}\left(P_{ij}+Q_{ij}\right)-\frac{1}{2n}\sum\limits_{i,j}\left(P_{ij}+Q_{ij}-2\sqrt{P_{ij}\cdot Q_{ij}}\right)\\
        %= & 1 - \frac{1}{2n}\sum\limits_{i,j}\left(\sqrt{P_{ij}}-\sqrt{Q_{ij}}\right)^2 \ge 
        %1 - \frac{1}{2n}\sum\limits_{i,j}\left|\sqrt{P_{ij}}-\sqrt{Q_{ij}}\right|\cdot\left|\sqrt{P_{ij}}+\sqrt{Q_{ij}}\right|\\
        %= & 1 - \frac{1}{2n}\sum\limits_{i,j}\left|P_{ij}-Q_{ij}\right|=1 - \frac{1}{2n}\onenorm{P-Q}.
%\end{align*}
%Therefore, we conclude that $\frac{1}{n}\onenorm{P-Q}\ge 2\eps.$
%\end{proof}

\begin{theorem}
Given the description of a symmetric Markov chain $Q$ and access to a single trajectory of length $m$ from another symmetric Markov chain $P$,
Algorithm~\ref{alg:symmetric_MC} distinguishes between the cases $P = Q$ versus $1-\specr{\srprod{P}{Q}}>\eps$ with probability at least $2/3$, for  $m=\wO{\hitt{Q}\cdot\log\left(\hitt{Q}\right)+\frac{n}{\eps}}$. 
\label{th:symmetric_ub}
\end{theorem}
\begin{proof}
	In the case $P=Q$, the probability that Algorithm~\ref{alg:symmetric_MC} proceeds to IID tester, i.e., it
	does not reject $P$, because of small number of visits to a state, is at least
	$\Prx{\forall i\in[n]~|\{t: i=s_t\in w\}|>\frac{m}{8e\cdot n}}\cdot\Prx{\forall i: \frac{m}{8e\cdot n}>k_i} \ge 
	\left(1-\frac{\eps^2}{n}\right)\cdot\left(1-\frac{\eps^2}{n}\right)\ge 1-\frac{2\eps^2}{n}$. In the previous estimate, we used Lemma~\ref{lem:large_deviation_bound} 
	to bound $\Prx{\forall i\in[n]~|\{t: s_t\in w, s_t=i\}|>\frac{m}{8e\cdot n}}$, the fact that $\Prx{\frac{m}{8e\cdot n} \le k_i} \le \frac{\eps^2}{n^2}$ (follows from a Chernoff bound), and a union bound.  IID tester then correctly accepts $P=Q$ with probability at least $4/5$.
	Hence, the error probability is at most $1/5+\frac{2\eps^2}{n}<1/3$.
	
	For the case $P\neq Q$, Lemma~\ref{lem:rho_l1_distances} says that if $1-\specr{\srprod{P}{Q}}>\eps$, then distributions passed down to the IID tester 
	$\{p: p_{ij}=\frac{1}{n}P_{ij}\}$ and $\{q: q_{ij}=\frac{1}{n}Q_{ij}\}$ are at least $\eps$ far in Hellinger-squared distance. A black-box application of Lemma \ref{lem:hellinger_idtest} implies a  $\Ocomplex{\frac{n}{\eps}}$ sampling complexity for the IID tester in our case.
	Furthermore,
	random mapping $\infmap{\vect{k}}:\word{P}{\infty}\to p$ (where $\vect{k}$ is a histogram of $m'=\Theta\left(\frac{m}{\log^2 (n/\eps)}\right)$ i.i.d. uniform samples from $[n]$) produces
	$m'$ i.i.d. samples from $p$. Hence, if Algorithm~\ref{alg:symmetric_MC} has sufficient samples from $P$ to define the mapping $\infmap{\vect{k}}$, it would be able to distinguish $p$ and $q$ with probability
	at least $2/3$. On the other hand, if Algorithm~\ref{alg:symmetric_MC} gets finite number of samples which are not sufficient to define the mapping $\infmap{\vect{k}}$, then 
	it correctly rejects $P$ before even running the IID tester.
	
	Thus in both cases the probability of error is at most $1/3$.
\end{proof}


%Our approach:
%\begin{enumerate}
%\item We define a mapping $\infmap{\vect{k}}$ from infinite words $\word{M}{\infty}$ of an irreducible Markov chain $M$ to $\prod_{i=1}^{n}
%[n]^{k_i}$, where $\vect{k}=(k_1,\cdots,k_n)$ is a vector of $n$ positive integers, as follows. For each infinite word $w=s_1s_2\cdots$ and each state 
%$i\in[n]$ we look at the first $k_i$ visits to state $i$ (i.e., at times $t=t_1,\dots,t_{k_i}$ with $s_{t}=i$) and write down the corresponding 
%transitions in the infinite word $w$, i.e., $s_{t+1}$. We note that every state is visited almost surely in $w$, since $M$ is an irreducible Markov chain. 
%Therefore, mapping $\infmap{\vect{k}}$ defines a probability distribution on $\prod_{i=1}^{n}[n]^{k_i}$. We note that by construction the realized values 
%in $\prod_{i=1}^{n}[n]^{k_i}$ of each fixed state $i$ and across all different 
%states are independent.
%\item We show that for large enough $m=\wO{\covert{M}+n\cdot f(\eps)}$ and 
%$k_i=\frac{\Ex{\text{\# visits to } i}}{\log^2 n}=\frac{m}{n\log^2 n}$ the mapping
%$\infmap{\vect{k}}$ is well defined for a finite $m$ number of samples for all but a small fraction of the words in $\word{M}{\infty}$. (Here we use 
%the fact that $M$ is symmetric irreducible MC, implying that $\onev$ is the stationary distribution.)
%\item We are going to use as a black-box \cite{AcharyaDK15} for identity $L_1$-testing with i.i.d. samples from a distribution with a support of size $n^2$. We want to simulate a number of i.i.d samples where we first pick uniformly at random a state $i\in[n]$ and then observe  
%transition from $i$ according to transition probabilities of $P$. We first simulate $m'$ (to be determined later) i.i.d. samples from $[n]$. Let 
%$\vect{k}$ be the histogram of these $m'$ samples (note that $\max_{i} k_i \le O(m'\log n /n)$ with high probability). 
%We apply $\infmap{\vect{k}}$ mapping to our stream of $m$ consecutive samples of Markov chain $P$, which is well defined with high probability. 
%Apart from a small fraction of events (when $\max_{i} k_i$ is too large, or $\infmap{\vect{k}}$ is not defined) we obtain the desired $m'$ i.i.d. 
%samples. 
%
%Now \cite{AcharyaDK15} says that we can test using $m=\Ocomplex{\frac{n}{\eps^2}}$ samples whether $P=Q$, or tell that $P\neq Q$, if $\frac{1}{n}\onenorm{P-Q}\ge\eps$. We use our $m'=\wO{\frac{n}{\eps^2}}$ samples to detect whether $\frac{1}{n}\onenorm{P-Q}\ge\eps$. It remains to show that the latter guarantee is implied by our notion of distance.
%
%We note that, as $P$ and $Q$ are symmetric matrices, so is $\srprod{P}{Q}$. Thus we have
%\be
%\label{eq:sv_def}
%1-\eps = \specr{\srprod{P}{Q}} = \max_{\twonorm{\vev}=1} \vev\circ\srprod{P}{Q}\circ\vevt.
%\ee
%
%If we use a particular $\vev=\frac{1}{\sqrt{n}}\onev$ in \eqref{eq:sv_def}, then we get the following inequality.
%\begin{align*}
%1-\eps \ge & \frac{1}{\sqrt{n}}\onev\circ\srprod{P}{Q}\circ\frac{1}{\sqrt{n}}\onevt = \frac{1}{n}\sum\limits_{i,j} \sqrt{P_{ij}\cdot Q_{ij}}\\
       %=  &\frac{1}{2n}\sum\limits_{i,j}\left(P_{ij}+Q_{ij}\right)-\frac{1}{2n}\sum\limits_{i,j}\left(P_{ij}+Q_{ij}-2\sqrt{P_{ij}\cdot Q_{ij}}\right)\\
        %= & 1 - \frac{1}{2n}\sum\limits_{i,j}\left(\sqrt{P_{ij}}-\sqrt{Q_{ij}}\right)^2 \ge 
        %1 - \frac{1}{2n}\sum\limits_{i,j}\left|\sqrt{P_{ij}}-\sqrt{Q_{ij}}\right|\cdot\left|\sqrt{P_{ij}}+\sqrt{Q_{ij}}\right|\\
        %= & 1 - \frac{1}{2n}\sum\limits_{i,j}\left|P_{ij}-Q_{ij}\right|=1 - \frac{1}{2n}\onenorm{P-Q}.
%\end{align*}
%
%Therefore, we conclude that $\frac{1}{n}\onenorm{P-Q}\ge 2\eps.$
%
%\end{enumerate}