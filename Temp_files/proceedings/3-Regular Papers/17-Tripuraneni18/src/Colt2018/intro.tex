%!TEX root = main.tex
\vspace{-0.21pt}
\section{Introduction}
\vspace{-0.22pt}
We consider stochastic optimization of a (potentially non-convex) function $f$  defined on a Riemannian manifold $\M$, and accessible only through unbiased estimates of its gradients.
The framework is broad---encompassing fundamental problems such as principal components analysis (PCA) \citep{edelman1998geometry}, dictionary learning \citep{SunQinWri17}, low-rank matrix completion \citep{BouAbs11} and tensor factorization \citep{IshAbsVanDeL11}.

The classical setting of stochastic approximation in $\mathbb{R}^d$, first appearing in the work of
\citet{robbins1951stochastic}, has been thoroughly explored in both the optimization and machine learning communities. A key step in the development of this theory was the discovery of Polyak-Ruppert averaging---a technique in which the iterates are averaged along the optimization path. Such averaging provably reduces the impact of noise on the problem solution and improves convergence rates in certain important settings~\citep{Pol90, ruppert1988efficient}.

By contrast, the general setting of stochastic approximation  on Riemannian manifolds has been far less studied. There are many open questions regarding achievable rates and the possibility of accelerating these rates with techniques such as averaging.  The problems are twofold: it is not always clear how to extend a gradient-based algorithm to a setting which is missing the global vector-space structure of Euclidean space, and, equally importantly, classical analysis techniques often rely on the Euclidean structure and do not always carry over. In particular, Polyak-Ruppert averaging  relies critically on the Euclidean structure of the configuration space, both in its design and its analysis.  We therefore ask: \emph{Can the classical technique of Polyak-Ruppert iterate averaging be adapted to the Riemannian setting?}  Moreover, do the advantages of iterate averaging, in terms of rate and robustness, carry over from the Euclidean setting to the Riemannian setting?

Indeed, in the traditional setting of Euclidean stochastic optimization, averaged optimization algorithms not only improve convergence rates, but also have the advantage of adapting to the hardness of the problem \citep{moulines2011non}.  They provide a single, robust algorithm that achieves optimal rates with and without strong convexity, and achieve the statistically optimal asymptotic variance. In the presence of strong convexity, setting the step size proportional to $\gamma_n\!=\!\frac{1}{\mu n}$ is sufficient to achieve the optimal $O(\frac{1}{n})$ rate. However, as highlighted by \citet{NemJudLan08} and \citet{moulines2011non}, the convergence of such a scheme is highly sensitive to the choice of constant prefactor $C$ in the step size;
%an improper choice of $C$ can lead to an arbitrarily slow convergence \emph{rate}. 
an improper choice can lead to an arbitrarily slow convergence \emph{rate}.
Moreover, since $\mu$ is often never known, properly calibrating $C$ is often impossible (unless an explicit regularizer is added to the objective, which adds an extra hyperparameter).

In this paper, we provide a practical iterate-averaging scheme that enhances the robustness and speed of stochastic, gradient-based optimization algorithms, applicable to a  wide range of Riemannian optimization problems---including those that are (Euclidean) non-convex. Principally, our framework extends the classical Polyak-Ruppert iterate-averaging scheme (and its inherent benefits) to the Riemannian setting.
Moreover, our results hold in the general stochastic approximation setting and do not rely on any finite-sum structure of the objective.

Our main contributions are:
\begin{itemize}
\vspace*{-6pt}
  \item The development of a geometric framework to transform a sequence of slowly converging iterates, produced from SGD, to an iterate-averaged sequence
  with a robust, fast $O(\frac{1}{n})$ rate.
  %The development of a geometric framework to transform a sequence of slowly converging iterates on $\M$, produced from SGD, to an iterate-averaged sequence with a robust, fast $O(\frac{1}{n})$ rate.
  \vspace*{-6pt}
  \item A general formulation of geometric iterate averaging for a class of locally smooth and geodesically-strongly-convex optimization problems.
  \vspace*{-6pt}
  \item An application of our framework to the (non-convex) problem of streaming PCA, where we show how to transform the slow rate of the randomized power method (with no knowledge of the unknown eigengap) into an algorithm that achieves the optimal rate of convergence and which empirically outperforms existing algorithms.
  \vspace*{-6pt}
\end{itemize}
\vspace*{-5.1pt}
\subsection{Related Work}
\vspace*{-.0856cm}
\textbf{Stochastic Optimization:}
The literature on (Euclidean) stochastic optimization is vast, having been studied through the lens of machine learning \citep{bottou-98x, ShaShaSreSri09}, optimization \citep{NesVia08}, and stochastic approximation \citep{KusYin03}.
Polyak-Ruppert averaging first appeared in the works of \citet{Pol90} and \citet{ruppert1988efficient}; \citet{polyak1992acceleration} then provided asymptotic normality results for
the distribution of the averaged iterate sequence. \citet{moulines2011non} later generalized these results, providing non-asymptotic guarantees for the convergence of the averaged iterates.
An important contribution of \citet{moulines2011non} was to present a unified analysis showing that  averaging coupled with sufficiently slow step-sizes achieves
optimal convergence in all settings (with and without strong~convexity).
\\
\textbf{Riemannian Optimization:}
Riemannian optimization has not been explored in the machine learning community until relatively recently. \citet{udriste1994convex} and
\citet{absil2009optimization} provide comprehensive background on the topic. Most existing work has primarily focused on providing asymptotic convergence guarantees for non-stochastic algorithms \citep[see, e.g.,][who analyze the convergence of Riemannian trust-region and Riemannian L-BFGS methods]{Absil2007,ring2012optimization}.

\citet{bonnabel2013stochastic}
provided the first asymptotic convergence
proof of stochastic gradient descent (SGD) on Riemannian manifolds while highlighting diverse applications of the Riemannian framework to problems such as PCA.
The first global complexity results for first-order Riemannian optimization, utilizing the notion of \emph{functional g-convexity}, were obtained
in the foundational work of \citet{zhang2016first}. The finite-sum, stochastic setting has been further investigated by \citet{zhang2016riemannian} and \citet{sato2017riemannian}, who developed Riemannian SVRG methods. However, the potential utility of Polyak-Ruppert averaging in the Riemannian setting has been unexplored.
