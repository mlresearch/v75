\documentclass[final,12pt]{colt2018} % Anonymized submission
% \documentclass{colt2017} % Include author names

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e


\usepackage{times}
\usepackage{physics}
\usepackage{natbib}
\usepackage{mathtools}

\newcommand{\BEAS}{\begin{eqnarray*}}
\newcommand{\EEAS}{\end{eqnarray*}}
\newcommand{\BEA}{\begin{eqnarray}}
\newcommand{\EEA}{\end{eqnarray}}
\newcommand{\BA}{\begin{align}}
\newcommand{\EA}{\end{align}}
\newcommand{\BEQ}{\begin{equation}}
\newcommand{\EEQ}{\end{equation}}
\newcommand{\BIT}{\begin{itemize}}
\newcommand{\EIT}{\end{itemize}}
\newcommand{\BNUM}{\begin{enumerate}}
\newcommand{\ENUM}{\end{enumerate}}
\newcommand{\diag}{\mathop{\rm diag}}
\newcommand{\Diag}{\mathop{\rm Diag}}


\newcommand{\x}{\mathbf{x}}
\newcommand{\D}{\Delta}
\renewcommand{\O}{\mathcal{O}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\g}{\mathfrak{g}}
\newcommand{\G}{\mathcal{G}_{d,k}}

\newcommand{\Hess}{\nabla^2}

\newcommand{\eps}{\varepsilon}
\newcommand{\tp}[2]{\Gamma_{#1}^{#2}}
\newcommand{\te}[2]{\Lambda_{#1}^{#2}}

\newcommand{\mysec}[1]{Section~\ref{sec:#1}}
\newcommand{\myapp}[1]{Appendix~\ref{sec:#1}}
\newcommand{\eq}[1]{Eq.~(\ref{eq:#1})}
\newcommand{\myfig}[1]{Figure~\ref{fig:#1}}


\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\Exp}{{\mathop { \rm Exp{}}}}
\newcommand{\Cov}{{\mathop { \rm cov{}}}}
\newcommand{\cov}{{\mathop {\rm cov{}}}}
\newcommand{\corr}{{\mathop { \rm corr{}}}}
\newcommand{\Var}{\mathop{ \rm var{}}}
\newcommand{\sign}{\mathop{ \rm sign}}
\newcommand{\idm}{I}
\newcommand{\rb}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}


% \theoremstyle{plain}
%\newtheorem{theorem}{Theorem}
% \newtheorem{claim}{Claim}
% \newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assumption}{Assumption}
% \newtheorem{remark}{Remark}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{fact}{Fact}
% \theoremstyle{definition}
% \newtheorem{condition}{Condition}
% \newtheorem{definition}{Definition}
% \newtheorem{example}{Example}
%\theoremstyle{remark}
%\newtheorem{remark}{Remark}
\allowdisplaybreaks

\title[Averaging on Manifolds]{Averaging Stochastic Gradient Descent on Riemannian Manifolds}
\usepackage{times}
 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
  % \coltauthor{\Name{Author Name1} \Email{abc@sample.com}\and
  %  \Name{Author Name2} \Email{xyz@sample.com}\\
  %  \addr Address}

 % Three or more authors with the same address:
 % \coltauthor{\Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \addr Address}


 % Authors with different addresses:
 \coltauthor{\Name{Nilesh Tripuraneni} \Email{nilesh\_tripuraneni@berkeley.edu}\\
 \addr University of California, Berkeley
 \AND
 \Name{Nicolas Flammarion} \Email{flammarion@berkeley.edu}\\
 \addr University of California, Berkeley
 \AND
 \Name{Francis Bach} \Email{francis.bach@inria.fr}\\
 \addr INRIA, Ecole Normale Sup\'erieure and PSL Research University
 \AND
 \Name{Michael I. Jordan} \Email{jordan@cs.berkeley.edu}\\
 \addr University of California, Berkeley
 }

\begin{document}

\maketitle
\vspace*{-.35cm}
\begin{abstract}
We consider the minimization of a function defined on a Riemannian manifold $\mathcal{M}$ accessible only through unbiased estimates of its gradients. We develop a geometric framework to transform a sequence of slowly converging iterates generated from stochastic gradient descent (SGD) on $\mathcal{M}$ to an averaged iterate sequence with a robust and fast $O(1/n)$ convergence rate. We then present an application of our framework to geodesically-strongly-convex (and possibly Euclidean non-convex) problems.  Finally, we demonstrate how these ideas apply to the case of streaming $k$-PCA, where we show how to accelerate the slow rate of the randomized power method  (without requiring knowledge of the eigengap) into a robust algorithm achieving the optimal rate of convergence.
\end{abstract}

\begin{keywords}
Optimization, Riemannian Manifold, Stochastic Approximation, $k$-PCA.
\end{keywords}

\input{intro}
\input{results}
\input{prelims}
\input{proofsketch}
\input{application}
\input{experiments}
\input{conclusion}

%\newpage
\bibliographystyle{plainnat}
\bibliography{onlinepca}

\newpage
\onecolumn
\appendix
\input{proof1}
\input{proof2}
\input{proof3}
\input{appgeostrong}
\input{apppca}
\input{add_exp}

\end{document}
