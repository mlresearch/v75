\documentclass[final,12pt]{colt2018} % Anonymized submission
% \documentclass[11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{times}

% \usepackage{fullpage}
% \usepackage{natbib}
% \usepackage{algorithm}
% \usepackage[noend]{algpseudocode}

% \usepackage{amsmath,amsthm,amsfonts,amssymb}
% \usepackage{hyperref}
% % \usepackage{jmlr2e}
% \usepackage{color}
% \usepackage{mathrsfs}
% \usepackage{mathtools}
% \usepackage{enumitem}
% \usepackage{bm}
% % \usepackage{tabularx}
% \usepackage{multirow}
% \usepackage{booktabs}
% \usepackage{makecell}
% \usepackage{graphicx}
% \usepackage{subfigure}
% \usepackage{caption}



\usepackage{algorithm}
\usepackage[noend]{algorithmic}
% \usepackage{algpseudocode}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{bm}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{graphicx}
% \usepackage{subfigure}
% \usepackage{caption}

%\usepackage{nth}
\usepackage{intcalc}

% Definitions of handy macros can go here
% \setlength\parindent{0pt}

\include{notations}

% \newtheorem{theorem}{Theorem}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \newtheorem{remark}[theorem]{Remark}
% \newtheorem{claim}{Remark}
\newtheorem*{fact}{Fact}
% \newtheorem{proposition}[theorem]{Proposition}
% \theoremstyle{definition}
% \newtheorem{definition}{Definition}
% \newtheorem{assumption}{Assumption}
% \renewcommand\theassumption{A\arabic{assumption}}

\newcommand{\g}{\bm{g}}
\newcommand{\m}{\bm{m}}

\newcommand{\ca}{\hat{c}}
\newcommand{\Ts}{T'}
\newcommand{\Tt}{T''}
\newcommand{\cb}{c_2}
\newcommand{\ugrad}{\mathscr{G}}
\newcommand{\ufun}{\mathscr{E}}
\newcommand{\uspace}{\mathscr{S}}
\newcommand{\utime}{\mathscr{T}}
\newcommand{\umom}{\mathscr{M}}

\renewcommand{\S}{\mathcal{S}}
\newcommand{\Scomp}{\mathcal{S}^c}
\newcommand{\balpha}{\bm{\alpha}}
\newcommand{\bbeta}{\bm{\beta}}
\newcommand{\bdelta}{\bm{\delta}}
\newcommand{\logterms}{\frac{d\cn}{\delta}}
\newcommand{\overh}{\ca \log(\logterms)}

\newcommand{\sigstarl}{\sigma^\star_1}
\newcommand{\sigstarr}{\sigma^\star_r}
\newcommand{\zero}{\mathbf{0}}
\newcommand{\mR}{\mat{R}}
\newcommand{\mZ}{\mat{Z}}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\cXstar}{\mathcal{X}^\star}
\newcommand{\cXe}{\mathcal{X}_{\text{escape}}}
\newcommand{\cXs}{\mathcal{X}_{\text{stuck}}}

\newcommand{\ball}{\mathbb{B}}
\newcommand{\EFSP}{$\epsilon$-first-order stationary point}
\newcommand{\ESSP}{$\epsilon$-second-order stationary point}
\newcommand{\ESP}{$\epsilon$-suboptimal point}

\renewcommand{\Im}{\mathrm{Im}}
\newcommand{\pmat}[1]{\begin{pmatrix} #1 \end{pmatrix}}
\newcommand{\modify}[1]{#1 '}

\newcommand{\pn}[1]{{\color{red} PN: #1}}
\newcommand{\cj}[1]{{\color{blue} CJ: #1}}
\newcommand{\cnote}{\textcolor[rgb]{1,0,0}{C: }\textcolor[rgb]{1,0,1}}

% \newcommand{\citep}{\cite}
% \newcommand{\citet}{\cite}


\begin{document}

\title[AGD Escapes Saddle Points Faster than GD]{Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent}

% \title{\textbf{Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent}}

% \author{Chi Jin \\ University of California, Berkeley \\ \texttt{chijin@cs.berkeley.edu}
% \and 
% Praneeth Netrapalli \\ Microsoft Research, India \\ \texttt{praneeth@microsoft.com}
% \and
% Michael I. Jordan \\ University of California, Berkeley \\ \texttt{jordan@cs.berkeley.edu}}

 \coltauthor{\Name{Chi Jin} \Email{chijin@cs.berkeley.edu}\\
 \addr University of California, Berkeley
 \AND
 \Name{Praneeth Netrapalli} \Email{praneeth@microsoft.com}\\
 \addr Microsoft Research India
 \AND
 \Name{Michael I. Jordan} \Email{jordan@cs.berkeley.edu}\\
 \addr University of California, Berkeley
 }

\maketitle

\begin{abstract}
% Nesterov's accelerated gradient descent (\nag), an instance of the general family of ``momentum methods,'' provably achieves faster convergence rate than gradient descent (\gd) in the convex setting. However, whether these methods are superior to~\gd~in the nonconvex setting remains open. This paper studies a simple variant of~\nag, and shows that it escapes saddle points and finds a second-order stationary point in $\tilde{O}(1/\epsilon^{7/4})$ iterations, faster than the $\tilde{O}(1/\epsilon^{2})$ iterations required by~\gd. To the best of our knowledge, this is the first Hessian-free algorithm to find a second-order stationary point faster than~\gd, and also the first single-loop algorithm with a faster rate than~\gd~even in the setting of finding a first-order stationary point. Our analysis is based on two key ideas: (1) the use of a simple Hamiltonian function, inspired by a continuous-time perspective, which~\nag~monotonically decreases per step even for nonconvex functions, and (2) a novel framework called~\emph{\iol}, which is useful for tracking the long-term behavior of gradient-based optimization algorithms. We believe that these techniques may deepen our understanding of both acceleration algorithms and nonconvex optimization.

\noindent
Nesterov's accelerated gradient descent (\nag), an instance of the general family of ``momentum methods,'' provably achieves faster convergence rate than gradient descent (\gd) in the convex setting. While these methods are widely used in modern \emph{nonconvex} applications, including training of deep neural networks, whether they are provably superior to~\gd~in the nonconvex setting remains open. This paper studies a simple variant of Nesterov's~\nag, and shows that it escapes saddle points and finds a second-order stationary point in $\tilde{O}(1/\epsilon^{7/4})$ iterations, matching the best known convergence rate, which is faster than the $\tilde{O}(1/\epsilon^{2})$ iterations required by~\gd. To the best of our knowledge, this is the first direct acceleration (single-loop) algorithm that is provably faster than GD in general nonconvex setting---all previous nonconvex accelerated algorithms rely on more complex mechanisms such as nested loops and proximal terms. Our analysis is based on two key ideas: (1) the use of a simple Hamiltonian function, inspired by a continuous-time perspective, which~\nag~monotonically decreases on each step even for nonconvex functions, and (2) a novel framework called~\emph{\iol}, which is useful for tracking the long-term behavior of gradient-based optimization algorithms. We believe that these techniques may deepen our understanding of both acceleration algorithms and nonconvex optimization.


\end{abstract}

% \thispagestyle{empty}
% \clearpage
% \newpage
% \setcounter{page}{1}

% \cnote{Think name of title, algorithm, improve or localize, negative curvature exploration}
\input{intro}
\input{related}
\input{techniq}
\input{prelim}
\input{result}
\input{sketch}
\input{sketch1}
\input{sketch2}
\input{conclu}

% \newpage

% \bibliographystyle{plainnat}
\bibliography{saddle}

\newpage

\appendix
\input{energy}
\input{proof}
\input{proof_first}
\input{proof_second}
\input{auxilem}
\input{counterex.tex}


\end{document}
