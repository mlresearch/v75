\section{Conclusion and Future Work}

We presented a novel importance sampling technique for variance reduction in an online learning formulation. First, we motivated why regret is a sensible measure of performance in this setting. Despite the bandit feedback and the unbounded costs, we provided an expected regret guarantee of $\tO(n^{1/3}T^{2/3})$, where our reference is the best fixed sampling distribution in hindsight. We confirmed the theoretical findings with empirical validation.

Among the many possible future directions stands the question of the tightness of  the expected regret bound of the algorithm. Another naturally arising idea is the theoretical analysis of the method when employed in conjunction with advanced stochastic solvers such as SVRG and SAGA.