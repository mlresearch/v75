%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

@article{cesa2004generalization,
  title={On the generalization ability of on-line learning algorithms},
  author={Cesa-Bianchi, Nicolo and Conconi, Alex and Gentile, Claudio},
  journal={IEEE Transactions on Information Theory},
  volume={50},
  number={9},
  pages={2050--2057},
  year={2004},
  publisher={IEEE}
}


@inproceedings{Abernethy08,
  author    = {Jacob Abernethy and
               Elad Hazan and
               Alexander Rakhlin},
  title     = {Competing in the Dark: An Efficient Algorithm for Bandit
               Linear Optimization},
  booktitle = {COLT},
  year      = {2008},
  pages     = {263-274},
  ee        = {http://colt2008.cs.helsinki.fi/papers/127-Abernethy.pdf},
  crossref  = {DBLP:conf/colt/2008},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@InProceedings{pmlr-v70-namkoong17a,
  title = 	 {Adaptive Sampling Probabilities for Non-Smooth Optimization},
  author = 	 {Hongseok Namkoong and Aman Sinha and Steve Yadlowsky and John C. Duchi},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2574--2583},
  year = 	 {2017},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  abstract = 	 {Standard forms of coordinate and stochastic gradient methods do not adapt to structure in data; their good behavior under random sampling is predicated on uniformity in data. When gradients in certain blocks of features (for coordinate descent) or examples (for SGD) are larger than others, there is a natural structure that can be exploited for quicker convergence. Yet adaptive variants often suffer nontrivial computational overhead. We present a framework that discovers and leverages such structural properties at a low computational cost. We employ a bandit optimization procedure that “learns” probabilities for sampling coordinates or examples in (non-smooth) optimization problems, allowing us to guarantee performance close to that of the optimal stationary sampling distribution. When such structures exist, our algorithms achieve tighter convergence guarantees than their non-adaptive counterparts, and we complement our analysis with experiments on several datasets.}
}

Query Results from the ADS Database


Retrieved 1 abstracts, starting with number 1.  Total number selected: 1.

@ARTICLE{salehi2017,
   author = {{Salehi}, F. and {Celis}, L.~E. and {Thiran}, P.},
    title = "{Stochastic Optimization with Bandit Sampling}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1708.02544},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control, Statistics - Machine Learning},
     year = 2017,
    month = aug,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170802544S},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}


@article{shalev2012online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2012},
  publisher={Now Publishers, Inc.}
}
  
@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{bouchard2015online,
  title={Online learning to sample},
  author={Bouchard, Guillaume and Trouillon, Th{\'e}o and Perez, Julien and Gaidon, Adrien},
  journal={arXiv preprint arXiv:1506.09016},
  year={2015}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={ICLR},
  year={2015}
}

@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={88},
  number={2},
  pages={303--338},
  year={2010},
  publisher={Springer}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@inproceedings{arthur2007k,
  title={k-means++: The advantages of careful seeding},
  author={Arthur, David and Vassilvitskii, Sergei},
  booktitle={Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms},
  pages={1027--1035},
  year={2007},
  organization={Society for Industrial and Applied Mathematics}
}

@misc{kddcup2004,
  key={KDD Cup 2004},
  title = {{KDD Cup 2004. Protein Homology Dataset.}},
  howpublished = {\url{http://osmot.cs.cornell.edu/kddcup/}},
  note = {Accessed: 10.11.2016},
  year = {2004}
}

@inproceedings{faulkner2011next,
  title={The next big one: Detecting earthquakes and other rare events from community-based sensors},
  author={Faulkner, Matthew and Olson, Michael and Chandy, Rishi and Krause, Jonathan and Chandy, K Mani and Krause, Andreas},
  booktitle={Information Processing in Sensor Networks (IPSN), 2011 10th International Conference on},
  pages={13--24},
  year={2011},
  organization={IEEE}
}

@article{lecun1998gradient,
  title={{Gradient-based learning applied to document recognition}},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@inproceedings{shrivastava2016training,
  title={Training region-based object detectors with online hard example mining},
  author={Shrivastava, Abhinav and Gupta, Abhinav and Girshick, Ross},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={761--769},
  year={2016}
}

@article{chawla2002smote,
  title={SMOTE: synthetic minority over-sampling technique},
  author={Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
  journal={Journal of artificial intelligence research},
  volume={16},
  pages={321--357},
  year={2002}
}

@inproceedings{bottou1995convergence,
  title={Convergence properties of the k-means algorithms},
  author={Bottou, Leon and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={585--592},
  year={1995}
}

@inproceedings{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={Advances in neural information processing systems},
  pages={315--323},
  year={2013}
}

@inproceedings{defazio2014saga,
  title={Saga: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1646--1654},
  year={2014}
}

@inproceedings{sculley2010web,
  title={Web-scale k-means clustering},
  author={Sculley, David},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={1177--1178},
  year={2010},
  organization={ACM}
}

@inproceedings{zhao2015stochastic,
  title={Stochastic optimization with importance sampling for regularized loss minimization},
  author={Zhao, Peilin and Zhang, Tong},
  booktitle={Proceedings of the 32nd International Conference on Machine Learning (ICML-15)},
  pages={1--9},
  year={2015}
}

@article{csiba2016importance,
  title={Importance sampling for minibatches},
  author={Csiba, Dominik and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1602.02283},
  year={2016}
}

@article{freedman1975tail,
  title={On tail probabilities for martingales},
  author={Freedman, David A},
  journal={the Annals of Probability},
  pages={100--118},
  year={1975},
  publisher={JSTOR}
}

@article{mcmahan2010adaptive,
  title={Adaptive Bound Optimization for Online Convex Optimization},
  author={McMahan, H Brendan and Streeter, Matthew},
  journal={COLT 2010},
  pages={244},
  year={2010}
}

@inproceedings{kakade2009generalization,
  title={On the generalization ability of online strongly convex programming algorithms},
  author={Kakade, Sham M and Tewari, Ambuj},
  booktitle={Advances in Neural Information Processing Systems},
  pages={801--808},
  year={2009}
}

@incollection{NIPS2017_7025,
title = {Safe Adaptive Importance Sampling},
author = {Stich, Sebastian U and Raj, Anant and Jaggi, Martin},
booktitle = {Advances in Neural Information Processing Systems 30},
pages = {4384--4394},
year = {2017},
publisher = {Curran Associates, Inc.}
}

@inproceedings{allen2016even,
  title={Even faster accelerated coordinate descent using non-uniform sampling},
  author={Allen-Zhu, Zeyuan and Qu, Zheng and Richt{\'a}rik, Peter and Yuan, Yang},
  booktitle={International Conference on Machine Learning},
  pages={1110--1119},
  year={2016}
}

@inproceedings{needell2014stochastic,
  title={Stochastic gradient descent, weighted sampling, and the randomized Kaczmarz algorithm},
  author={Needell, Deanna and Ward, Rachel and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1017--1025},
  year={2014}
}


@inproceedings{perekrestenko2017faster,
  title={Faster Coordinate Descent via Adaptive Importance Sampling},
  author={Perekrestenko, Dmytro and Cevher, Volkan and Jaggi, Martin},
  booktitle={Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  volume={54},
  number={EPFL-CONF-226287},
  year={2017},
  organization={PMLR}
}


@article{alain2015variance,
  title={Variance reduction in SGD by distributed importance sampling},
  author={Alain, Guillaume and Lamb, Alex and Sankar, Chinnadhurai and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1511.06481},
  year={2015}
}

@article{kalai2005efficient,
  title={Efficient algorithms for online decision problems},
  author={Kalai, Adam and Vempala, Santosh},
  journal={Journal of Computer and System Sciences},
  volume={71},
  number={3},
  pages={291--307},
  year={2005},
  publisher={Elsevier}
}

@article{Hazan09,
  title={A survey: The convex optimization approach to regret minimization},
  author={Hazan, Elad},
  journal={Optimization for machine learning},
  pages={287-302},
  year={2011},
  publisher={MIT press}
}

@article{salehi2017stochastic,
  title={Stochastic Dual Coordinate Descent with Bandit Sampling},
  author={Salehi, Farnood and Thiran, Patrick and Celis, L Elisa},
  journal={arXiv preprint arXiv:1712.03010},
  year={2017}
}

@article{nesterov2012efficiency,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}

@inproceedings{necoara2011random,
  title={A random coordinate descent method on large optimization problems with linear constraints},
  author={Necoara, I and Nesterov, Y and Glineur, F},
  year={2011},
  journal={International Conference on Continuous Optimization}
}

@article{strohmer2009randomized,
  title={A randomized Kaczmarz algorithm with exponential convergence},
  author={Strohmer, Thomas and Vershynin, Roman},
  journal={Journal of Fourier Analysis and Applications},
  volume={15},
  number={2},
  pages={262},
  year={2009},
  publisher={Springer}
}

@article{xiao2014proximal,
  title={A proximal stochastic gradient method with progressive variance reduction},
  author={Xiao, Lin and Zhang, Tong},
  journal={SIAM Journal on Optimization},
  volume={24},
  number={4},
  pages={2057--2075},
  year={2014},
  publisher={SIAM}
}