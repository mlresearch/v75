\documentclass[final,12pt]{colt2018} % Anonymized submission
% \documentclass{colt2018} % Include author names

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e

\usepackage[capitalise]{cleveref}
%\Crefname{subappendix}{Section}{Sections}

\include{header}  



\title[Online Variance Reduction for Stochastic Optimization]{Online Variance Reduction for Stochastic Optimization}
\usepackage{times}
 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
  % \coltauthor{\Name{Author Name1} \Email{abc@sample.com}\and
  %  \Name{Author Name2} \Email{xyz@sample.com}\\
  %  \addr Address}

 % Three or more authors with the same address:
 \coltauthor{\Name{Zal\'an Borsos} \Email{zalan.borsos@inf.ethz.ch}\\
  \Name{Andreas Krause} \Email{krausea@inf.ethz.ch}\\
  \Name{Kfir Y. Levy} \Email{yehuda.levy@inf.ethz.ch}\\
  \addr Department of Computer Science\\ETH Zurich}


 % Authors with different addresses:
%  \coltauthor{\Name{Author Name1} \Email{abc@sample.com}\\
%  \addr Address 1
%  \AND
%  \Name{Author Name2} \Email{xyz@sample.com}\\
%  \addr Address 2
%  }

\begin{document}

\maketitle

\begin{abstract}
Modern stochastic optimization methods often rely on uniform sampling which is agnostic to the underlying characteristics of the data.
This might degrade the convergence by  yielding estimates that suffer from a high variance.  
A possible remedy is to employ non-uniform \emph{importance sampling} techniques, which take the structure of the dataset into account. 
In this work, we investigate a recently proposed  setting  which poses variance reduction as an online optimization problem with bandit feedback.
We devise a novel and efficient algorithm for this setting  that finds a sequence of importance sampling distributions competitive with the best fixed distribution in hindsight, the first result of this kind.
While we present our method for sampling data points, it naturally extends to selecting coordinates or even blocks of thereof.  Empirical validations underline the benefits of our method in several settings.
\end{abstract}

\begin{keywords}
importance sampling, variance reduction, bandit feedback, empirical risk minimization
\end{keywords}	

\input{introduction}
\input{motivation}
\input{fullinfo}
\input{bandit}
% \input{experiments}
\input{conclusion}

% Acknowledgments---Will not appear in anonymized version
\acks{The authors would like  to thank  
Hasheminezhad Seyedrouzbeh  for useful discussions during the course of this work. This research was supported by SNSF grant $407540\_167212$ through the NRP 75 Big Data program.
K.Y.L. is supported by the ETH Z\"urich Postdoctoral Fellowship and Marie Curie Actions for People COFUND program.}

\newpage
\bibliography{bib}
\input{appendix}



\end{document}
