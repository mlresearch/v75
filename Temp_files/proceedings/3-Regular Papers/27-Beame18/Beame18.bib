@InProceedings{Beame18,
author = {Beame, Paul and Oveis Gharan, Shayan and Yang, Xin},
title = {Time-Space Tradeoffs for Learning Finite Functions from Random Evaluations,
with Applications to Polynomials},
pages = {},
abstract = {We develop an extension of recent analytic methods for 
obtaining time-space tradeoff lower bounds for problems of learning 
from uniformly random labelled examples.  With our methods we can obtain bounds for learning concept classes of finite functions from random evaluations even when
the sample space of random inputs can be significantly smaller
than the concept class of functions and the function values can be from
an arbitrary finite set.


At the core of our results, we reduce the time-space complexity of learning
from random evaluations to the question of how much the corresponding
evaluation matrix amplifies the 2-norms of ``almost uniform'' probability
distributions. To analyze the latter, we formulate it as a semidefinite
program, and we analyze its dual.  
In order to handle function values from arbitrary finite sets, we apply this
norm amplification analysis to complex matrices.

As applications that follow from our new techniques, we show that
any algorithm that learns $n$-variate  polynomial
functions of degree at most $d$ over $\mathbb{F}_2$ with success at least
$2^{-O(n)}$ from evaluations on
randomly chosen inputs either requires space
$\Omega(nm/d)$ or $2^{\Omega(n/d)}$ time where $m=(n/d)^{\Theta(d)}$ is the
dimension of the space of such polynomials.   These bounds are asymptotically
optimal for polynomials of arbitrary constant degree since
they match the tradeoffs achieved by natural learning algorithms for the
problems.
We extend these results to learning polynomials of degree at most $d$ over any odd prime field $\mathbb{F}_p$ where we show
that $\Omega((mn/d)\log p)$ space or time $p^{\Omega(n/d)}$ is required.

To derive our bounds for learning polynomials over finite fields,
we show that an analysis of the dual of
the corresponding semidefinite program follows from an understanding of the distribution of the bias
of all degree $d$ polynomials with respect to uniformly random inputs.}
}