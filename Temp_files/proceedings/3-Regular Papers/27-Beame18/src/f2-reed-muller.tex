\newcommand{\w}{\textrm{weight}}
\section{Applications to Learning Polynomial Functions over Finite Fields}

\subsection{The Bias of $\mathbb{F}_2$ Polynomials and the Weight Distribution of Reed-Muller Codes}
\label{sec:f2-reed-muller}

Let $d\ge 2$ be an integer.  For any integer $m\ge d$, consider the learning
problem for $\mathbb{F}_2$ polynomials in $m$ variables of degree at most $d$, 
%we have $n=\sum_{i=1}^d \binom{m}{d}$. 
That is $A=\mathbb{F}_2^m$ and, expressing polynomials by their coefficients,
we have $X=\mathbb{F}_2^n$ where $n=\sum_{i=0}^d \binom{m}{d}$ and
for $a\in A$ and $x\in X$,
$\fun (a,x)=x(a)=\sum_{S: 0\leq |S|\leq d} x_S \prod_{i\in S} a_i$ over
$\mathbb{F}_2$.

Recall that since the range of $\fun$ is $\coltset{0,1}$,
we have a $N=M^T\cdot M$ 
where $M(a,x)=(-1)^{\fun(a,x)}=(-1)^{x(a)}$.
Let $M_x$ denote the $x$-th column of $M$ where $x\in \coltset{0,1}^n$.
Then $N_{xy}=2^m \cdot \langle M_x,M_y\rangle$.
%Recall that for $a\in \mathbb{F}_2^m$ and $x\in \mathbb{F}_2^n$,
%$x(a)=\sum_{S: 0\leq |S|\leq d} x_S \prod_{i\in S} a_i$ over $\mathbb{F}_2$.

\begin{proposition}
\label{prop:equalrows}
Let $\mathbf{0}=0^n$.
Then $\langle M_x,M_y\rangle=\langle M_{\mathbf{0}},M_{x+y}\rangle$.
\end{proposition}

\begin{proof}
\begin{align*}
\langle M_x,M_y\rangle&=\E_{a\in \mathbb{F}_2^m} M_x(a)M_y(a)
=\E_{a\in \mathbb{F}_2^m} (-1)^{x(a)}(-1)^{y(a)}
=\E_{a\in \mathbb{F}_2^m} (-1)^{x(a)+y(a)}\\
&=\E_{a\in \mathbb{F}_2^m} (-1)^{(x+y)(a)}
=\E_{a\in \mathbb{F}_2^m} M_{\mathbf{0}}(a)M_{x+y}(a)
=\langle M_{\mathbf{0}},M_{x+y}\rangle
\end{align*}
\end{proof}

Since the mapping $y\mapsto x+y$ for $x\in \mathbb{F}_2^n$ is
1-1 on $\mathbb{F}_2^n$, 
every row of $N_x$ for $x\in X$ contains the same multi-set of values.
Therefore, in order to analyze the function $W_\kappa(N)$,
we only need to examine the fixed row $N_\mathbf{0}$ of $N$,
where each entry
$$N_{\mathbf{0}x}=\sum_{a\in \mathbb{F}_2^m} M(a,x)=\sum_{a\in \mathbb{F}_2^m}(-1)^{x(a)}.$$
For $x\in X$, define $\w(x)=|\coltset{a\in \mathbb{F}_2^m\ :\ x(a)=1}|$.
By definition, for $x\in \mathbb{F}_2^n$, 
$N_{\mathbf{0}x}=\sum_{a\in \mathbb{F}_2^m}(-1)^{x(a)}=2^m-2\cdot \w(x)$.
Thus, understanding the function $W_\kappa(N)$ that we use to derive our
bounds via Theorem~\ref{thm:quadcurve} reduces to understanding the distribution of
$\w(x)$ for $x\in X$.
In particular, our goal of showing that for some $\kappa$ for which
$(\kappa+W_\kappa(N))/2^m$ is at most $2^{2\tau m}$ for some $\tau<0$ 
follows by showing that the distribution of $\w(x)$ is tightly concentrated
around $2^{m}/2$.

We can express this question in terms of 
%(a small variation of)
the Reed-Muller error-correcting code $RM(d,n)$ over $\mathbb{F}_2$
(see, e.g.\cite{berlekamp-book}).

\begin{defn}
The Reed-Muller code $RM(d,m)$ over $\mathbb{F}_2$ is the set of vectors
$\coltset{G\cdot x\mid x\in \coltset{0,1}^n}$ where $G$ is the $2^m\times n$ matrix
for $n=\sum_{t=0}^d \binom{m}{t}$ over $\mathbb{F}_2$
with rows indexed by vectors $a\in \coltset{0,1}^m$ and columns indexed by
subsets $S\subseteq [m]$ with $|S|\le d$ given by $G(a,S)=\prod_{i\in S} a_i$.
\end{defn}

%Evaluating $\w(x)$ for all $x\in \coltset{0,1}^n$ is almost exactly that of

Evaluating $\w(x)$ for all $x\in \coltset{0,1}^n$ is that of
understanding the distribution of Hamming weights of the vectors in $RM(m,d)$,
a question with a long history.

%Because we assumed that the constant term of our polynomials is 0 (in order to
%view the learning problem as a variant of the parity learning problem with a
%smaller set of test vectors), we need to make a small change in the
%Reed-Muller code.
%Consider the subcode $RM'(d,m)$ of $RM(d,m)$ having the 
%generator matrix $G'$ that is the same as $G$ but with the (all 1's) column
%indexed by $\emptyset$ removed.
%In this case, for each $x\in \coltset{0,1}^m$, by definition, $\w(x)$ is 
%precisely the Hamming weight of the vector $G'\cdot x$ in $RM'(d,m)$.

%Now by definition
%$$RM(d,m)=\coltset{y\mid y\in RM'(d,m)\mbox{ or }\overline{y}\in RM'(d,m)}$$
%where $\overline{y}$ is the same as $y$ with every bit flipped.
%In particular, $RM'(d,m)\subset RM(d,m)$ and the distribution of the
%weights for $RM(d,m)$
%is symmetric about $2^{m-1}$, whereas the distribution of weights in
%$RM'(d,m)$ is not necessarily symmetric.

\paragraph{Quadratic polynomials over $\mathbb{F}_2$}
For the special case that $d=2$, \cite{DBLP:journals/tit/SloaneB70} derived an exact
enumeration of the number of vectors of each weight in $RM(2,m)$.

\begin{proposition}\cite{DBLP:journals/tit/SloaneB70}
\label{lem:RM(2,m)-count}
The weight of every codeword of $RM(2,m)$ is of the form $2^{m-1}\pm 2^{m-i}$
for some integer $i$ with $1\le i\le \lceil m/2\rceil$ or precisely $2^{m-1}$
and the number of codewords of weight $2^{m-1}+2^{m-i}$ or $2^{m-1}-2^{m-i}$ 
is precisely
$$2^{i(i+1)} \prod_{j=0}^{i-1} \frac{2^{m-2j}(2^{m-2j-1}-1)}{2^{2(j+1)}-1}.$$
\end{proposition}

(Though the original proof used other methods, a simpler alternative
proof by \cite{mceliece1967linear} follows from
a lemma of  \cite{dickson:book} giving a normal form theorem for quadratic polynomials over
$\mathbb{F}_{2^t}$.  
We will use a similar approach when we analyze
quadratic polynomials over $\mathbb{F}_{p^t}$.)

%\begin{proposition}\label{main_counting}
%Let $M$ be the matrix for learning quadratic functions over 
%$\mathbb{F}_2[z_1,\ldots,z_m]$ and let $N=M^T\cdot M$. 
%\begin{enumerate}
%\item Every row of $N_x$ for $x\in X$ contains the same multi-set of values.
%\item $N_{xx}=2^m$ and $N_{xy}\in \{\pm 2^{m-1},\pm 2^{m-2},\cdots,\pm 2^{\lceil \frac m 2\rceil},0\}$ for $x\neq y\in \coltset{0,1}^n$.
%\item For $i>0$, let $c_i$ be the number of entries equal to $2^{m-i}$ in each
%row of $N$;
%then 
%\[c_i=(2^{2i-1}+2^{i-1})\frac{\prod_{j=0}^{2i-1}(2^m-2^j)}{\prod_{j=1}^i2^{2j-1}(2^{2j}-1)}\leq 2^{2im}\]
%\end{enumerate}
%\end{proposition}

%Given Proposition~\ref{main_counting} we can derive
%Theorem~\ref{thm:quadcurve}.

\begin{proof}[Proof of Theorem~\ref{thm:quadcurve}]
Let the threshold $\kappa=2^{m-k}$ for some integer $k$ to be determined later.
By Lemma~\ref{c-SDP-lemma} with $X=\{0,1\}^n$, for \eqref{c-original}, we have
$OPT_{M,\delta}\le (\kappa+W_\kappa(N) 2^{(\delta-1)n})/2^m$ where
$N=M^T\cdot M$.
By definition for all $x\in X$ we have $N_{\mathbf{0}x}=2^m-2\cdot \w(x)$
and by Proposition~\ref{lem:RM(2,m)-count}, we know that if $2^m-2\cdot \w(x)>0$
then it is $2^{m-i+1}$ for some $1\le i\le \lceil m/2\rceil$.
Also by Proposition~\ref{lem:RM(2,m)-count}, the number, $c_i$, of $x\in X$
such that $N_{\mathbf{0}x}=2^{m-i+1}$ is at most
$$2^{i(i+1)} \prod_{j=0}^{i-1} \frac{2^{m-2j}(2^{m-2j-1}-1)}{2^{2(j+1)}-1}
\le 2^{2(i-1)m}.$$
Therefore, by definition
of $W_\kappa$ and Proposition~\ref{prop:equalrows}, for any $x\in X$ 
we have 
\begin{equation*}
W_\kappa(N)
\le \sum_{y\in X: N_{xy}> 2^{m-k}} N_{xy}
=\sum_{i=1}^{k}  c_i\cdot 2^{m-i+1} 
\le \sum_{i=1}^{k} 2^{2(i-1)m}\cdot 2^{m-i+1}
=\sum_{i=1}^{k} 2^{(2m-1)(i-1)+m}
< 2^{(2m-1)k}.
\end{equation*}
Thus for any $k$,
$$OPT_{M,\delta}\le (2^{m-k}+2^{(2m-1)k+(\delta-1)n})/2^m\le 2^{-k}+2^{(2m-1)k-(1-\delta)m(m+1)/2-m}.$$
The first term is larger for $k\le (1-\delta) m/4 + (3-\delta)/4$ so to balance
them as much as possible we choose
$k=\lfloor (1-\delta) m/4 + (3-\delta)/4\rfloor\ge (1-\delta)m/4 -(1+\delta)/4$.
Hence $OPT_{M,\delta}\le 2\cdot 2^{-k} \le 2^{-\frac {1-\delta}4 m +\frac{5+\delta}4}$
Therefore,
$\tau_M(\delta)=\frac12 \log_{2^m} OPT_{M,\delta}\le -\frac{(1-\delta)}8+\frac{(5+\delta)}{8m}$ as required. 
\end{proof}

%The proof of Proposition~\ref{main_counting} is in the appendix but in the
%next section we outline the connection to the weight distribution of
%Reed-Muller codes over $\mathbb{F}_2$, and show how bounds on the weight
%distribution of such codes allow us to derive time-space tradeoffs for
%learning larger degree $\mathbb{F}_2$ polynomials as well.

%The exact enumeration for the values of the weight function $\w$ for $RM'(2,m)$
%that corresponds to the values in
%Proposition~\ref{main_counting} are only slightly different from those for
%$RM(2,m)$ in Proposition~\ref{lem:RM(2,m)-count} and 
%Proposition~\ref{lem:RM(2,m)-count} gives the same asymptotic 
%bound we used in the proof of Theorem~\ref{thm:quadcurve} since words of weight
%$2^{m-1}-2^{m-i}$ correspond to entries of value $2^{m-i+1}$ in the matrix $N$.
%We give a proof of the exact counts of
%Proposition~\ref{main_counting} in the appendix.

\paragraph{Polynomials of degree $d>2$ over $\mathbb{F}_2$}
For the case that $d>2$, the minimum distance, the smallest 
weight of a non-zero codeword, in $RM(d,m)$ is known to be $2^{m-d}$ but
for $2<d<m-2$, no exact enumeration of the weight distribution of the code
$RM(d,m)$ is known.
It was a longstanding problem even to approximate the
number of codewords of different weights in $RM(d,m)$.  
Relatively recently, bounds on
these weights (or more precisely the associated biases) that are good enough
for our purposes were shown by
\cite{DBLP:journals/cc/Ben-EliezerHL12}.

\begin{proposition}
\label{prop:behl-bias}
For $\varepsilon>0$ there are constants $c_1, c_2$ with $0<c_1,c_2<1$ such that if $p$ is a uniformly random degree $d$ polynomial over
$\mathbb{F}^m_2$ and $d\le (1-\varepsilon)m$ then 
$$\Pr[|\E_{a\in \coltset{0,1}^m} (-1)^{p(a)}|>2^{-c_1 m/d}]\le 2^{-c_2 \sum_{i=0}^d \binom{m}{i}}.$$
\end{proposition}

From this form we can obtain the bound on the norm amplification curve
of the associated matrix fairly directly.

\begin{proof}[Proof of Theorem~\ref{thm:F2curve}]
Fix $\varepsilon>0$ and let $0<c_1, c_2<1$ be the constants depending on
$\varepsilon$ from Proposition~\ref{prop:behl-bias}.
Let $\delta=c_2/2$ so $0<\delta<1/2$.
Let $M$ be the $2^m\times 2^n$ matrix associated with learning 
polynomials of degree at most $d$ over $\mathbb{F}_2$, let $N=M^T\cdot M$ and
Setting $\kappa=2^{(1-c_1/d)m}$, by Proposition~\ref{prop:behl-bias} at
most $2^{(1-c_2)n}$ 
polynomials $p$ have entries $N_{0p}$ larger than $\kappa$.
Each such entry has value at most $2^m$ so 
$W_\kappa(N)\le 2^m\cdot 2^{(1-c_2)n}$.
by Lemma~\ref{c-SDP-lemma} with 
$X=\coltset{0,1}^n$ we have
$$OPT_{M,\delta}\le (\kappa+W_\kappa(N)\cdot 2^{(\delta-1)n})/2^m
\le 2^{-c_1 m/d}+2^{(\delta - c_2)n+1}\le 2^{-c_1 m/d}+2^{1-\delta n}$$
which is at most $2^{-c' m/d}$ for some constant $c'>0$. 
Hence $\tau_M(\delta)\le -c'/d$.
\end{proof}

