%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Maxim Raginsky at 2018-06-05 09:49:21 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{carmon2017,
	Author = {Carmon, Yair and Duchi, John C. and Hinder, Oliver and Sidford, Aaron},
	Booktitle = {ICML},
	Date-Added = {2018-06-05 14:47:33 +0000},
	Date-Modified = {2018-06-05 14:49:21 +0000},
	Title = {"{C}onvex until proven guilty:" Dimension-free acceleration of gradient descent for non-convex functions},
	Year = {2017}}

@misc{natasha2,
	Author = {{Allen-Zhu}, Zeyuan},
	Date-Added = {2018-06-05 14:31:48 +0000},
	Date-Modified = {2018-06-05 14:38:09 +0000},
	Howpublished = {Preprint},
	Month = {February},
	Title = {Natasha 2: Faster non-convex optimization than {SGD}},
	Url = {https://arxiv.org/abs/1708.08694},
	Year = {2018}}

@inproceedings{natasha,
	Author = {{Allen-Zhu}, Zeyuan},
	Booktitle = {ICML},
	Date-Added = {2018-06-05 14:29:17 +0000},
	Date-Modified = {2018-06-05 14:35:22 +0000},
	Title = {Natasha: Faster non-convex stochastic optimization via strongly non-convex parameter},
	Year = {2017}}

@book{Olivieri_Vares_metastability,
	Author = {Olivieri, Enzo and Vares, Maria Eul\'alia},
	Date-Added = {2018-02-16 15:24:01 +0000},
	Date-Modified = {2018-02-16 15:26:23 +0000},
	Publisher = {Cambridge University Press},
	Title = {Large Deviations and Metastability},
	Year = {2004}}

@book{Bhatia_matrix_analysis,
	Author = {Rajendra Bhatia},
	Date-Added = {2018-02-16 06:04:45 +0000},
	Date-Modified = {2018-02-16 06:04:45 +0000},
	Publisher = {Springer},
	Title = {Matrix Analysis},
	Year = {1997}}

@book{Hale_book,
	Author = {J. K. Hale},
	Date-Added = {2018-02-16 05:22:14 +0000},
	Date-Modified = {2018-02-16 05:22:14 +0000},
	Publisher = {American Mathematical Society},
	Title = {Asymptotic Behavior of Dissipative Systems},
	Year = {1988}}

@article{berglund_gentz_pathwise,
	Author = {Nils Berglund and Barbara Gentz},
	Date-Added = {2018-02-16 03:58:03 +0000},
	Date-Modified = {2018-02-16 03:59:10 +0000},
	Journal = {J. Differential Equations},
	Pages = {1-54},
	Title = {Geometric singular perturbation theory for stochastic differential equations},
	Volume = {191},
	Year = {2003}}

@inproceedings{wellingteh2011sgld,
	Author = {Max Welling and Yee Whye Teh},
	Booktitle = {ICML},
	Date-Added = {2018-02-16 01:13:55 +0000},
	Date-Modified = {2018-02-16 18:11:12 +0000},
	Journal = {ICML},
	Title = {Bayesian Learning via {Stochastic Gradient Langevin Dynamics}},
	Year = {2011}}

@book{Lindvall_coupling,
	Address = {Mineola, NY},
	Author = {Torgny Lindvall},
	Date-Added = {2018-02-13 23:14:47 +0000},
	Date-Modified = {2018-02-13 23:16:23 +0000},
	Publisher = {Dover Publications},
	Title = {Lectures on the Coupling Method},
	Year = {1992}}

@inproceedings{zhang2017hitting,
	Author = {Zhang, Yuchen and Liang, Percy and Charikar, Moses},
	Booktitle = {COLT},
	Date-Added = {2018-02-12 09:00:12 +0000},
	Date-Modified = {2018-02-16 06:27:57 +0000},
	Title = {A Hitting time analysis of {Stochastic Gradient Langevin Dynamics}},
	Year = {2017}}

@inproceedings{rrt_colt17,
	Abstract = {Stochastic Gradient Langevin Dynamics (SGLD) is a popular variant of Stochastic Gradient Descent, where properly scaled isotropic Gaussian noise is added to an unbiased estimate of the gradient at each iteration. This modest change allows SGLD to escape local minima and suffices to guarantee asymptotic convergence to global minimizers for sufficiently regular non-convex objectives. The present work provides a nonasymptotic analysis in the context of non-convex learning problems, giving finite-time guarantees for SGLD to find approximate minimizers of both empirical and population risks. As in the asymptotic setting, our analysis relates the discrete-time SGLD Markov chain to a continuous-time diffusion process. A new tool that drives the results is the use of weighted transportation cost inequalities to quantify the rate of convergence of SGLD to a stationary distribution in the Euclidean $2$-Wasserstein distance.},
	Author = {Maxim Raginsky and Alexander Rakhlin and Matus Telgarsky},
	Booktitle = {COLT},
	Date-Added = {2018-02-05 22:03:28 +0000},
	Date-Modified = {2018-02-16 18:11:30 +0000},
	Title = {Non-convex learning via {Stochastic Gradient Langevin Dynamics}: a nonasymptotic analysis},
	Year = {2017},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v65/raginsky17a.html}}

@article{dalalyan2017theoretical,
	Author = {Dalalyan, Arnak S},
	Date-Added = {2018-01-26 03:00:12 +0000},
	Date-Modified = {2018-01-26 03:00:12 +0000},
	Journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	Number = {3},
	Pages = {651--676},
	Publisher = {Wiley Online Library},
	Title = {Theoretical guarantees for approximate sampling from smooth and log-concave densities},
	Volume = {79},
	Year = {2017}}

@article{mei2016landscape,
	Author = {Mei, Song and Bai, Yu and Montanari, Andrea},
	Date-Added = {2018-01-24 22:50:22 +0000},
	Date-Modified = {2018-02-16 06:29:16 +0000},
	Journal = {Annals of Statistics},
	Note = {To appear},
	Title = {The landscape of empirical risk for non-convex losses},
	Year = {2016}}

@book{nesterov2013introductory,
	Author = {Nesterov, Yurii},
	Date-Added = {2017-08-31 15:13:49 +0000},
	Date-Modified = {2018-02-16 17:45:06 +0000},
	Publisher = {Springer Science \& Business Media},
	Title = {Introductory Lectures on Convex Optimization: A Basic Course},
	Year = {2013}}

@article{borkar1999strong,
	Author = {Borkar, Vivek S and Mitter, Sanjoy K},
	Date-Added = {2017-08-25 14:40:52 +0000},
	Date-Modified = {2018-02-16 15:27:28 +0000},
	Journal = {Journal of Optimization Theory and Applications},
	Number = {3},
	Pages = {499--513},
	Publisher = {Springer},
	Title = {A strong approximation theorem for stochastic recursive algorithms},
	Volume = {100},
	Year = {1999}}

@conference{raginsky2017non,
	Author = {Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
	Booktitle = {Proceedings},
	Date-Added = {2017-08-25 14:22:21 +0000},
	Date-Modified = {2018-02-05 22:03:28 +0000},
	Journal = {arXiv preprint arXiv:1702.03849},
	Title = {Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis},
	Year = {2017}}

@book{morters2010brownian,
	Author = {M{\"o}rters, Peter and Peres, Yuval},
	Date-Added = {2017-08-23 15:23:21 +0000},
	Date-Modified = {2018-02-16 15:22:05 +0000},
	Publisher = {Cambridge University Press},
	Title = {Brownian Motion},
	Volume = {30},
	Year = {2010}}

@book{bovier2016metastability,
	Author = {Bovier, Anton and Den Hollander, Frank},
	Date-Added = {2017-08-22 19:36:03 +0000},
	Date-Modified = {2018-02-16 15:23:00 +0000},
	Publisher = {Springer},
	Title = {Metastability: A Potential-Theoretic Approach},
	Year = {2016}}

@article{laurent2000adaptive,
	Author = {Laurent, Beatrice and Massart, Pascal},
	Date-Added = {2017-08-21 21:07:56 +0000},
	Date-Modified = {2017-08-21 21:07:56 +0000},
	Journal = {Annals of Statistics},
	Pages = {1302--1338},
	Publisher = {JSTOR},
	Title = {Adaptive estimation of a quadratic functional by model selection},
	Year = {2000}}

@article{berglund2011kramers,
	Author = {Berglund, Nils},
	Date-Added = {2017-08-20 17:46:48 +0000},
	Date-Modified = {2017-08-20 17:46:48 +0000},
	Journal = {arXiv preprint arXiv:1106.5799},
	Title = {Kramers' law: Validity, derivations and generalisations},
	Year = {2011}}

@article{bovier2004metastability,
	Author = {Bovier, Anton and Eckhoff, Michael and Gayrard, V{\'e}ronique and Klein, Markus},
	Date-Added = {2017-08-20 16:24:20 +0000},
	Date-Modified = {2018-02-16 15:21:43 +0000},
	Journal = {Journal of the European Mathematical Society},
	Number = {4},
	Pages = {399--424},
	Title = {Metastability in reversible diffusion processes {I}: Sharp asymptotics for capacities and exit times},
	Volume = {6},
	Year = {2004}}
