\documentclass[final,12pt]{colt2018} % Anonymized submission
% \documentclass{colt2017} % Include author names

% The following packages will be automatically loaded:
% amsmath, amssymb, natbib, graphicx, url, algorithm2e



%%%%%% PACKAGES
\usepackage{times}		% for the front
\usepackage{minibox}		% for creating boxes
\usepackage{amsfonts} 	% for set notation (e.g. the integers)
\usepackage{bbm}			% for indicator function 
\usepackage[bf, format=plain, font={small, it}]{caption}


%%%%%% some COLT 2018 instructions
 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
  % \coltauthor{\Name{Author Name1} \Email{abc@sample.com}\and
  %  \Name{Author Name2} \Email{xyz@sample.com}\\
  %  \addr Address}

 % Three or more authors with the same address:
 % \coltauthor{\Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \addr Address}


 % Authors with different addresses:
 \coltauthor{\Name{Samory Kpotufe}\footnotemark \Email{samory@princeton.edu}\\
 \addr ORFE, Princeton University
 \AND
 \Name{Guillaume Martinet}\footnotemark \Email{ggm2@princeton.edu}\\
 \addr ORFE, Princeton University
 }

%%%%%% PERSONAL DEFS 

% definitions of assumptions
\newtheorem{assumption}{Assumption}
\newcommand{\thisHypName}{}
\newtheorem*{genericHyp}{\thisHypName}
\newenvironment{namedHyp}[1]
  {\renewcommand{\thisHypName}{#1}%
   \begin{genericHyp}}
  {\end{genericHyp}}

% Define all the variables
% metric and space
\newcommand{\spa}{\mathcal{X}}
\newcommand{\labSpa}{\mathcal{Y}}
\newcommand{\dist}{\rho}
\newcommand{\vcDim}{\mathcal{V}_{\mathcal{B}}}
\newcommand{\diam}{\text{diam}}
\newcommand{\cBall}[2]{B(#1 , #2 )}
\newcommand{\ballColl}{\mathcal{B}}

% distributions and their domains
\newcommand{\tJoinProb}{Q}
\newcommand{\sJoinProb}{P}
\newcommand{\featVar}{X}
\newcommand{\labVar}{Y}
\newcommand{\tProb}{\tJoinProb_{\featVar}}
\newcommand{\sProb}{\sJoinProb_{\featVar}}
\newcommand{\sCondProb}{\sJoinProb_{\labVar | \featVar}}
\newcommand{\tCondProb}{\tJoinProb_{\labVar | \featVar}}
\newcommand{\sReCondProb}[1]{\sJoinProb_{\labVar | #1}}
\newcommand{\tReCondProb}[1]{\tJoinProb_{\labVar | #1}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\empSProb}{\hat{\sProb}}
\newcommand{\empTProb}{\hat{\tProb}}
\newcommand{\sDom}{\mathcal{X}_{\sJoinProb}}
\newcommand{\tDom}{\mathcal{X}_{\tJoinProb}}
\newcommand{\regFct}{\eta}
\newcommand{\empRegFct}{\hat{\regFct}}
\newcommand{\family}{\mathcal{T}}
\newcommand{\dmFam}{\family_{\dm}}
\newcommand{\bcnFam}{\family_{\bcn}}

% sample sizes and data
\newcommand{\totN}{n}
\newcommand{\nn}{k}
\newcommand{\labVarHat}{\hat{\labVar}}
%\newcommand{\indX}{I}
%\newcommand{\labIndX}{R}
%\newcommand{\labIndXK}{\labIndX_{known}}
%\newcommand{\labIndXG}{\labIndX_{guessed}}
\newcommand{\sN}{n_{\sJoinProb}}
\newcommand{\tN}{n_{\tJoinProb}}
%\newcommand{\sampleBase}{{\bf S}}
\newcommand{\sampleBase}{({\bf X, Y})}
\newcommand{\sample}{\sampleBase}
\newcommand{\sSample}{\sampleBase_{\sJoinProb}}
\newcommand{\tSample}{\sampleBase_{\tJoinProb}}
%\newcommand{\rSample}{\sampleBase_{\labIndX}}
%\newcommand{\rHatSample}{\hat{\sampleBase}_{\labIndX}}
\newcommand{\featVectBase}{\bold{\featVar}}
\newcommand{\featVect}{\featVectBase}
\newcommand{\sFeatVect}{\featVectBase_{\sJoinProb}}
\newcommand{\tFeatVect}{\featVectBase_{\tJoinProb}}
%\newcommand{\rFeatVect}{\featVectBase_{\labIndX}}
\newcommand{\labVectBase}{\bold{\labVar}}
\newcommand{\labVect}{\labVectBase}
\newcommand{\sLabVect}{\labVectBase_{\sJoinProb}}
\newcommand{\tLabVect}{\labVectBase_{\tJoinProb}}

% stuff related to classifiers
\newcommand{\err}{\text{err}_{\tJoinProb}}
\newcommand{\exErr}{\mathcal{E}_{\tJoinProb}}
\newcommand{\h}{h}
\newcommand{\hStar}{h^{*}}
\newcommand{\hHat}{\hat{\h}}
\newcommand{\hHatR}{\hHat_{\labIndX}}
\newcommand{\hP}{h_{\sJoinProb}}
%\newcommand{\hPQ}{h_{\sJoinProb, \tJoinProb} }
\newcommand{\hPQ}{\hat{h}_{k} }
\newcommand{\hR}{h_{\labIndX} }
\newcommand{\hI}{h_{\indX} }
\newcommand{\empReg}{\hat{\regFct}}
\newcommand{\empRegPQ}{_{\nn, \sJoinProb, \tJoinProb}}
\newcommand{\empRegR}{\empReg_{\nn, \labIndX}}
\newcommand{\empRegI}{\empReg_{\nn, \indX}}
\newcommand{\empRegP}{\empReg_{\nn, \sJoinProb}}
\newcommand{\realR}{r}
\newcommand{\empR}{\hat{\realR}}
\newcommand{\realRPQ}{\realR_{\nn, \sJoinProb, \tJoinProb}}
\newcommand{\empRPQ}{\empR_{\nn, \sJoinProb, \tJoinProb}}
\newcommand{\realRPQTilde}{\realR_{\tilde{\nn}, \sJoinProb, \tJoinProb}}
\newcommand{\empRPQTilde}{\empR_{\tilde{\nn}, \sJoinProb, \tJoinProb}}
\newcommand{\varNum}{\delta}
\newcommand{\errBnd}{\Delta}
\newcommand{\empErrBnd}{\hat{\Delta}}
\newcommand{\empErrBndPQ}{\empErrBnd_{\nn,\sJoinProb,\tJoinProb}}
\newcommand{\errBndPQ}{\errBnd_{\nn,\sJoinProb,\tJoinProb}}
\newcommand{\nnFeat}[2]{\featVar_{(#1)}^{#2}}
\newcommand{\nnLab}[2]{\labVar_{(#1)}^{#2}}
\newcommand{\nnRatio}{D}
\newcommand{\guessT}{\hat{t}}

% general assumptions stuff
\newcommand{\holderExp}{\alpha}
\newcommand{\holderCoeff}{C_{\holderExp}}
\newcommand{\tTsyCoeff}{C_{\tTsyExp}}
\newcommand{\tTsyExp}{\beta}
\newcommand{\transMargin}{\Gamma}

% special settings stuff
\newcommand{\domBnd}{D}
\newcommand{\sCovCoeff}{C_{\sJoinProb}}

\newcommand{\sCovDim}{d}
\newcommand{\tCovDim}{d}
\newcommand{\sDmCoeff}{C_{\sJoinProb}}
\newcommand{\tCovCoeff}{C_{\tCovDim}}

\newcommand{\sDmDim}{d}
\newcommand{\tDmDim}{d}
\newcommand{\tDmCoeff}{C_{\tDmDim}}
\newcommand{\transMarginCoeff}{C_{\transMarginExp}}
\newcommand{\transMarginExp}{\gamma}

% Define the hypotheses
\newcommand{\comp}{(COMP)}
\newcommand{\included}{(IN)}
\newcommand{\dom}{(DOM)}
\newcommand{\bcn}{\text{(BCN)}}
\newcommand{\dm}{\text{(DM)}}

% definitions of new commands for convergence rate theorem
\newcommand{\diamDom}{\Delta_\spa} 
\newcommand{\thmParam}{\epsilon} 
\newcommand{\thmParamProb}{p} 
\newcommand{\bigElement}{\Phi} 
\newcommand{\varConst}{C_0} 
\newcommand{\biasConst}{C}

% lower bound theorem params
\newcommand{\dmLbConst}{c}
\newcommand{\s}{s}

% miscellaneous
\newcommand{\diff}{\, \text{d}}
\newcommand{\upConst}{C}
\newcommand{\lowConst}{c}
\newcommand{\rates}{d_0}

% lower bound notations
\newcommand{\M}{M}
\newcommand{\m}{m}
\newcommand{\alp}{\kappa}
\newcommand{\semiMetric}{\bar \rho}
\newcommand{\semiDist}[2]{\semiMetric \left( #1 , #2 \right)}
\newcommand{\KLDiv}[2]{\mathcal{D}_{\text{kl}} \left(#1 | #2 \right)}
\newcommand{\radius}{r}
\newcommand{\tempRadius}{r'}
\newcommand{\w}{w}
\newcommand{\wConst}{\lowConst_{\w}}
\newcommand{\rConst}{\lowConst_{\radius}}
\newcommand{\mConst}{\lowConst_{\m}}
\newcommand{\grid}{\mathcal{Z}}
\newcommand{\p}{z}
\newcommand{\ball}{B}
\newcommand{\inSet}{C^{in}}
\newcommand{\outSet}{C^{out}}

\newcommand{\lbda}{q}
\newcommand{\PDensity}{p}
\newcommand{\phiD}{\phi_{\tDmDim}}
\newcommand{\holderFct}{u}
\newcommand{\sig}{\sigma}
\newcommand{\hammingDist}[2]{\rho_{H}\left(#1,#2 \right)}
\newcommand{\sampleDist}{\Pi}
\newcommand{\modelClass}{\mathcal{H}}

% adaptative result notations
\newcommand{\coverSet}{R}
\newcommand{\nnZero}{\nn_{0}}
\newcommand{\lowerBd}{\hat \eta^\text{-}}
\newcommand{\upperBd}{\hat \eta^\text{+}}
\newcommand{\nR}{\totN_{\coverSet}}
\newcommand{\est}{\hat \eta }

\DeclareMathOperator*{\Expectation}{\mathbb{E}}

\newcounter{myremark}[chapter]
\newenvironment{myremark}[1][]{\refstepcounter{myremark}\medskip
 \noindent\textbf{Remark~\themyremark \hspace{0.1mm} (#1)} \rmfamily}{\medskip}

 %\usepackage{amsthm}
 
 \newtheorem{mydefinition}{Definition}%[mydef]
 
 \newtheorem{myproposition}{Proposition}
 
 
%\theoremstyle{remark} 
%\newtheorem{myremark}{Remark}  

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


% \noindent\textbf{Definition~\themydefinition \hspace{0.1mm} (#1)} \rmfamily}{\medskip}
 
 

%%%%%%%%% END OF PERSONAL DEFS

%%%%% DOCUMENT BEGIN %%%%%
\title[Minimax Transfer]{Marginal Singularity, and the Benefits of Labels in Covariate-Shift}

\begin{document}

%%% TITLE %%%
\maketitle


%%% ABSTRACT %%%
\begin{abstract} \blfootnote{* $\dagger$ Authors are listed in alphabetical order.} \blfootnote{Extended abstract. Full version appears as 
arXiv:1803.01833v2.} 
We present new minimax results that concisely capture the relative benefits of source and target labeled data, under {covariate-shift}. Namely, we show that, in general classification settings, the benefits of target labels are controlled by a \emph{transfer-exponent} $\gamma$ that encodes how \emph{singular} $Q$ is locally w.r.t. $P$, and interestingly allows situations where transfer did not seem possible under previous insights. In fact, our new minimax analysis -- in terms of $\gamma$ -- reveals a \emph{continuum of regimes} ranging from situations where target labels have little benefit, to regimes where target labels dramatically improve classification. 
We then show that a recently proposed semi-supervised procedure can be extended to adapt to unknown $\gamma$, and therefore requests target labels only when beneficial, while achieving nearly minimax transfer rates. 
\end{abstract}

%%% KEY WORDS %%%
\begin{keywords}
Transfer learning, covariate-shift, nonparametric classification, nearest-neighbors.
\end{keywords}
\text{} 

\section*{Extended Abstract}
\subsection*{Introduction}
The goal in transfer learning is to improve prediction on a \emph{target} distribution $Q$ by harnessing labeled data coming from a \emph{source} distribution $P$. Much of theoretical work in transfer learning concerns understanding the fundamental limitations of transfer, and in particular, proper ways of capturing \emph{relatedness} between source $P$ and target $Q$. Here we consider the common \emph{covariate-shift} setting for classification, where it is assumed that conditional distributions $P_{Y|X}$ and $Q_{Y|X}$ remain the same, while marginals $P_X$, $Q_X$ are different but somewhat related. 

We consider general nonparametric settings that capture a range of easy to difficult classification under $Q$, through standard smoothness and noise conditions (see e.g. \cite{audibert2007fast}). Our aim is then to understand which relation between marginals $P_X$ and $Q_X$ control the rates of transfer, and in particular, control the relative benefits between source and target data in achieving low error under $Q$. 
A basic intuition, present in previous work, is that transfer is easiest when $P$ assigns sufficient mass to regions of considerable $Q$-mass. Here, we formalize this intuition through a new \emph{asymmetric} notion, the \emph{transfer-exponent} $\gamma$, that parametrizes the behavior of ball-mass ratios $Q_X(B(x,r))/ P_X(B(x,r))$ as a function of the radius $r$, namely, that these ratios behave like $r^{-\gamma}$. The notion of $\gamma$ can be interpreted, roughly, as capturing how close to \emph{singular} $Q$ is with respect to $P$, as it shifts mass into regions of low $P$ mass. 

We show the pertinence of our parametrization by establishing tight minimax upper and lower bounds in terms of $\gamma$, under standard nonparametric conditions. The notion of $\gamma$ is thus shown to encode a \emph{continuum of regimes} between easy and hard transfer, 
and interestingly, reveals situations where transfer is possible (even at fast rates) despite $P$ and $Q$ seeming \emph{unrelated} under previous notions of \emph{relatedness}. As an example, $\gamma$ remains well defined even when Q is singular w.r.t. P (e.g. $Q$ puts mass on lower-dimensional structures) â€“ in which case common notions of density-ratio and information-theoretic divergences (KL or Renyi) fail to exist, and common extensions of total-variation can be too large to characterize transfer. 

Finally, we show that a recently proposed semi-supervised procedure can be extended to adapt to unknown $\gamma$, and therefore requests target labels only when beneficial, while achieving nearly minimax transfer rates. 

\subsection*{Related Work}
Many insightful notions of \emph{relatedness} are present in the literature on transfer and related problems. 

A first line of work considers refinements of total-variation which encode changes in classification error from $P$ to $Q$ (restricted to a hypothesis class $\mathcal{H}$). The most common such measures are the so-called $d_{\mathcal{A}}$-divergence \citep{ben2010theory, david2010impossibility, germain2013pac} and $\mathcal{Y}$-discrepancy \citep{mansour2009domain, mohri2012new, cortesadaptation}. These notions are the first to capture -- through \emph{differences} in mass over space -- the intuition that transfer is easiest when $P$ has sufficient mass in regions of substantial $Q$-mass. Typical excess-error bounds on classifiers learned from source (and some or no target) data are of the form $o_p(1) + C\cdot \text{divergence}(P, Q)$. In other words, 
transfer seems impossible when these divergences are large; however, we show that there are ranges of reasonable situations ($0\leq \gamma < \infty$) where fast transfer is possible even when such divergences are large. Furthermore, while such divergences are symmetric, the notion of $\gamma$ is not, thus capturing the fact that transfer might be easy from $P$ to $Q$ but not from $Q$ to $P$. 

Another prominent line or work, which has led to many practical procedures, considers so-called density-ratios $f_Q/f_P$ or more generally, Radon-Nikodym derivatives $dQ/dP$, as a way to capture the similarity between $P$ and $Q$ 
\citep{quionero2009dataset, sugiyama2012density}. It is often assumed in such work that $dQ/dP$ is bounded, 
which corresponds to assuming $\gamma = 0$. Typical excess-error bounds are dominated by the estimation rates for $dQ/dP$ (see e.g. rates for $\alpha$-H\"older $dQ/dP$, $\alpha\to 0$, in \cite{kpotufe2017lipschitz}), which unfortunately could be arbitrarily higher than the minimax rates we establish for the boundary case with $\gamma = 0$.

Finally, another line of work instead considers information-theoretic measures such as KL-divergence or Renyi divergence 
\citep{sugiyama2008direct, mansour2009multiple}. In particular, such divergences are closer in spirit to our notion of 
transfer-exponent $\gamma$ (viewing $\gamma$ as roughly characterizing the log of mass-ratios between), but are also undefined in typical scenarios with structured data where $Q_X$ might be singular w.r.t. $P_X$. 

\subsection*{Result Overview}

Our first results consider transfer settings where the learner has access to $n_{P}$ labeled samples drawn from $P$ and $n_{Q}$ labeled samples drawn from $Q$, where typically $n_{P} \gg n_{Q}$. The label $Y$ is assumed in $\{0, 1\}$, while the input $X$ belongs to a compact metric space $\mathcal{X}$. 

We work under common smoothness and low noise conditions, namely, we assume the \emph{regression function} $\eta(x) \doteq E[Y|X=x]$ to be $\alpha$--H\"{o}lder, and also that $\tProb \left( 0 < \left| \regFct(\featVar) - 1/2 \right| \leq t \right) \lesssim t^{\tTsyExp}$ (see e.g. \cite{audibert2007fast}). A \emph{transfer exponent} is then defined, roughly, as any quantity $\gamma$ that satisfies:
\begin{equation*} 
\forall x, \forall  \text{ small } r, \quad \sProb(\cBall{x}{r}) \gtrsim \tProb(\cBall{x}{r}) \cdot r^{\transMarginExp}.
\end{equation*}

Two main distributional regimes are considered, which capture the difficulty of vanilla classification under $Q_{X}$. The first regime, $\text{(DM)}$ (for \emph{doubling measure}), roughly assumes that $Q_X$ behaves like a uniform measure on its support (this is the most common assumption in nonparametric classification, and is sometimes termed the \emph{strong-density assumption}). The second regime, $\text{(BCN)}$ (for \emph{bounded covering number}), allows for general $Q_X$ and is most difficult with slower rates. Both regimes 
introduce a parameter $d$ that might be viewed as a notion of \emph{dimension} of the marginal $Q_X$. 

For exact definitions we refer the reader to the archived version of this work \citep{kpotufe2018marginal}). 

Our minimax rates are then of the following form.

\begin{theorem} [Sketch] \label{thm:minimaxLowerBound}
Call $\mathcal{T}_{\text{(DM)}}$ (resp. $\mathcal{T}_{\text{(BCN)}}$) the class of all the tuples $(P,Q)$ under $\text{(DM)}$ (resp. $\text{(BCN)}$) regime. Let $\mathcal{T} \in \{\mathcal{T}_{\text{(DM)}},\mathcal{T}_{\text{(BCN)}}\}$, we have then:
\begin{equation*}
\inf_{\hat{h}}\sup_{(\sJoinProb, \tJoinProb) \in \family} \mathbb{E}[\exErr(\hat h)] \asymp \left( \sN ^{\rates / (\rates + \transMarginExp / \holderExp)} + \tN \right)^{ -(\tTsyExp + 1) / \rates}, 
\end{equation*}
where $\exErr$ represents the excess error, the infimum is taken over all classifiers $\hat{h}$ learned on the data, the expectation is taken w.r.t.~the data, $\rates = 2  + \tCovDim / \holderExp$ when $\family = \dmFam$, and $\rates = 2 + \tTsyExp + \tCovDim / \holderExp$ when $\family = \bcnFam$.
\end{theorem}

Our upper-bounds are established with a generic
$k$-NN classifier defined over the combined source and target sample. In particular, our results imply
new convergence rates of independent interest for vanilla $k$-NN under the $\text{BCN}$ regime, which complements recent developments on vanilla $k$-NN \citep{samworth2012optimal, chaudhuri2014rates, shalev2014understanding,gadat2014classification}. On the other hand, our lower-bounds are established over any learner with access to both source and target samples, and interestingly, which is also allowed access to infinite unlabeled source and target data (i.e., full knowledge of $P_X$ and $Q_X$). In other words, the above rates cannot be improved (beyond constants) with access to unlabeled data, which is often an important consideration in practice given the cost of target labels \citep{huang2007correcting, ben2012hardness}.

Finally, we address semi-supervised situations where the learner has access to $n_Q$ \emph{unlabeled} target data, along with $n_P$ labeled source data, and is allowed to request (as few as possible) target labels 
in order to improve classification \citep{saha2011active, chen2011co, pmlr-v28-chattopadhyay13}. An early theoretical treatment of this can be found in \citep{yang2013theory}, but which however considers a transfer setting with fixed marginal but varying conditionals (labeling functions). For our setting of covariate-shift, we build on a recent approach of \cite{berlind2015active} which constructs so-called $k$-$2k$ covers, to help limit label requests to regions of low $P$ mass. In this work, we show a strategy for choosing $k$ from data (building on so-called \emph{Lepski's method} \citep{lepski1997optimal}), so as to nearly attain the above minimax rates with no a priori knowledge of distributional parameters, nor of $\gamma$. Furthermore, labeling complexity is shown to be controlled by unknown $\gamma$, i.e. the resulting approach requests labels only when \emph{useful}, as controlled by $\gamma$ and relative sample sizes $n_P, n_Q$. 



\bibliography{refs}



\end{document}