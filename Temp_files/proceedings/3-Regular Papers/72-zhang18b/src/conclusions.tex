\section{Conclusions and future work}

We give a computationally efficient PAC active halfspace learning algorithm that enjoys sharp attribute efficient label complexity bounds.
It combines the margin-based framework of~\cite{BBZ07,BL13} with iterative hard thresholding~\citep{BD09, GK09}.
The main novel technical component in our analysis is a uniform concentration bound of hinge losses over shrinking $\ell_1$ balls in the sampling regions.
We outline several promising directions of future research:
\begin{itemize}
\item Can we extend our algorithm to work under $\eta$-bounded noise, when $\eta$ is arbitrarily close to $\frac 1 2$? Recall that the results of \cite{ZC14}
imply a computationally inefficient algorithm with a label complexity of $O(\frac{t \ln d}{(1-2\eta)^2} \ln \frac 1 \epsilon)$ in this setting,
which state of the art computationally efficient algorithms~\citep[e.g.][]{ABHZ16} cannot achieve.
%A promising direction is to ``activize'' existing computationally and attribute efficient online halfspace learning algorithms, e.g.~\cite{L87, GLS01, G03}, as is done in the full-dimensional setting~\citep{DKM05, YZ17}.

\item Can we design attribute and computationally efficient active learning algorithms that work under broader distributions? Existing results in the active learning and one-bit compressed sensing literature have made substantial progress on settings when the unlabeled distribution is $\alpha$-stable~\citep{L16}, subgaussian~\citep{ALPV14, CB15}, or $s$-concave~\citep{BZ17}; an attribute and computationally efficient, statistically consistent recovery algorithm under any of the above settings would be a step forward.

%Recent work~\citep{L16} shows that when
%the unlabeled distribution is $\alpha$-stable for small $\alpha$, then the support of the target vector can be provably recovered. Can one approximately recover the target halfspace under this distribution?
%Can the result of \cite{L16} be extended to approximately
%recover $u$?

\item In one-bit compressed sensing, under the symmetric noise condition~\citep{PV13b}, algorithms with sample complexity polynomial in $\frac 1 \epsilon$ have been proposed~\citep{PV13b, ZYJ14, ZG15}.
Can we develop adaptive one-bit compressed sensing algorithms with $O(t \polylog(d,\frac 1 \epsilon))$ measurement complexity in this setting?
\end{itemize}
