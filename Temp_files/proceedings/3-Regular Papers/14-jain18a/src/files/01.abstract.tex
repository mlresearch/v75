

There is widespread sentiment that fast gradient methods (\emph{e.g.}
Nesterov's acceleration, conjugate gradient, heavy ball) are not
effective for the purposes of stochastic optimization due to their
instability and error accumulation. Numerous works have attempted to
quantify these instabilities in the face of either statistical or
non-statistical
errors~\citep{Paige71,Proakis74,Polyak87,Greenbaum89,DevolderGN14}.
This work considers these issues for the special case of
stochastic approximation for the least squares regression problem, and
our main result refutes this conventional wisdom by showing that
acceleration can be made robust to statistical errors.  In
particular, this work introduces an accelerated stochastic gradient
method that provably achieves the minimax optimal statistical risk
faster than stochastic gradient descent.  Critical to the analysis is
a sharp characterization of accelerated stochastic gradient descent as
a stochastic process. We hope this characterization gives insights
towards the broader question of designing simple and effective
accelerated stochastic methods for more general convex and non-convex
optimization problems.


\iffalse
There is widespread sentiment that fast gradient methods (\emph{e.g.}
Nesterov's acceleration, conjugate gradient, heavy ball) are not
effective for the purposes of stochastic optimization due to their
instability and error accumulation, a notion made precise
in~\cite{dAspremont08,DevolderGN14}.  This work considers the use of
fast gradient methods for the special case of stochastic approximation for the
least squares regression problem.  Our main
result refutes the conventional wisdom by showing that acceleration can
be made robust to \emph{statistical} errors.  In particular, this work
introduces an accelerated stochastic gradient method that provably
achieves the minimax optimal statistical risk faster than stochastic
gradient descent.  Critical to the analysis is a sharp
characterization of accelerated stochastic gradient descent as a
stochastic process. We hope this characterization gives insights
towards the broader question of designing simple and effective
accelerated stochastic methods for more general convex and non-convex
optimization problems.
\fi