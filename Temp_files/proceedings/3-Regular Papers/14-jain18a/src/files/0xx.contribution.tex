In summary, the main contributions of this work are:
\begin{itemize}
\item We propose the first tail-averaged Accelerated Stochastic Gradient Algorithm for the Stochastic Approximation setting, by considering the case of strongly convex streaming least squares regression. Incidentally, this algorithm is a direct primal Accelerated Algorithm.
\item We introduce several tools for analyzing the proposed algorithm, including a new potential function that is used to track the rate of initial error (bias) decay.
\item The Algorithm is shown to obtain minimax optimal statistical error rates on a per problem basis, thus staking a new (and surprising) claim that acceleration is robust to statistical noise and errors in the gradient.
\end{itemize}