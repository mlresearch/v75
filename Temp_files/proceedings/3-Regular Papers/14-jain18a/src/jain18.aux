\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{Paige71,Proakis74,Polyak87,Greenbaum89,DevolderGN14}
\citation{BottouB07}
\citation{NemirovskyY83}
\citation{Zhu16}
\citation{FrostigGKS15}
\citation{JainKKNS16}
\citation{FrostigGKS15,JainKKNS16}
\citation{Zhu16}
\citation{FrostigGKS15,JainKKNS16}
\citation{Zhu16}
\providecommand \oddpage@label [2]{}
\jmlr@workshop{31st Annual Conference on Learning Theory}
\jmlr@title{Accelerating Stochastic Gradient Descent}{Accelerating Stochastic Gradient Descent for Least Squares Regression}
\jmlr@author{\Name {Prateek Jain}\Email {prajain@microsoft.com}\\ \Name {Praneeth Netrapalli}\Email {praneeth@microsoft.com}\\ \addr Microsoft Research, Bangalore, India \AND \Name {Sham M. Kakade} \Email {sham@cs.washington.edu}\\ \Name {Rahul Kidambi} \Email {rkidambi@uw.edu}\\ \addr University of Washington, Seattle, WA, USA \AND \Name {Aaron Sidford} \Email {sidford@stanford.com}\\ \addr Stanford University, Palo Alto, CA, USA }{\Name {Prateek Jain}\Email {prajain@microsoft.com}\\ \Name {Praneeth Netrapalli}\Email {praneeth@microsoft.com}\\ \addr Microsoft Research, Bangalore, India \AND \Name {Sham M. Kakade} \Email {sham@cs.washington.edu}\\ \Name {Rahul Kidambi} \Email {rkidambi@uw.edu}\\ \addr University of Washington, Seattle, WA, USA \AND \Name {Aaron Sidford} \Email {sidford@stanford.com}\\ \addr Stanford University, Palo Alto, CA, USA }
\newlabel{jmlrstart}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.0.1}}
\newlabel{eq:objFun}{{1}{1}{Introduction}{equation.0.1.1}{}}
\newlabel{eq:stochFirstOrderOracle}{{2}{1}{Introduction}{equation.0.1.2}{}}
\citation{KushnerClark,PolyakJ92,lehmann1998theory,Vaart00}
\citation{Ruppert88,PolyakJ92}
\citation{Cauchy1847}
\citation{Nesterov04}
\citation{Nesterov83}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of this work to the best known non-asymptotic results\nobreakspace  {}\citep  {FrostigGKS15,JainKKNS16} for the least squares stochastic approximation problem.\ Here, $d,n$ are the problem dimension, number of samples; ${\kappa }$, $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \kappa $}\mathaccent "0365{\kappa }$ denote the condition number and statistical condition number of the distribution; $\sigma ^2$, $P(\xt [0])-P(\xt [*])$ denote the noise level and initial excess risk, $\mathcal  {O}^*$ hides lower order terms in $d,{\kappa },\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \kappa $}\mathaccent "0365{\kappa }$ (see section\nobreakspace  {}\ref  {sec:prob} for definitions and a proof for $\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle \kappa $}\mathaccent "0365{\kappa }\leq {\kappa }$). Note that Accelerated SVRG\nobreakspace  {}\citep  {Zhu16} is not a streaming algorithm. }}{2}{table.1}}
\newlabel{tab:comp}{{1}{2}{Comparison of this work to the best known non-asymptotic results~\citep {FrostigGKS15,JainKKNS16} for the least squares stochastic approximation problem.\iffalse See section~\ref {sec:related} for related work.\fi \ Here, $d,n$ are the problem dimension, number of samples; $\cnH $, $\cnS $ denote the condition number and statistical condition number of the distribution; $\sigma ^2$, $P(\xt [0])-P(\xt [*])$ denote the noise level and initial excess risk, $\mathcal {O}^*$ hides lower order terms in $d,\cnH ,\cnS $ (see section~\ref {sec:prob} for definitions and a proof for $\cnS \leq \cnH $). Note that Accelerated SVRG~\citep {Zhu16} is not a streaming algorithm}{table.1}{}}
\newlabel{eq:ERMVarianceAdditive}{{3}{2}{Introduction}{equation.0.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Review: Acceleration with Exact Gradients}{2}{subsection.0.1.1}}
\newlabel{sec:background}{{1.1}{2}{Review: Acceleration with Exact Gradients}{subsection.0.1.1}{}}
\citation{Nesterov04}
\citation{HestenesS52}
\citation{Polyak64}
\citation{JainKKNS16}
\citation{JainKKNS16}
\citation{JainKKNS16}
\citation{FrostigGKS15}
\citation{FrostigGKS15}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plot of total error vs number of samples for averaged SGD and the minimax risk (green) of $d\sigma ^2/n$ for the discrete and Gaussian distributions with $d=50$, ${\kappa }\approx 10^5$ (see section\nobreakspace  {}\ref  {sec:exp} for details on the distribution). The kink in the SGD curve represents when the tail-averaging phase begins\nobreakspace  {}\citep  {JainKKNS16}; this point is chosen appropriately. The vertical dashed line shows the sample size at which the empirical covariance, $\frac  {1}{n}\DOTSB \sum@ \slimits@ _{i=1}^n \mathbf  {a}_i\mathbf  {a}_i^{\top }$, becomes full rank, which is shown at $\frac  {1}{\qopname  \relax m{min}_i p_{i}}$ in the discrete case and $d$ in the Gaussian case. With fewer samples than this (i.e. before the dashed line), it is information theoretically not possible to guarantee non-trivial risk (without further assumptions). For the Gaussian case, note how the behavior of SGD is far from the minimax risk; it is this behavior that one might hope to improve upon. See the text for more discussion. }}{3}{figure.1}}
\newlabel{fig:exp}{{1}{3}{Plot of total error vs number of samples for averaged SGD and the minimax risk (green) of $d\sigma ^2/n$ for the discrete and Gaussian distributions with $d=50$, $\cnH \approx 10^5$ (see section~\ref {sec:exp} for details on the distribution). The kink in the SGD curve represents when the tail-averaging phase begins~\citep {JainKKNS16}; this point is chosen appropriately. The vertical dashed line shows the sample size at which the empirical covariance, $\frac {1}{n}\sum _{i=1}^n \a _i\a _i\T $, becomes full rank, which is shown at $\frac {1}{\min _i p_{i}}$ in the discrete case and $d$ in the Gaussian case. With fewer samples than this (i.e. before the dashed line), it is information theoretically not possible to guarantee non-trivial risk (without further assumptions). For the Gaussian case, note how the behavior of SGD is far from the minimax risk; it is this behavior that one might hope to improve upon. See the text for more discussion}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}A thought experiment: Is Accelerating Stochastic Approximation possible?}{3}{subsection.0.1.2}}
\newlabel{sec:exp}{{1.2}{3}{A thought experiment: Is Accelerating Stochastic Approximation possible?}{subsection.0.1.2}{}}
\citation{JainKKNS16}
\citation{Paige71,Proakis74,Polyak87,Greenbaum89,RoyS90,SharmaSB98,dAspremont08,DevolderGN13,DevolderGN14,YuanYS16}
\citation{HsuKZ14}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plot of total error vs number of samples for averaged SGD, (this paper's) accelerated SGD method and the minimax risk for the discrete and Gaussian distributions with $d=50,{\kappa }\approx 10^5$ (see section\nobreakspace  {}\ref  {sec:exp} for details on the distribution). For the discrete case, accelerated SGD mimics SGD, which nearly matches the minimax risk (when it becomes well defined). For the Gaussian case, accelerated SGD significantly improves upon SGD. }}{4}{figure.2}}
\newlabel{fig:res}{{2}{4}{Plot of total error vs number of samples for averaged SGD, (this paper's) accelerated SGD method and the minimax risk for the discrete and Gaussian distributions with $d=50,\cnH \approx 10^5$ (see section~\ref {sec:exp} for details on the distribution). For the discrete case, accelerated SGD mimics SGD, which nearly matches the minimax risk (when it becomes well defined). For the Gaussian case, accelerated SGD significantly improves upon SGD}{figure.2}{}}
\newlabel{eq:sgd_rate}{{4}{4}{A thought experiment: Is Accelerating Stochastic Approximation possible?}{equation.0.1.4}{}}
\citation{Nesterov12}
\citation{FrostigGKS15,JainKKNS16}
\citation{JainKKNS16}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison of averaged SGD with this paper's accelerated SGD in the absence of noise ($\sigma ^2=0$) for the Discrete and Gaussian distributions with $d=50,{\kappa }\approx 10^5$. Acceleration yields substantial gains over averaged SGD for the Gaussian case, while degenerating to SGD's behavior for the discrete case. See section\nobreakspace  {}\ref  {sec:exp} for discussion.}}{5}{figure.3}}
\newlabel{fig:bias}{{3}{5}{Comparison of averaged SGD with this paper's accelerated SGD in the absence of noise ($\sigma ^2=0$) for the Discrete and Gaussian distributions with $d=50,\cnH \approx 10^5$. Acceleration yields substantial gains over averaged SGD for the Gaussian case, while degenerating to SGD's behavior for the discrete case. See section~\ref {sec:exp} for discussion}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Contributions}{5}{subsection.0.1.3}}
\newlabel{sec:res}{{1.3}{5}{Contributions}{subsection.0.1.3}{}}
\citation{DefossezB15}
\citation{DieuleveutB15,JainKKNS16}
\citation{RobbinsM51}
\citation{Ruppert88,PolyakJ92}
\citation{BachM11,Bach14,FrostigGKS15}
\citation{BachM13,DefossezB15,NeedellSW16,FrostigGKS15,JainKKNS16}
\citation{DefossezB15,DieuleveutB15}
\citation{NeedellSW16}
\citation{FrostigGKS15,JainKKNS16}
\citation{dAspremont08}
\citation{DevolderGN13,DevolderGN14}
\citation{Polyak87}
\citation{Polyak64}
\citation{HestenesS52}
\citation{Polyak87}
\citation{Paige71,Greenbaum89}
\citation{WidrowS85}
\citation{Proakis74,RoyS90,SharmaSB98}
\citation{YuanYS16}
\citation{YuanYS16}
\citation{Proakis74,RoyS90,SharmaSB98,YuanYS16}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Related Work}{6}{subsection.0.1.4}}
\newlabel{sec:related}{{1.4}{6}{Related Work}{subsection.0.1.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Non-asymptotic Stochastic Approximation:}{6}{section*.1}}
\@writefile{toc}{\contentsline {paragraph}{Acceleration and Noise Stability:}{6}{section*.2}}
\citation{anbar1971optimal,Fabian:1973:AES,KushnerClark,PolyakJ92}
\citation{NemirovskyY83}
\citation{PolyakJ92}
\citation{lehmann1998theory,Vaart00}
\citation{BachM13,Bach14,DefossezB15,DieuleveutB15,NeedellSW16,FrostigGKS15,JainKKNS16}
\citation{NemirovskyY83}
\citation{Lan08,HuKP09,ghadimi2012optimal,ghadimi2013optimal,DieuleveutFB16}
\citation{NemirovskyY83}
\citation{KushnerClark,KushnerY03}
\citation{NemirovskyY83}
\citation{Lan08,HuKP09,ghadimi2012optimal,ghadimi2013optimal,DieuleveutFB16}
\citation{PolyakJ92,BachM13,DefossezB15,DieuleveutB15,FrostigGKS15,JainKKNS16}
\citation{HuKP09,ghadimi2012optimal,ghadimi2013optimal,DieuleveutFB16}
\citation{ghadimi2012optimal,ghadimi2013optimal,DieuleveutFB16}
\@writefile{toc}{\contentsline {paragraph}{Oracle models and optimality:}{7}{section*.3}}
\newlabel{eq:stochFirstOrderOracle-diff}{{5}{7}{Oracle models and optimality:}{equation.0.1.5}{}}
\newlabel{eq:noiseModel2}{{6}{7}{Oracle models and optimality:}{equation.0.1.6}{}}
\citation{ShwartzZ14,FrostigGKS15b,LinMH15,LanZ15,Zhu16}
\citation{LanZ15,WoodworthS16}
\citation{FrostigGKS15}
\citation{BachM11,BachM13}
\citation{DefossezB15,JainKKNS16}
\@writefile{toc}{\contentsline {paragraph}{Acceleration and Finite Sums:}{8}{section*.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Main Results}{8}{section.0.2}}
\newlabel{sec:prob}{{2}{8}{Main Results}{section.0.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Assumptions and Definitions}{8}{subsection.0.2.1}}
\newlabel{asmp:finiteness}{{{{$\mathbf  {(\mathcal  A1)}$}}}{8}{Assumptions and Definitions}{Item.1}{}}
\newlabel{asmp:positiveDefinite}{{{{$\mathbf  {(\mathcal  A2)}$}}}{8}{Assumptions and Definitions}{Item.2}{}}
\citation{HsuKZ14}
\citation{Nesterov12}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces (Tail-Averaged) \textbf  {A}ccelerated \textbf  {S}tochastic \textbf  {G}radient \textbf  {D}escent (ASGD)}}{9}{algorithm.1}}
\newlabel{algo:TAASGD}{{1}{9}{Assumptions and Definitions}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Algorithm and Main Theorem}{9}{subsection.0.2.2}}
\newlabel{sec:results}{{2.2}{9}{Algorithm and Main Theorem}{subsection.0.2.2}{}}
\newlabel{thm:main}{{1}{9}{Algorithm and Main Theorem}{theorem.0.2.1}{}}
\citation{RobbinsM51}
\citation{PolyakJ92,JainKKNS16}
\citation{NemirovskyY83,RaginskyR11,AgarwalBRW12}
\citation{lehmann1998theory,Vaart00}
\citation{lehmann1998theory,Vaart00}
\citation{JainKKNS16}
\citation{FrostigGKS15}
\citation{JainKKNS16}
\citation{PolyakJ92}
\newlabel{cor:lowerOrder}{{2}{10}{Algorithm and Main Theorem}{theorem.0.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Discussion and Open Problems}{10}{subsection.0.2.3}}
\newlabel{sec:resultDiscussion}{{2.3}{10}{Discussion and Open Problems}{subsection.0.2.3}{}}
\newlabel{eq:ERMVariance}{{7}{10}{Discussion and Open Problems}{equation.0.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proof Outline}{10}{section.0.3}}
\newlabel{sec:proofoutline}{{3}{10}{Proof Outline}{section.0.3}{}}
\citation{BachM11,FrostigGKS15,JainKKNS16}
\citation{WilsonRJ16}
\newlabel{eqn:bound-covar}{{8}{11}{Proof Outline}{equation.0.3.8}{}}
\newlabel{eq:genErrorExp}{{9}{11}{Proof Outline}{equation.0.3.9}{}}
\newlabel{lem:average-covar-bias}{{3}{11}{Proof Outline}{theorem.0.3.3}{}}
\newlabel{lem:main-bias}{{4}{11}{Bias contraction}{theorem.0.3.4}{}}
\citation{RobbinsM51,PolyakJ92,JainKKNS16}
\citation{FrostigGKS15}
\@writefile{toc}{\contentsline {paragraph}{Remarks:}{12}{section*.5}}
\newlabel{lem:average-covar-var}{{5}{12}{Remarks:}{theorem.0.3.5}{}}
\newlabel{lem:main-variance}{{6}{12}{Stationary covariance}{theorem.0.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{12}{section.0.4}}
\newlabel{sec:conclusion}{{4}{12}{Conclusion}{section.0.4}{}}
\bibdata{refs}
\bibcite{AgarwalBRW12}{{1}{2012}{{Agarwal et~al.}}{{Agarwal, Bartlett, Ravikumar, and Wainwright}}}
\bibcite{Zhu16}{{2}{2016}{{Allen-Zhu}}{{}}}
\bibcite{anbar1971optimal}{{3}{1971}{{Anbar}}{{}}}
\bibcite{Bach14}{{4}{2014}{{Bach}}{{}}}
\bibcite{BachM11}{{5}{2011}{{Bach and Moulines}}{{}}}
\bibcite{BachM13}{{6}{2013}{{Bach and Moulines}}{{}}}
\bibcite{BottouB07}{{7}{2007}{{Bottou and Bousquet}}{{}}}
\bibcite{Cauchy1847}{{8}{1847}{{Cauchy}}{{}}}
\bibcite{dAspremont08}{{9}{2008}{{d'Aspremont}}{{}}}
\bibcite{DefossezB15}{{10}{2015}{{D{\'e}fossez and Bach}}{{}}}
\bibcite{DevolderGN13}{{11}{2013}{{Devolder et~al.}}{{Devolder, Glineur, and Nesterov}}}
\bibcite{DevolderGN14}{{12}{2014}{{Devolder et~al.}}{{Devolder, Glineur, and Nesterov}}}
\bibcite{DieuleveutB15}{{13}{2015}{{Dieuleveut and Bach}}{{}}}
\bibcite{DieuleveutFB16}{{14}{2016}{{Dieuleveut et~al.}}{{Dieuleveut, Flammarion, and Bach}}}
\bibcite{Fabian:1973:AES}{{15}{1973}{{Fabian}}{{}}}
\bibcite{FrostigGKS15b}{{16}{2015{a}}{{Frostig et~al.}}{{Frostig, Ge, Kakade, and Sidford}}}
\bibcite{FrostigGKS15}{{17}{2015{b}}{{Frostig et~al.}}{{Frostig, Ge, Kakade, and Sidford}}}
\bibcite{ghadimi2012optimal}{{18}{2012}{{Ghadimi and Lan}}{{}}}
\bibcite{ghadimi2013optimal}{{19}{2013}{{Ghadimi and Lan}}{{}}}
\bibcite{Greenbaum89}{{20}{1989}{{Greenbaum}}{{}}}
\bibcite{HestenesS52}{{21}{1952}{{Hestenes and Stiefel}}{{}}}
\bibcite{HsuKZ14}{{22}{2014}{{Hsu et~al.}}{{Hsu, Kakade, and Zhang}}}
\bibcite{HuKP09}{{23}{2009}{{Hu et~al.}}{{Hu, Kwok, and Pan}}}
\bibcite{JainKKNS16}{{24}{2016}{{Jain et~al.}}{{Jain, Kakade, Kidambi, Netrapalli, and Sidford}}}
\bibcite{KushnerClark}{{25}{1978}{{Kushner and Clark}}{{}}}
\bibcite{KushnerY03}{{26}{2003}{{Kushner and Yin}}{{}}}
\bibcite{Lan08}{{27}{2008}{{Lan}}{{}}}
\bibcite{LanZ15}{{28}{2015}{{Lan and Zhou}}{{}}}
\bibcite{lehmann1998theory}{{29}{1998}{{Lehmann and Casella}}{{}}}
\bibcite{LinMH15}{{30}{2015}{{Lin et~al.}}{{Lin, Mairal, and Harchaoui}}}
\bibcite{NeedellSW16}{{31}{2016}{{Needell et~al.}}{{Needell, Srebro, and Ward}}}
\bibcite{NemirovskyY83}{{32}{1983}{{Nemirovsky and Yudin}}{{}}}
\bibcite{Nesterov83}{{33}{1983}{{Nesterov}}{{}}}
\bibcite{Nesterov04}{{34}{2004}{{Nesterov}}{{}}}
\bibcite{Nesterov12}{{35}{2012}{{Nesterov}}{{}}}
\bibcite{Paige71}{{36}{1971}{{Paige}}{{}}}
\bibcite{Polyak64}{{37}{1964}{{Polyak}}{{}}}
\bibcite{Polyak87}{{38}{1987}{{Polyak}}{{}}}
\bibcite{PolyakJ92}{{39}{1992}{{Polyak and Juditsky}}{{}}}
\bibcite{Proakis74}{{40}{1974}{{Proakis}}{{}}}
\bibcite{RaginskyR11}{{41}{2011}{{Raginsky and Rakhlin}}{{}}}
\bibcite{RobbinsM51}{{42}{1951}{{Robbins and Monro}}{{}}}
\bibcite{RoyS90}{{43}{1990}{{Roy and Shynk}}{{}}}
\bibcite{Ruppert88}{{44}{1988}{{Ruppert}}{{}}}
\bibcite{ShwartzZ14}{{45}{2014}{{Shalev-Shwartz and Zhang}}{{}}}
\bibcite{SharmaSB98}{{46}{1998}{{Sharma et~al.}}{{Sharma, Sethares, and Bucklew}}}
\bibcite{Vaart00}{{47}{2000}{{van~der Vaart}}{{}}}
\bibcite{WidrowS85}{{48}{1985}{{Widrow and Stearns}}{{}}}
\bibcite{WilsonRJ16}{{49}{2016}{{Wilson et~al.}}{{Wilson, Recht, and Jordan}}}
\bibcite{WoodworthS16}{{50}{2016}{{Woodworth and Srebro}}{{}}}
\bibcite{YuanYS16}{{51}{2016}{{Yuan et~al.}}{{Yuan, Ying, and Sayed}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix setup}{16}{section.0.A}}
\newlabel{sec:setup}{{A}{16}{Appendix setup}{section.0.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Organization}{16}{subsection.0.A.1}}
\newlabel{ssec:org}{{A.1}{16}{Organization}{subsection.0.A.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Notations}{16}{subsection.0.A.2}}
\newlabel{ssec:notations}{{A.2}{16}{Notations}{subsection.0.A.2}{}}
\newlabel{eq:mainRec}{{10}{17}{Notations}{equation.0.A.10}{}}
\newlabel{eqn:theta-det}{{11}{17}{Notations}{equation.0.A.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}The Tail-Average Iterate: Covariance and bias-variance decomposition}{18}{section.0.B}}
\newlabel{sec:tailAverageIterateCovariance}{{B}{18}{The Tail-Average Iterate: Covariance and bias-variance decomposition}{section.0.B}{}}
\newlabel{eq:finalIterateCovariance}{{12}{18}{The Tail-Average Iterate: Covariance and bias-variance decomposition}{equation.0.B.12}{}}
\newlabel{eq:biasRec}{{13}{18}{The Tail-Average Iterate: Covariance and bias-variance decomposition}{equation.0.B.13}{}}
\newlabel{eq:varianceRec}{{14}{18}{The Tail-Average Iterate: Covariance and bias-variance decomposition}{equation.0.B.14}{}}
\newlabel{eq:condExpBias}{{15}{18}{The Tail-Average Iterate: Covariance and bias-variance decomposition}{equation.0.B.15}{}}
\newlabel{eq:condExpVar}{{16}{18}{The Tail-Average Iterate: Covariance and bias-variance decomposition}{equation.0.B.16}{}}
\citation{BachM13,FrostigGKS15,JainKKNS16}
\newlabel{eq:tailAvgCovarBound}{{17}{19}{The Tail-Average Iterate: Covariance and bias-variance decomposition}{equation.0.B.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}The tail-averaged iterate and its covariance}{20}{subsection.0.B.1}}
\newlabel{eq:tailAvgCovar}{{18}{20}{The tail-averaged iterate and its covariance}{equation.0.B.18}{}}
\newlabel{eq:biasTailAvg1}{{19}{21}{The tail-averaged iterate and its covariance}{equation.0.B.19}{}}
\newlabel{eq:varianceTailAvg1}{{20}{21}{The tail-averaged iterate and its covariance}{equation.0.B.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Covariance of Bias error of the tail-averaged iterate}{21}{subsection.0.B.2}}
\newlabel{eq:biasLP}{{21}{21}{Covariance of Bias error of the tail-averaged iterate}{equation.0.B.21}{}}
\newlabel{eq:biasTA}{{22}{22}{Covariance of Bias error of the tail-averaged iterate}{equation.0.B.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Covariance of Variance error of the tail-averaged iterate}{22}{subsection.0.B.3}}
\newlabel{eq:varianceLP}{{23}{22}{Covariance of Variance error of the tail-averaged iterate}{equation.0.B.23}{}}
\newlabel{eq:varianceTA}{{24}{23}{Covariance of Variance error of the tail-averaged iterate}{equation.0.B.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Useful lemmas}{23}{section.0.C}}
\newlabel{sec:commonLemmas}{{C}{23}{Useful lemmas}{section.0.C}{}}
\newlabel{lem:com3}{{7}{23}{Useful lemmas}{theorem.0.C.7}{}}
\newlabel{eq:ATInv}{{25}{24}{Useful lemmas}{equation.0.C.25}{}}
\newlabel{lem:com1}{{8}{24}{Useful lemmas}{theorem.0.C.8}{}}
\newlabel{lem:com2}{{9}{24}{Useful lemmas}{theorem.0.C.9}{}}
\newlabel{eq:intermediateEqn}{{26}{24}{Useful lemmas}{equation.0.C.26}{}}
\newlabel{lem:eig-A}{{10}{25}{Useful lemmas}{theorem.0.C.10}{}}
\newlabel{lem:lhs-psd-lemma}{{11}{25}{Useful lemmas}{theorem.0.C.11}{}}
\newlabel{lem:G-bound}{{12}{26}{Useful lemmas}{theorem.0.C.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Lemmas and proofs for bias contraction}{27}{section.0.D}}
\newlabel{sec:biasContraction}{{D}{27}{Lemmas and proofs for bias contraction}{section.0.D}{}}
\newlabel{eq:biasContraction}{{27}{27}{Lemmas and proofs for bias contraction}{equation.0.D.27}{}}
\newlabel{eq:gd}{{28}{27}{Lemmas and proofs for bias contraction}{equation.0.D.28}{}}
\newlabel{eq:1}{{29}{28}{Lemmas and proofs for bias contraction}{equation.0.D.29}{}}
\newlabel{eq:3}{{30}{28}{Lemmas and proofs for bias contraction}{equation.0.D.30}{}}
\newlabel{eq:2}{{31}{28}{Lemmas and proofs for bias contraction}{equation.0.D.31}{}}
\newlabel{eq:4}{{32}{28}{Lemmas and proofs for bias contraction}{equation.0.D.32}{}}
\newlabel{lem:B-contraction}{{13}{29}{Lemmas and proofs for bias contraction}{theorem.0.D.13}{}}
\newlabel{lem:bias-bound}{{14}{29}{Lemmas and proofs for bias contraction}{theorem.0.D.14}{}}
\newlabel{cor:bias-tail1}{{15}{30}{Lemmas and proofs for bias contraction}{theorem.0.D.15}{}}
\newlabel{lem:bound-bias}{{16}{31}{Lemmas and proofs for bias contraction}{theorem.0.D.16}{}}
\newlabel{eqn:bias-main-1}{{33}{31}{Lemmas and proofs for bias contraction}{equation.0.D.33}{}}
\newlabel{eqn:bias-main}{{34}{31}{Lemmas and proofs for bias contraction}{equation.0.D.34}{}}
\newlabel{eqn:bias-11}{{35}{32}{Lemmas and proofs for bias contraction}{equation.0.D.35}{}}
\newlabel{eqn:bias-1}{{36}{32}{Lemmas and proofs for bias contraction}{equation.0.D.36}{}}
\newlabel{eqn:bias-2}{{37}{33}{Lemmas and proofs for bias contraction}{equation.0.D.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Lemmas and proofs for Bounding variance error}{33}{section.0.E}}
\newlabel{sec:varianceContraction}{{E}{33}{Lemmas and proofs for Bounding variance error}{section.0.E}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Notations}{33}{subsection.0.E.1}}
\newlabel{eq:simpleXYRec}{{38}{34}{Notations}{equation.0.E.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}An exact expression for the stationary distribution}{35}{subsection.0.E.2}}
\newlabel{eq:steadyStateExp}{{39}{35}{An exact expression for the stationary distribution}{equation.0.E.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.3}Computing the steady state distribution}{35}{subsection.0.E.3}}
\newlabel{eq:ibinv}{{40}{35}{Computing the steady state distribution}{equation.0.E.40}{}}
\newlabel{eq:phivInftyBound}{{41}{36}{Computing the steady state distribution}{equation.0.E.41}{}}
\newlabel{eq:phivInftyUpperBound}{{42}{36}{Computing the steady state distribution}{equation.0.E.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.3.1}Understanding the second moment effects}{36}{subsubsection.0.E.3.1}}
\newlabel{ssec:secMomentEffects}{{E.3.1}{36}{Understanding the second moment effects}{subsubsection.0.E.3.1}{}}
\newlabel{eq:linEq}{{43}{37}{Understanding the second moment effects}{equation.0.E.43}{}}
\newlabel{eq:t11}{{44}{37}{Understanding the second moment effects}{equation.0.E.44}{}}
\newlabel{eq:t12}{{45}{37}{Understanding the second moment effects}{equation.0.E.45}{}}
\newlabel{eq:t22}{{46}{38}{Understanding the second moment effects}{equation.0.E.46}{}}
\newlabel{eq:u22-1}{{47}{38}{Understanding the second moment effects}{equation.0.E.47}{}}
\newlabel{eq:u12-1}{{48}{38}{Understanding the second moment effects}{equation.0.E.48}{}}
\newlabel{eq:dr-u22-int1}{{49}{38}{Understanding the second moment effects}{equation.0.E.49}{}}
\newlabel{eq:dr-u22-p1}{{50}{39}{Understanding the second moment effects}{equation.0.E.50}{}}
\newlabel{eq:dr-u22-p2}{{51}{39}{Understanding the second moment effects}{equation.0.E.51}{}}
\newlabel{eq:dr-u22}{{52}{39}{Understanding the second moment effects}{equation.0.E.52}{}}
\newlabel{eq:nr-u22-int}{{53}{39}{Understanding the second moment effects}{equation.0.E.53}{}}
\newlabel{eq:nr-u22-p1}{{54}{40}{Understanding the second moment effects}{equation.0.E.54}{}}
\newlabel{eq:nr-u22}{{55}{40}{Understanding the second moment effects}{equation.0.E.55}{}}
\newlabel{eq:u22}{{56}{40}{Understanding the second moment effects}{equation.0.E.56}{}}
\newlabel{eq:nr-u12-start}{{57}{40}{Understanding the second moment effects}{equation.0.E.57}{}}
\newlabel{eq:nr-u12-p1}{{58}{40}{Understanding the second moment effects}{equation.0.E.58}{}}
\newlabel{eq:nr-u12-p2}{{59}{40}{Understanding the second moment effects}{equation.0.E.59}{}}
\newlabel{eq:nr-u12}{{60}{41}{Understanding the second moment effects}{equation.0.E.60}{}}
\newlabel{eq:u12}{{61}{41}{Understanding the second moment effects}{equation.0.E.61}{}}
\newlabel{eq:nr-u11}{{62}{41}{Understanding the second moment effects}{equation.0.E.62}{}}
\newlabel{eq:u11}{{63}{41}{Understanding the second moment effects}{equation.0.E.63}{}}
\newlabel{eq:oneOverc}{{64}{43}{Understanding the second moment effects}{equation.0.E.64}{}}
\newlabel{eq:u22b}{{65}{43}{Understanding the second moment effects}{equation.0.E.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {E.3.2}Understanding fourth moment effects}{43}{subsubsection.0.E.3.2}}
\newlabel{ssec:fourthMomentEffects}{{E.3.2}{43}{Understanding fourth moment effects}{subsubsection.0.E.3.2}{}}
\newlabel{eq:MU22}{{66}{44}{Understanding fourth moment effects}{equation.0.E.66}{}}
\newlabel{eq:fourthMomentAccBound}{{67}{44}{Understanding fourth moment effects}{equation.0.E.67}{}}
\newlabel{eq:stationaryDistBound}{{68}{44}{Understanding fourth moment effects}{equation.0.E.68}{}}
\newlabel{lem:var-main-1}{{17}{45}{Understanding fourth moment effects}{theorem.0.E.17}{}}
\newlabel{lem:leadingOrderVar}{{17}{45}{Understanding fourth moment effects}{theorem.0.E.17}{}}
\newlabel{eq:simpVarMain}{{69}{47}{Understanding fourth moment effects}{equation.0.E.69}{}}
\newlabel{lem:var1N2bound}{{19}{47}{Understanding fourth moment effects}{theorem.0.E.19}{}}
\newlabel{eq:lotpmain1}{{71}{48}{Understanding fourth moment effects}{equation.0.E.71}{}}
\newlabel{eq:p1}{{72}{49}{Understanding fourth moment effects}{equation.0.E.72}{}}
\newlabel{eq:lotp2}{{73}{49}{Understanding fourth moment effects}{equation.0.E.73}{}}
\newlabel{eq:lotp3}{{74}{50}{Understanding fourth moment effects}{equation.0.E.74}{}}
\newlabel{eq:lotp4}{{75}{51}{Understanding fourth moment effects}{equation.0.E.75}{}}
\newlabel{eq:lotp5}{{76}{51}{Understanding fourth moment effects}{equation.0.E.76}{}}
\newlabel{eq:lotp51}{{77}{51}{Understanding fourth moment effects}{equation.0.E.77}{}}
\newlabel{eq:t1final}{{78}{53}{Understanding fourth moment effects}{equation.0.E.78}{}}
\newlabel{eq:t2final}{{79}{54}{Understanding fourth moment effects}{equation.0.E.79}{}}
\newlabel{eq:perDirectionBound}{{80}{54}{Understanding fourth moment effects}{equation.0.E.80}{}}
\newlabel{eq:lotpmain2}{{81}{54}{Understanding fourth moment effects}{equation.0.E.81}{}}
\newlabel{lem:bound-variance}{{20}{54}{Understanding fourth moment effects}{theorem.0.E.20}{}}
\newlabel{eq:e1}{{82}{55}{Understanding fourth moment effects}{equation.0.E.82}{}}
\newlabel{eq:e2}{{83}{55}{Understanding fourth moment effects}{equation.0.E.83}{}}
\newlabel{eq:e31}{{84}{56}{Understanding fourth moment effects}{equation.0.E.84}{}}
\newlabel{eq:e311}{{85}{56}{Understanding fourth moment effects}{equation.0.E.85}{}}
\newlabel{eq:alpBound}{{86}{56}{Understanding fourth moment effects}{equation.0.E.86}{}}
\newlabel{eq:e3}{{87}{57}{Understanding fourth moment effects}{equation.0.E.87}{}}
\newlabel{eq:e41}{{88}{57}{Understanding fourth moment effects}{equation.0.E.88}{}}
\newlabel{eq:e42}{{89}{58}{Understanding fourth moment effects}{equation.0.E.89}{}}
\newlabel{eq:e4}{{90}{59}{Understanding fourth moment effects}{equation.0.E.90}{}}
\newlabel{eq:e51}{{91}{59}{Understanding fourth moment effects}{equation.0.E.91}{}}
\newlabel{eq:e5}{{92}{60}{Understanding fourth moment effects}{equation.0.E.92}{}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Proof of Theorem\nobreakspace  {}\ref  {thm:main}}{60}{section.0.F}}
\newlabel{sec:proofMainTheorem}{{F}{60}{Proof of Theorem~\ref {thm:main}}{section.0.F}{}}
\newlabel{jmlrend}{{F}{60}{end of Accelerating Stochastic Gradient Descent}{section*.8}{}}
