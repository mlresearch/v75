@InProceedings{BottouB07,
  title =	{The Tradeoffs of Large Scale Learning},
  author =	"L{\'e}on Bottou and Olivier Bousquet",
  year = 	"2007",
  booktitle =	"NIPS 20",
}

@article{ghadimi2012optimal,
	title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization I: A generic algorithmic framework},
	author={Ghadimi, Saeed and Lan, Guanghui},
	journal={SIAM Journal on Optimization},
	year={2012},
}

@article{ghadimi2013optimal,
	title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, II: shrinking procedures and optimal algorithms},
	author={Ghadimi, Saeed and Lan, Guanghui},
	journal={SIAM Journal on Optimization},
	year={2013},
}

@article{Nesterov12,
	title={Efficiency of coordinate descent methods on huge-scale optimization problems},
	author={Nesterov, Yurii E.},
	journal={SIAM Journal on Optimization},
	volume={22},
	number={2},
	pages={341--362},
	year={2012},
	publisher={SIAM}
}

@Article{HardtRS15,
  title =	{Train faster, generalize better: Stability of
		 stochastic gradient descent},
  author =	"Moritz Hardt and Benjamin Recht and Yoram Singer",
  journal =	"CoRR",
  year = 	"2015",
  volume =	"abs/1509.01240",
}

@Article{RobbinsM51,
  author =	"Herbert Robbins and Sutton Monro",
  title =	{A Stochastic Approximation Method},
  journal =	"The Annals of Mathematical Statistics",
  volume =	"vol. 22",
  year = 	"1951",
}

@Article{Ruppert88,
  author =	"David Ruppert",
  title =	{Efficient Estimations from a Slowly Convergent Robbins-Monro Process},
  journal =	"Tech. Report, ORIE, Cornell University",
  year = 	"1988",
}

@Article{PolyakJ92,
  title =	{Acceleration of Stochastic Approximation by Averaging},
  author =	"Boris T. Polyak and Anatoli B. Juditsky",
  volume =	"volume 30",
  year = 	"1992",
  journal =	"SIAM Journal on Control and Optimization",
}

@Article{KushnerY03,
  author =	"Harold J. Kushner and George Yin",
  title =	{Stochastic Approximation and Recursive Algorithms and Applications},
  journal =	"Springer-Verlag",
  year = 	"2003",
}

@inproceedings{BachM11,
  author = {Francis R. Bach and Eric Moulines},
  title = {Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning},
  booktitle = {NIPS 24},
  year = {2011},
}

@inproceedings{BachM13,
  title =	{Non-strongly-convex smooth stochastic approximation with convergence rate {O}(1/n)},
  author =	"Francis R. Bach and Eric Moulines",
  booktitle =	{NIPS 26},
  year = 	"2013",
 }
 
 @ARTICLE{Bach14,
  title =	{Adaptivity of averaged stochastic gradient descent to local strong convexity for logistic regression},
  author =	"Francis R. Bach",
  journal =	"Journal of Machine Learning Research (JMLR)",
  year = 	"2014",
  volume =	{volume 15},
}

@Article{RosenblattN14,
  title =	{On the Optimality of Averaging in Distributed Statistical Learning},
  author =	"Jonathan Rosenblatt and Boaz Nadler",
  journal = "CoRR",
  volume = "abs/1407.2724",
  year = 	"2014",
}

@Article{DieuleveutB15,
  title =	{Non-parametric Stochastic Approximation with Large Step sizes},
  author =	"Aymeric Dieuleveut and Francis R. Bach",
  journal = "The Annals of Statistics",
  year = 	"2015",
}

@InProceedings{DefossezB15,
  title =	{Averaged Least-Mean-Squares: Bias-Variance Trade-offs
		 and Optimal Sampling Distributions},
  author =	"Alexandre D{\'e}fossez and Francis R. Bach",
  booktitle =	"AISTATS",
  year = 	"2015",
  volume =	"38",
}

@InProceedings{FrostigGKS15,
  title =	{Competing with the Empirical Risk Minimizer in a Single Pass},
  author =	"Roy Frostig and Rong Ge and Sham M. Kakade and Aaron Sidford",
  booktitle =	"COLT",
  year = 	"2015",
}

@InProceedings{JainJKNS16,
  title =	{ Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja's Algorithm},
  author =	"Prateek Jain and Chi Jin and Sham M. Kakade and Praneeth Netrapalli and Aaron Sidford",
	booktitle =	"COLT",
	year = 	"2016",
}

@Article{JainKKNS16,
  author =	"Prateek Jain and Sham M. Kakade and Rahul Kidambi and Praneeth Netrapalli and Aaron Sidford",
  title =	" Parallelizing Stochastic Approximation Through Mini-Batching and Tail-Averaging",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1610.03774",
}

@Article{GadatPS16,
  title =	" Stochastic Heavy Ball",
  author =	"SÃ©bastien Gadat and Fabien Panloup and Sofiane Saadane",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1609.04228",
}

@Article{HestenesS52,
  author =	"Magnus R. Hestenes and Eduard Stiefel",
  title =	"Methods of Conjuate Gradients for Solving Linear Systems",
  journal =	"Journal of Research of the National Bureau of Standards",
  year = 	"1952",
}

@Article{Polyak64,
  author =	"Boris T. Polyak",
  title =	"Some Methods of Speeding up the Convergence of
		 Iteration Methods",
  journal =	"USSR  Computational Mathematics and Mathematical Physics",
  year = 	"1964",
  volume =	"4",
}

@Article{Nesterov83,
  author =	"Yurii E. Nesterov",
  title =	"A method for unconstrained convex minimization problem
		 with the rate of convergence ${O}(1/k^2)$",
  journal =	"Doklady AN SSSR",
  year = 	"1983",
  volume =	"269",
}

@Book{NemirovskyY83,
  author =	"Arkadii S. Nemirovsky and David B. Yudin",
  title =	"Problem Complexity and Method Efficiency in Optimization",
  year = 	"1983",
  publisher =	"John Wiley",
}

@Book{Polyak87,
  author =	"Boris T. Polyak",
  title =	"Introduction to Optimization",
  year = 	"1987",
  publisher =	"Optimization Software",
}

@Article{Bubeck14,
  title =	"Theory of Convex Optimization for Machine Learning",
  author =	"S{\'e}bastien Bubeck",
  journal =	"CoRR",
  year = 	"2014",
  volume =	"abs/1405.4980",
}

@Article{ZhuO16,
  title =	"Linear Coupling: An Ultimate Unification of Gradient
		 and Mirror Descent",
  author =	"Zeyuan Allen-Zhu and Lorenzo Orecchia",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1407.1537",
}

@Article{WoodworthS16,
  title =	"Tight Complexity Bounds for Optimizing Composite Objectives",
  author =	"Blake Woodworth and Nathan Srebro",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1605.08003",
}

@article{Nesterov05,
	title={Smooth minimization of non-smooth functions},
	author={Nesterov, Yu},
	journal={Mathematical programming},
	volume={103},
	number={1},
	pages={127--152},
	year={2005},
	publisher={Springer}
}

@Article{BubeckLS15,
  title =	"A geometric alternative to Nesterov's accelerated
		 gradient descent",
  author =	"S{\'e}bastien Bubeck and Yin Tat Lee and Mohit Singh",
  journal =	"CoRR",
  year = 	"2015",
  volume =	"abs/1506.08187",
}

@Article{BubeckL16,
  title =	" Black-box optimization with a politician",
  author =	"S{\'e}bastien Bubeck and Yin Tat Lee",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1602.04847",
}

@Article{WilsonRJ16,
  title =	"A Lyapunov Analysis of Momentum Methods in Optimization",
  author =	"Ashia C. Wilson and Benjamin Recht and Michael I. Jordan",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1611.02635",
}

@Article{FlammarionB15,
  title =	"From Averaging to Acceleration, There is Only a
		 Step-size",
  author =	"Nicolas Flammarion and Francis R. Bach",
  journal =	"CoRR",
  year = 	"2015",
  volume = "abs/1504.01577",
}

@Article{DieuleveutFB16,
  title =	" Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression",
  author =	"Aymeric Dieuleveut and Nicolas Flammarion and Francis R. Bach",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1602.05419",
}

@Article{DevolderGN14,
  title =	"First-order methods of smooth convex optimization with
		 inexact oracle",
  author =	"Olivier Devolder and Fran{\c c}ois Glineur and Yurii E.
		 Nesterov",
  journal =	"Mathematical Programming",
  year = 	"2014",
  volume =	"146",
  pages =	"37--75",
}

@Article{DevolderGN13,
  title =	"First-order methods with inexact oracle: the strongly convex case",
  author =	"Olivier Devolder and Fran{\c c}ois Glineur and Yurii E.
		 Nesterov",
  journal =	"CORE Discussion Papers 2013016",
  year = 	"2013",
}

@Article{Devolder13,
  title =	"Exactness, inexactness and stochasticity in first-order methods for large-scale convex optimization",
  author =	"Olivier Devolder",
  journal =	"PhD Thesis, Universite Catholique de Louvain",
  year = 	"2013",
}

@Article{ShwartzZ12,
  title =	{Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization},
  author =	"Shai Shalev-Shwartz and Tong Zhang",
  journal =	"CoRR",
  volume =	"abs/1209.1873",
  year = 	"2012",
}

@inproceedings{RouxSB12,
  author = {Nicolas Le Roux and Mark Schmidt and Francis R. Bach},
  title = {A Stochastic Gradient Method with an Exponential Convergence Rate for Strongly-Convex Optimization with Finite Training Sets},
  booktitle = {NIPS 25},
  year = {2012},
}

@InProceedings{JohnsonZ13,
  title =	{Accelerating Stochastic Gradient Descent using Predictive Variance Reduction},
  author =	"Rie Johnson and Tong Zhang",
  booktitle =	{NIPS 26},
  year = 	"2013",
 }
 
 @InProceedings{DefazioBJ14,
  title =	{{SAGA}: {A} Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives},
  author =	"Aaron Defazio and Francis R. Bach and Simon Lacoste-Julien",
  booktitle =	{NIPS 27},
  year = 	"2014",
 }
 
@InProceedings{CotterSSS11,
  title =	{Better Mini-Batch Algorithms via Accelerated Gradient Methods},
  author =	"Andrew Cotter and Ohad Shamir and Nati Srebro and Karthik Sridharan",
  booktitle =	{NIPS 24},
  year = 	"2011",
}

@InProceedings{ShwartzZ13,
  title =	{Accelerated Mini-Batch Stochastic Dual Coordinate Ascent},
  author =	"Shai Shalev-Shwartz and Tong Zhang",
  booktitle =	{NIPS 26},
  year = 	"2013",
 }

@InProceedings{ShwartzZ14,
  title =	{Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization},
  author =	"Shai Shalev-Shwartz and Tong Zhang",
  booktitle =	{ICML},
  year = 	"2014",
 }

@InProceedings{FrostigGKS15b,
  title =	{Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization},
  author =	"Roy Frostig and Rong Ge and Sham Kakade and Aaron Sidford",
  booktitle =	"ICML",
  year = 	"2015",
}

@ARTICLE{Defazio16, 
 author = {Aaron Defazio}, 
 title = {A Simple Practical Accelerated Method for Finite Sums}, 
 journal = {Advances in Neural Information Processing Systems 29 (NIPS 2016)}, 
 year = {2016} 
}

@Article{Zhu16,
  title =	" Katyusha: The First Direct Acceleration of Stochastic Gradient Methods",
  author =	"Zeyuan Allen-Zhu",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1603.05953",
}

@Article{LessardRP14,
  title =	"Analysis and Design of Optimization Algorithms via
		 Integral Quadratic Constraints",
  author =	"Laurent Lessard and Benjamin Recht and Andrew
		 Packard",
  journal =	"CoRR",
  year = 	"2014",
  volume =	"abs/1408.3595",
}

@InProceedings{SuBC14,
  title =	"A Differential Equation for Modeling Nesterov's
		 Accelerated Gradient Method: Theory and Insights",
  author =	"Weijie Su and Stephen P. Boyd and Emmanuel J.
		 Cand{\`e}s",
  booktitle = {Advances in Neural Information Processing Systems 27},
  year = 	"2014",
  pages =	"2510--2518",
}

@inproceedings{KricheneBB15,
title = {Accelerated Mirror Descent in Continuous and Discrete Time},
author = {Krichene, Walid and Bayen, Alexandre and Bartlett, Peter L},
booktitle = {Advances in Neural Information Processing Systems 28},
pages = {2845--2853},
year = {2015},
}

@Article{ODonoghueC15,
  title =	"Adaptive Restart for Accelerated Gradient Schemes",
  author =	"Brendan O'Donoghue and Emmanuel J. Cand{\`e}s",
  journal =	"Foundations of Computational Mathematics",
  year = 	"2015",
  volume =	"15",
}

@Article{WibisonoWJ16,
  title =	" A Variational Perspective on Accelerated Methods in Optimization",
  author =	"Andre Wibisono and Ashia C. Wilson and Michael I. Jordan",
  journal =	"CoRR",
  year = 	"2016",
  volume =	"abs/1603.04245",
}

@Article{HsuKZ14,
  title =	"Random Design Analysis of Ridge Regression",
  author =	"Daniel J. Hsu and Sham M. Kakade and Tong Zhang",
  journal =	"Foundations of Computational Mathematics",
  year = 	"2014",
  number =	"3",
  volume =	"14",
  pages =	"569--600",
}

@InProceedings{SutskeverMDH13,
  title =	"On the importance of initialization and momentum in
		 deep learning",
  author =	"Ilya Sutskever and James Martens and George E. Dahl
		 and Geoffrey E. Hinton",
  year = 	"2013",
  volume =	"28",
  booktitle =	"ICML",
}

@article{dAspremont08,
	title={Smooth optimization with approximate gradient},
	author={d'Aspremont, Alexandre},
	journal={SIAM Journal on Optimization},
	volume={19},
	number={3},
	pages={1171--1183},
	year={2008},
	publisher={SIAM}
}
@Book{Nesterov04,
  author =	"Yurii E. Nesterov",
  title =	"Introductory lectures on convex optimization: A basic course",
  series =	"Applied Optimization",
  volume =	"87",
  publisher =	"Kluwer Academic Publishers",
  year = 	"2004",
}
@InProceedings{LinMH15,
  title =	"A Universal Catalyst for First-Order Optimization",
  author =	"Hongzhou Lin and Julien Mairal and Za{\"i}d
		 Harchaoui",
  booktitle =	"NIPS",
  year = 	"2015",
}
@Book{Tropp15,
  title =	"An Introduction to Matrix Concentration Inequalities",
  author =	"Joel A. Tropp",
  publisher =	"Foundations and Trends in Machine Learning",
  year = 	"2015",
}
@Book{Vaart00,
  author =	"Aad W. van der Vaart",
  title =	"Asymptotic Statistics",
  publisher =	"Cambridge University Publishers",
  year = 	"2000",
}
@article{NeedellSW16,
  author    = {Deanna Needell and
               Nathan Srebro and
               Rachel Ward},
  title     = {Stochastic gradient descent, weighted sampling, and the randomized
               Kaczmarz algorithm},
  journal   = {Mathematical Programming},
  year      = {2016},
}
 @ARTICLE{YuanYS16,
  title =	{On the influence of momentum acceleration on online learning},
  author =	"Kun Yuan and Bicheng Ying and Ali H. Sayed",
  journal =	"Journal of Machine Learning Research (JMLR)",
  year = 	"2016",
  volume =	{volume 17},
}
 @ARTICLE{Proakis74,
  title =	{Channel identification for high speed digital communications},
  author =	"John G. Proakis",
  journal =	"IEEE Transactions on Automatic Control",
  year = 	"1974",
}

 @ARTICLE{RoyS90,
  title =	{Analysis of the momentum LMS algorithm},
  author =	"Sumit Roy and John J. Shynk",
  journal =	"IEEE Transactions on Acoustics, Speech and Signal Processing",
  year = 	"1990",
}

 @ARTICLE{SharmaSB98,
  title =	{Analysis of momentum adaptive filtering algorithms},
  author =	"Rajesh Sharma and William A. Sethares and James A. Bucklew",
  journal =	"IEEE Transactions on Signal Processing",
  year = 	"1998",
}

@InProceedings{HuKP09,
  title =	{Accelerated Gradient Methods for Stochastic Optimization and Online Learning},
  author =	"Chonghai Hu and James T. Kwok and Weike Pan",
  booktitle =	{NIPS 22},
  year = 	"2009",
 }
@Book{WidrowS85,
  author =	"Bernard Widrow and Samuel D. Stearns",
  title =	"Adaptive Signal Processing",
  publisher =	"Englewood Cliffs, NJ: Prentice-Hall",
  year = 	"1985",
}
@Article{Paige71,
  author =	"Christopher C. Paige",
  title =	{The Computation of Eigenvalues and Eigenvectors of Very Large Sparse Matrices},
  journal =	"PhD Thesis, University of London",
  year = 	"1971",
}
@Article{Greenbaum89,
  author =	"Anne Greenbaum",
  title =	{Behavior of slightly perturbed Lanczos and conjugate-gradient recurrences},
  journal =	"Linear Algebra and its Applications",
  year = 	"1989",
}
 @ARTICLE{AgarwalBRW12,
  title =	{Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization},
  author =	"Alekh Agarwal and Peter L. Bartlett and Pradeep Ravikumar and Martin J. Wainwright",
  journal =	"IEEE Transactions on Information Theory",
  year = 	"2012",
}
 @ARTICLE{RaginskyR11,
  title =	{Information-based complexity, feedback and dynamics in convex programming},
  author =	"Maxim Raginsky and Alexander Rakhlin",
  journal =	"IEEE Transactions on Information Theory",
  year = 	"2011",
}

@Article{Lan08,
  author =	"G. Lan",
  title =	{An  Optimal  Method  for  Stochastic  Composite Optimization},
  journal =	"Tech. Report, GaTech.",
  year = 	"2008",
}

@Article{Fabian:1973:AES,
  author =       "Vaclav Fabian",
  title =        "Asymptotically Efficient Stochastic Approximation; The
                 {RM} Case",
  volume =       "1",
  number =       "3",
  year =         "1973",
  journal =     "Annals of Statistics"
}

@book{anbar1971optimal,
  title={On Optimal Estimation Methods Using Stochastic Approximation Procedures},
  author={Dan Anbar},
  url={http://books.google.com/books?id=MmpHJwAACAAJ},
  year={1971},
  publisher={University of California}
}


@book{KushnerClark,
  title={Stochastic Approximation Methods for Constrained and Unconstrained Systems.},
  author={Harold J. Kushner and Dean S. Clark},
  year={1978},
  publisher={Springer-Verlag}
}

@book{lehmann1998theory,
  title={Theory of Point Estimation},
  author={Erich L. Lehmann and George Casella},
  year={1998},
  publisher={Springer}
}

@Article{LanZ15,
  title =	" An optimal randomized incremental gradient method",
  author =	"Guanghui Lan and Yi Zhou",
  journal =	"CoRR",
  year = 	"2015",
  volume =	"abs/1507.02000",
}

@article{cauchy1847,
	title={M\'ethode g\'en\'erale pour la r\'esolution des syst\'emes d'\'equations simultanees},
	author={Louis Augustin Cauchy},
	journal={C. R. Acad. Sci. Paris},
	year={1847}
}
