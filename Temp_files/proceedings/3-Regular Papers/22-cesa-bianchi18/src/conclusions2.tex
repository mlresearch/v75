
\section{Conclusions}
%
We have investigated the setting of $d$-delayed composite anonymous feedback as applied to nonstochastic bandits.
% Composite anonymous feedback lends itself to formalize scenarios where the actions perfomed by the online decision maker produce long-lasting effects that combine additively over time.
A general reduction technique was introduced that enables the conversion of a (backward stable) algorithm working in a standard bandit framework into one working in the composite feedback framework. In the case of $K$-armed bandits, we relied on a lower bound for bandit linear optimization in the probability simplex to show that no algorithm in the composite feedback framework can do better than $\scO(\sqrt{dKT})$. In turn, up to log factors, this is what we obtain as an upper bound by applying our reduction to the standard Exp3 algorithm. We showed the generality and flexibility of our conversion technique by further applying it to Combinatorial Bandits (the Exp2 algorithm) and to Bandit Convex Optimization (the self-concordant barrier-based algorithms by \cite{ahr12} and \cite{st11}) with smooth/linear loss functions.

Three main directions for extending our work are:
\begin{itemize} 
\item Proving an upper bound for the case of nonoblivious adversaries;
\item Investigating the setting where the delay parameter $d$ is not perfectly known;
\item Extending our results to the nonstochastic contextual case.
\end{itemize}

\iffalse
 ****** CG: still working on it *****

In the latter case, the resulting Bandit Convex Optimization algorithm for composite anonymous feedback turned out to achieve regret bounds with higher rates than those of the corresponding base bandit algorithms, and we suspect that there is margin for improvement in our stability analysis of Lemma \ref{l:stabilityconvexscrible}.

Say something about possible directions
\fi
