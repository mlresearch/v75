@article{guzman2015lower,
  title={On lower complexity bounds for large-scale smooth convex optimization},
  author={Guzm{\'a}n, Crist{\'o}bal and Nemirovski, Arkadi},
  journal={Journal of Complexity},
  volume={31},
  number={1},
  pages={1--14},
  year={2015},
  publisher={Elsevier}
}

@misc{abernethy2015faster,
  title={Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier. arXiv 1507.02528},
  author={Abernethy, J and Hazan, E},
  year={2015},
  publisher={July}
}

@book{nesterov1994interior,
  title={Interior-point polynomial algorithms in convex programming},
  author={Nesterov, Yurii and Nemirovskii, Arkadii},
  year={1994},
  publisher={SIAM}
}

@inproceedings{lee2015faster,
  title={A faster cutting plane method and its implications for combinatorial and convex optimization},
  author={Lee, Yin Tat and Sidford, Aaron and Wong, Sam Chiu-wai},
  booktitle={Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on},
  pages={1049--1065},
  year={2015},
  organization={IEEE}
}

@inproceedings{lovasz2006fast,
  title={Fast algorithms for logconcave functions: Sampling, rounding, integration and optimization},
  author={Lov{\'a}sz, L{\'a}szl{\'o} and Vempala, Santosh},
  booktitle={Foundations of Computer Science, 2006. FOCS'06. 47th Annual IEEE Symposium on},
  pages={57--68},
  year={2006},
  organization={IEEE}
}

@article{kalai2006simulated,
  title={Simulated annealing for convex optimization},
  author={Kalai, Adam Tauman and Vempala, Santosh},
  journal={Mathematics of Operations Research},
  volume={31},
  number={2},
  pages={253--266},
  year={2006},
  publisher={INFORMS}
}

@book{grotschel2012geometric,
  title={Geometric algorithms and combinatorial optimization},
  author={Gr{\"o}tschel, Martin and Lov{\'a}sz, L{\'a}szl{\'o} and Schrijver, Alexander},
  volume={2},
  year={2012},
  publisher={Springer Science \& Business Media}
}


@inproceedings{Agarwal:2017:FAL:3055399.3055464,
 author = {Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
 title = {Finding Approximate Local Minima Faster Than Gradient Descent},
 booktitle = {Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
 series = {STOC 2017},
 year = {2017},
 isbn = {978-1-4503-4528-6},
 location = {Montreal, Canada},
 pages = {1195--1199},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/3055399.3055464},
 doi = {10.1145/3055399.3055464},
 acmid = {3055464},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Cubic Regularization, Deep Learning, Non-convex Optimization, Second-Order Optimization},
} 



@article{bollapragada2016exact,
  title={Exact and inexact subsampled Newton methods for optimization},
  author={Bollapragada, Raghu and Byrd, Richard and Nocedal, Jorge},
  journal={arXiv preprint arXiv:1609.08502},
  year={2016}
}

@inproceedings{xu2016sub,
  title={Sub-sampled newton methods with non-uniform sampling},
  author={Xu, Peng and Yang, Jiyan and Roosta-Khorasani, Farbod and R{\'e}, Christopher and Mahoney, Michael W},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3000--3008},
  year={2016}
}

@article{shamir2017oracle,
  title={Oracle Complexity of Second-Order Methods for Smooth Convex Optimization},
  author={Arjevani, Yossi and Shamir, Ohad and Shiff, Ron},
  journal={arXiv preprint arXiv:1705.07260v2},
  year={2017}
}

@article{monteiro2013accelerated,
  title={An accelerated hybrid proximal extragradient method for convex optimization and its implications to second-order methods},
  author={Monteiro, Renato DC and Svaiter, Benar Fux},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={2},
  pages={1092--1125},
  year={2013},
  publisher={SIAM}
}

@inproceedings{agarwal2009information,
  title={Information-theoretic lower bounds on the oracle complexity of convex optimization},
  author={Agarwal, Alekh and Wainwright, Martin J and Bartlett, Peter L and Ravikumar, Pradeep K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1--9},
  year={2009}
}

@article{arjevani2015lower,
  title={On lower and upper bounds for smooth and strongly convex optimization problems},
  author={Arjevani, Yossi and Shalev-Shwartz, Shai and Shamir, Ohad},
  journal={arXiv preprint arXiv:1503.06833},
  year={2015}
}

@article{carmon2017convex,
  title={" Convex Until Proven Guilty": Dimension-Free Acceleration of Gradient Descent on Non-Convex Functions},
  author={Carmon, Yair and Hinder, Oliver and Duchi, John C and Sidford, Aaron},
  journal={arXiv preprint arXiv:1705.02766},
  year={2017}
}

@article{allen2017natasha,
  title={Natasha: Faster stochastic non-convex optimization via strongly non-convex parameter},
  author={Allen-Zhu, Zeyuan},
  journal={arXiv preprint arXiv:1702.00763},
  year={2017}
}

@inproceedings{woodworth2016tight,
  title={Tight complexity bounds for optimizing composite objectives},
  author={Woodworth, Blake E and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3639--3647},
  year={2016}
}

@article{arjevanisecondorder,
  title={Oracle Complexity of Second-Order Methods for Finite-Sum Problems},
  author={Arjevani, Yossi and Shamir, Ohad},
  journal={arXiv preprint arXiv:1611.04982},
  year={2016}
}

@inproceedings{vaidya1989new,
  title={A new algorithm for minimizing convex functions over convex sets},
  author={Vaidya, Pravin M},
  booktitle={Foundations of Computer Science, 1989., 30th Annual Symposium on},
  pages={338--343},
  year={1989},
  organization={IEEE}
}

@article{bertsimas2004solving,
  title={Solving convex programs by random walks},
  author={Bertsimas, Dimitris and Vempala, Santosh},
  journal={Journal of the ACM (JACM)},
  volume={51},
  number={4},
  pages={540--556},
  year={2004},
  publisher={ACM}
}


@article{khachiyan1980polynomial,
  title={Polynomial algorithms in linear programming},
  author={Khachiyan, Leonid G},
  journal={USSR Computational Mathematics and Mathematical Physics},
  volume={20},
  number={1},
  pages={53--72},
  year={1980},
  publisher={Elsevier}
}

@article{grotschel1981ellipsoid,
  title={The ellipsoid method and its consequences in combinatorial optimization},
  author={Gr{\"o}tschel, Martin and Lov{\'a}sz, L{\'a}szl{\'o} and Schrijver, Alexander},
  journal={Combinatorica},
  volume={1},
  number={2},
  pages={169--197},
  year={1981},
  publisher={Springer}
}

@article{baeshigherorder,
  title={Estimate sequence methods: extensions and approximations},
  author={Baes, Michel},
  journal={Institute for Operations Research, ETH, Z{\"u}rich, Switzerland},
  year={2009}
}

@article{CarmonAGD,
  title={Accelerated Methods for Non-Convex Optimization},
  author={Yair Carmon and John C. Duchi and Oliver Hinder and  Aaron Sidford},
  journal={arXiv preprint 1611.00756},
  year={2016}
}

@article{LiSSA2016,
  title={Second Order Stochastic Optimization for Machine Learning in
Linear Time},
  author={Naman Agarwal and Brian Bullins and Elad Hazan},
  journal={arXiv preprint arXiv:1602.03943},
  year={2016}
}


@inproceedings{LV06,
 author = {Lovasz, Laszlo and Vempala, Santosh},
 title = {Fast Algorithms for Logconcave Functions: Sampling, Rounding, Integration and Optimization},
 booktitle = {Proceedings of the 47th Annual IEEE Symposium on Foundations of Computer Science},
 series = {FOCS '06},
 year = {2006},
 isbn = {0-7695-2720-5},
 pages = {57--68},
 numpages = {12},
 url = {http://dx.doi.org/10.1109/FOCS.2006.28},
 doi = {10.1109/FOCS.2006.28},
 acmid = {1170488},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 


@inproceedings{GeHJY15,
  author    = {Rong Ge and
               Furong Huang and
               Chi Jin and
               Yang Yuan},
  title     = {Escaping From Saddle Points - Online Stochastic Gradient for Tensor
               Decomposition},
  booktitle = {Proceedings of The 28th Conference on Learning Theory, {COLT} 2015,
               Paris, France, July 3-6, 2015},
  pages     = {797--842},
  year      = {2015},
}

@inproceedings{GarberHJKMNS16,
  author    = {Dan Garber and
               Elad Hazan and
               Chi Jin and
               Sham M. Kakade and
               Cameron Musco and
               Praneeth Netrapalli and
               Aaron Sidford},
  title     = {Faster Eigenvector Computation via Shift-and-Invert Preconditioning},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning,
               {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  pages     = {2626--2634},
  year      = {2016},
  crossref  = {DBLP:conf/icml/2016},
  url       = {http://jmlr.org/proceedings/papers/v48/garber16.html},
  timestamp = {Tue, 12 Jul 2016 21:51:16 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icml/GarberHJKMNS16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{cartisadaptive2,
  title={Adaptive cubic regularisation methods for unconstrained optimization. Part II: worst-case function-and derivative-evaluation complexity},
  author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
  journal={Mathematical Programming},
  volume={130},
  number={2},
  pages={295--319},
  year={2011},
  publisher={Springer}
}
@article{cartisadaptive,
  title={Adaptive cubic regularisation methods for unconstrained optimization. Part I: motivation, convergence and numerical results},
  author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
  journal={Mathematical Programming},
  volume={127},
  number={2},
  pages={245--295},
  year={2011},
  publisher={Springer}
}

@article{nesterovcubic,
  title={Cubic regularization of Newton method and its global performance},
  author={Nesterov, Yurii and Polyak, Boris T},
  journal={Mathematical Programming},
  volume={108},
  number={1},
  pages={177--205},
  year={2006},
  publisher={Springer}
}

@article{hazantrust,
  title={A linear-time algorithm for trust region problems},
  author={Hazan, Elad and Koren, Tomer},
  journal={Mathematical Programming},
  pages={1--19},
  year={2015},
  publisher={Springer}
}
@article{curtis2016trust,
  title={A trust region algorithm with a worst-case iteration complexity of$\backslash$ mathcal $\{$O$\}$($\backslash$ epsilon\^{}$\{$-3/2$\}$) for nonconvex optimization},
  author={Curtis, Frank E and Robinson, Daniel P and Samadi, Mohammadreza},
  journal={Mathematical Programming},
  pages={1--32},
  year={2016},
  publisher={Springer}
}
@article{ghadimilan,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}
@book{nocedalbook,
  title={Numerical optimization},
  author={Nocedal, Jorge and Wright, Stephen},
  year={2006},
  publisher={Springer Science \& Business Media}
  }


@inproceedings{PengRowSampling,
  author    = {Mu Li and
               Gary L. Miller and
               Richard Peng},
  title     = {Iterative Row Sampling},
  booktitle = {54th Annual {IEEE} Symposium on Foundations of Computer Science, {FOCS}
               2013, 26-29 October, 2013, Berkeley, CA, {USA}},
  pages     = {127--136},
  year      = {2013},
  crossref  = {DBLP:conf/focs/2013},
  url       = {http://dx.doi.org/10.1109/FOCS.2013.22},
  doi       = {10.1109/FOCS.2013.22},
  timestamp = {Tue, 16 Dec 2014 09:57:25 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/focs/LiMP13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Catalyst2015,
  author    = {Hongzhou Lin and
               Julien Mairal and
               Za{\"{\i}}d Harchaoui},
  title     = {A Universal Catalyst for First-Order Optimization},
  booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
               on Neural Information Processing Systems 2015, December 7-12, 2015,
               Montreal, Quebec, Canada},
  pages     = {3384--3392},
  year      = {2015},
  crossref  = {DBLP:conf/nips/2015},
}

@article{HillarL13,
  author    = {Christopher J. Hillar and
               Lek{-}Heng Lim},
  title     = {Most Tensor Problems Are NP-Hard},
  journal   = {J. {ACM}},
  volume    = {60},
  number    = {6},
  pages     = {45},
  year      = {2013},
  url       = {http://doi.acm.org/10.1145/2512329},
  doi       = {10.1145/2512329},
  timestamp = {Fri, 06 Dec 2013 15:28:53 +0100},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/journals/jacm/HillarL13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{Katyusha2016,
  author    = {Zeyuan Allen Zhu},
  title     = {Katyusha: Accelerated Variance Reduction for Faster {SGD}},
  journal   = {CoRR},
  volume    = {abs/1603.05953},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.05953},
  timestamp = {Sat, 02 Apr 2016 11:49:48 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Zhu16c},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
homebrowsesearchabout




@inproceedings{YinTatPaper,
  author    = {Michael B. Cohen and
               Yin Tat Lee and
               Cameron Musco and
               Christopher Musco and
               Richard Peng and
               Aaron Sidford},
  title     = {Uniform Sampling for Matrix Approximation},
  booktitle = {Proceedings of the 2015 Conference on Innovations in Theoretical Computer
               Science, {ITCS} 2015, Rehovot, Israel, January 11-13, 2015},
  pages     = {181--190},
  year      = {2015},
  crossref  = {DBLP:conf/innovations/2015},
  url       = {http://doi.acm.org/10.1145/2688073.2688113},
  doi       = {10.1145/2688073.2688113},
  timestamp = {Sun, 25 Jan 2015 11:31:05 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/innovations/CohenLMMPS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@book{NesterovBook,
  title={Introductory lectures on convex optimization},
  author={Nesterov, Yurii},
  volume={87},
  year={2004},
  publisher={Springer Science \& Business Media}
}

@inproceedings{newsamp,
  title={Convergence rates of sub-sampled Newton methods},
  author={Erdogdu, Murat A and Montanari, Andrea},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3034--3042},
  year={2015}
}

@inproceedings{SAGA,
  title={SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1646--1654},
  year={2014}
}

@inproceedings{Bachpaper,
  title={A stochastic gradient method with an exponential convergence \_rate for finite training sets},
  author={Roux, Nicolas L and Schmidt, Mark and Bach, Francis R},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2663--2671},
  year={2012}
}

@inproceedings{SVRG,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={315--323},
  year={2013}
}

@article{adagrad,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={The Journal of Machine Learning Research},
  volume={12},
  pages={2121--2159},
  year={2011},
  publisher={JMLR. org}
}

@article{mnist,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {http://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-01-14T15:24:40.000+0100},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@article{covertype,
  title={Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables},
  author={Blackard, Jock A and Dean, Denis J},
  journal={Computers and electronics in agriculture},
  volume={24},
  number={3},
  pages={131--151},
  year={1999},
  publisher={Elsevier}
}


@article{Tropp,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  number={4},
  pages={389--434},
  year={2012},
  publisher={Springer}
}

@article{SDCA,
  title={Stochastic dual coordinate ascent methods for regularized loss},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={567--599},
  year={2013},
  publisher={JMLR. org}
}

@article{RM51,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@inproceedings{MAR10,
  title={Deep learning via Hessian-free optimization},
  author={Martens, James},
  booktitle={Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
  pages={735--742},
  year={2010}
}

@article{BCNN11,
  title={On the use of stochastic hessian information in optimization methods for machine learning},
  author={Byrd, Richard H and Chin, Gillian M and Neveitt, Will and Nocedal, Jorge},
  journal={SIAM Journal on Optimization},
  volume={21},
  number={3},
  pages={977--995},
  year={2011},
  publisher={SIAM}
}

@inproceedings{VP12,
    Title = {Krylov Subspace Descent for Deep Learning},
    Url = {http://jmlr.csail.mit.edu/proceedings/papers/v22/vinyals12/vinyals12.pdf},
    Journal = {Journal of Machine Learning Research - Workshop and Conference Proceedings},
    Author = {Oriol Vinyals and Daniel Povey},
    Pages = {1261-1268},
    Volume = {22},
    Editor = {Neil D. Lawrence and Mark A. Girolami},
    Year = {2012},
    Booktitle = {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS-12)}
}

@misc{uci,
author = "M. Lichman",
year = "2013",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@inproceedings{SYG07,
  title={A stochastic quasi-Newton method for online convex optimization},
  author={Schraudolph, Nicol N and Yu, Jin and G{\"u}nter, Simon},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={436--443},
  year={2007}
}

@article{BHNS14,
  title={A stochastic quasi-Newton method for large-scale optimization},
  author={Byrd, Richard H and Hansen, SL and Nocedal, Jorge and Singer, Yoram},
  journal={arXiv preprint arXiv:1401.7020},
  year={2014}
}

@book{boyd,
  title={Convex optimization},
  author={Boyd, Stephen and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{pegasos,
  title={Pegasos: Primal estimated sub-gradient solver for svm},
  author={Shalev-Shwartz, Shai and Singer, Yoram and Srebro, Nathan and Cotter, Andrew},
  journal={Mathematical programming},
  volume={127},
  number={1},
  pages={3--30},
  year={2011},
  publisher={Springer}
}

@book{rockafellar2015convex,
  title={Convex analysis},
  author={Rockafellar, Ralph Tyrell},
  year={2015},
  publisher={Princeton university press}
}

@inproceedings{mahdavi,
  title={Linear convergence with condition number independent access of full gradients},
  author={Zhang, Lijun and Mahdavi, Mehrdad and Jin, Rong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={980--988},
  year={2013}
}

@article{bro70,
  title={The convergence of a class of double-rank minimization algorithms 2. The new algorithm},
  author={Broyden, Charles G},
  journal={IMA Journal of Applied Mathematics},
  volume={6},
  number={3},
  pages={222--231},
  year={1970},
  publisher={IMA}
}

@article{fle70,
  title={A new approach to variable metric algorithms},
  author={Fletcher, Roger},
  journal={The computer journal},
  volume={13},
  number={3},
  pages={317--322},
  year={1970},
  publisher={Br Computer Soc}
}

@article{gol70,
  title={A family of variable-metric methods derived by variational means},
  author={Goldfarb, Donald},
  journal={Mathematics of computation},
  volume={24},
  number={109},
  pages={23--26},
  year={1970}
}

@article{sha70,
  title={Conditioning of quasi-Newton methods for function minimization},
  author={Shanno, David F},
  journal={Mathematics of computation},
  volume={24},
  number={111},
  pages={647--656},
  year={1970}
}

@article{shamirPCA,
  title={Fast stochastic algorithms for svd and pca: Convergence properties and convexity},
  author={Shamir, Ohad},
  journal={arXiv preprint arXiv:1507.08788},
  year={2015}
}

@article{FastPCAGarber,
  title={Fast and Simple PCA via Convex Optimization},
  author={Garber, Dan and Hazan, Elad},
  journal={arXiv preprint arXiv:1509.05647},
  year={2015}
}


@article{AccSDCA,
  title={Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={Mathematical Programming},
  volume={155},
  number={1-2},
  pages={105--145},
  year={2016},
  publisher={Springer}
}

@article{HessianPearlmutter,
  title={Fast exact multiplication by the Hessian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}
@PREAMBLE{ "\newcommand{\noopsort}[1]{} "}

@techreport{Brochu:2010c,
Author = {Eric Brochu and Vlad M Cora and Nando {de Freitas}},
Institution = {arXiv.org},
Month = {December},
Number = {arXiv:1012.2599},
Title = {A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning},
Type = {eprint},
Year = {2010}}
}

@ARTICLE{Kirkpatrick83optimizationby,
    author = {S. Kirkpatrick and C. D. Gelatt and M. P. Vecchi},
    title = {Optimization by simulated annealing},
    journal = {SCIENCE},
    year = {1983},
    volume = {220},
    number = {4598},
    pages = {671--680}
}


@article{HsuKZ12,
  author    = {Daniel Hsu and
               Sham M. Kakade and
               Tong Zhang},
  title     = {A spectral algorithm for learning Hidden Markov Models},
  journal   = {J. Comput. Syst. Sci.},
  volume    = {78},
  number    = {5},
  pages     = {1460--1480},
  year      = {2012},
}

@inproceedings{AroraGHMMSWZ13,
  author    = {Sanjeev Arora and
               Rong Ge and
               Yonatan Halpern and
               David M. Mimno and
               Ankur Moitra and
               David Sontag and
               Yichen Wu and
               Michael Zhu},
  title     = {A Practical Algorithm for Topic Modeling with Provable Guarantees},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning,
               {ICML} 2013, Atlanta, GA, USA, 16-21 June 2013},
  pages     = {280--288},
  year      = {2013},
}


@inproceedings{AroraGM14,
  author    = {Sanjeev Arora and
               Rong Ge and
               Ankur Moitra},
  title     = {New Algorithms for Learning Incoherent and Overcomplete Dictionaries},
  booktitle = {Proceedings of The 27th Conference on Learning Theory, {COLT} 2014,
               Barcelona, Spain, June 13-15, 2014},
  pages     = {779--806},
  year      = {2014},
}


@article{MOV2012,
author = {Mahoney, Michael W. and Orecchia, Lorenzo and Vishnoi, Nisheeth K.},
journal = {Journal of Machine Learning Research},
pages = {2339--2365},
title = {A local spectral method for graphs: with applications to improving graph partitions and exploring data graphs locally},
volume = {13},
year = {2012}
}
%
@inproceedings{GS12,
  author = {David F. Gleich and C. Seshadhri},
  title = {Vertex neighborhoods, low conductance cuts, and good seeds for local
	community methods},
  booktitle = {KDD '2012},
  year = {2012}
}
%
@article{SM00,
  author    = {J. Shi and J. Malik},
  title     = {Normalized cuts and image segmentation},
  journal   = {IEEE Transactions on  Pattern Analysis and Machine Intelligence},
  volume    = {22},
  number    = {8},
  year      = {2000},
  pages     = {888-905}
}


@article{S07,
  author    = {S. E. Schaeffer},
  title     = {Graph clustering},
  journal   = {Computer Science Review,},
  volume    = {1},
  number    = {1},
  year      = {2007},
  pages     = {27-64}
}

@inproceedings{silvio-security13,
  author = {L. Alvisi and A. Clement and A. Epasto and S. Lattanzi and A. Panconesi},
  title = {The evolution of sybil defense via social networks},
  booktitle = {IEEE Symposium on Security and Privacy},
  year = {2013}
}

 @article{LLDM09,
  author    = {Jure Leskovec and
               Kevin J. Lang and
               Anirban Dasgupta and
               Michael W. Mahoney},
  title     = {Community Structure in Large Networks: Natural Cluster Sizes
               and the Absence of Large Well-Defined Clusters},
  journal   = {Internet Mathematics},
  volume    = {6},
  number    = {1},
  year      = {2009},
  pages     = {29-123},
}


@inproceedings{GLMY11,
  author    = {Ullas Gargi and  Wenjun Lu and Vahab S. Mirrokni and Sangho Yoon},
  title     = {Large-Scale Community Detection on YouTube for Topic Discovery and Exploration},
  booktitle = {AAAI Conference on Weblogs and Social Media},
  year      = {2011},
 }

@inproceedings{AGM12,
  author = {Andersen, Reid and Gleich, David F. and Mirrokni, Vahab},
  title = {Overlapping clusters for distributed computation},
  year = {2012},
  series = {WSDM '12},
  pages = {273--282},
}

@inproceedings{AndersenPeres09,
  author    = {Reid Andersen and Yuval Peres},
  title     = {Finding sparse cuts locally using evolving sets},
  series    = {STOC},
  year      = {2009},
}
%
@inproceedings{MorrisPeres03,
 author = {Morris, Ben and Peres, Yuval},
 title = {Evolving sets and mixing},
 series = {STOC '03},
 year = {2003},
 location = {San Diego, CA, USA},
 pages = {279--286},
 numpages = {8},
 publisher = {ACM},
}

@article{LessardRP14,
  author    = {Laurent Lessard and
               Benjamin Recht and
               Andrew Packard},
  title     = {Analysis and Design of Optimization Algorithms via Integral Quadratic
               Constraints},
  journal   = {CoRR},
  volume    = {abs/1408.3595},
  year      = {2014},
}

@article{ST08c,
abstract = {We present a randomized algorithm that, on input a symmetric, weakly diagonally dominant n-by-n matrix A with m nonzero entries and an n-vector b, produces a y such that \$\backslash norm\{y - \backslash pinv\{A\} b\}\_\{A\} \backslash leq \backslash epsilon \backslash norm\{\backslash pinv\{A\} b\}\_\{A\}\$ in expected time \$O (m \backslash log\^{}\{c\}n \backslash log (1/\backslash epsilon)),\$ for some constant c. By applying this algorithm inside the inverse power method, we compute approximate Fiedler vectors in a similar amount of time. The algorithm applies subgraph preconditioners in a recursive fashion. These preconditioners improve upon the subgraph preconditioners first introduced by Vaidya (1990). For any symmetric, weakly diagonally-dominant matrix A with non-positive off-diagonal entries and \$k \backslash geq 1\$, we construct in time \$O (m \backslash log\^{}\{c\} n)\$ a preconditioner B of A with at most \$2 (n - 1) + O ((m/k) \backslash log\^{}\{39\} n)\$ nonzero off-diagonal entries such that the finite generalized condition number \$\backslash kappa\_\{f\} (A,B)\$ is at most k, for some other constant c. In the special case when the nonzero structure of the matrix is planar the corresponding linear system solver runs in expected time \$ O (n \backslash log\^{}\{2\} n + n \backslash log n \backslash \backslash log \backslash log n \backslash \backslash log (1/\backslash epsilon))\$. We hope that our introduction of algorithms of low asymptotic complexity will lead to the development of algorithms that are also fast in practice.},
archivePrefix = {arXiv},
arxivId = {cs/0607105},
author = {Spielman, Daniel A. and Teng, Shang-Hua},
doi = {10.1137/090771430},
eprint = {0607105},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 2006 - Nearly-Linear Time Algorithms for Preconditioning and Solving Symmetric, Diagonally Dominant Linear Systems.pdf:pdf},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
mendeley-groups = {Algorithms/Sparsification},
month = jul,
number = {3},
pages = {835--885},
primaryClass = {cs},
title = {{Nearly Linear Time Algorithms for Preconditioning and Solving Symmetric, Diagonally Dominant Linear Systems}},
volume = {35},
year = {2014}
}
@article{ST08a,
abstract = {We study the design of local algorithms for massive graphs. A local algorithm is one that finds a solution containing or near a given vertex without looking at the whole graph. We present a local clustering algorithm. Our algorithm finds a good cluster--a subset of vertices whose internal connections are significantly richer than its external connections--near a given vertex. The running time of our algorithm, when it finds a non-empty local cluster, is nearly linear in the size of the cluster it outputs. Our clustering algorithm could be a useful primitive for handling massive graphs, such as social networks and web-graphs. As an application of this clustering algorithm, we present a partitioning algorithm that finds an approximate sparsest cut with nearly optimal balance. Our algorithm takes time nearly linear in the number edges of the graph. Using the partitioning algorithm of this paper, we have designed a nearly-linear time algorithm for constructing spectral sparsifiers of graphs, which we in turn use in a nearly-linear time algorithm for solving linear systems in symmetric, diagonally-dominant matrices. The linear system solver also leads to a nearly linear-time algorithm for approximating the second-smallest eigenvalue and corresponding eigenvector of the Laplacian matrix of a graph. These other results are presented in two companion papers.},
archivePrefix = {arXiv},
arxivId = {0809.3232},
author = {Spielman, Daniel A. and Teng, Shang-Hua},
doi = {10.1137/080744888},
eprint = {0809.3232},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 2013 - A Local Clustering Algorithm for Massive Graphs and Its Application to Nearly Linear Time Graph Partitioning.pdf:pdf},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
mendeley-groups = {Algorithms/Sparsest Cut/Local Clustering,Algorithms/Sparsification},
month = jan,
number = {1},
pages = {1--26},
title = {{A Local Clustering Algorithm for Massive Graphs and Its Application to Nearly Linear Time Graph Partitioning}},
volume = {42},
year = {2013}
}
@article{ST08b,
abstract = {We introduce a new notion of graph sparsificaiton based on spectral similarity of graph Laplacians: spectral sparsification requires that the Laplacian quadratic form of the sparsifier approximate that of the original. This is equivalent to saying that the Laplacian of the sparsifier is a good preconditioner for the Laplacian of the original. We prove that every graph has a spectral sparsifier of nearly linear size. Moreover, we present an algorithm that produces spectral sparsifiers in time \$\backslash softO\{m\}\$, where \$m\$ is the number of edges in the original graph. This construction is a key component of a nearly-linear time algorithm for solving linear equations in diagonally-dominant matrcies. Our sparsification algorithm makes use of a nearly-linear time algorithm for graph partitioning that satisfies a strong guarantee: if the partition it outputs is very unbalanced, then the larger part is contained in a subgraph of high conductance.},
archivePrefix = {arXiv},
arxivId = {0808.4134},
author = {Spielman, Daniel A. and Teng, Shang-Hua},
doi = {10.1137/08074489X},
eprint = {0808.4134},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 2008 - Spectral Sparsification of Graphs.pdf:pdf},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
mendeley-groups = {Algorithms/Sparsification},
month = jan,
number = {4},
pages = {981--1025},
title = {{Spectral Sparsification of Graphs}},
volume = {40},
year = {2011}
}
@article{ACL06,
  AUTHOR =       {Reid Andersen and Fan Chung and Kevin Lang},
  TITLE =        {Using PageRank to Locally Partition a Graph},
  note =         {An extended abstract appeared in FOCS '2006},
  year = {2006},
  ee =       {http://www.math.ucsd.edu/~fan/wp/localpartfull.pdf},
}
%
@article{CKKRS06,
 author = {Chawla, Shuchi and Krauthgamer, Robert and Kumar, Ravi and Rabani, Yuval and Sivakumar, D.},
 title = {On the Hardness of Approximating Multicut and Sparsest-Cut},
 journal = {Computational Complexity},
 volume = {15},
 number = {2},
 month = jun,
 year = {2006},
 pages = {94--114},
 numpages = {21},
 publisher = {Birkhauser Verlag},
}
%
@article{Alon86,
  author    = {Noga Alon},
  title     = {Eigenvalues and expanders},
  journal   = {Combinatorica},
  volume    = {6},
  number    = {2},
  year      = {1986},
  pages     = {83-96},
}
%
@inproceedings{ZCZ09,
 author = {Zhu, Zeyuan Allen and Chen, Weizhu and Zhu, Chenguang and Wang, Gang and Wang, Haixun and Chen, Zheng},
 title = {Inverse Time Dependency in Convex Regularized Learning},
 series = {ICDM},
 year = {2009},
}
%
@inproceedings{SS08,
  author    = {Shai {Shalev-Shwartz} and
               Nathan Srebro},
  title     = {{SVM} optimization: inverse dependence on training set size},
  booktitle = {ICML},
  year      = {2008},
}
%
@article{SinclairJerrum89,
  author    = {Alistair Sinclair and
               Mark Jerrum},
  title     = {Approximate Counting, Uniform Generation and Rapidly Mixing
               Markov Chains},
  journal   = {Information and Computation},
  volume    = {82},
  number    = {1},
  year      = {1989},
  pages     = {93-133},
  ee        = {http://dx.doi.org/10.1016/0890-5401(89)90067-9},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
%
@article{LeightonRao99,
  author    = {Frank Thomson Leighton and
               Satish Rao},
  title     = {Multicommodity max-flow min-cut theorems and their use in
               designing approximation algorithms},
  journal   = {Journal of the ACM},
  volume    = {46},
  number    = {6},
  year      = {1999},
  pages     = {787-832},
  ee        = {http://doi.acm.org/10.1145/331524.331526},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
%
@article{ARV09,
  author    = {Sanjeev Arora and
               Satish Rao and
               Umesh V. Vazirani},
  title     = {Expander flows, geometric embeddings and graph partitioning},
  journal   = {Journal of the ACM},
  volume    = {56},
  number    = {2},
  year      = {2009},
  ee        = {http://doi.acm.org/10.1145/1502793.1502794},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
%
@inproceedings{Sherman09,
 author = {Sherman, Jonah},
 title = {Breaking the Multicommodity Flow Barrier for $O(\sqrt{\log n})$-Approximations to Sparsest Cut},
 booktitle = {Proceedings of the 50th Annual IEEE Symposium on Foundations of Computer Science},
 series = {FOCS '09},
 year = {2009},
 pages = {363--372},
 numpages = {10},
}
%
@inproceedings{ST04,
address = {New York, New York, USA},
author = {Spielman, Daniel A. and Teng, Shang-Hua},
booktitle = {Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04},
doi = {10.1145/1007352.1007372},
isbn = {1581138520},
mendeley-groups = {Algorithms/Sparsification},
pages = {81},
publisher = {ACM Press},
title = {{Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems}},
year = {2004}
}
%
@INPROCEEDINGS{GharanTrevisan12,
author={Gharan, Shayan Oveis and Trevisan, Luca},
series={FOCS},
title={Approximating the Expansion Profile and Almost Optimal Local Graph Clustering},
year={2012},
pages={187-196},
}
%
@article{KVV04,
  author    = {Ravi Kannan and
               Santosh Vempala and
               Adrian Vetta},
  title     = {On clusterings: Good, bad and spectral},
  journal   = {Journal of the ACM},
  volume    = {51},
  number    = {3},
  year      = {2004},
  pages     = {497-515},
  ee        = {http://doi.acm.org/10.1145/990308.990313},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
%
@inproceedings{MMV12,
  author    = {Konstantin Makarychev and
               Yury Makarychev and
               Aravindan Vijayaraghavan},
  title     = {Approximation algorithms for semi-random partitioning problems},
  booktitle = {STOC '12},
  year      = {2012},
  pages     = {367-384},
  ee        = {http://doi.acm.org/10.1145/2213977.2214013},
}
%
@article{PageRank-BrinPage98,
  author    = {Sergey Brin and
               Lawrence Page},
  title     = {The Anatomy of a Large-Scale Hypertextual Web Search Engine},
  journal   = {Computer Networks},
  volume    = {30},
  number    = {1-7},
  year      = {1998},
  pages     = {107-117},
  ee        = {http://dx.doi.org/10.1016/S0169-7552(98)00110-X},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
%
@inproceedings{Haveliwala02,
  author    = {Taher H. Haveliwala},
  title     = {Topic-sensitive PageRank},
  booktitle = {WWW '02},
  year      = {2002},
  pages     = {517-526},
}
%
@inproceedings{LovaszSimonovits90,
  author    = {L{\'a}szl{\'o} Lov{\'a}sz and
               Mikl{\'o}s Simonovits},
 title = {The mixing rate of Markov chains, an isoperimetric inequality, and computing the volume},
 series = {FOCS},
 year = {1990},
 pages = {346-354},
}
%
@article{LovaszSimonovits93,
  author    = {L{\'a}szl{\'o} Lov{\'a}sz and
               Mikl{\'o}s Simonovits},
  title     = {Random Walks in a Convex Body and an Improved Volume Algorithm},
  journal   = {Random Struct. Algorithms},
  volume    = {4},
  number    = {4},
  year      = {1993},
  pages     = {359-412},
}
%
@ARTICLE{CosinePowerSum,
  AUTHOR =       {Mircea Merca},
  TITLE =        {A Note on Cosine Power Sums },
  JOURNAL =      {Journal of Integer Sequences},
  YEAR =         {2012},
  volume =       {15},
  pages =        {12.5.3},
  month =        {May},
}
%
@book{RandomizedAlgorithms,
 author = {Motwani, Rajeev and Raghavan, Prabhakar},
 title = {Randomized algorithms},
 year = {1995},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
}
%
@InProceedings{NIPS12-WLSWC,
   Author = {Wu, Xiao-Ming and Li, Zhenguo and So, Anthony Man-Cho and Wright, John and Chang, Shih-Fu},
   Title = {Learning with Partially Absorbing Random Walks},
   BookTitle = {NIPS},
   year = {2012},
}
%
@inproceedings{LinCohen10,
  author    = {Frank Lin and
               William W. Cohen},
  title     = {Power Iteration Clustering},
  booktitle = {ICML '10},
  year      = {2010},
  pages     = {655-662},
}
%
@inproceedings{AndersenLang06WWW,
 author = {Andersen, Reid and Lang, Kevin J.},
 title = {Communities from seed sets},
 series = {WWW '06},
 year = {2006},
 pages = {223--232},
}
%
@inproceedings{LLM10WWW,
 author = {Leskovec, Jure and Lang, Kevin J. and Mahoney, Michael},
 title = {Empirical comparison of algorithms for network community detection},
 series = {WWW},
 year = {2010},
 pages = {631--640},
}
%
@inproceedings{AndersenLang2008,
author = {Andersen, Reid and Lang, Kevin J.},
series = {SODA},
pages = {651--660},
title = {An algorithm for improving graph partitions},
year = {2008},
}
%
@inproceedings{ZLM13,
  author    = {Zeyuan Allen Zhu and Silvio Lattanzi and Vahab Mirrokni},
  title     = {A Local Algorithm for Finding Well-Connected Clusters},
  booktitle = {ICML},
  year      = {2013},
}

%
@inproceedings{Alamgir2010,
author = {Alamgir, Morteza and von Luxburg, Ulrike},
title = {Multi-agent Random Walks for Local Clustering on Graphs},
series = {ICDM '10},
pages = {18--27},
year = {2010}
}
%
@article{SleatorTarjan1983,
author = {Sleator, Daniel D. and Tarjan, Robert Endre},
journal = {Journal of computer and system sciences},
number = {3},
title = {A data structure for dynamic trees},
volume = {26},
year = {1983}
}
%
@article{Dinic1970,
author = {Dinic, E. A.},
journal = {Soviet Math Doklady},
pages = {1277--1280},
title = {Algorithm for solution of a problem of maximum flow in networks with power estimation},
volume = {11},
year = {1970}
}
%
@article{Gallo1989,
author = {Gallo, Giorgio and Grigoriadis, Michael D. and Tarjan, Robert E.},
journal = {SIAM Journal on Computing},
month = feb,
number = {1},
pages = {30--55},
title = {A Fast Parametric Maximum Flow Algorithm and Applications},
volume = {18},
year = {1989}
}
%
@article{Goldberg1998,
author = {Goldberg, Andrew V. and Rao, Satish},
journal = {Journal of the ACM},
month = sep,
number = {5},
pages = {783--797},
title = {Beyond the flow decomposition barrier},
volume = {45},
year = {1998}
}
%
@article{FeigeKrauthgamer02,
 author = {Feige, Uriel and Krauthgamer, Robert},
 title = {A Polylogarithmic Approximation of the Minimum Bisection},
 journal = {SIAM J. Comput.},
 issue_date = {2002},
 volume = {31},
 number = {4},
 month = apr,
 year = {2002},
 numpages = {29},
 publisher = {Society for Industrial and Applied Mathematics},
}
%
@inproceedings{HHR03,
 author = {Harrelson, Chris and Hildrum, Kirsten and Rao, Satish},
 title = {A polynomial-time tree decomposition to minimize congestion},
 series = {SPAA '03},
 year = {2003},
 isbn = {1-58113-661-7},
 pages = {34--43},
 numpages = {10},
}
%
@article{LangRao2004,
author = {Lang, Kevin and Rao, Satish},
journal = {Integer Programming and Combinatorial Optimization},
pages = {325--337},
title = {{A flow-based method for improving the expansion or conductance of graph cuts}},
volume = {3064},
year = {2004}
}
%
@article{METIS1998,
author = {Karypis, George and Kumar, Vipin},
journal = {SIAM Journal on Scientific Computing},
month = jan,
number = {1},
pages = {359--392},
title = {A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs},
volume = {20},
year = {1998}
}
%
@inproceedings{Kwok2013,
author = {Kwok, Tsz Chiu and Lau, Lap Chi and Lee, Yin Tat and Gharan, Shayan Oveis and Trevisan, Luca},
booktitle = {STOC 2013},
month = jan,
title = {Improved Cheeger's Inequality: Analysis of Spectral Partitioning Algorithms through Higher Order Spectral Gap},
year = {2013}
}
%
@inproceedings{KRV2006,
author = {Khandekar, Rohit and Rao, Satish and Vazirani, Umesh},
booktitle = {STOC '06},
title = {Graph partitioning using single commodity flows},
year = {2006}
}
%
@inproceedings{OSVV2008,
address = {New York, New York, USA},
author = {Orecchia, Lorenzo and Schulman, Leonard J. and Vazirani, Umesh V. and Vishnoi, Nisheeth K.},
booktitle = {STOC 08},
title = {On partitioning graphs via single commodity flows},
year = {2008}
}
@inproceedings{OSV12,
author = {Orecchia, Lorenzo and Sachdeva, Sushant and Vishnoi, Nisheeth K.},
booktitle = {STOC '12},
month = nov,
publisher = {ACM Press},
title = {Approximating the exponential, the lanczos method and an $\tilde{O}(m)$-time spectral algorithm for balanced separator},
year = {2012}
}
@inproceedings{CKMST2011,
abstract = {We introduce a new approach to computing an approximately maximum s-t flow in a capacitated, undirected graph. This flow is computed by solving a sequence of electrical flow problems. Each electrical flow is given by the solution of a system of linear equations in a Laplacian matrix, and thus may be approximately computed in nearly-linear time. Using this approach, we develop the fastest known algorithm for computing approximately maximum s-t flows. For a graph having n vertices and m edges, our algorithm computes a (1-$\backslash$epsilon)-approximately maximum s-t flow in time $\backslash$tilde\{O\}(mn\^{}\{1/3\} $\backslash$epsilon\^{}\{-11/3\}). A dual version of our approach computes a (1+$\backslash$epsilon)-approximately minimum s-t cut in time $\backslash$tilde\{O\}(m+n\^{}\{4/3\}$\backslash$eps\^{}\{-8/3\}), which is the fastest known algorithm for this problem as well. Previously, the best dependence on m and n was achieved by the algorithm of Goldberg and Rao (J. ACM 1998), which can be used to compute approximately maximum s-t flows in time $\backslash$tilde\{O\}(m$\backslash$sqrt\{n\}$\backslash$epsilon\^{}\{-1\}), and approximately minimum s-t cuts in time $\backslash$tilde\{O\}(m+n\^{}\{3/2\}$\backslash$epsilon\^{}\{-3\}).},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1010.2921},
author = {Christiano, Paul and Kelner, Jonathan A. and Madry, Aleksander and Spielman, Daniel A. and Teng, Shang-Hua},
booktitle = {Proceedings of the 43rd annual ACM symposium on Theory of computing - STOC '11},
doi = {10.1145/1993636.1993674},
eprint = {1010.2921},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Christiano et al. - 2011 - Electrical flows, laplacian systems, and faster approximation of maximum flow in undirected graphs.pdf:pdf},
isbn = {9781450306911},
mendeley-groups = {Algorithms/Maxflow},
month = oct,
pages = {273},
publisher = {ACM Press},
title = {{Electrical flows, laplacian systems, and faster approximation of maximum flow in undirected graphs}},
year = {2011}
}
@inproceedings{ImprovedCheeger2013,
author = {Kwok, Tsz Chiu and Lau, Lap Chi and Lee, Yin Tat and {Oveis Gharan}, Shayan and Trevisan, Luca},
booktitle = {STOC '13},
month = jan,
title = {Improved Cheeger's Inequality: Analysis of Spectral Partitioning Algorithms through Higher Order Spectral Gap},
year = {2013}
}
%
@article{Awerbuch2008,
address = {New York, New York, USA},
author = {Awerbuch, Baruch and Khandekar, Rohit},
doi = {10.1145/1374376.1374476},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Awerbuch, Khandekar - 2008 - Stateless distributed gradient descent for positive linear programs.pdf:pdf},
isbn = {9781605580470},
journal = {Proceedings of the fourtieth annual ACM symposium on Theory of computing - STOC 08},
keywords = {convergence,distributed and stateless algorithms,fast,gradient descent,linear programming},
mendeley-groups = {Algorithms/Multiplicative Weight/LP},
pages = {691},
publisher = {ACM Press},
title = {{Stateless distributed gradient descent for positive linear programs}},
year = {2008}
}
%
@inproceedings{Young2001,
author = {Young, Neal E.},
booktitle = {42nd Annual IEEE Symposium on Foundations of Computer Science (FOCS'01)},
doi = {10.1109/SFCS.2001.959930},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Young - 2001 - Sequential and parallel algorithms for mixed packing and covering.pdf:pdf},
isbn = {0-7695-1116-3},
mendeley-groups = {Algorithms/Multiplicative Weight/LP},
pages = {538--546},
publisher = {IEEE Comput. Soc},
title = {{Sequential and parallel algorithms for mixed packing and covering}},
year = {2001}
}
%
@inproceedings{LubyNisan1993,
address = {New York, New York, USA},
author = {Luby, Michael and Nisan, Noam},
booktitle = {Proceedings of the twenty-fifth annual ACM symposium on Theory of computing - STOC '93},
doi = {10.1145/167088.167211},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Luby, Nisan - 1993 - A parallel approximation algorithm for positive linear programming.pdf:pdf},
isbn = {0897915917},
mendeley-groups = {Algorithms/Multiplicative Weight/LP},
pages = {448--457},
publisher = {ACM Press},
title = {{A parallel approximation algorithm for positive linear programming}},
year = {1993}
}
%
@article{JainYao2011,
author = {Jain, Rahul and Yao, Penghui},
doi = {10.1109/FOCS.2011.25},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Jain, Yao - 2011 - A Parallel Approximation Algorithm for Positive Semidefinite Programming.pdf:pdf},
isbn = {978-0-7695-4571-4},
journal = {2011 IEEE 52nd Annual Symposium on Foundations of Computer Science},
keywords = {-fast parallel algorithms,gramming,multiplicative weight update,positive semidefinite pro-},
mendeley-groups = {Algorithms/Multiplicative Weight/SDP},
month = oct,
pages = {463--471},
publisher = {Ieee},
title = {{A Parallel Approximation Algorithm for Positive Semidefinite Programming}},
year = {2011}
}
%
@inproceedings{BartalByersRaz1997,
author = {Bartal, Yair and Byers, John W. and Raz, Danny},
booktitle = {Proceedings 38th Annual Symposium on Foundations of Computer Science},
doi = {10.1109/SFCS.1997.646119},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Bartal, Byers, Raz - 1997 - Global optimization using local information with applications to flow control.pdf:pdf},
isbn = {0-8186-8197-7},
mendeley-groups = {Algorithms/Multiplicative Weight/LP},
pages = {303--312},
publisher = {IEEE Comput. Soc},
title = {{Global optimization using local information with applications to flow control}},
year = {1997}
}
%
@article{BartalByersRaz2004,
author = {Bartal, Yair and Byers, John W. and Raz, Danny},
doi = {10.1137/S0097539700379383},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Bartal, Byers, Raz - 2004 - Fast, Distributed Approximation Algorithms for Positive Linear Programming with Applications to Flow Control.pdf:pdf},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
keywords = {1,10,1137,68w15,68w25,ams subject classifications,approximation algorithm,doi,environment must make decisions,flow control,introduction,linear programming,primal-dual,processors in a distributed,s0097539700379383},
mendeley-groups = {Algorithms/Multiplicative Weight/LP},
month = jan,
number = {6},
pages = {1261--1279},
title = {{Fast, Distributed Approximation Algorithms for Positive Linear Programming with Applications to Flow Control}},
volume = {33},
year = {2004}
}
%
@article{KoufogiannakisYoung2013,
abstract = {We give an approximation algorithm for packing and covering linear programs (linear programs with non-negative coefficients). Given a constraint matrix with n non-zeros, r rows, and c columns, the algorithm computes feasible primal and dual solutions whose costs are within a factor of 1+eps of the optimal cost in time O((r+c)log(n)/eps\^{}2 + n).},
author = {Koufogiannakis, Christos and Young, Neal E.},
doi = {10.1007/s00453-013-9771-6},
issn = {0178-4617},
journal = {Algorithmica},
month = mar,
pages = {494--506},
title = {{A Nearly Linear-Time PTAS for Explicit Fractional Packing and Covering Linear Programs}},
year = {2013},
note = {Previously appeared in FOCS '07.}
}
%
@inproceedings{PengTangwongsan2012,
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1201.5135v1},
author = {Peng, Richard and Tangwongsan, Kanat},
booktitle = {Proceedinbgs of the 24th ACM symposium on Parallelism in algorithms and architectures - SPAA '12},
doi = {10.1145/2312005.2312026},
eprint = {arXiv:1201.5135v1},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Peng, Tangwongsan - 2012 - Faster and simpler width-independent parallel algorithms for positive semidefinite programming.pdf:pdf},
isbn = {9781450312134},
mendeley-groups = {Algorithms/Multiplicative Weight/SDP},
month = jan,
pages = {101},
publisher = {ACM Press},
title = {{Faster and simpler width-independent parallel algorithms for positive semidefinite programming}},
year = {2012}
}
%
@techreport{JainYao2012,
abstract = {We present a parallel approximation algorithm for a class of mixed packing and covering semidefinite programs which generalize on the class of positive semidefinite programs as considered by Jain and Yao [2011]. As a corollary we get a faster approximation algorithm for positive semidefinite programs with better dependence of the parallel running time on the approximation factor, as compared to that of Jain and Yao [2011]. Our algorithm and analysis is on similar lines as that of Young [2001] who considered analogous linear programs.},
archivePrefix = {arXiv},
arxivId = {1201.6090},
author = {Jain, Rahul and Yao, Penghui},
booktitle = {arXiv preprint arXiv:1201.6090},
eprint = {1201.6090},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop//Jain, Yao - 2012 - A parallel approximation algorithm for mixed packing and covering semidefinite programs.pdf:pdf},
mendeley-groups = {Algorithms/Multiplicative Weight/SDP},
month = jan,
pages = {8},
title = {{A parallel approximation algorithm for mixed packing and covering semidefinite programs}},
year = {2012}
}
%
@inproceedings{Nesterov1983,
  title={A method of solving a convex programming problem with convergence rate {$O(1/k^2)$}},
  author={Nesterov, Yurii},
  booktitle={Doklady AN SSSR (translated as Soviet Mathematics Doklady)},
  volume={269},
  pages={543--547},
  year={1983}
}
%
@book{Nesterov2004,
author = {Nesterov, Yurii},
isbn = {1402075537},
publisher = {Kluwer Academic Publishers},
title = {Introductory Lectures on Convex Programming Volume: A Basic course},
volume = {I},
year = {2004}
}
%
@article{Nesterov2005,
abstract = {In this paper we propose a new approach for constructing efficient schemes for non- smooth convex optimization. It is based on a special smoothing technique, which can be applied to the functions with explicit max-structure. Our approach can be considered as an alternative to black-box minimization. From the viewpoint of efficiency estimates, we manage to improve the traditional bounds on the number of iterations of the gra- dient schemes from O 1 unchanged. 2 to O1, keeping basically the complexity of each iteration},
author = {Nesterov, Yurii},
doi = {10.1007/s10107-004-0552-5},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Nesterov - 2005 - Smooth minimization of non-smooth functions.pdf:pdf},
isbn = {1010700405},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {complexity theory,convex optimization,non smooth optimization,optimal methods,optimization,structural optimization},
mendeley-groups = {Optimization/Gradient Descent Theory},
mendeley-tags = {optimization},
month = dec,
number = {1},
pages = {127--152},
title = {{Smooth minimization of non-smooth functions}},
volume = {103},
year = {2005}
}
%
@article{Nesterov2009,
abstract = {In this paper we present a new approach for constructing subgradient schemesfordifferent types ofnonsmoothproblems withconvexstructure.Ourmethods are primal-dual since they are always able to generate a feasible approximation to the optimum of an appropriately formulated dual problem. Besides other advantages, this useful feature provides the methods with a reliable stopping criterion. The proposed schemes differ from the classical approaches (divergent series methods, mirror descent methods) by presence of two control sequences. The first sequence is responsible for aggregating the support functions in the dual space, and the second one establishes a dynamically updated scale between the primal and dual spaces. This additional flexi- bility allows to guarantee a boundedness of the sequence of primal test points even in the case of unbounded feasible set (however, we always assume the uniform bounded- ness of subgradients).We present the variants of subgradient schemes for nonsmooth convex minimization, minimax problems, saddle point problems, variational inequali- ties, and stochastic optimization. In all situations our methods are proved to be optimal from the view point of worst-case black-box lower complexity bounds.},
annote = {A good citation to his dual averaging.},
author = {Nesterov, Yurii},
doi = {10.1007/s10107-007-0149-x},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Nesterov - 2007 - Primal-dual subgradient methods for convex problems.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {Black-box methods,Convex optimization,Lower complexity bounds,Minimax problems,Non-smooth optimization,Saddle points,Stochastic optimization,Subgradient methods,Variational inequalities},
mendeley-groups = {Optimization/Gradient Descent Theory},
month = jun,
number = {1},
pages = {221--259},
title = {{Primal-dual subgradient methods for convex problems}},
volume = {120},
year = {2007}
}
%
@article{AHK2012,
author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
doi = {10.4086/toc.2012.v008a006},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Arora, Hazan, Kale - 2012 - The Multiplicative Weights Update Method a Meta-Algorithm and Applications.pdf:pdf},
journal = {Theory of Computing},
mendeley-groups = {Algorithms/Multiplicative Weight},
pages = {121--164},
title = {{The Multiplicative Weights Update Method: a Meta-Algorithm and Applications.}},
volume = {8},
year = {2012}
}
%
@book{Nemirovsky1978,
  title={Problem complexity and method efficiency in optimization.},
  author={Nemirovsky, Arkadi and Yudin, David},
  publisher={Nauka Publishers, Moscow (in Russian)},
  year={1978},
  note={John Wiley, New York (in English) 1983}
}
%
@book{Nemirovski2013,
author = {{Ben-Tal}, Aharon and Nemirovski, Arkadi},
doi = {10.1137/1.9780898718829},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Ben-Tal, Nemirovski - 2013 - Lectures on Modern Convex Optimization.pdf:pdf},
isbn = {978-0-89871-491-3},
mendeley-groups = {Optimization/Gradient Descent Theory,Books/Optimization},
month = jan,
publisher = {Society for Industrial and Applied Mathematics},
title = {{Lectures on Modern Convex Optimization}},
year = {2013}
}
%
@MISC{Juditsky13-lecture,
  author =       {Anatoli Juditsky},
  title =        {Convex Optimization II: Algorithms},
  howpublished = {Lecture notes},
  year =         {2013},
  month =        {November},
}
%
@article{Trevisan1998,
author = {Trevisan, Luca},
doi = {10.1007/PL00009209},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Trevisan - 1998 - Parallel Approximation Algorithms by Positive Linear Programming.pdf:pdf},
issn = {0178-4617},
journal = {Algorithmica},
mendeley-groups = {Algorithms/Multiplicative Weight/LP},
month = may,
number = {1},
pages = {72--88},
title = {{Parallel Approximation Algorithms by Positive Linear Programming}},
volume = {21},
year = {1998}
}
%
@article{PlotkinST1995,
author = {Plotkin, Serge A. and Shmoys, David B. and Tardos, \'{E}va},
doi = {10.1287/moor.20.2.257},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Plotkin, Shmoys, Tardos - 1995 - Fast Approximation Algorithms for Fractional Packing and Covering Problems.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
mendeley-groups = {Algorithms/Multiplicative Weight/LP},
month = may,
number = {2},
pages = {257--301},
title = {{Fast Approximation Algorithms for Fractional Packing and Covering Problems}},
volume = {20},
year = {1995}
}
%
@article{AwerbuchKR2012,
author = {Awerbuch, Baruch and Khandekar, Rohit and Rao, Satish},
doi = {10.1145/2390176.2390179},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Awerbuch, Khandekar, Rao - 2012 - Distributed algorithms for multicommodity flow problems via approximate steepest descent framework.pdf:pdf},
issn = {15496325},
journal = {ACM Transactions on Algorithms},
mendeley-groups = {Algorithms/Multiplicative Weight/Flow},
month = dec,
number = {1},
pages = {1--14},
title = {{Distributed algorithms for multicommodity flow problems via approximate steepest descent framework}},
volume = {9},
year = {2012}
}
@article{Fleischer2000,
author = {Fleischer, Lisa K.},
doi = {10.1137/S0895480199355754},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Fleischer - 2000 - Approximating Fractional Multicommodity Flow Independent of the Number of Commodities.pdf:pdf},
issn = {0895-4801},
journal = {SIAM Journal on Discrete Mathematics},
mendeley-groups = {Algorithms/Multiplicative Weight/Flow},
month = jan,
number = {4},
pages = {505--520},
title = {{Approximating Fractional Multicommodity Flow Independent of the Number of Commodities}},
volume = {13},
year = {2000}
}
@article{GargK2007,
author = {Garg, Naveen and K\"{o}nemann, Jochen},
doi = {10.1137/S0097539704446232},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Garg, K\"{o}nemann - 2007 - Faster and Simpler Algorithms for Multicommodity Flow and Other Fractional Packing Problems.pdf:pdf},
isbn = {0-8186-9172-7},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
mendeley-groups = {Algorithms/Multiplicative Weight/LP,Algorithms/Multiplicative Weight/Flow},
month = jan,
number = {2},
pages = {630--652},
publisher = {IEEE Comput. Soc},
title = {{Faster and Simpler Algorithms for Multicommodity Flow and Other Fractional Packing Problems}},
volume = {37},
year = {2007}
}
@inproceedings{Madry2010,
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1003.5907v2},
author = {Madry, Aleksander},
booktitle = {Proceedings of the 42nd ACM symposium on Theory of computing - STOC '10},
doi = {10.1145/1806689.1806708},
eprint = {arXiv:1003.5907v2},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Madry - 2010 - Faster approximation schemes for fractional multicommodity flow problems via dynamic graph algorithms.pdf:pdf},
isbn = {9781450300506},
mendeley-groups = {Algorithms/Multiplicative Weight/Flow},
pages = {121},
publisher = {ACM Press},
title = {{Faster approximation schemes for fractional multicommodity flow problems via dynamic graph algorithms}},
year = {2010}
}
@inproceedings{Xiaodi2012,
author={Gutoski, G. and Xiaodi Wu},
booktitle={Computational Complexity (CCC), 2012 IEEE 27th Annual Conference on},
title={Parallel Approximation of Min-max Problems with Applications to Classical and Quantum Zero-Sum Games},
year={2012},
month={June},
pages={21-31},
keywords={approximation theory;computational complexity;game theory;mathematical programming;matrix multiplication;minimax techniques;parallel algorithms;quantum theory;theorem proving;DQIP;PSPACE;QRG(2);SQG;competing-provers complexity class;direct polynomial-space simulation;matrix multiplicative weights update method;min-max problems;multimessage quantum interactive proofs;near-optimal strategies;parallel algorithm;parallel approximation scheme;semidefinite matrices;semidefinite programs;transcript-like consistency condition;two player classical zero-sum games;two player quantum zero-sum games;Approximation methods;Bismuth;Complexity theory;Game theory;Games;Parallel algorithms;Registers;interactive proofs with competing provers;parallel approximation algorithms;semidefinite programs;zero-sum games},
doi={10.1109/CCC.2012.12},
ISSN={1093-0159},}
}
%
@incollection{AwerbuchKhandekar2008latin,
  title={Stateless near optimal flow control with poly-logarithmic convergence},
  author={Awerbuch, Baruch and Khandekar, Rohit},
  booktitle={LATIN 2008: Theoretical Informatics},
  pages={580--592},
  year={2008},
  publisher={Springer}
}
%
@article{AwerbuchKhandekar2009DistributedComputing,
year={2009},
issn={0178-2770},
journal={Distributed Computing},
volume={21},
number={5},
doi={10.1007/s00446-008-0074-0},
title={Greedy distributed optimization of multi-commodity flows},
publisher={Springer-Verlag},
keywords={Multi-commodity flows; Distributed algorithms; Statelessness; Self-stabilization},
author={Awerbuch, Baruch and Khandekar, Rohit},
pages={317-329}
}
%
@inproceedings{AwerbuchAzarKhandekar2008soda,
 author = {Awerbuch, Baruch and Azar, Yossi and Khandekar, Rohit},
 title = {Fast Load Balancing via Bounded Best Response},
 booktitle = {Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
 series = {SODA '08},
 year = {2008},
 location = {San Francisco, California},
 pages = {314--322},
 numpages = {9},
 acmid = {1347117},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
}
%
@article{Nemirovski2004,
annote = {Nemirovski's Mirror-Prox Method},
author = {Nemirovski, Arkadi},
doi = {10.1137/S1052623403425629},
issn = {1052-6234},
journal = {SIAM Journal on Optimization},
mendeley-groups = {Optimization/Gradient Descent Theory},
month = jan,
number = {1},
pages = {229--251},
title = {{Prox-Method with Rate of Convergence $O(1/t)$ for Variational Inequalities with Lipschitz Continuous Monotone Operators and Smooth Convex-Concave Saddle Point Problems}},
volume = {15},
year = {2004}
}
%
@techreport{Shalev-Shwartz2007a,
annote = {Contains the detailed proof for the PEGASOS paper},
author = {{Shalev-Shwartz}, Shai and Singer, Yoram},
booktitle = {The Hebrew University, Technical \ldots},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shalev-Shwartz, Singer - 2007 - Logarithmic regret algorithms for strongly convex repeated games.pdf:pdf},
mendeley-groups = {Optimization/Stochastic Online Regularized Optimization},
pages = {1--16},
institution = {The Hebrew University},
title = {{Logarithmic regret algorithms for strongly convex repeated games}},
year = {2007}
}
%
@phdthesis{Shalev-Shwartz2007b,
author = {{Shalev-Shwartz}, Shai},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shalev-Shwartz - 2007 - Online learning Theory, algorithms, and applications.pdf:pdf},
mendeley-groups = {Optimization/Stochastic Online Optimization,Optimization/General Theory},
number = {July},
school = {Hebrew University},
title = {{Online learning: Theory, algorithms, and applications}},
year = {2007}
}
%
@article{Shalev-Shwartz2011,
author = {{Shalev-Shwartz}, Shai},
doi = {10.1561/2200000018},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
mendeley-groups = {Optimization/Stochastic Online Regularized Optimization},
number = {2},
pages = {107--194},
title = {{Online Learning and Online Convex Optimization}},
volume = {4},
year = {2012}
}
%
@inproceedings{AroraKale2007,
address = {New York, New York, USA},
author = {Arora, Sanjeev and Kale, Satyen},
booktitle = {Proceedings of the thirty-ninth annual ACM symposium on Theory of computing - STOC '07},
doi = {10.1145/1250790.1250823},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Arora, Kale - 2007 - A combinatorial, primal-dual approach to semidefinite programs.pdf:pdf},
isbn = {9781595936318},
mendeley-groups = {Algorithms/Multiplicative Weight,Algorithms/Multiplicative Weight/SDP},
pages = {227},
publisher = {ACM Press},
title = {{A combinatorial, primal-dual approach to semidefinite programs}},
year = {2007}
}
%
@inproceedings{AHK2005,
author = {Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
booktitle = {46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)},
doi = {10.1109/SFCS.2005.35},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Arora, Hazan, Kale - 2005 - Fast Algorithms for Approximate Semidefinite Programming using the Multiplicative Weights Update Method.pdf:pdf},
isbn = {0-7695-2468-0},
mendeley-groups = {Algorithms/Multiplicative Weight,Algorithms/Multiplicative Weight/SDP},
pages = {339--348},
publisher = {IEEE},
title = {{Fast Algorithms for Approximate Semidefinite Programming using the Multiplicative Weights Update Method}},
year = {2005}
}
%
@techreport{Kakade2009,
author = {Kakade, Sham M. and {Shalev-Shwartz}, Shai and Tewari, Ambuj},
booktitle = {\ldots Manuscript, http://ttic. \ldots},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Kakade, Shalev-Shwartz, Tewari - 2009 - On the duality of strong convexity and strong smoothness Learning applications and matrix regula.pdf:pdf},
mendeley-groups = {Optimization/General Theory},
title = {{On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization}},
year = {2009}
}
%
@inproceedings{KLOS2014,
abstract = {In this paper, we introduce a new framework for approximately solving flow problems in capacitated, undirected graphs and apply it to provide asymptotically faster algorithms for the maximum \$s\$-\$t\$ flow and maximum concurrent multicommodity flow problems. For graphs with \$n\$ vertices and \$m\$ edges, it allows us to find an \$\backslash epsilon\$-approximate maximum \$s\$-\$t\$ flow in time \$O(m\^{}\{1+o(1)\}\backslash epsilon\^{}\{-2\})\$, improving on the previous best bound of \$\backslash tilde\{O\}(mn\^{}\{1/3\} poly(1/\backslash epsilon))\$. Applying the same framework in the multicommodity setting solves a maximum concurrent multicommodity flow problem with \$k\$ commodities in \$O(m\^{}\{1+o(1)\}\backslash epsilon\^{}\{-2\}k\^{}2)\$ time, improving on the existing bound of \$\backslash tilde\{O\}(m\^{}\{4/3\} poly(k,\backslash epsilon\^{}\{-1\})\$. Our algorithms utilize several new technical tools that we believe may be of independent interest: - We give a non-Euclidean generalization of gradient descent and provide bounds on its performance. Using this, we show how to reduce approximate maximum flow and maximum concurrent flow to the efficient construction of oblivious routings with a low competitive ratio. - We define and provide an efficient construction of a new type of flow sparsifier. In addition to providing the standard properties of a cut sparsifier our construction allows for flows in the sparse graph to be routed (very efficiently) in the original graph with low congestion. - We give the first almost-linear-time construction of an \$O(m\^{}\{o(1)\})\$-competitive oblivious routing scheme. No previous such algorithm ran in time better than \$\backslash tilde\{\{\backslash Omega\}\}(mn)\$. We also note that independently Jonah Sherman produced an almost linear time algorithm for maximum flow and we thank him for coordinating submissions.},
archivePrefix = {arXiv},
arxivId = {1304.2338},
author = {Kelner, Jonathan A. and Lee, Yin Tat and Orecchia, Lorenzo and Sidford, Aaron},
booktitle = {Proceedings of the 25th Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '14},
doi = {10.1137/1.9781611973402.16},
eprint = {1304.2338},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Kelner et al. - 2014 - An Almost-Linear-Time Algorithm for Approximate Max Flow in Undirected Graphs, and its Multicommodity Generalizat.pdf:pdf},
mendeley-groups = {Algorithms/Maxflow},
series = {STOC '14},
month = apr,
number = {1},
title = {{An Almost-Linear-Time Algorithm for Approximate Max Flow in Undirected Graphs, and its Multicommodity Generalizations}},
year = {2014}
}
%
@inproceedings{LRS2013,
address = {New York, New York, USA},
author = {Lee, Yin Tat and Rao, Satish and Srivastava, Nikhil},
booktitle = {Proceedings of the 45th annual ACM symposium on Symposium on theory of computing - STOC '13},
doi = {10.1145/2488608.2488704},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Lee, Rao, Srivastava - 2013 - A new approach to computing maximum flows using electrical flows.pdf:pdf},
isbn = {9781450320290},
mendeley-groups = {Algorithms/Maxflow},
pages = {755},
publisher = {ACM Press},
title = {{A new approach to computing maximum flows using electrical flows}},
year = {2013}
}
%
@inproceedings{Madry2013,
author = {Madry, Aleksander},
booktitle = {2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
doi = {10.1109/FOCS.2013.35},
isbn = {978-0-7695-5135-7},
mendeley-groups = {Algorithms/Maxflow},
month = oct,
pages = {253--262},
publisher = {IEEE},
title = {{Navigating Central Path with Electrical Flows: From Flows to Matchings, and Back}},
year = {2013}
}
%
@inproceedings{Sherman2013,
author = {Sherman, Jonah},
booktitle = {2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
doi = {10.1109/FOCS.2013.36},
isbn = {978-0-7695-5135-7},
mendeley-groups = {Algorithms/Maxflow},
month = oct,
pages = {263--269},
publisher = {IEEE},
title = {{Nearly Maximum Flows in Nearly Linear Time}},
year = {2013}
}
%
@inproceedings{Shalev-Shwartz2013b,
booktitle={Proceedings of the 31st International Conference on Machine Learning},
series={ICML 2014},
author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
pages = {64--72},
title = {{Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization}},
year = {2014}
}
@inproceedings{Shalev-Shwartz2013a,
abstract = {Stochastic dual coordinate ascent (SDCA) is an effective technique for solving regularized loss minimization problems in machine learning. This paper considers an extension of SDCA under the mini-batch setting that is often used in practice. Our main contribution is to introduce an accelerated mini-batch version of SDCA and prove a fast convergence rate for this method. We discuss an implementation of our method over a parallel computing system, and compare the results to both the vanilla stochastic dual coordinate ascent and to the accelerated deterministic gradient descent method of $\backslash$cite\{nesterov2007gradient\}.},
archivePrefix = {arXiv},
arxivId = {1305.2581},
author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
booktitle = {NIPS},
eprint = {1305.2581},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shalev-Shwartz, Zhang - 2013 - Accelerated Mini-Batch Stochastic Dual Coordinate Ascent.pdf:pdf},
mendeley-groups = {Optimization/Stochastic Online Regularized Optimization},
month = may,
pages = {1--17},
title = {{Accelerated Mini-Batch Stochastic Dual Coordinate Ascent}},
year = {2013}
}
%
@inproceedings{Shalev-Shwartz2015-SDCAwithoutDual,
author = {{Shalev-Shwartz}, Shai},
booktitle = {ICML},
title = {{SDCA without Duality, Regularization, and Individual Convexity}},
year = {2016}
}
%
@article{Shalev-ShwartzZhang2014-ProxSDCA,
archivePrefix = {arXiv},
arxivId = {1211.2717},
author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
eprint = {1211.2717},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shalev-shwartz, Zhang - 2012 - Proximal Stochastic Dual Coordinate Ascent.pdf:pdf},
journal = {arXiv preprint arXiv:1211.2717},
mendeley-groups = {Optimization/Stochastic Online Optimization},
pages = {1--18},
title = {{Proximal Stochastic Dual Coordinate Ascent}},
url = {http://arxiv.org/pdf/1211.2717v1.pdf},
year = {2012}
}
%
@techreport{BienstockIyengar2004,
author = {Bienstock, D. and Iyengar, G.},
title = {{Faster approximation algorithms for packing and covering problems}},
year = {2004},
note = {Preliminary version published in STOC '04}
}
%
@article{Dekel2012,
abstract = {Online prediction methods are typically presented as serial algorithms running on a single processor. However, in the age of web-scale prediction problems, it is increasingly common to encounter situations where a single processor cannot keep up with the high rate at which inputs arrive. In this work, we present the $\backslash$emph\{distributed mini-batch\} algorithm, a method of converting many serial gradient-based online prediction algorithms into distributed algorithms. We prove a regret bound for this method that is asymptotically optimal for smooth convex loss functions and stochastic inputs. Moreover, our analysis explicitly takes into account communication latencies between nodes in the distributed environment. We show how our method can be used to solve the closely-related distributed stochastic optimization problem, achieving an asymptotically linear speed-up over multiple processors. Finally, we demonstrate the merits of our approach on a web-scale online prediction problem.},
annote = {Contains some information about "using mirror descent steps" on smooth objectives, though analyzed in stochastic way.},
archivePrefix = {arXiv},
arxivId = {1012.1367},
author = {Dekel, Ofer and {Gilad-Bachrach}, Ran and Shamir, Ohad and Xiao, Lin},
eprint = {1012.1367},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Dekel et al. - 2012 - Optimal distributed online prediction using mini-batches.pdf:pdf},
isbn = {978-1-4503-0619-5},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
keywords = {convex,distributed computing,online learning,regret bounds,stochastic optimization},
mendeley-groups = {Optimization/Stochastic Online Optimization},
number = {1},
pages = {165--202},
title = {{Optimal distributed online prediction using mini-batches}},
volume = {13},
year = {2012}
}
%
@inproceedings{zurel2001efficient,
  title={An efficient approximate allocation algorithm for combinatorial auctions},
  author={Zurel, Edo and Nisan, Noam},
  booktitle={Proceedings of the 3rd ACM conference on Electronic Commerce},
  pages={125--136},
  year={2001},
  organization={ACM}
}
%
@inproceedings{byers2000utility,
  title={Utility-based decision-making in wireless sensor networks},
  author={Byers, John and Nasser, Gabriel},
  booktitle={Mobile and Ad Hoc Networking and Computing, 2000. MobiHOC. 2000 First Annual Workshop on},
  pages={143--144},
  year={2000},
  organization={IEEE}
}
%
@article{kivinen1997exponentiated,
  title={Exponentiated gradient versus gradient descent for linear predictors},
  author={Kivinen, Jyrki and Warmuth, Manfred K},
  journal={Information and Computation},
  volume={132},
  number={1},
  pages={1--63},
  year={1997},
  publisher={Elsevier}
}
%
@inproceedings{ShamirZhang2013,
abstract = {Stochastic Gradient Descent (SGD) is one of the simplest and most popular stochastic optimization methods. While it has already been theoretically studied for decades, the classical analysis usually required non-trivial smoothness assumptions, which do not apply to many modern applications of SGD with non-smooth objective functions such as support vector machines. In this paper, we investigate the performance of SGD without such smoothness assumptions, as well as a running average scheme to convert the SGD iterates to a solution with optimal optimization accuracy. In this framework, we prove that after T rounds, the suboptimality of the last SGD iterate scales as O(log(T)/$\backslash$sqrt\{T\}) for non-smooth convex objective functions, and O(log(T)/T) in the non-smooth strongly convex case. To the best of our knowledge, these are the first bounds of this kind, and almost match the minimax-optimal rates obtainable by appropriate averaging schemes. We also propose a new and simple averaging scheme, which not only attains optimal rates, but can also be easily computed on-the-fly (in contrast, the suffix averaging scheme proposed in Rakhlin et al. (2011) is not as simple to implement). Finally, we provide some experimental illustrations.},
annote = {This paper answers the open question of Shamir in COLT'12 about how to get a non-smooth algorithm whose last round is great, rather than avearging of the history. This paper also works for strongly-convex non-smooth functions.},
archivePrefix = {arXiv},
arxivId = {1212.1824},
author = {Shamir, Ohad and Zhang, Tong},
booktitle = {Proceedings of the 30th International Conference on Machine Learning - ICML '13},
eprint = {1212.1824},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Shamir, Zhang - 2013 - Stochastic Gradient Descent for Non-smooth Optimization Convergence Results and Optimal Averaging Schemes.pdf:pdf},
mendeley-groups = {Optimization/Gradient Descent Theory},
title = {{Stochastic Gradient Descent for Non-smooth Optimization: Convergence Results and Optimal Averaging Schemes}},
volume = {28},
year = {2013}
}
%
@article{Fercoq2013,
author = {Fercoq, Olivier and Richt\'{a}rik, Peter},
title = {Accelerated, Parallel, and Proximal Coordinate Descent},
journal = {SIAM Journal on Optimization},
volume = {25},
number = {4},
pages = {1997-2023},
year = {2015},
note = {First appeared on ArXiv 1312.5799 in 2013},
}
%
@article{ODonoghue2012,
author = {{O'Donoghue}, Brendan and Cand\`{e}s, Emmanuel},
doi = {10.1007/s10208-013-9150-3},
file = {:C$\backslash$:/Users/Zeyuan Zhu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title.pdf:pdf},
issn = {1615-3375},
journal = {Foundations of Computational Mathematics},
mendeley-groups = {Optimization/Gradient Descent Theory},
month = jul,
title = {{Adaptive Restart for Accelerated Gradient Schemes}},
year = {2013}
}
%
@ARTICLE{BLS2015,
   author = {Bubeck, S{\'e}bastien and Lee, Yin Tat and Singh, Mohit},
   title = {A geometric alternative to {N}esterov's accelerated gradient descent},
   journal = {ArXiv e-prints},
   volume    = {abs/1506.08187},
   url       = {http://arxiv.org/abs/1506.08187},
   year = 2015,
   month = jun,
}
%
@inproceedings{freund1995desicion,
  title={A desicion-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E},
  booktitle={Computational learning theory},
  pages={23--37},
  year={1995},
  organization={Springer}
}
%
@article{McMahan2011,
abstract = {We study three families of online convex optimization algorithms: follow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual averaging (RDA), and composite-objective mirror descent. We first prove equivalence theorems that show all of these algorithms are instantiations of a general FTRL update. This provides theoretical insight on previous experimental observations. In particular, even though the FOBOS composite mirror descent algorithm handles L1 regularization explicitly, it has been observed that RDA is even more effective at producing sparsity. Our results demonstrate that FOBOS uses subgradient approximations to the L1 penalty from previous rounds, leading to less sparsity than RDA, which handles the cumulative penalty in closed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two, and outperforms both on a large, real-world dataset. Our second contribution is a unified analysis which produces regret bounds that match (up to logarithmic terms) or improve the best previously known bounds. This analysis also extends these algorithms in two important ways: we support a more general type of composite objective and we analyze implicit updates, which replace the subgradient approximation of the current loss function with an exact optimization.},
annote = {This is presumably the journal version of "Follow-the-regularized-leader and mirror descent: Equivalence theorems and l1 regularization"
      },
archivePrefix = {arXiv},
arxivId = {1009.3240},
author = {McMahan, H. Brendan},
eprint = {1009.3240},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/McMahan - 2011 - A Unified View of Regularized Dual Averaging and Mirror Descent with Implicit Updates.pdf:pdf},
journal = {arXiv preprint arXiv:1009.3240},
keywords = {bounds,follow-the-leader algorithms,online convex optimization,online learning,regret,subgradient methods},
mendeley-groups = {Optimization/Gradient Descent Theory},
month = sep,
title = {{A Unified View of Regularized Dual Averaging and Mirror Descent with Implicit Updates}},
year = {2011},
note = {Previously appeared in AISTATS 2011 as a conference paper entitled ``{Follow-the-regularized-leader and mirror descent: Equivalence theorems and l1 regularization}''}
}
%
@inproceedings{McMahanStreeter2010,
abstract = {We introduce a new online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far. This is in contrast to previous algorithms that use a fixed regularization function such as L2-squared, and modify it only via a single time-dependent parameter. Our algorithm's regret bounds are worst-case optimal, and for certain realistic classes of loss functions they are much better than existing bounds. These bounds are problem-dependent, which means they can exploit the structure of the actual problem instance. Critically, however, our algorithm does not need to know this structure in advance. Rather, we prove competitive guarantees that show the algorithm provides a bound within a constant factor of the best possible bound (of a certain functional form) in hindsight.},
archivePrefix = {arXiv},
arxivId = {1002.4908},
author = {McMahan, H. Brendan and Streeter, Matthew},
booktitle = {Proceedings of the 23rd Annual Conference on Learning Theory - COLT '10},
eprint = {1002.4908},
mendeley-groups = {Optimization/Gradient Descent Theory},
month = feb,
title = {{Adaptive Bound Optimization for Online Convex Optimization}},
year = {2010}
}
%


@inproceedings{Duchi2010,
abstract = {We present a new method for regularized convex optimization and analyze it under both online and stochastic optimization settings. In addition to unifying previously known ﬁrstorder algorithms, such as the projected gradient method, mirror descent, and forwardbackward splitting, our method yields new analysis and algorithms. We also derive speciﬁc instantiations of our method for commonly used regularization functions, such as ℓ1, mixed norm, and trace-norm.},
author = {Duchi, John and {Shalev-Shwartz}, Shai and Singer, Yoram and Tewari, Ambuj},
booktitle = {Proceedings of the 23rd Annual Conference on Learning Theory - COLT '10},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Duchi et al. - 2010 - Composite Objective Mirror Descent.pdf:pdf},
keywords = {Learning/Statistics \& Optimisation,Theory \& Algorithms},
mendeley-groups = {Optimization/Gradient Descent Theory/Composite},
number = {1},
title = {{Composite Objective Mirror Descent}},
year = {2010}
}
%
@article{Nesterov2013,
author = {Nesterov, Yurii},
doi = {10.1007/s10107-012-0629-5},
file = {:D$\backslash$:/Mendeley Desktop/Nesterov - 2013 - Gradient methods for minimizing composite functions.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
mendeley-groups = {Optimization/Gradient Descent Theory,Optimization/Gradient Descent Theory/Composite},
number = {1},
pages = {125--161},
title = {{Gradient methods for minimizing composite functions}},
volume = {140},
year = {2013}
}
%
@article{Lan2011,
author = {Lan, Guanghui},
doi = {10.1007/s10107-010-0434-y},
file = {:D$\backslash$:/Mendeley Desktop/Lan - 2011 - An optimal method for stochastic composite optimization.pdf:pdf},
isbn = {0001408100},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {convex optimization,stochastic approximation},
mendeley-groups = {Optimization/Gradient Descent Theory/Composite},
month = jan,
number = {1-2},
pages = {365--397},
title = {{An optimal method for stochastic composite optimization}},
volume = {133},
year = {2011}
}
%
@article{nesterov2008cubic,
  title={Accelerating the cubic regularization of Newton's method on convex problems},
  author={Nesterov, Yurii},
  journal={Mathematical Programming},
  volume={112},
  number={1},
  pages={159--181},
  year={2008},
  publisher={Springer}
}
%
@article{Nesterov2014,
author = {Nesterov, Yurii},
doi = {10.1007/s10107-014-0790-0},
issn = {0025-5610},
journal = {Mathematical Programming},
mendeley-groups = {Optimization/Gradient Descent Theory},
month = may,
title = {{Universal gradient methods for convex optimization problems}},
year = {2014}
}
%
@article{Xiao2010,
annote = {Contains the so-called "dual averaging" step.},
author = {Xiao, Lin},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Xiao - 2010 - Dual averaging method for regularized stochastic learning and online optimization.pdf:pdf},
journal = {The Journal of Machine Learning Research},
mendeley-groups = {Optimization/Stochastic Online Optimization},
pages = {2543--2596},
title = {{Dual averaging method for regularized stochastic learning and online optimization}},
volume = {11},
year = {2010}
}
%
@article{banerjee2005clustering,
  title={Clustering with Bregman divergences},
  author={Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S. and Ghosh, Joydeep},
  journal={The Journal of Machine Learning Research},
  volume={6},
  pages={1705--1749},
  year={2005},
  publisher={JMLR. org}
}
%
@book{Rockafellar1996convex,
  title={Convex Analysis (Princeton Landmarks in Mathematics and Physics)},
  author={Rockafellar, R. Tyrrell},
  year={1996},
  publisher={Princeton University Press}
}
%
@inproceedings{Auer1995,
author = {Auer, Peter and {Cesa-Bianchi}, Nicol\`{o} and Freund, Yoav and Schapire, Robert E.},
booktitle = {Proceedings of IEEE 36th Annual Foundations of Computer Science},
doi = {10.1109/SFCS.1995.492488},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Gambling in a rigged casino The adversarial multi-armed bandit problem.pdf:pdf},
isbn = {0-8186-7183-1},
mendeley-groups = {Optimization/Bandit},
pages = {322--331},
publisher = {IEEE Comput. Soc. Press},
title = {{Gambling in a rigged casino: The adversarial multi-armed bandit problem}},
year = {1995}
}
%
@article{Auer2002nonstochastic,
author = {Auer, Peter and {Cesa-Bianchi}, Nicol\`{o} and Freund, Yoav and Schapire, Robert E.},
doi = {10.1137/S0097539701398375},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/7c440d389dadd89e5dc4f71b705d5fb816b5cad6.pdf:pdf},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
keywords = {1995,331,68q32 68t05 91a20,adversarial bandit problem,ams subject classification,an early extended abstract,in the proceedings of,of this paper appeared,on founda-,pages 322,the 36th annual symposium,tions of computer science,unknown matrix games},
mendeley-groups = {Optimization/Bandit},
month = jan,
number = {1},
pages = {48--77},
title = {{The Nonstochastic Multiarmed Bandit Problem}},
volume = {32},
note = {The journal version of Auer et al. 1995},
year = {2002}
}
%
@book{Cesa-Bianchi2006,
address = {Cambridge},
author = {{Cesa-Bianchi}, Nicolo and Lugosi, Gabor},
doi = {10.1017/CBO9780511546921},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cesa-Bianchi, Lugosi - 2006 - Prediction, Learning, and Games.pdf:pdf},
isbn = {9780511546921},
mendeley-groups = {Books/Optimization},
publisher = {Cambridge University Press},
title = {{Prediction, Learning, and Games}},
year = {2006}
}
%
@inproceedings{AbernethyRakhlin2009,
abstract = {We provide a principled way of proving Omacr(radicT) high-probability guarantees for partial-information (bandit) problems over arbitrary convex decision sets. First, we prove a regret guarantee for the full-information problem in terms of ldquolocalrdquo norms, both for entropy and self-concordant barrier regularization, unifying these methods. Given one of such algorithms as a black-box, we can convert a bandit problem into a full-information problem using a sampling scheme. The main result states that a high-probability Omacr(radicT) bound holds whenever the black-box, the sampling scheme, and the estimates of missing information satisfy a number of conditions, which are relatively easy to check. At the heart of the method is a construction of linear upper bounds on confidence intervals. As applications of the main result, we provide the first known efficient algorithm for the sphere with an Omacr(radicT) high-probability bound. We also derive the result for the n-simplex, improving the O(radicnT log(nT)) bound of Auer et al [3] by replacing the log T term with log log T and closing the gap to the lower bound of Omacr(radicnT). While Omacr(radicT) high-probability bounds should hold for general decision sets through our main result, construction of linear upper bounds depends on the particular geometry of the set; we believe that the sphere example already exhibits the necessary ingredients. The guarantees we obtain hold for adaptive adversaries (unlike the in-expectation results of [1]) and the algorithms are efficient, given that the linear upper bounds on confidence can be computed.},
author = {Abernethy, Jacob and Rakhlin, Alexander},
booktitle = {Proceedings of the 22nd Conference on Learning Theory - COLT' 09},
doi = {10.1109/ITA.2009.5044958},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abernethy, Rakhlin - 2009 - Beating the adaptive bandit with high probability.pdf:pdf},
isbn = {9781424439904},
mendeley-groups = {Optimization/Bandit},
pages = {280--289},
title = {{Beating the adaptive bandit with high probability}},
year = {2009}
}
%
@inproceedings{BDHKRT2008,
author = {Bartlett, Peter L. and Dani, Varsha and Hayes, Thomas P. and Kakade, Sham M. and Rakhlin, Alexander and Tewari, Ambuj},
booktitle = {Proceedings of the 21st Conference on Learning Theory - COLT '08},
file = {:D$\backslash$:/Mendeley Desktop/Bartlett et al. - 2008 - High-probability regret bounds for bandit online linear optimization.pdf:pdf},
mendeley-groups = {Optimization/Bandit},
title = {{High-probability regret bounds for bandit online linear optimization}},
year = {2008}
}
%
@article{robbins1952some,
  title={Some Aspects of the Sequential Design of Experiments},
  author={Robbins, Herbert},
  journal={Bulletin of the American Mathematical Society},
  volume={58},
  pages={527--535},
  year={1952}
}
%
@inproceedings{Kleinberg2003,
abstract = {We consider price-setting algorithms for a simple market in which a seller has an unlimited supply of identical copies of some good, and interacts sequentially with a pool of n buyers, each of whom wants at most one copy of the good. In each transaction, the seller offers a price between 0 and 1, and the buyer decides whether or not to buy, by comparing the offered price to his privately-held valuation for the good. The price offered to a given buyer may be influenced by the outcomes of prior transactions, but each individual buyer participates only once. In this setting, what is the value of knowing the demand curve? In other words, how much revenue can an uninformed seller expect to obtain, relative to a seller with prior information about the buyers' valuations? The answer depends on how the buyers' valuations are modeled. We analyze three cases - identical, random, and worst-case valuations - in each case deriving upper and lower bounds which match within a sublogarithmic factor.},
author = {Kleinberg, R. and Leighton, T.},
booktitle = {44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings.},
doi = {10.1109/SFCS.2003.1238232},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title(2).pdf:pdf},
isbn = {0-7695-2040-5},
issn = {0272-5428},
mendeley-groups = {Operation Research},
number = {Focs 2003},
pages = {594--605},
publisher = {IEEE Computer. Soc},
title = {{The value of knowing a demand curve: bounds on regret for online posted-price auctions}},
year = {2003}
}
%
@book{berry1985bandit,
  title={Bandit Problems: Sequential Allocation of Experiments (Monographs on Statistics and Applied Probability)},
  author={Berry, Donald A and Fristedt, Bert},
  year={1985},
  publisher={Springer}
}
%
@article{veatch1996scheduling,
  title={Scheduling a make-to-stock queue: Index policies and hedging points},
  author={Veatch, Michael H and Wein, Lawrence M},
  journal={Operations Research},
  volume={44},
  number={4},
  pages={634--647},
  year={1996},
  publisher={INFORMS}
}
%
@article{whittle1988restless,
  title={Restless bandits: Activity allocation in a changing world},
  author={Whittle, Peter},
  journal={Journal of applied probability},
  pages={287--298},
  year={1988},
  publisher={JSTOR}
}
%
@inproceedings{radlinski2008learning,
  title={Learning diverse rankings with multi-armed bandits},
  author={Radlinski, Filip and Kleinberg, Robert and Joachims, Thorsten},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={784--791},
  year={2008},
  organization={ACM}
}
%
@inproceedings{awerbuch2004adaptive,
  title={Adaptive routing with end-to-end feedback: Distributed learning and geometric approaches},
  author={Awerbuch, Baruch and Kleinberg, Robert D},
  booktitle={Proceedings of the thirty-sixth annual ACM symposium on Theory of computing},
  pages={45--53},
  year={2004},
  organization={ACM}
}
%
@article{gyorgy2007line,
  title={The On-Line Shortest Path Problem Under Partial Monitoring},
  author={Gy{\"o}rgy, Andr{\'a}s and Linder, Tam{\'a}s and Lugosi, G{\'a}bor and Ottucs{\'a}k, Gy{\"o}rgy},
  journal={Journal of Machine Learning Research},
  volume={8},
  pages={2369--2403},
  year={2007}
}
%
@article{Auer2002stochastic,
annote = {This is for the case when there is a fixed (but unknown) distribution where the feedbacks are generated.

It is different from the other type of bandit work where there is no distribution.},
author = {Auer, Peter and {Cesa-Bianchi}, Nicol\`{o} and Fischer, Paul},
doi = {10.1023/A:1013689704352},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Auer, Cesa-Bianchi, Fischer - 2002 - Finite-time analysis of the multiarmed bandit problem.pdf:pdf},
journal = {Machine Learning},
mendeley-groups = {Optimization/Bandit},
number = {2-3},
pages = {235--256},
title = {{Finite-time analysis of the multiarmed bandit problem}},
volume = {47},
year = {2002}
}
%
@article{Abernethy2012,
author = {Abernethy, Jacob D. and Hazan, Elad and Rakhlin, Alexander},
doi = {10.1109/TIT.2012.2192096},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abernethy, Hazan, Rakhlin - 2012 - Interior-Point Methods for Full-Information and Bandit Online Learning.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
mendeley-groups = {Optimization/Bandit},
month = jul,
number = {7},
pages = {4164--4175},
title = {{Interior-Point Methods for Full-Information and Bandit Online Learning}},
volume = {58},
year = {2012},
note = {An earlier version of this paper has appeared in COLT'08}
}
%
@inproceedings{mcmahan2004online,
  title={Online Geometric Optimization in the Bandit Setting Against an Adaptive Adversary},
  author={McMahan, H Brendan and Blum, Avrim},
  booktitle={COLT 2004},
  volume={17},
  pages={109},
  year={2004},
  organization={Springer}
}
%
@inproceedings{flaxman2005online,
  title={Online convex optimization in the bandit setting: gradient descent without a gradient},
  author={Flaxman, Abraham D and Kalai, Adam Tauman and McMahan, H Brendan},
  booktitle={Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms},
  pages={385--394},
  year={2005},
  organization={Society for Industrial and Applied Mathematics}
}
%
@inproceedings{dani2007price,
  title={The price of bandit information for online optimization},
  author={Dani, Varsha and Kakade, Sham M and Hayes, Thomas P},
  booktitle={Advances in Neural Information Processing Systems},
  pages={345--352},
  year={2007}
}
%
@article{bartlett2008high,
  title={High-probability regret bounds for bandit online linear optimization},
  author={Bartlett, Peter L and Dani, Varsha and Hayes, Thomas and Kakade, Sham and Rakhlin, Alexander and Tewari, Ambuj},
  booktitle={COLT 2008},
  year={2008},
}
%
@inproceedings{babaioff2009characterizing,
  title={Characterizing truthful multi-armed bandit mechanisms},
  author={Babaioff, Moshe and Sharma, Yogeshwer and Slivkins, Aleksandrs},
  booktitle={Proceedings of the 10th ACM conference on Electronic commerce},
  pages={79--88},
  year={2009},
  organization={ACM}
}
%
@article{rakhlin2009lecture,
  title={Lecture notes on online learning},
  author={Rakhlin, Alexander},
  journal={Draft},
  year={2009},
  note={Available at \url{http://www-stat.wharton.upenn.edu/~rakhlin/courses/stat991/papers/lecture_notes.pdf}}
}
%
@inproceedings{zinkevich2003online,
  title={Online Convex Programming and Generalized Infinitesimal Gradient Ascent},
  author={Zinkevich, Martin},
  booktitle={Proceedings of the 20th International Conference on Machine Learning},
  series = {ICML 2003},
  pages={928--936},
  year={2003}
}
%
@book{barto1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Barto, Andrew G},
  year={1998},
  publisher={MIT press}
}
%
@article{Young14,
  author    = {Neal E. Young},
  title     = {Nearly Linear-Time Approximation Schemes for Mixed Packing/Covering
               and Facility-Location Linear Programs},
journal   = {ArXiv e-prints},
  year      = {2014},
  month     = jul,
  volume    = {abs/1407.3015},
  url       = {http://arxiv.org/abs/1407.3015},
}
%
@inproceedings{KOSZ13,
  author =       {Jonathan A. Kelner and Lorenzo Orecchia and Aaron Sidford and Zeyuan Allen Zhu},
  title =        {A Simple, Combinatorial Algorithm for Solving {SDD} Systems in Nearly-{L}inear Time},
 booktitle = {Proceedings of the 45th Annual ACM Symposium on Theory of Computing},
 series    = {STOC~'13},
 year      = {2013},
}
%
@article{Lieb1973convex,
  title={Convex trace functions and the Wigner-Yanase-Dyson conjecture},
  author={Lieb, Elliott H.},
  journal={Advances in Mathematics},
  volume={11},
  number={3},
  pages={267--288},
  year={1973},
  publisher={Elsevier}
}
%
@article{SpielmanSrivastava2011,
archivePrefix = {arXiv},
arxivId = {arXiv:0803.0929v4},
author = {Spielman, Daniel A. and Srivastava, Nikhil},
doi = {10.1137/080734029},
eprint = {arXiv:0803.0929v4},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman - 2009 - Graph Sparsification by Effective Resistances ∗.pdf:pdf},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
mendeley-groups = {Algorithms/Sparsification},
month = jan,
number = {6},
pages = {1913--1926},
title = {{Graph Sparsification by Effective Resistances}},
volume = {40},
year = {2011}
}
%
@article{BSS2009,
abstract = {We prove that every graph has a spectral sparsifier with a number of edges linear in its number of vertices. As linear-sized spectral sparsifiers of complete graphs are expanders, our sparsifiers of arbitrary graphs can be viewed as generalizations of expander graphs. In particular, we prove that for every \$d>1\$ and every undirected, weighted graph \$G=(V,E,w)\$ on \$n\$ vertices, there exists a weighted graph \$H=(V,F,\backslash tilde\{w\})\$ with at most \$\backslash ceil\{d(n-1)\}\$ edges such that for every \$x \backslash in \backslash R\^{}\{V\}\$, $\backslash$[ x\^{}\{T\}L\_\{G\}x $\backslash$leq x\^{}\{T\}L\_\{H\}x $\backslash$leq ($\backslash$frac\{d+1+2$\backslash$sqrt\{d\}\}\{d+1-2$\backslash$sqrt\{d\}\})$\backslash$cdot x\^{}\{T\}L\_\{G\}x $\backslash$] where \$L\_\{G\}\$ and \$L\_\{H\}\$ are the Laplacian matrices of \$G\$ and \$H\$, respectively. Thus, \$H\$ approximates \$G\$ spectrally at least as well as a Ramanujan expander with \$dn/2\$ edges approximates the complete graph. We give an elementary deterministic polynomial time algorithm for constructing \$H\$.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {0808.0163},
author = {Batson, Joshua and Spielman, Daniel A. and Srivastava, Nikhil},
doi = {10.1137/130949117},
eprint = {0808.0163},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Batson, Spielman, Srivastava - 2009 - Twice-\{R\}amanujan Sparsifiers.pdf:pdf},
isbn = {9781605585062},
issn = {0036-1445},
journal = {SIAM Review},
mendeley-groups = {Algorithms/Sparsification},
month = may,
number = {2},
pages = {315--334},
publisher = {ACM Press},
title = {{Twice-Ramanujan Sparsifiers}},
volume = {56},
year = {2014}
}
%
@techreport{Silva2011,
abstract = {Recently there has been much interest in "sparsifying" sums of rank one matrices: modifying the coefficients such that only a few are nonzero, while approximately preserving the matrix that results from the sum. Results of this sort have found applications in many different areas, including sparsifying graphs. In this paper we consider the more general problem of sparsifying sums of positive semidefinite matrices that have arbitrary rank. We give several algorithms for solving this problem. The first algorithm is based on the method of Batson, Spielman and Srivastava (2009). The second algorithm is based on the matrix multiplicative weights update method of Arora and Kale (2007). We also highlight an interesting connection between these two algorithms. Our algorithms have numerous applications. We show how they can be used to construct graph sparsifiers with auxiliary constraints, sparsifiers of hypergraphs, and sparse solutions to semidefinite programs.},
archivePrefix = {arXiv},
arxivId = {1107.0088},
author = {{\noopsort{Carli Silva}}de {Carli Silva}, Marcel K. and Harvey, Nicholas J. A. and Sato, Cristiane M.},
eprint = {1107.0088},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva, Harvey, Sato - 2011 - Sparse Sums of Positive Semidefinite Matrices(2).pdf:pdf},
mendeley-groups = {Algorithms/Sparsification},
month = jul,
title = {{Sparse Sums of Positive Semidefinite Matrices}},
year = {2011}
}
%
@article{JL1984,
author = {Johnson, William B. and Lindenstrauss, Joram},
doi = {10.1090/conm/026/737400},
journal = {Contemporary Mathematics},
mendeley-groups = {Algorithms/Sublinear Algorithms/JL},
pages = {189--206},
title = {{Extensions of Lipschitz mappings into a Hilbert space}},
volume = {26},
year = {1984}
}
%
@inproceedings{Bansal2011,
abstract = {We study graph partitioning problems from a min-max perspective, in which an input graph on n vertices should be partitioned into k parts, and the objective is to minimize the maximum number of edges leaving a single part. The two main versions we consider are where the k parts need to be of equal-size, and where they must separate a set of k given terminals. We consider a common generalization of these two problems, and design for it an \$O(\backslash sqrt\{\backslash log n\backslash log k\})\$-approximation algorithm. This improves over an \$O(\backslash log\^{}2 n)\$ approximation for the second version, and roughly \$O(k\backslash log n)\$ approximation for the first version that follows from other previous work. We also give an improved O(1)-approximation algorithm for graphs that exclude any fixed minor. Our algorithm uses a new procedure for solving the Small-Set Expansion problem. In this problem, we are given a graph G and the goal is to find a non-empty set \$S\backslash subseteq V\$ of size \$|S| \backslash leq \backslash rho n\$ with minimum edge-expansion. We give an \$O(\backslash sqrt\{\backslash log\{n\}\backslash log\{(1/\backslash rho)\}\})\$ bicriteria approximation algorithm for the general case of Small-Set Expansion, and O(1) approximation algorithm for graphs that exclude any fixed minor.},
archivePrefix = {arXiv},
arxivId = {1110.4319},
author = {Bansal, Nikhil and Feige, Uriel and Krauthgamer, Robert and Makarychev, Konstantin and Nagarajan, Viswanath and Naor, Joseph (Seffi) and Schwartz, Roy},
booktitle = {2011 IEEE 52nd Annual Symposium on Foundations of Computer Science},
doi = {10.1109/FOCS.2011.79},
eprint = {1110.4319},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bansal et al. - 2011 - Min-max Graph Partitioning and Small Set Expansion.pdf:pdf},
isbn = {978-0-7695-4571-4},
mendeley-groups = {Algorithms/Sparsest Cut,Algorithms/Small Set Expansion,Algorithms/Sparsest Cut/SSE},
month = oct,
pages = {17--26},
publisher = {IEEE},
title = {{Min-max Graph Partitioning and Small Set Expansion}},
year = {2011}
}
%
@inproceedings{Asadpour2010,
author = {Asadpour, Arash and Goemans, Michel X. and Mądry, Aleksander and Gharan, Shayan Oveis and Saberi, Amin},
booktitle = {Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '10},
file = {:D$\backslash$:/Mendeley Desktop/Asadpour et al. - 2010 - An O ( log n log log n ) -approximation Algorithm for the Asymmetric Traveling Salesman Problem.pdf:pdf},
isbn = {0001405101},
mendeley-groups = {Algorithms/Traveling Salesman},
pages = {379--389},
title = {{An $O(\log n / \log \log n )$-approximation Algorithm for the Asymmetric Traveling Salesman Problem}},
year = {2010}
}
%
@inproceedings{Daskalakis2011,
author = {Daskalakis, Constantinos and Deckelbaum, Alan and Kim, Anthony},
booktitle = {Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '11},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Daskalakis, Deckelbaum, Kim - 2011 - Near-optimal no-regret algorithms for zero-sum games.pdf:pdf},
mendeley-groups = {Game Theory/Zero-sum Games},
pages = {235--254},
title = {{Near-optimal no-regret algorithms for zero-sum games}},
year = {2011}
}
%
@inproceedings{Steurer2010,
author = {Steurer, David},
booktitle = {Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '10},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Steurer - 2010 - Fast SDP algorithms for constraint satisfaction problems.pdf:pdf},
mendeley-groups = {Optimization/Multiplicative Weight/SDP},
pages = {684----697},
title = {{Fast SDP algorithms for constraint satisfaction problems}},
year = {2010}
}
%
@article{audibert2011minimax,
  title={Minimax Policies for Combinatorial Prediction Games},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien and Lugosi, G{\'a}bor},
  journal={Proceedings of COLT 2011},
  year={2011}
}
%
@phdthesis{Orecchia11,
    Author = {Orecchia, Lorenzo},
    Title = {Fast Approximation Algorithms for Graph Partitioning using Spectral and Semidefinite-Programming Techniques},
    School = {EECS Department, University of California, Berkeley},
    Year = {2011},
    Month = {May},
    Number = {UCB/EECS-2011-56}
}
%
@techreport{BenczurKarger02,
archivePrefix = {arXiv},
arxivId = {cs/0207078},
author = {Bencz\'{u}r, Andr\'{a}s A. and Karger, David R.},
booktitle = {arXiv preprint cs/0207078},
eprint = {0207078},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/110a03446ced34ac8baaf80534e7433c45797196.pdf:pdf},
mendeley-groups = {Algorithms/Sparsification},
month = jul,
pages = {1--20},
primaryClass = {cs},
title = {{Randomized Approximation Schemes for Cuts and Flows in Capacitated Graphs}},
year = {2002}
}
@inproceedings{BenczurKarger96,
address = {New York, New York, USA},
author = {Bencz\'{u}r, Andr\'{a}s A. and Karger, David R.},
booktitle = {Proceedings of the twenty-eighth annual ACM symposium on Theory of computing - STOC '96},
doi = {10.1145/237814.237827},
isbn = {0897917855},
mendeley-groups = {Algorithms/Sparsification},
pages = {47--55},
publisher = {ACM Press},
title = {{Approximating s-t minimum cuts in $\tilde{O}(n^2)$ time}},
year = {1996}
}
%
@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and {Cesa-Bianchi}, Nicolo},
  journal={Foundations and trends in machine learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publisher}
}
%
@article{Anderson2014,
journal   = {ArXiv e-prints},
author = {Anderson, David G. and Gu, Ming and Melgaard, Christopher},
eprint = {1410.4273},
month = oct,
title = {{An Efficient Algorithm for Unweighted Spectral Graph Sparsification}},
url = {http://arxiv.org/abs/1410.4273v1},
volume    = {abs/1410.4273},
year = {2014}
}
%
@incollection{KleinYoung99,
year={1999},
isbn={978-3-540-66019-4},
booktitle={Integer Programming and Combinatorial Optimization},
volume={1610},
series={Lecture Notes in Computer Science},
editor={Cornu\'{e}jols, G\'{e}rard and Burkard, Rainer E. and Woeginger, Gerhard J.},
doi={10.1007/3-540-48777-8_24},
title={On the Number of Iterations for Dantzig-Wolfe Optimization and Packing-Covering Approximation Algorithms},
publisher={Springer Berlin Heidelberg},
author={Klein, Philip and Young, Neal},
pages={320-327},
}
%
@article{Shalev-Shwartz2011a,
author = {{Shalev-Shwartz}, Shai and Tewari, Ambuj},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title(3).pdf:pdf},
journal = {Journal of Machine Learning Research},
mendeley-groups = {Optimization/Stochastic Online Optimization},
pages = {1865−-1892},
title = {{Stochastic methods for l1-regularized loss minimization}},
volume = {12},
year = {2011}
}
%
@article{DuanPettie2014,
author = {Duan, Ran and Pettie, Seth},
doi = {10.1145/2529989},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/3492dea6a70b4a1339999fc8ae8e26be784d1cb1.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
mendeley-groups = {Algorithms/Maxflow},
month = jan,
number = {1},
pages = {1--23},
title = {{Linear-Time Approximation for Maximum Weight Matching}},
volume = {61},
year = {2014}
}
%
@inproceedings{Zouzias2012,
 author = {Zouzias, Anastasios},
 title = {A Matrix Hyperbolic Cosine Algorithm and Applications},
 booktitle = {Proceedings of the 39th International Colloquium Conference on Automata, Languages, and Programming - Volume Part I},
 series = {ICALP'12},
 year = {2012},
 isbn = {978-3-642-31593-0},
 location = {Warwick, UK},
 pages = {846--858},
 numpages = {13},
 doi = {10.1007/978-3-642-31594-7_71},
 acmid = {2359454},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}
%
@incollection{Hazan2012-survey,
  title={The Convex Optimization Approach to Regret Minimization},
  author={Hazan, Elad},
  booktitle={Optimization for machine learning},
  editors={Suvrit Sra, Sebastian Nowozin and Stephen J. Wright},
  chapter = {10},
  pages={287--304},
  year={2012},
  publisher={MIT press}
}
%
%
@inproceedings{CharikarLLM10,
  author    = {Moses Charikar and
               Tom Leighton and
               Shi Li and
               Ankur Moitra},
  title     = {Vertex Sparsifiers and Abstract Rounding Algorithms},
  booktitle = {51th Annual {IEEE} Symposium on Foundations of Computer Science, {FOCS}
               2010, October 23-26, 2010, Las Vegas, Nevada, {USA}},
  year      = {2010},
  pages     = {265--274},
  url       = {http://doi.ieeecomputersociety.org/10.1109/FOCS.2010.32},
  doi       = {10.1109/FOCS.2010.32},
  timestamp = {Mon, 03 Nov 2014 22:22:11 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/focs/CharikarLLM10},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
%
@inproceedings{PengS14,
  author    = {Richard Peng and
               Daniel A. Spielman},
  title     = {An efficient parallel solver for {SDD} linear systems},
  booktitle = {Symposium on Theory of Computing, {STOC} 2014, New York, NY, USA,
               May 31 - June 03, 2014},
  year      = {2014},
  pages     = {333--342},
  url       = {http://doi.acm.org/10.1145/2591796.2591832},
  doi       = {10.1145/2591796.2591832},
  timestamp = {Mon, 03 Nov 2014 22:25:46 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/stoc/PengS14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
%
@book{Bhatia1997,
address = {New York, NY},
author = {Bhatia, Rajendra},
doi = {10.1007/978-1-4612-0653-8},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhatia - 1997 - Matrix Analysis.pdf:pdf},
isbn = {978-1-4612-6857-4},
mendeley-groups = {Books/Algebra},
publisher = {Springer New York},
series = {Graduate Texts in Mathematics},
title = {{Matrix Analysis}},
volume = {169},
year = {1997}
}
%
@article{Naor2012,
  title={SPARSE QUADRATIC FORMS AND THEIR GEOMETRIC APPLICATIONS [after {B}atson, {S}pielman and {S}rivastava]},
  author={Naor, Assaf},
  journal={Ast{\'e}risque},
  year={2012},
  publisher={Soci{\'e}t{\'e} math{\'e}matique de France}
}
%
@article{JainJiUpadhyayWatrous2009,
  title={{QIP = PSPACE}},
  author={Jain, Rahul and Ji, Zhengfeng and Upadhyay, Sarvagya and Watrous, John},
  journal={Journal of the ACM (JACM)},
  volume={58},
  number={6},
  pages={30},
  year={2011},
  publisher={ACM}
}
%
@article{HazanAK2007,
author = {Hazan, Elad and Agarwal, Amit and Kale, Satyen},
doi = {10.1007/s10994-007-5016-8},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Agarwal, Kale - 2007 - Logarithmic regret algorithms for online convex optimization.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
mendeley-groups = {Optimization/Stochastic Online Optimization},
month = aug,
number = {2-3},
pages = {169--192},
title = {{Logarithmic regret algorithms for online convex optimization}},
volume = {69},
year = {2007}
}
%
@inproceedings{Saha2011,
abstract = {Given \$n\$ points in a \$d\$ dimensional Euclidean space, the Minimum Enclosing Ball (MEB) problem is to find the ball with the smallest radius which contains all \$n\$ points. We give a \$O(nd\backslash Qcal/\backslash sqrt\{\backslash epsilon\})\$ approximation algorithm for producing an enclosing ball whose radius is at most \$\backslash epsilon\$ away from the optimum (where \$\backslash Qcal\$ is an upper bound on the norm of the points). This improves existing results using $\backslash$emph\{coresets\}, which yield a \$O(nd/\backslash epsilon)\$ greedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is a related problem wherein a convex polytope of a fixed shape is given and the aim is to find the smallest magnification of the polytope which encloses the given points. For this problem we present a \$O(mnd\backslash Qcal/\backslash epsilon)\$ approximation algorithm, where \$m\$ is the number of faces of the polytope. Our algorithms borrow heavily from convex duality and recently developed techniques in non-smooth optimization, and are in contrast with existing methods which rely on geometric arguments. In particular, we specialize the excessive gap framework of $\backslash$citet\{Nesterov05a\} to obtain our results.},
archivePrefix = {arXiv},
arxivId = {0909.1062},
author = {Saha, Ankan and Vishwanathan, S. V. N. and Zhang, Xinhua},
booktitle = {Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms - SODA '11},
eprint = {0909.1062},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Saha, Vishwanathan, Zhang - 2011 - New Approximation Algorithms for Minimum Enclosing Convex Shapes.pdf:pdf},
mendeley-groups = {Algorithms/Computational Geometry},
month = sep,
pages = {1146--1160},
title = {{New Approximation Algorithms for Minimum Enclosing Convex Shapes}},
year = {2011}
}
%
@inproceedings{Xie2006,
author = {Xie, Yulai and Snoeyink, Jack and Xu, Jinhui},
booktitle = {Proceedings of the 22nd annual symposium on computational geometry - SCG '06},
doi = {10.1145/1137856.1137861},
isbn = {1595933409},
mendeley-groups = {Algorithms/Computational Geometry},
title = {{Efficient algorithm for approximating maximum inscribed sphere in high dimensional polytope}},
year = {2006}
}
%
@article{nesterov2008rounding,
  title={Rounding of convex sets and efficient gradient methods for linear programming problems},
  author={Nesterov, Yu},
  journal={Optimisation Methods and Software},
  volume={23},
  number={1},
  pages={109--128},
  year={2008},
  publisher={Taylor \& Francis}
}
%
@article{Kumar2003,
author = {Kumar, Piyush and Mitchell, Joseph S. B. and Yildirim, E. Alper},
doi = {10.1145/996546.996548},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Kumar, Mitchell, Yildirim - 2003 - Approximate minimum enclosing balls in high dimensions using core-sets.pdf:pdf},
issn = {10846654},
journal = {Journal of Experimental Algorithmics},
mendeley-groups = {Algorithms/Computational Geometry},
month = jan,
pages = {1--29},
title = {{Approximate minimum enclosing balls in high dimensions using core-sets}},
volume = {8},
year = {2003}
}
%
@inproceedings{Chudak2005,
author = {Chudak, Fabi\'{a}n A. and Eleut\'{e}rio, V\^{a}nia},
booktitle = {Proceedings of the 11th International IPCO Conference on Integer Programming and Combinatorial Optimization},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Chudak, Eleut\'{e}rio - 2005 - Improved Approximation Schemes for Linear Programming Relaxations of Combinatorial Optimization Problems.pdf:pdf},
mendeley-groups = {Optimization/Multiplicative Weight/LP},
pages = {81--96},
title = {{Improved Approximation Schemes for Linear Programming Relaxations of Combinatorial Optimization Problems}},
year = {2005}
}
%
@article{ClarksonHW2012,
author = {Clarkson, Kenneth L. and Hazan, Elad and Woodruff, David P.},
doi = {10.1145/2371656.2371658},
file = {:D$\backslash$:/Mendeley Desktop/Clarkson, Hazan, Woodruff - 2012 - Sublinear optimization for machine learning.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
mendeley-groups = {Algorithms/Computational Geometry},
month = oct,
number = {5},
pages = {23:1--23:49},
title = {{Sublinear optimization for machine learning}},
volume = {59},
year = {2012}
}
%
@inproceedings{Badoiu2002,
address = {New York, New York, USA},
author = {{B{\u{a}}doiu}, Mihai and {Har-Peled}, Sariel and Indyk, Piotr},
booktitle = {Proceedings of the thiry-fourth annual ACM symposium on Theory of computing - STOC '02},
doi = {10.1145/509907.509947},
isbn = {1581134959},
mendeley-groups = {Algorithms/Computational Geometry},
pages = {250},
publisher = {ACM Press},
title = {{Approximate clustering via core-sets}},
year = {2002}
}
%
@article{sylvester1857question,
  title={A question in the geometry of situation},
  author={Sylvester, James Joseph},
  journal={Quarterly Journal of Pure and Applied Mathematics},
  volume={1},
  year={1857}
}
%
@article{elzinga1975central,
  title={A central cutting plane algorithm for the convex programming problem},
  author={Elzinga, Jack and Moore, Thomas G.},
  journal={Mathematical Programming},
  volume={8},
  number={1},
  pages={134--145},
  year={1975},
  publisher={Springer}
}
%
@article{agarwal2005geometric,
  title={Geometric approximation via coresets},
  author={Agarwal, Pankaj K. and {Har-Peled}, Sariel and Varadarajan, Kasturi R.},
  journal={Combinatorial and computational geometry},
  volume={52},
  pages={1--30},
  year={2005},
  publisher={Cambridge University Press New York}
}
%
@article{anstreicher2002improved,
  title={Improved complexity for maximum volume inscribed ellipsoids},
  author={Anstreicher, Kurt M.},
  journal={SIAM Journal on Optimization},
  volume={13},
  number={2},
  pages={309--320},
  year={2002},
  publisher={SIAM}
}
%
@article{khachiyan1993complexity,
  title={On the complexity of approximating the maximal inscribed ellipsoid for a polytope},
  author={Khachiyan, Leonid G and Todd, Michael J},
  journal={Mathematical Programming},
  volume={61},
  number={1},
  pages={137--159},
  year={1993},
  publisher={Springer}
}
%
@book{nesterov1994interior,
  title={Interior-point polynomial algorithms in convex programming},
  author={Nesterov, Yurii and Nemirovskii, Arkadii and Ye, Yinyu},
  volume={13},
  year={1994},
  publisher={SIAM}
}
%
@TECHREPORT{nemirovski1997,
  author =       {Nemirovskii, Arkadii},
  title =        {On self-concordant convex-concave functions},
  institution =  {Optimization Laboratory Faculty of Industrial Engineering and Management, The Technion - Israel Institute of Technology},
  year =         {1997},
  number =       {\# 3/97},
  month =        jun,
}
%
@article{khachiyan1996rounding,
  title={Rounding of polytopes in the real number model of computation},
  author={Khachiyan, Leonid G.},
  journal={Mathematics of Operations Research},
  volume={21},
  number={2},
  pages={307--320},
  year={1996},
  publisher={INFORMS}
}
%
@article{clarkson2010coresets,
  title={Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm},
  author={Clarkson, Kenneth L},
  journal={ACM Transactions on Algorithms (TALG)},
  volume={6},
  number={4},
  pages={63},
  year={2010},
  publisher={ACM}
}
%
@inproceedings{gartner2009coresets,
  title={Coresets for polytope distance},
  author={G{\"a}rtner, Bernd and Jaggi, Martin},
  booktitle={Proceedings of the 25th annual symposium on computational geometry},
  pages={33--42},
  year={2009},
  organization={ACM}
}
%
@inproceedings{har2007maximum,
  title={Maximum margin coresets for active and noise tolerant learning},
  author={{Har-Peled}, Sariel and Roth, Dan and Zimak, Dav},
  booktitle={Proceedings of the 20th international joint conference on Artifical intelligence},
  pages={836--841},
  year={2007},
  organization={Morgan Kaufmann Publishers Inc.}
}
%
@book{welzl1991smallest,
  title={Smallest enclosing disks (balls and ellipsoids)},
  author={Welzl, Emo},
  year={1991},
  publisher={Springer}
}
%
@article{yildirim2008two,
  title={Two algorithms for the minimum enclosing ball problem},
  author={Yildirim, E. Alper},
  journal={SIAM Journal on Optimization},
  volume={19},
  number={3},
  pages={1368--1391},
  year={2008},
  publisher={SIAM}
}
%
@article{Nesterov2005excessive,
annote = {YinTat mentioned that this paper may have combined the primal/dual descent steps of Nesterov into (either one or two, I forgot) Prox steps.},
author = {Nesterov, Yurii},
doi = {10.1137/S1052623403422285},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nesterov - 2005 - Excessive Gap Technique in Nonsmooth Convex Minimization.pdf:pdf},
issn = {1052-6234},
journal = {SIAM Journal on Optimization},
keywords = {black-box oracle,complexity theory,convex optimization,non-smooth optimization,optimal methods,structural},
mendeley-groups = {Optimization/Gradient Descent Theory},
month = jan,
number = {1},
pages = {235--249},
title = {{Excessive Gap Technique in Nonsmooth Convex Minimization}},
volume = {16},
year = {2005}
}
%
@article{buadoiu2008optimal,
  title={Optimal core-sets for balls},
  author={B{\u{a}}doiu, Mihai and Clarkson, Kenneth L},
  journal={Computational Geometry},
  volume={40},
  number={1},
  pages={14--22},
  year={2008},
  publisher={Elsevier}
}
%
@article{sion1958general,
  title={On general minimax theorems.},
  author={Sion, Maurice},
  journal={Pacific Journal of Mathematics},
  volume={8},
  number={1},
  pages={171--176},
  year={1958},
  publisher={Pacific Journal of Mathematics}
}
%
@article{lee2011chebyshev,
  title={Chebyshev center based column generation},
  author={Lee, Chungmok and Park, Sungsoo},
  journal={Discrete Applied Mathematics},
  volume={159},
  number={18},
  pages={2251--2265},
  year={2011},
  publisher={Elsevier}
}
%
@inproceedings{su2014differential,
  title={A Differential Equation for Modeling Nesterov’s Accelerated Gradient Method: Theory and Insights},
  author={Su, Weijie and Boyd, Stephen and Candes, Emmanuel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2510--2518},
  year={2014}
}
%
@article{murty2012m,
  title={$O(m)$ Bound on Number of Iterations in Sphere Methods for LP},
  author={Murty, Katta G.},
  journal={Algorithmic Operations Research},
  volume={7},
  number={1},
  pages={30--40},
  year={2012}
}
%
@article{zhou2005efficient,
  title={Efficient algorithms for the smallest enclosing ball problem},
  author={Zhou, Guanglu and Tohemail, Kim-Chuan and Sun, Jie},
  journal={Computational Optimization and Applications},
  volume={30},
  number={2},
  pages={147--160},
  year={2005},
  publisher={Springer}
}
%
@inproceedings{HazanKS2012,
abstract = {In several online prediction problems of recent interest the comparison class is composed of matrices with bounded entries. For example, in the online max-cut problem, the comparison class is matrices which represent cuts of a given graph and in online gambling the comparison class is matrices which represent permutations over n teams. Another important example is online collaborative filtering in which a widely used comparison class is the set of matrices with a small trace norm. In this paper we isolate a property of matrices, which we call (beta,tau)-decomposability, and derive an efficient online learning algorithm, that enjoys a regret bound of O*(sqrt(beta tau T)) for all problems in which the comparison class is composed of (beta,tau)-decomposable matrices. By analyzing the decomposability of cut matrices, triangular matrices, and low trace-norm matrices, we derive near optimal regret bounds for online max-cut, online gambling, and online collaborative filtering. In particular, this resolves (in the affirmative) an open problem posed by Abernethy (2010); Kleinberg et al (2010). Finally, we derive lower bounds for the three problems and show that our upper bounds are optimal up to logarithmic factors. In particular, our lower bound for the online collaborative filtering problem resolves another open problem posed by Shamir and Srebro (2011).},
archivePrefix = {arXiv},
arxivId = {arXiv:1204.0136v1},
author = {Hazan, Elad and Kale, Satyen and {Shalev-Shwartz}, Shai},
booktitle = {Proceedings of the 25th Annual Conference on Learning Theory - COLT '12},
eprint = {arXiv:1204.0136v1},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Kale, Shalev-Shwartz - 2012 - Near-optimal algorithms for online matrix prediction.pdf:pdf},
issn = {15337928},
mendeley-groups = {Optimization/Mirror Descent/Mirror Descent for NP-hard Problems},
pages = {38.1----38.13},
title = {{Near-optimal algorithms for online matrix prediction}},
url = {http://arxiv.org/abs/1204.0136},
year = {2012}
}
%
@article{Grigoriadis1995,
abstract = {This paper presents a parallel randomizedalgorithm which computes a pair of $\epsilon$-optimal strategies for a given (m,n)-matrixgameA = [aij] ? [?1, 1] in O($\epsilon$?2log2(n+m)) expected time on an (n+m)/log(n+m)-processor EREW PRAM. For any fixed accuracy ? > 0, the expected sequential running time of the suggested algorithm is O((n + m)log(n + m)), which is sublinear in mn, the number of input elements of A. On the other hand, simple arguments are given to show that for , any deterministic algorithm for computing a pair of $\epsilon$-optimal strategies of an (m, n)-matrixgameA with ± 1 elements examines $\Omega$(mn) of its elements. In particular, for m = n the randomizedalgorithm achieves an almost quadratic expected speedup relative to any deterministic method.},
author = {Grigoriadis, Michael D. and Khachiyan, Leonid G.},
doi = {10.1016/0167-6377(95)00032-0},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grigoriadis, Khachiyan - 1995 - A sublinear-time randomized approximation algorithm for matrix games.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {approximation algorithms,complexity,linear programming,matrix games,parallel algorithms,randomized},
mendeley-groups = {Optimization/Multiplicative Weight/LP},
pages = {53--58},
title = {{A sublinear-time randomized approximation algorithm for matrix games}},
volume = {18},
year = {1995}
}
%
@article{XiaoZhang2014-ProximalSVRG,
abstract = {We consider the problem of minimizing the sum of two convex functions: one is the average of a large number of smooth component functions, and the other is a general convex function that admits a simple proximal mapping. We assume the whole objective function is strongly convex. Such problems often arise in machine learning, known as regularized empirical risk minimization. We propose and analyze a new proximal stochastic gradient method, which uses a multi-stage scheme to progressively reduce the variance of the stochastic gradient. While each iteration of this algorithm has similar cost as the classical stochastic gradient method (or incremental gradient method), we show that the expected objective value converges to the optimum at a geometric rate. The overall complexity of this method is much lower than both the proximal full gradient method and the standard proximal stochastic gradient method. 1},
archivePrefix = {arXiv},
arxivId = {arXiv:1403.4699v1},
author = {Xiao, Lin and Zhang, Tong},
doi = {10.1137/140961791},
eprint = {arXiv:1403.4699v1},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiao, Zhang - 2014 - A Proximal Stochastic Gradient Method with Progressive Variance Reduction(2).pdf:pdf},
issn = {1052-6234},
journal = {SIAM Journal on Optimization},
mendeley-groups = {Optimization/[with Yuan Yang],Optimization/Variance Reduction},
number = {4},
pages = {2057----2075},
title = {{A Proximal Stochastic Gradient Method with Progressive Variance Reduction}},
volume = {24},
year = {2014}
}
%
@inproceedings{JohnsonZhang2013-SVRG,
author = {Johnson, Rie and Zhang, Tong},
booktitle = {Advances in Neural Information Processing Systems},
series = {NIPS 2013},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Johnson, Zhang - 2013 - Accelerating stochastic gradient descent using predictive variance reduction.pdf:pdf},
mendeley-groups = {Optimization/Variance Reduction,Optimization/[with Yuan Yang]},
pages = {315--323},
title = {{Accelerating stochastic gradient descent using predictive variance reduction}},
year = {2013}
}
%
@inproceedings{Defazio2014-SAGA,
abstract = {In this work we introduce a new optimisation method called SAGA in the spirit of SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient algorithms with fast linear convergence rates. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and has support for composite objectives where a proximal operator is used on the regulariser. Unlike SDCA, SAGA supports non-strongly convex problems directly, and is adaptive to any inherent strong convexity of the problem. We give experimental results showing the effectiveness of our method.},
archivePrefix = {arXiv},
arxivId = {arXiv:1407.0202v2},
author = {Defazio, Aaron and Bach, Francis and {Lacoste-Julien}, Simon},
booktitle = {NIPS},
eprint = {arXiv:1407.0202v2},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Defazio, Bach, Lacoste-Julien - 2014 - SAGA A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives.pdf:pdf},
mendeley-groups = {Optimization/[with Yuan Yang],Optimization/Variance Reduction},
title = {{SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives}},
url = {http://arxiv.org/abs/1407.0202},
year = {2014}
}
%
@inproceedings{Defazio2014-Finito,
abstract = {Recent advances in optimization theory have shown that smooth strongly convex finite sums can be minimized faster than by treating them as a black box ”batch” problem. In this work we introduce a new method in this class with a theoretical convergence rate four times faster than existing methods, for sums with sufficiently many terms. This method is also amendable to a sampling without replacement scheme that in practice gives further speed-ups. We give empirical results showing state of the art performance. 1},
archivePrefix = {arXiv},
arxivId = {1407.2710},
author = {Defazio, Aaron J. and Caetano, Tib\'{e}rio S. and Domke, Justin},
booktitle = {Proceedings of the 31st International Conference on Machine Learning},
series = {ICML 2014},
eprint = {1407.2710},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Defazio, Caetano, Domke - 2014 - Finito A Faster, Permutable Incremental Gradient Method for Big Data Problems.pdf:pdf},
mendeley-groups = {Optimization/[with Yuan Yang],Optimization/Variance Reduction},
title = {{Finito: A Faster, Permutable Incremental Gradient Method for Big Data Problems}},
url = {http://jmlr.org/proceedings/papers/v32/defazio14.pdf},
year = {2014}
}
%
@article{Mairal2015-MISO,
author = {Mairal, Julien},
doi = {10.1137/140957639},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Mairal - 2015 - Incremental Majorization-Minimization Optimization with Application to Large-Scale Machine Learning.pdf:pdf},
issn = {1052-6234},
journal = {SIAM Journal on Optimization},
keywords = {1,10,1137,140957639,90c06,90c25,90c26,ams subject classifications,convex optimization,doi,introduction,majorization-minimization,minimizing upper bounds of,nonconvex optimization,the,the principle of successively},
mendeley-groups = {Optimization/Variance Reduction},
month = apr,
number = {2},
pages = {829--855},
title = {{Incremental Majorization-Minimization Optimization with Application to Large-Scale Machine Learning}},
url = {http://epubs.siam.org/doi/10.1137/140957639},
volume = {25},
note = {Preliminary version appeared in ICML 2013},
year = {2015}
}
%
@article{Schmidt2013-SAG,
abstract = {We propose the stochastic average gradient (SAG) method for optimizing the sum of a finite number of smooth convex functions. Like stochastic gradient (SG) methods, the SAG method's iteration cost is independent of the number of terms in the sum. However, by incorporating a memory of previous gradient values the SAG method achieves a faster convergence rate than black-box SG methods. The convergence rate is improved from O(1/k\^{}\{1/2\}) to O(1/k) in general, and when the sum is strongly-convex the convergence rate is improved from the sub-linear O(1/k) to a linear convergence rate of the form O(p\^{}k) for p < 1. Further, in many cases the convergence rate of the new method is also faster than black-box deterministic gradient methods, in terms of the number of gradient evaluations. Numerical experiments indicate that the new algorithm often dramatically outperforms existing SG and deterministic gradient methods, and that the performance may be further improved through the use of non-uniform sampling strategies.},
archivePrefix = {arXiv},
arxivId = {1309.2388},
author = {Schmidt, Mark and {Le Roux}, Nicolas and Bach, Francis},
eprint = {1309.2388},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/6bb9f6695c64ca57938706579bcdff9c8712f8e9.pdf:pdf},
journal = {arXiv preprint arXiv:1309.2388},
mendeley-groups = {Optimization/Variance Reduction},
pages = {1--45},
title = {{Minimizing finite sums with the stochastic average gradient}},
url = {http://arxiv.org/abs/1309.2388},
note = {Preliminary version appeared in NIPS 2012},
year = {2013}
}
%
@inproceedings{zhang2004solving,
  title={Solving large scale linear prediction problems using stochastic gradient descent algorithms},
  author={Zhang, Tong},
  booktitle={Proceedings of the 21st International Conference on Machine Learning},
  series={ICML 2004},
  year={2004}
}
%
@MISC{Bottou-SGD,
  author =       {L\'{e}on Bottou},
  title =        {Stochastic Gradient Descent},
  howpublished = {\url{http://leon.bottou.org/projects/sgd}}
}
%
@article{Shalev-Shwartz2013-SDCA,
author = {{Shalev-Shwartz}, Shai and Zhang, Tong},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shalev-Shwartz, Zhang - 2013 - Stochastic dual coordinate ascent methods for regularized loss minimization.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {computational complexity,ized loss minimization,logistic regression,optimization,regular-,ridge regression,stochastic dual coordinate ascent,support vector machines},
mendeley-groups = {Optimization/Stochastic Online Optimization},
pages = {567--599},
title = {{Stochastic dual coordinate ascent methods for regularized loss minimization}},
url = {http://arxiv.org/abs/1209.1873},
volume = {14},
year = {2013}
}
%
@inproceedings{Ng2004-L1LR,
  title={Feature selection, {L1 vs. L2} regularization, and rotational invariance},
  author={Ng, Andrew Y.},
  booktitle={Proceedings of the 21st International Conference on Machine Learning},
  series={ICML 2004},
  pages={78},
  year={2004},
  organization={ACM}
}
%
@article{Tibshirani1996-Lasso,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={267--288},
  year={1996},
  publisher={JSTOR}
}
%
@inproceedings{LLX2014-ProxSDCA-APCG,
annote = {A short version has appeared in NIPS 2014 with its first 3 sections.},
archivePrefix = {arXiv},
arxivId = {1407.1296},
author = {Lin, Qihang and Lu, Zhaosong and Xiao, Lin},
booktitle = {NIPS},
eprint = {1407.1296},
pages = {3059--3067},
title = {{An Accelerated Proximal Coordinate Gradient Method and its Application to Regularized Empirical Risk Minimization}},
url = {http://arxiv.org/abs/1407.1296 http://papers.nips.cc/paper/5356-an-accelerated-proximal-coordinate-gradient-method.pdf},
year = {2014}
}
%
@article{LuXiao2013,
  title={On the complexity analysis of randomized block-coordinate descent methods},
  author={Lu, Zhaosong and Xiao, Lin},
  journal={Mathematical Programming},
  pages={1--28},
  year={2013},
  publisher={Springer}
}
%
@inproceedings{ZhangXiao2015-SPDC,
abstract = {We consider a generic convex optimization problem associated with regularized empirical risk minimization of linear predictors. The problem structure allows us to reformulate it as a convex-concave saddle point problem. We propose a stochastic primal-dual coordinate (SPDC) method, which alternates between maximizing over a randomly chosen dual variable and minimizing over the primal variable. An extrapolation step on the primal variable is performed to obtain accelerated convergence rate. We also develop a mini-batch version of the SPDC method which facilitates parallel computing, and an extension with weighted sampling probabilities on the dual variables, which has a better complexity than uniform sampling on unnormalized data. Both theoretically and empirically, we show that the SPDC method has comparable or better performance than several state-of-the-art optimization methods.},
archivePrefix = {arXiv},
arxivId = {1409.3257},
author = {Zhang, Yuchen and Xiao, Lin},
booktitle = {ICML},
eprint = {1409.3257},
file = {:C$\backslash$:/Users/Zeyuan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/1ca7470da54bcc99493d1dac5f702ca0b9ea4d23.pdf:pdf},
mendeley-groups = {Optimization/Saddle-Point,Optimization/[with Yuan Yang]},
title = {{Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization}},
url = {http://arxiv.org/abs/1409.3257},
year = {2015}
}
%
@article{Nesterov2012,
abstract = {In this paper we propose new methods for solving huge-scale optimization problems. For problems of this size, even the simplest full-dimensional vector operations are very expensive. Hence, we propose to apply an optimization technique based on random partial update of decision variables. For these methods, we prove the global estimates for the rate of convergence. Surprisingly, for certain classes of objective functions, our results are better than the standard worst-case bounds for deterministic algorithms. We present constrained and unconstrained versions of the method and its accelerated variant. Our numerical test confirms a high efficiency of this technique on problems of very big size. Read More: http://epubs.siam.org/doi/abs/10.1137/100802001},
author = {Nesterov, Yurii},
doi = {10.1137/100802001},
file = {:D$\backslash$:/Mendeley Desktop/Nesterov - 2012 - Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems.pdf:pdf},
issn = {1052-6234},
journal = {SIAM Journal on Optimization},
keywords = {Google problem,convex optimization,coordinate relaxation,fast gradient schemes,worst-case efficiency estimates},
mendeley-groups = {Optimization/Coordinate Descent},
month = {jan},
number = {2},
pages = {341--362},
title = {{Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems}},
url = {http://130.104.5.100/cps/ucl/doc/core/documents/coredp2010{\_}2web.pdf http://epubs.siam.org/doi/abs/10.1137/100802001},
volume = {22},
year = {2012}
}
%
@inproceedings{LeeSidford2013,
  title={Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems},
  author={Lee, Yin Tat and Sidford, Aaron},
  booktitle={FOCS},
  pages={147--156},
  year={2013},
  organization={IEEE}
}
%
@article{LeventhalLewis2010,
  title={Randomized methods for linear constraints: convergence rates and conditioning},
  author={Leventhal, Dennis and Lewis, Adrian S},
  journal={Mathematics of Operations Research},
  volume={35},
  number={3},
  pages={641--654},
  year={2010},
  publisher={INFORMS}
}
%
@article{RichtarikTakac2014,
  title={Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Mathematical Programming},
  volume={144},
  number={1-2},
  pages={1--38},
  year={2014},
  publisher={Springer}
}
%
@inproceedings{BradleyKBG2011,
  title={Parallel coordinate descent for l1-regularized loss minimization},
  author={Bradley, Joseph K. and Kyrola, Aapo and Bickson, Danny and Guestrin, Carlos},
  booktitle={Proceedings of the 28th International Conference on Machine Learning},
  series={ICML' 11},
  year={2011}
}
%
@article{RichtarikTakac2012parallel,
  title={Parallel coordinate descent methods for big data optimization},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Mathematical Programming},
  pages={1--52},
  year={2012},
  publisher={Springer}
}
%
@inproceedings{TakacBRS2013,
  title={Mini-Batch Primal and Dual Methods for SVMs},
  author={Takac, Martin and Bijral, Avleen and Richtarik, Peter and Srebro, Nati},
  booktitle={Proceedings of The 30th International Conference on Machine Learning},
  pages={1022--1030},
  year={2013}
}
%
@article{NecoaraClipici2013,
  title={Efficient parallel coordinate descent algorithm for convex optimization problems with separable constraints: application to distributed MPC},
  author={Necoara, Ion and Clipici, Dragos},
  journal={Journal of Process Control},
  volume={23},
  number={3},
  pages={243--253},
  year={2013},
  publisher={Elsevier}
}
%
@ARTICLE{FercoqRichtarik2013smooth,
   author = {{Fercoq}, Olivier and {Richt{\'a}rik}, Peter},
    title = {Smooth minimization of nonsmooth functions with parallel coordinate descent methods},
  journal = {ArXiv e-prints},
volume    = {abs/1309.5885},
     year = 2013,
    month = sep,
}
%
@article{RichtarikTakac2013distributed,
  title={Distributed coordinate descent method for learning with big data},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:1310.2059},
  year={2013}
}
%
@inproceedings{LiuWRBS2014asynchronous,
  title={An Asynchronous Parallel Stochastic Coordinate Descent Algorithm},
  author={Liu, Ji and Wright, Steve and Re, Christopher and Bittorf, Victor and Sridhar, Srikrishna},
  booktitle={Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
  pages={469--477},
  year={2014}
}
%
@inproceedings{LinMH2015-Catalyst,
archivePrefix = {arXiv},
arxivId = {1506.02186},
author = {Lin, Hongzhou and Mairal, Julien and Harchaoui, Zaid},
booktitle = {NIPS},
eprint = {1506.02186},
file = {:D$\backslash$:/Mendeley Desktop/Lin, Mairal, Harchaoui - 2015 - A Universal Catalyst for First-Order Optimization.pdf:pdf},
mendeley-groups = {Optimization/Gradient Descent Theory},
title = {{A Universal Catalyst for First-Order Optimization}},
url = {http://arxiv.org/pdf/1506.02186v1.pdf},
year = {2015}
}
@inproceedings{FrostigGKS2015-Catalyst,
abstract = {We develop a family of accelerated stochastic algorithms that minimize sums of convex functions. Our algorithms improve upon the fastest running time for empirical risk minimization (ERM), and in particular linear least-squares regression, across a wide range of problem settings. To achieve this, we establish a framework based on the classical proximal point algorithm. Namely, we provide several algorithms that reduce the minimization of a strongly convex function to approximate minimizations of regularizations of the function. Using these results, we accelerate recent fast stochastic algorithms in a black-box fashion. Empirically, we demonstrate that the resulting algorithms exhibit notions of stability that are advantageous in practice. Both in theory and in practice, the provided algorithms reap the computational benefits of adding a large strongly convex regularization term, without incurring a corresponding bias to the original problem.},
archivePrefix = {arXiv},
arxivId = {1506.07512},
author = {Frostig, Roy and Ge, Rong and Kakade, Sham M. and Sidford, Aaron},
booktitle = {ICML},
eprint = {1506.07512},
file = {:D$\backslash$:/Mendeley Desktop/Frostig et al. - 2015 - Un-regularizing approximate proximal point and faster stochastic algorithms for empirical risk minimization.pdf:pdf},
mendeley-groups = {Optimization/Gradient Descent Theory},
pages = {1--28},
title = {{Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization}},
url = {http://arxiv.org/abs/1506.07512},
volume = {37},
year = {2015}
}
%
@article{ChambollePock2011,
abstract = {In this paper we study a first-order primal-dual algorithm for non-smooth convex optimization problems with known saddle-point structure. We prove convergence to a saddle-point with rate O(1/N) in finite dimensions for the complete class of problems. We further show accelerations of the proposed algorithm to yield improved rates on problems with some degree of smoothness. In particular we show that we can achieve O(1/N 2) convergence on problems, where the primal or the dual objective is uniformly convex, and we can show linear convergence, i.e. O($\omega$ N ) for some $\omega$∈(0,1), on smooth problems. The wide applicability of the proposed algorithm is demonstrated on several imaging problems such as image denoising, image deconvolution, image inpainting, motion estimation and multi-label image segmentation.},
annote = {Gives the full-gradient based accelerated algorithm for the saddle point problem.},
author = {Chambolle, Antonin and Pock, Thomas},
doi = {10.1007/s10851-010-0251-1},
file = {:D$\backslash$:/Mendeley Desktop/Chambolle, Pock - 2011 - A first-order primal-dual algorithm for convex problems with applications to imaging.pdf:pdf},
isbn = {1085101002},
issn = {09249907},
journal = {Journal of Mathematical Imaging and Vision},
keywords = {Convex optimization,Dual approaches,Image,Inverse problems,Reconstruction,Total variation},
mendeley-groups = {Optimization/Gradient Descent Theory},
number = {1},
pages = {120--145},
title = {{A first-order primal-dual algorithm for convex problems with applications to imaging}},
volume = {40},
year = {2011}
}
%
@misc{LibSVMdata,
  title={{LIBSVM Data: Classification, Regression and Multi-label}},
  author={Fan, Rong-En and Lin, Chih-Jen},
  url={http://www.csie.ntu.edu.tw/cjlin/libsvmtools/datasets},
  note = {Accessed: 2015-06}
}
%
@misc{Snap-data,
  author       = {Jure Leskovec and Andrej Krevl},
  title        = {{SNAP Datasets}: {Stanford} Large Network Dataset Collection},
  howpublished = {\url{http://snap.stanford.edu/data}},
  month        = jun,
  year         = 2014
}
%
@article{AO-survey-nesterov,
author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
journal   = {ArXiv e-prints},
month = jul,
title = {Linear Coupling: An Ultimate Unification of Gradient and Mirror Descent},
volume    = {abs/1407.1537},
bibsource = {DBLP, http://dblp.uni-trier.de},
year = {2014}
}
%
@inproceedings{AO-lp-parallel,
author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
title = {Using Optimization to Break the Epsilon Barrier: A Faster and Simpler Width-Independent Algorithm for Solving Positive Linear Programs in Parallel},
 booktitle = {Proceedings of the 26th ACM-SIAM Symposium on Discrete Algorithms},
 series    = {SODA~'15},
 year      = {2015},
}
%
@article{AO-lp-parallel-arxiv,
author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
journal   = {ArXiv e-prints},
month = jul,
title = {Using Optimization to Break the Epsilon Barrier: A Faster and Simpler Width-Independent Algorithm for Solving Positive Linear Programs in Parallel},
volume    = {abs/1407.1925},
bibsource = {DBLP, http://dblp.uni-trier.de},
year = {2014}
}
%
@inproceedings{AO-lp-coordinate,
author = {{Allen-Zhu}, Zeyuan and Orecchia, Lorenzo},
title = {{Nearly-Linear Time Positive LP Solver with Faster Convergence Rate}},
booktitle = {Proceedings of the 47th Annual ACM Symposium on Theory of Computing},
series    = {STOC~'15},
year      = {2015},
}
%
@inproceedings{ALO-bss,
author = {{Allen-Zhu}, Zeyuan and Liao, Zhenyu and Orecchia, Lorenzo},
title = {{Spectral Sparsification and Regret Minimization Beyond Multiplicative Updates}},
booktitle = {Proceedings of the 47th Annual ACM Symposium on Theory of Computing},
series    = {STOC~'15},
year      = {2015},
}
%

@inproceedings{NSLIFK-gauss-southwell,
   title="Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection",
   Author={Nutini, Julie and Schmidt, Mark and Laradji, Issam and Friedlander, Michael and Koepke, Hoyt},
   year="2015",
   Booktitle="Proceedings of the 32nd International Conference on Machine Learning (ICML-15)",
   pages="1632-1641",
 }

@inproceedings{NWS-Kaczmarz-algorithm,
title = {Stochastic Gradient Descent, Weighted Sampling, and the Randomized Kaczmarz algorithm},
author = {Needell, Deanna and Ward, Rachel and Srebro, Nati},
booktitle = {Advances in Neural Information Processing Systems 27},
pages = {1017--1025},
year = {2014},
}
@article{QRZ-arbitrary-sampling,
  author    = {Zheng Qu and
               Peter Richt{\'{a}}rik and
               Tong Zhang},
  title     = {Randomized Dual Coordinate Ascent with Arbitrary Sampling},
  journal   = {CoRR},
  volume    = {abs/1411.5873},
  year      = {2014},
}

@inproceedings{CQ-adaptive-sampling,
  author    = {Dominik Csiba and
               Zheng Qu and
               Peter Richt{\'{a}}rik},
  title     = {Stochastic Dual Coordinate Ascent with Adaptive Probabilities},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning,
               {ICML} 2015, Lille, France, 6-11 July 2015},
  pages     = {674--683},
  year      = {2015},
}
@inproceedings{zz-sdca-sampling,
	author        = "Peilin Zhao and Tong Zhang",
	booktitle     = "{Proceedings of the 32nd International Conference on Machine Learning}",
	pages         = "1--9",
	title         = "{Stochastic Optimization with Importance Sampling for Regularized Loss Minimization}",
	volume        = 37,
	year          = 2015,
}
@inproceedings{HLM2015,
title = {Variance Reduced Stochastic Gradient Descent with Neighbors},
author = {Hofmann, Thomas and Lucchi, Aurelien and Lacoste-Julien, Simon and McWilliams, Brian},
booktitle = {NIPS 2015},
pages = {2296--2304},
year = {2015},
}
%
@inproceedings{AY2015-coord,
author = {{Allen-Zhu}, Zeyuan and Richt\'arik, Peter and Qu, Zheng and Yuan, Yang},
booktitle = {ICML},
title = {Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling},
year = {2016}
}
%
@misc{e2lsh,
  author = {Alexandr Andoni},
  title = {{E2LSH}},
  howpublished = "\url{http://www.mit.edu/~andoni/LSH/}",
  year = {2004},
}
%
@phdthesis{Andoni2009thesis,
  author = {Andoni, Alexandr},
  title = {Nearest Neighbor Search: the Old, the New, and the Impossible},
  school = {MIT},
  year = 2009
}
%
@article{NNpq2011,
  author    = {Herv{\'{e}} J{\'{e}}gou and
               Matthijs Douze and
               Cordelia Schmid},
  title     = {Product Quantization for Nearest Neighbor Search},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {33},
  number    = {1},
  pages     = {117--128},
  year      = {2011},
}

@article{NNopq2014,
  author    = {Tiezheng Ge and
               Kaiming He and
               Qifa Ke and
               Jian Sun},
  title     = {Optimized Product Quantization},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {36},
  number    = {4},
  pages     = {744--755},
  year      = {2014},
}
%
@article{Kaczmarz1937,
  title={Angen{\"a}herte aufl{\"o}sung von systemen linearer gleichungen},
  author={Kaczmarz, Stefan},
  journal={Bulletin International de l’Academie Polonaise des Sciences et des Lettres},
  volume={35},
  pages={355--357},
  year={1937}
}
%
@article{StrohmerVershynin2009,
  title={A randomized Kaczmarz algorithm with exponential convergence},
  author={Strohmer, Thomas and Vershynin, Roman},
  journal={Journal of Fourier Analysis and Applications},
  volume={15},
  number={2},
  pages={262--278},
  year={2009},
  publisher={Springer}
}
@article{JHSPS-VR-Framework-parallel,
  author    = {Sashank J. Reddi and
             Ahmed Hefny and
             Suvrit Sra and
             Barnab{\'{a}}s P{\'{o}}czos and
             Alexander J. Smola},
  title     = {On Variance Reduction in Stochastic Gradient Descent and its Asynchronous
             Variants},
  journal  = {NIPS},
  year      = {2015},
}
%
@article{HazanBook,
  title={{DRAFT}: Introduction to Online Convex Optimimization},
  author={Elad Hazan},
  journal={Foundations and Trends in Machine Learning},
  volume={XX},
  number={XX},
  pages={1--168},
  year={2015}
}
%
@article{Bubeck2015book,
  title={Convex Optimization: Algorithms and Complexity},
  author={Bubeck, S{\'e}bastien},
  journal={Foundations and Trends in Machine Learning},
  volume={8},
  number={3-4},
  pages={231--357},
  year={2015},
  publisher={Now Publishers Inc.}
}
%
@article{HazanKale2014,
 author = {Hazan, Elad and Kale, Satyen},
 title = {Beyond the Regret Minimization Barrier: Optimal Algorithms for Stochastic Strongly-convex Optimization},
 journal = {The Journal of Machine Learning Research},
 volume = {15},
 number = {1},
 year = {2014},
 pages = {2489--2512},
 publisher = {JMLR.org},
}
%
@inproceedings{RakhlinShamirSridharan2012,
  title={Making Gradient Descent Optimal for Strongly Convex Stochastic Optimization},
  author={Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
  year={2012},
  booktitle={ICML},
}
%
@article{LacosteJulienSB2012,
  author    = {Simon Lacoste{-}Julien and
               Mark W. Schmidt and
               Francis R. Bach},
  title     = {A simpler approach to obtaining an $O(1/t)$ convergence rate for the
               projected stochastic subgradient method},
  volume    = {abs/1212.2002},
  year      = {2012},
  journal   = {ArXiv e-prints},
}
%
@inproceedings{GeHJY2015,
  title={Escaping From Saddle Points---Online Stochastic Gradient for Tensor Decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
booktitle = {Proceedings of the 28th Annual Conference on Learning Theory},
series = {COLT 2015},
  year={2015}
}
%
@article{SimulatedAnnealing1953,
  title={Equation of state calculations by fast computing machines},
  author={Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  journal={The journal of chemical physics},
  volume={21},
  number={6},
  pages={1087--1092},
  year={1953},
  publisher={AIP Publishing}
}
%
@article{GeneticAlgorithm1950,
  title={Computing machinery and intelligence},
  author={Turing, Alan M.},
  journal={Mind},
  pages={433--460},
  year={1950},
  publisher={JSTOR}
}
%
@article{GhadimiLan2015,
archivePrefix = {arXiv},
arxivId = {1310.3787},
author = {Ghadimi, Saeed and Lan, Guanghui},
doi = {10.1007/s10107-015-0871-8},
eprint = {1310.3787},
file = {:D$\backslash$:/Mendeley Desktop/Ghadimi, Lan - 2013 - Accelerated gradient methods for nonconvex nonlinear and stochastic programming.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {62l20,68q25,90c15,90c25,accelerated gradient,ams 2000 subject classification,complexity,nonconvex optimization,stochastic programming},
mendeley-groups = {Optimization/Gradient Descent Theory/Nonconvex,Optimization/Non-Convex},
month = {feb},
pages = {1--26},
title = {{Accelerated gradient methods for nonconvex nonlinear and stochastic programming}},
url = {http://arxiv.org/abs/1310.3787 http://link.springer.com/10.1007/s10107-015-0871-8},
year = {2015}
}
%
@inproceedings{LiLin2015,
author = {Li, Huan and Lin, Zhouchen},
booktitle = {Advances in Neural Information Processing Systems - NIPS '15},
file = {:D$\backslash$:/Mendeley Desktop/Li, Lin - Unknown - Accelerated Proximal Gradient Methods for Nonconvex Programming.pdf:pdf},
mendeley-groups = {Optimization/Non-Convex},
pages = {379----387},
title = {{Accelerated Proximal Gradient Methods for Nonconvex Programming}},
year = {2015}
}
%
@ARTICLE{GarberHazan2015-PCA,
   author = {{Garber}, Dan and {Hazan}, Elad},
    title = {Fast and Simple {PCA} via Convex Optimization},
  journal = {ArXiv e-prints},
   volumn = {abs/1509.05647},
     year = 2015,
    month = sep,
}
%
@article{ShalevShwartzSS2011-zeroone,
  title={Learning kernel-based halfspaces with the 0-1 loss},
  author={Shalev-Shwartz, Shai and Shamir, Ohad and Sridharan, Karthik},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  pages={1623--1646},
  year={2011},
  publisher={SIAM}
}
%
@article{DuchiHazanSinger2011,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={The Journal of Machine Learning Research},
  volume={12},
  pages={2121--2159},
  year={2011},
  publisher={JMLR. org}
}
%
@inproceedings{MahdaviZhangJin2013-nonsc,
  title={Mixed optimization for smooth functions},
  author={Mahdavi, Mehrdad and Zhang, Lijun and Jin, Rong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={674--682},
  year={2013}
}
%
@inproceedings{MahdaviZhangJin2013-sc,
  title={Linear convergence with condition number independent access of full gradients},
  author={Zhang, Lijun and Mahdavi, Mehrdad and Jin, Rong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={980--988},
  year={2013}
}
%
@inproceedings{AH2016-reduction,
 author = {{Allen-Zhu}, Zeyuan and Hazan, Elad},
 title = {{Optimal Black-Box Reductions Between Optimization Objectives}},
 booktitle = {Proceedings of the 30th Conference on Neural Information Processing Systems},
 series = {NIPS~'16},
 year = {2016},
 }
%
@inproceedings{AH2016-nonconvex,
author = {{Allen-Zhu}, Zeyuan and Hazan, Elad},
booktitle = {ICML},
title = {{Variance Reduction for Faster Non-Convex Optimization}},
year = {2016}
}
%
@inproceedings{AY2015-univr,
author = {{Allen-Zhu}, Zeyuan and Yuan, Yang},
booktitle = {ICML},
title = {{Improved SVRG for Non-Strongly-Convex or Sum-of-Non-Convex Objectives}},
year = {2016}
}
%
@inproceedings{ALO-sdp-parallel,
author = {{Allen-Zhu}, Zeyuan and Lee, Yin Tat and Orecchia, Lorenzo},
title = {Using Optimization to Obtain a Width-Independent, Parallel, Simpler, and Faster Positive {SDP} Solver},
 booktitle = {Proceedings of the 27th ACM-SIAM Symposium on Discrete Algorithms},
 series    = {SODA~'16},
 year      = {2016},
}
%
@article{WangMMR2015,
  author    = {Di Wang and
               Michael W. Mahoney and
               Nishanth Mohan and
               Satish Rao},
  title     = {Faster Parallel Solver for Positive Linear Programs via Dynamically-Bucketed
               Selective Coordinate Descent},
journal = {ArXiv e-prints},
month = nov,
  volume    = {abs/1511.06468},
  year      = {2015},
}
%
@article{LanZhou2015,
  author    = {Guanghui Lan and Yi Zhou},
  title     = {An optimal randomized incremental gradient method},
  journal = {ArXiv e-prints},
  month = oct,
  volume    = {abs/1507.02000},
  year      = {2015},
}
%
@misc{Lin2016-email,
  author        = {Lin, Hongzhou},
  howpublished  = "private communication",
  year          = "2016"
}
%
@inproceedings{Fercoq2014fast,
  title={Fast distributed coordinate descent for non-strongly convex losses},
  author={Fercoq, Olivier and Qu, Zheng and Richt{\'a}rik, Peter and Tak{\'a}c, Martin},
  booktitle={MLSP},
  pages={1--6},
  year={2014},
  organization={IEEE}
}
%
@article{Orabona2012prisma,
  title={Prisma: Proximal iterative smoothing algorithm},
  author={Orabona, Francesco and Argyriou, Andreas and Srebro, Nathan},
  journal={arXiv preprint arXiv:1206.2372},
  year={2012}
}
%
@article{Allenzhu2016Katyusha,
author = {{Allen-Zhu}, Zeyuan},
journal   = {ArXiv e-prints},
month = mar,
title = {{Katyusha: The First Direct Acceleration of Stochastic Gradient Methods}},
volume    = {abs/1603.05953},
year = {2016}
}
%
@inproceedings{MuscoMusco2015,
  title={Randomized Block Krylov Methods for Stronger and Faster Approximate Singular Value Decomposition},
  author={Musco, Cameron and Musco, Christopher},
  booktitle={NIPS},
  pages={1396--1404},
  year={2015}
}
%
@inproceedings{Shamir2015-kSVD,
  title={Fast Stochastic Algorithms for SVD and PCA: Convergence Properties and Convexity},
  author={Ohad Shamir},
  booktitle={ICML},
  year={2016}
}
%
@inproceedings{GarberHazan-et-al-2016-ICML,
  title={Robust Shift-and-Invert Preconditioning: Faster and More Sample Efficient Algorithms for Eigenvector Computation},
  author={Dan Garber and Elad Hazan and Chi Jin and Kakade, Sham M. and Cameron Musco and Praneeth Netrapalli and Aaron Sidford},
  booktitle={ICML},
  year={2016}
}
%
@inproceedings{BhojanapalliJS2015-SVD,
author = {Bhojanapalli, Srinadh and Jain, Prateek and Sanghavi, Sujay},
booktitle = {SODA},
pages = {902--920},
title = {{Tighter Low-rank Approximation via Sampling the Leveraged Element}},
year = {2015}
}
%
@inproceedings{ClarksonWoodruf2013-SVD,
author={Clarkson, Kenneth L. and Woodruff, David P.},
booktitle = {STOC},
pages = {81--90},
title = {{Low rank approximation and regression in input sparsity time}},
year = {2013}
}
%
@article{Tropp-book2015,
author = {Tropp, Joel A.},
journal   = {ArXiv e-prints},
month = jan,
title = {{An Introduction to Matrix Concentration Inequalities}},
volume    = {abs/1501.01571},
year = {2015}
}
%
@MISC{Spielman-lecture,
  author =       {Daniel Spielman},
  title =        {Spectral Graph Theory: Lecture 7},
  howpublished = {Lecture notes},
  year =         {2012},
  note = {\url{http://www.cs.cmu.edu/~15859n/RelatedWork/Spielman-SpectralClass/lect07-12-3.pdf}},
}
%
@article{wedin1972perturbation,
  title={Perturbation bounds in connection with singular value decomposition},
  author={Wedin, P. {\AA}.},
  journal={BIT Numerical Mathematics},
  volume={12},
  number={1},
  pages={99--111},
  year={1972},
  publisher={Springer}
}
%
@book{GolubLoan-book2013,
author = {Golub, Gene H. and {Van Loan}, Charles F.},
edition = {4th},
file = {:C$\backslash$:/Users/Zeyuan/Desktop/2013 Matrix Computations 4th.pdf:pdf},
isbn = {1421407949},
mendeley-groups = {Books/Book-Optimization},
pages = {784},
publisher = {The JHU Press},
title = {{Matrix Computations}},
year = {2012}
}
%
@inproceedings{Shamir2015-1SVD,
author = {Shamir, Ohad},
booktitle = {ICML},
pages = {144----153},
title = {{A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate}},
year = {2015}
}
%
@article{li2015convergence,
  title={Convergence of the block Lanczos method for eigenvalue clusters},
  author={Li, Ren-Cang and Zhang, Lei-Hong},
  journal={Numerische Mathematik},
  volume={131},
  number={1},
  pages={83--113},
  year={2015},
  publisher={Springer}
}
%
@article{entrywise-sampling-PetroA2011,
author = {Petros Drineas and Anastasios Zouzias},
journal   = {ArXiv e-prints},
month = jan,
title = {{A Note on Element-wise Matrix Sparsification via a Matrix-valued Bernstein Inequality}},
volume    = {abs/1006.0407},
year = {2011}
}
%
@inproceedings{JainJKNS2016-online1SVD,
author = {Prateek Jain and Chi Jin and Sham M. Kakade and Praneeth Netrapalli and Aaron Sidford},
booktitle = {COLT},
title = {{Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja's Algorithm}},
year = {2016}
}
%
@article{LiWLZ2016-online1SVD,
author = {Chris J. Li and Mengdi Wang and Han Liu and Tong Zhang},
journal   = {ArXiv e-prints},
month = mar,
title = {{Near-Optimal Stochastic Approximation for Online Principal Component Estimation}},
volume    = {abs/1603.05305},
year = {2016}
}
%
@article{GeJKNS2016-CCA,
author = {Rong Ge and Chi Jin and Sham M. Kakade and Praneeth Netrapalli and Aaron Sidford},
journal   = {ArXiv e-prints},
month = apr,
title = {{Efficient Algorithms for Large-scale Generalized Eigenvector Computation and Canonical Correlation Analysis}},
volume    = {abs/1604.03930},
year = {2016}
}
%
@article{WangWGS2016-CCA,
author = {Weiran Wang and Jialei Wang and Dan Garber and Nathan Srebro},
journal   = {ArXiv e-prints},
month = apr,
title = {{Efficient Globally Convergent Stochastic Optimization for Canonical Correlation Analysis}},
volume    = {abs/1604.01870},
year = {2016}
}
%
@inproceedings{MaLuFoster2015-CCA,
  title={Finding Linear Structure in Large Datasets with Scalable Canonical Correlation Analysis},
  author={Ma, Zhuang and Lu, Yichao and Foster, Dean},
  booktitle={ICML},
  pages={169--178},
  year={2015}
}
%
@incollection{kakade2007multi,
  title={Multi-view regression via canonical correlation analysis},
  author={Kakade, Sham M and Foster, Dean P},
  booktitle={Learning theory},
  pages={82--96},
  year={2007},
  publisher={Springer}
}
%
@inproceedings{chaudhuri2009multi,
  title={Multi-view clustering via canonical correlation analysis},
  author={Chaudhuri, Kamalika and Kakade, Sham M and Livescu, Karen and Sridharan, Karthik},
  booktitle={ICML},
  pages={129--136},
  year={2009},
}
%
@inproceedings{karampatziakis2014discriminative,
  title={Discriminative Features via Generalized Eigenvectors},
  author={Karampatziakis, Nikos and Mineiro, Paul},
  booktitle={ICML},
  pages={494--502},
  year={2014}
}
%
@inproceedings{dhillon2011multi,
  title={Multi-View Learning of Word Embeddings via CCA},
  author={Dhillon, Paramveer and Foster, Dean P and Ungar, Lyle H},
  booktitle={NIPS},
  pages={199--207},
  year={2011}
}
%
@misc{AgonizingPain-Shewchuk1994,
  title={An introduction to the conjugate gradient method without the agonizing pain},
  author={Shewchuk, Jonathan Richard},
  year={1994},
  publisher={Carnegie-Mellon University. Department of Computer Science}
}
%
@article{ChebyshevMethod-Axelsson1985,
  title={A survey of preconditioned iterative methods for linear systems of algebraic equations},
  author={Axelsson, Owe},
  journal={BIT Numerical Mathematics},
  volume={25},
  number={1},
  pages={165--187},
  year={1985},
  publisher={Springer}
}
%
@inproceedings{ma2015finding,
  title={Finding Linear Structure in Large Datasets with Scalable Canonical Correlation Analysis},
  author={Ma, Zhuang and Lu, Yichao and Foster, Dean},
  booktitle={ICML},
  pages={169--178},
  year={2015}
}
%
@article{wang2015large,
  title={Large-Scale Approximate Kernel Canonical Correlation Analysis},
  author={Wang, Weiran and Livescu, Karen},
  journal={arXiv preprint},
  volume={abs/1511.04773},
  year={2015}
}
%
@article{michaeli2015nonparametric,
  title={Nonparametric Canonical Correlation Analysis},
  author={Michaeli, Tomer and Wang, Weiran and Livescu, Karen},
  journal={arXiv preprint},
  volume={abs/1511.04839},
  year={2015}
}
%
@article{witten2009penalized,
  title={A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis},
  author={Witten, Daniela M and Tibshirani, Robert and Hastie, Trevor},
  journal={Biostatistics},
  pages={kxp008},
  year={2009},
  publisher={Biometrika Trust}
}
%
@inproceedings{lu2014large,
  title={Large scale canonical correlation analysis with iterative least squares},
  author={Lu, Yichao and Foster, Dean P},
  booktitle={NIPS},
  pages={91--99},
  year={2014}
}
%
@inproceedings{Shamir2016-onlinePCA,
  title={Convergence of stochastic gradient descent for PCA},
  author={Shamir, Ohad},
  booktitle={ICML},
  year={2016}
}
%
@inproceedings{SaReOlukotun2015-online1PCA,
  title={Global Convergence of Stochastic Gradient Descent for Some Non-convex Matrix Problems},
  author={Sa, Christopher De and Re, Christopher and Olukotun, Kunle},
  booktitle={ICML},
  pages={2332--2341},
  year={2015}
}
%
@inproceedings{HardtPrice2014-noisyPM,
  title={The Noisy Power Method: A Meta Algorithm with Applications},
  author={Hardt, Moritz and Price, Eric},
  booktitle={NIPS},
  pages={2861--2869},
  year={2014}
}
%
@inproceedings{Mitliagkas2013-streamPCA,
  title={Memory limited, streaming PCA},
  author={Mitliagkas, Ioannis and Caramanis, Constantine and Jain, Prateek},
  booktitle={NIPS},
  pages={2886--2894},
  year={2013}
}
%
@inproceedings{Balsubramani2013-incrementalPCA,
  title={The fast convergence of incremental pca},
  author={Balsubramani, Akshay and Dasgupta, Sanjoy and Freund, Yoav},
  booktitle={NIPS},
  pages={3174--3182},
  year={2013}
}
%
@inproceedings{XieLiangSong2015-kernalPCA,
  title={Scale up nonlinear component analysis with doubly stochastic gradients},
  author={Xie, Bo and Liang, Yingyu and Song, Le},
  booktitle={NIPS},
  pages={2341--2349},
  year={2015}
}
%
@article{Szarek1991-EigenDistribution,
  title={Condition numbers of random matrices},
  author={Szarek, Stanislaw J},
  journal={Journal of Complexity},
  volume={7},
  number={2},
  pages={131--149},
  year={1991},
  publisher={Elsevier}
}
%
@article{ChungLu2006-concentration,
  title={Concentration inequalities and martingale inequalities: a survey},
  author={Chung, Fan and Lu, Linyuan},
  journal={Internet Mathematics},
  volume={3},
  number={1},
  pages={79--127},
  year={2006},
  publisher={Taylor \& Francis}
}
%
@book{GilSeguraTemme2007,
abstract = {Special functions arise in many problems of pure and applied mathematics, mathematical statistics, physics, and engineering. This book provides an up-to-date overview of numerical methods for computing special functions and discusses when to use these methods depending on the function and the range of parameters. Not only are standard and simple parameter domains considered, but methods valid for large and complex parameters are described as well. The first part of the book (basic methods) covers convergent and divergent series, Chebyshev expansions, numerical quadrature, and recurrence relations. Its focus is on the computation of special functions; however, it is suitable for general numerical courses. Pseudoalgorithms are given to help students write their own algorithms. In addition to these basic tools, the authors discuss other useful and efficient methods, such as methods for computing zeros of special functions, uniform asymptotic expansions, Pad{\'{e}} approximations, and sequence transformations. The book also provides specific algorithms for computing several special functions (like Airy functions and parabolic cylinder functions, among others).},
author = {Gil, Amparo and Segura, Javier and Temme, Nico M.},
doi = {10.1137/1.9780898717822},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Gil, Segura, Temme - 2007 - Numerical Methods for Special Functions.pdf:pdf},
isbn = {978-0-89871-634-4},
issn = {0029599X},
mendeley-groups = {Books/Book-Optimization},
month = {jan},
pages = {405},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Numerical Methods for Special Functions}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9780898717822 http://epubs.siam.org/doi/book/10.1137/1.9780898717822},
year = {2007}
}
%
@inproceedings{FrostigMMS2016,
author = {Frostig, Roy and Musco, Cameron and Musco, Christopher and Sidford, Aaron},
booktitle = {ICML},
title = {{Principal Component Projection Without Principal Component Analysis}},
year = {2016}
}
%
@article{Eremenko2007uniform,
  title={Uniform approximation of sgn x by polynomials and entire functions},
  author={Eremenko, Alexandre and Yuditskii, Peter},
  journal={Journal d'Analyse Math{\'e}matique},
  volume={101},
  number={1},
  pages={313--324},
  year={2007},
  publisher={Springer}
}
%
@article{Eremenko2011polynomials,
  title={Polynomials of the best uniform approximation to sgn (x) on two intervals},
  author={Eremenko, Alexandre and Yuditskii, Peter},
  journal={Journal d'Analyse Math{\'e}matique},
  volume={114},
  number={1},
  pages={285--315},
  year={2011},
  publisher={Springer}
}
%
@misc{FrostigMMS2016-pcr-krylov,
author = {Frostig, Roy and Musco, Cameron and Musco, Christopher and Sidford, Aaron},
  title={{Code \verb"kpcr.m"}},
  note = {Accessed: 2016-07, \url{http://www.chrismusco.com/kpcr.m}},
  year = {2015}
}
%
@article{Elliott1968error,
  title={Error analysis of an algorithm for summing certain finite series},
  author={Elliott, David},
  journal={Journal of the Australian Mathematical Society},
  volume={8},
  number={02},
  pages={213--221},
  year={1968},
  publisher={Cambridge Univ Press}
}
%
@book{Trefethen2013,
author = {Trefethen, Lloyd N.},
file = {:C$\backslash$:/Users/Zeyuan/Documents/Mendeley Desktop/Trefethen - 2013 - Approximation Theory and Approximation Practice.pdf:pdf},
mendeley-groups = {Books/Book-Theory,Notes-Tools/Chebyshev,Books/Book-Optimization},
publisher = {SIAM},
title = {{Approximation Theory and Approximation Practice}},
year = {2013}
}
%
@article{ChanHansen1990computing,
  title={{Computing truncated singular value decomposition least squares solutions by rank revealing QR-factorizations}},
  author={Chan, Tony F and Hansen, Per Christian},
  journal={SIAM Journal on Scientific and Statistical Computing},
  volume={11},
  number={3},
  pages={519--530},
  year={1990},
  publisher={SIAM}
}
%
@inproceedings{Boutsidis2014faster,
  title={{Faster SVD-truncated regularized least-squares}},
  author={Boutsidis, Christos and Magdon-Ismail, Malik},
  booktitle={2014 IEEE International Symposium on Information Theory},
  pages={1321--1325},
  year={2014},
  organization={IEEE}
}
%
@article{EshofFLSV2002numerical,
  title={Numerical methods for the QCDd overlap operator. I. Sign-function and error bounds},
  author={van den Eshof, Jasper and Frommer, Andreas and Lippert, Th and Schilling, Klaus and van der Vorst, Henk A.},
  journal={Computer Physics Communications},
  volume={146},
  number={2},
  pages={203--224},
  year={2002},
  publisher={Elsevier}
}
%
@book{Schilders2008model,
  title={Model order reduction: theory, research aspects and applications},
  author={Schilders, Wilhelmus H.A. and Van der Vorst, Henk A. and Rommes, Joost},
  volume={13},
  year={2008},
  publisher={Springer}
}
%
@book{Higham2008,
author = {Higham, N.},
title = {Functions of Matrices},
publisher = {Society for Industrial and Applied Mathematics},
year = {2008},
doi = {10.1137/1.9780898717778},
address = {},
edition   = {},
URL = {http://epubs.siam.org/doi/abs/10.1137/1.9780898717778},
eprint = {http://epubs.siam.org/doi/pdf/10.1137/1.9780898717778}
}
%
@article{Wendel1948note,
  title={Note on the gamma function},
  author={Wendel, J. G. },
  journal={The American Mathematical Monthly},
  volume={55},
  number={9},
  pages={563--564},
  year={1948},
}
%
@inproceedings{LeeSun2015-bss,
  title={Constructing Linear-Sized Spectral Sparsification in Almost-Linear Time},
  author={Lee, Yin Tat and Sun, He},
  booktitle={FOCS},
  pages={250--269},
  year={2015},
  organization={IEEE}
}
%
@inproceedings{GarberHazanMa2015-onlineEV,
  title={Online learning of eigenvectors},
  author={Garber, Dan and Hazan, Elad and Ma, Tengyu},
  booktitle={Proceedings of the 32nd International Conference on Machine Learning (ICML-15)},
  pages={560--568},
  year={2015}
}
%
@article{KotlowskiWarmuth2015-onlineEV,
  title={PCA with Gaussian perturbations},
  author={Kot{\l}owski, Wojciech and Warmuth, Manfred K.},
  journal   = {ArXiv e-prints},
  volume    = {abs/1506.04855},
  year={2015}
}
%
@inproceedings{DworkTTZ2014-onlineEV,
  title={Analyze gauss: optimal bounds for privacy-preserving principal component analysis},
  author={Dwork, Cynthia and Talwar, Kunal and Thakurta, Abhradeep and Zhang, Li},
  booktitle={STOC},
  pages={11--20},
  year={2014},
  organization={ACM}
}
%
@article{AbernethyLeeTewari2015-onlineEV-wrong,
  title={Spectral smoothing via random matrix perturbations},
  author={Abernethy, Jacob and Lee, Chansoo and Tewari, Ambuj},
  journal   = {ArXiv e-prints},
  volume    = {abs/1507.03032},
  year={2015}
}
%
@inproceedings{AbernethyLST2014-online-linear-opt,
  title={Online Linear Optimization via Smoothing.},
  author={Abernethy, Jacob and Lee, Chansoo and Sinha, Abhinav and Tewari, Ambuj},
  booktitle={COLT},
  pages={807--823},
  year={2014}
}
%
@inproceedings{Nie2013online,
  title={Online pca with optimal regrets},
  author={Nie, Jiazhong and Kot{\l}owski, Wojciech and Warmuth, Manfred K},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={98--112},
  year={2013},
  organization={Springer}
}
%
@inproceedings{Boutsidis2015online,
  title={Online principal components analysis},
  author={Boutsidis, Christos and Garber, Dan and Karnin, Zohar and Liberty, Edo},
  booktitle={Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={887--901},
  year={2015},
  organization={SIAM}
}
%
@inproceedings{Karnin2015online,
  title={Online PCA with spectral bounds},
  author={Karnin, Zohar and Liberty, Edo},
  booktitle={Proceedings of the 28th Annual Conference on Computational Learning Theory (COLT)},
  pages={505--509},
  year={2015}
}
%
@article{Beck2012smoothing,
  title={Smoothing and first order methods: A unified framework},
  author={Beck, Amir and Teboulle, Marc},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={557--580},
  year={2012},
  publisher={SIAM}
}
%
@inproceedings{ALY2016-geometry,
author = {{Allen-Zhu}, Zeyuan and Liao, Zhenyu and Yuan, Yang},
booktitle = {ICALP},
title = {{Optimization Algorithms for Faster Computational Geometry}},
year = {2016}
}
%
%
@inproceedings{hu2009accelerated,
  title={Accelerated gradient methods for stochastic optimization and online learning},
  author={Hu, Chonghai and Pan, Weike and Kwok, James T},
  booktitle={Advances in Neural Information Processing Systems},
  pages={781--789},
  year={2009}
}
%
@inproceedings{WoodworthSrebro2016,
author = {Blake Woodworth and Nati Srebro},
booktitle = {NIPS},
title = {{Tight Complexity Bounds for Optimizing Composite Objectives}},
year = {2016}
}
%
@techreport{NesterovStich2016,
  title={Efficiency of accelerated coordinate descent method on structured optimization problems},
  author={Nesterov, Yurii and Stich, Sebastian},
  year={2016},
  institution={CORE Discussion Papers}
}
%
@article{XiaoZhang2013-homotopy,
  title={A proximal-gradient homotopy method for the sparse least-squares problem},
  author={Xiao, Lin and Zhang, Tong},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={2},
  pages={1062--1091},
  year={2013},
  publisher={SIAM}
}
%
@article{TranDinh2015adaptive,
  title={Adaptive Smoothing Algorithms for Nonsmooth Composite Convex Minimization},
  author={Tran-Dinh, Quoc},
  journal={arXiv preprint arXiv:1509.00106},
  year={2015}
}
%
@article{Boct2015variable,
  title={A variable smoothing algorithm for solving convex optimization problems},
  author={Bo{\c{t}}, Radu Ioan and Hendrich, Christopher},
  journal={TOP},
  volume={23},
  number={1},
  pages={124--150},
  year={2015},
  publisher={Springer}
}
%
@ARTICLE{Reddi2016-nonconvexSVRG,
   author = {Sashank J. Reddi and Ahmed Hefny and Suvrit Sra and Barnabas Poczos and Alex Smola},
    title = {Stochastic Variance Reduction for Nonconvex Optimization},
  journal = {ArXiv e-prints},
   volume = {abs/1603.06160},
     year = 2016,
    month = mar,
}
%
@ARTICLE{Reddi2016-nonconvexSAGA,
   author = {Sashank J. Reddi and Suvrit Sra and Barnabas Poczos and Alex Smola},
    title = {Fast Incremental Method for Nonconvex Optimization},
  journal = {ArXiv e-prints},
   volume = {abs/1603.06159},
     year = 2016,
    month = mar,
}
%
@inproceedings{AL2016-kSVD,
 author = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi},
 title = {{Even Faster SVD Decomposition Yet Without Agonizing Pain}},
 booktitle = {NIPS},
 year = {2016},
}
%
@inproceedings{Cohen2015dimensionality,
  title={Dimensionality reduction for k-means clustering and low rank approximation},
  author={Cohen, Michael B. and Elder, Sam and Musco, Cameron and Musco, Christopher and Persu, Madalina},
  booktitle={STOC},
  pages={163--172},
  year={2015},
  organization={ACM}
}
%
@article{Rudelson2009smallest,
  title={Smallest singular value of a random rectangular matrix},
  author={Rudelson, Mark and Vershynin, Roman},
  journal={Communications on Pure and Applied Mathematics},
  volume={62},
  number={12},
  pages={1707--1739},
  year={2009},
  publisher={Wiley Online Library}
}
%
@article{HazanKoren2015trustregion,
  title={A linear-time algorithm for trust region problems},
  author={Hazan, Elad and Koren, Tomer},
  journal={Mathematical Programming},
  pages={1--19},
  year={2015},
  publisher={Springer}
}
%
@article{AL2016-kCCA,
author = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi},
journal   = {ArXiv e-prints},
title = {{Doubly Accelerated Methods for Faster CCA and Generalized Eigendecomposition}},
volume    = {abs/1607.06017},
month = jul,
year = {2016}
}
%
@article{AL2016-onlinePCA,
author = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi},
journal   = {ArXiv e-prints},
title = {{Fast Global Convergence of Online PCA}},
volume    = {abs/1607.07837},
month = jul,
year = {2016}
}
%
@article{AL2016-PCR,
author = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi},
journal   = {ArXiv e-prints},
 title = {{Faster Principal Component Regression via Optimal Polynomial Approximation to sgn(x)}},
volume    = {abs/1608.04773},
month = aug,
year = {2016}
}
%
@misc{MaoJieming2016-email,
  author        = {Mao, Jieming},
  howpublished  = "private communication",
  year          = "2016"
}
%
@misc{EladHazan2016-email,
  author        = {Hazan, Elad},
  howpublished  = "private communication",
  year          = "2016"
}
