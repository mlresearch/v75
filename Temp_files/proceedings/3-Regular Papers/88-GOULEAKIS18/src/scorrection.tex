% !TeX root = main.tex
\section{Strong Correction Model} \label{sec:scorr}

  In section, we show that it is possible to obtain more efficient correction schemes for several problems. 
  We show that this is true for the sum function which implies strong correction schemes for other functions such as the average. 
  In addition, we show strong correction schemes for more general combinatorial tasks through a connection with conditional sampling.
  However, as we show there are 
simple functions, e.g. the composition of the max and the sum function, for which good weak correction schemes exist that do not admit strong correction schemes.

\subsection{Computing the Sum of Values of Records}

 Using the formulation in Section \ref{ssec:certificationSum}, we get the following result. Its proof appears in Appendix \ref{sec:app:scorr} and shows that $\Theta(1/\eps^2)$ verifications are both necessary and sufficient.

  
\begin{lemma} \label{lem:sumC}
    Let $x_1, x_2, \dots, x_n \ge 0$ be the values of the records $\Workers$ and $f(\xw) = \sum_{i \in \Workers} x_i$.
  Consider the probability distribution $p_i = \frac {x_i} {\sum_j x_j}$ which selects a record $x_i$ with probability 
  proportional to its value. If we sample $M$ times independently from $p$ until 
  $k = \Theta\left(\frac{1}{\eps^2}\log (1/\delta)\right)$ valid records found, then the estimator 
  $\hat{s} = \frac{k}{M} \sum_{i \in \Workers} x_i$ lies in
  $\left[ 1 - \eps, \frac{1}{1 - \eps} \right] \cdot \sum_{i \in \Truth} x_i$ w.p. at least $1 - \delta$. 
\end{lemma}


\subsection{Lower Bound for the Maximum of Sums Function}

  In this section we show that no efficient strong correction scheme exists for the composition of the max and the sum function. 
More precisely we assume we have a partition $\mathcal{J} = \{\Workers_1, \dots, \Workers_{\ell}\}$ of the set $\Workers$ and we 
want a strong correction scheme for the function $f(\xw) = \max_{A \in \mathcal{J}} \sum_{i \in A} x_i$. Lemma \ref{lem:maxOfSumC} shows that any strong 
correction scheme for $f$ that achieves constant approximation has to verify at least a constant fraction of the records. Its proof can be found in Appendix \ref{sec:app:scorr}. 

\begin{lemma} \label{lem:maxOfSumC}
    Let $c >0$. There exists a partition $\mathcal{J} = \{\Workers_1, \dots, \Workers_{\ell}\}$ of
  $\Workers$ and a vector $\xw \in \reals^n$ such that any strong correction scheme for the function 
  $f(\xw) = \max_{A \in \mathcal{J}} \sum_{i \in A} x_i$, that returns an estimate 
  $\hat{s} \in \left[\frac{1}{c}, c\right] \cdot f(\xt)$ with probability at least $3/4$, must verify
  $\abs{\Workers} / 4 c^2$ records.
\end{lemma}



\subsection{From Algorithms using Conditional Sampling to Strong Correction Schemes}

  The design of a strong correction scheme can be challenging since the guarantee is very strong. Our main theorem 
in this section shows that there is a correspondence of strong correction schemes with 
\textit{sublinear algorithms using conditional sampling}, introduced recently in \cite{GouleakisTZ2017}. We state here the main
theorem for this section and we defer its proof and applications for Appendix \ref{sec:app:applicationsStrongCorrection}.

\begin{theorem} \label{thm:sCorrection}
    Any function that can be approximated using $k$ conditional samples admits a strong correction scheme with cost $k$.
\end{theorem}