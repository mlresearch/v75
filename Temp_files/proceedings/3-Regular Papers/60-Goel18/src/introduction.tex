%!TEX root = LookingGlass.tex


In this paper we develop a new algorithmic framework, \ouralg\ (\ourack), for online convex optimization problems with switching costs, a class of problems termed smoothed online convex optimization (SOCO).  Specifically, we consider a setting where a learner plays a series of rounds $1,2,\ldots,T$. In each round, the learner observes a convex cost function $f_t$, picks a point $x_t$ from a convex set $\mathcal{X}$, and then incurs a \emph{hitting cost} $f_t(x_t)$. Additionally, she incurs a \emph{switching cost} for changing her actions between successive rounds, $\|x_t - x_{t-1}\|$, where $\|\cdot\|$ is a norm.  

This setting generalizes classical Online Convex Optimization (OCO), and has received considerable attention in recent years as a result of the recognition that switching costs play a crucial role in many learning, algorithms, control, and networking problems.  In particular, many applications have, in reality, some cost associated with a change of action that motivates the learner to adopt ``smooth'' sequences of actions.  For example, switching costs have received considerable attention in the $k$-armed bandit setting  \citep{agrawal1990multi, guha2009multi, koren2017multi} and the core of the Metrical Task Systems (MTS) literature is determining how to manage switching costs, e.g., the $k$-server problem \citep{borodin1992, borodin2005}. %More generally, even when there is no measurable cost to switching, if there is concept drift in a penalized estimation problem, then it is natural to use a regularization term (switching cost) to control the drift of the estimator.  

Outside of learning, SOCO has received considerable attention in the networking and control communities.  In these problems there is typically a measurable cost to changing an action.  For example, one of the initial applications where SOCO was adopted is the dynamic management of service capacity in data centers \citep{lin2011, lu2013simple}, where the wear-and-tear costs of switching servers into and out of deep power-saving states is considerable.  Other applications where SOCO has seen real-world deployment are the dynamic management of routing between data centers \citep{lin2012,wang2014exploring}, management of electrical vehicle charging \citep{kim2014real}, video streaming \citep{joseph2012jointly}, speech animation \citep{kim2015}, multi-timescale control \citep{goel2017thinking}, power generation planning \citep{badiei2015online}, and the thermal management of System-on-Chip (SoC) circuits \citep{zanini2009multicore,zanini2010online}. 


\paragraph{High-dimensional SOCO.} An important aspect of nearly all the problems mentioned above is that they are \emph{high-dimensional}, i.e., the dimension $d$ of the action space is large.  For example, in the case of dynamic management of data centers the dimension grows with the heterogeneity of the storage and compute nodes in the cluster, as well as the heterogeneity of the incoming workloads. However, the design of algorithms for high-dimensional SOCO problems has proven challenging, with fundamental lower bounds blocking progress.  

Initial results on SOCO focused on finding competitive algorithms in the low-dimensional settings. Specifically, \cite{lin2011} introduced the problem in the one-dimensional case and gave a 3-competitive algorithm.  A few years later, \cite{bansal2015} gave a 2-competitive algorithm, still for the one-dimensional case.  Following these papers, \cite{antoniadis2016} claimed that SOCO is equivalent to the classical problem of Convex Body Chasing \cite{Friedman1993}, in the sense that a competitive algorithm for one problem implies the existence of a competitive problem for the other. Using this connection, they claimed to show the existence of a constant competitive algorithm for two-dimensional SOCO. However, their analysis turned out to have a bug and their claims have been retracted \citep{errata}. 
However, the connection to Convex Body Chasing does highlight a fundamental limitation.  In particular, it is not possible to design a competitive algorithm for high-dimensional SOCO without making restrictions on the cost functions considered since, as we observe in Section \ref{sec: model}, for general convex cost functions and $\ell_2$ switching costs, the competitive ratio of any algorithm is $\Omega(\sqrt{d})$. 

The importance of high-dimensional SOCO problems in practical applications has motivated the ``beyond worst-case'' analysis for SOCO as a way of overcoming the challenge of designing constant competitive algorithms in high dimensions.  To this end, \cite{lin2012, andrew2013, chen2015, badiei2015online, chen2016} all explored the value of predictions in SOCO, highlighting that it is possible to provide constant-competitive algorithms for high-dimensional SOCO problems using algorithms that have predictions of future cost functions, e.g., \cite{lin2012} gave an algorithm based on receding horizon control that is $1+O(1/w)$-competitive when given $w$-step lookahead. Recently, this was revisited in the case quadratic switching costs by \cite{li2018online}, which gives an algorithm that combines receding horizon control with gradient descent to achieve a competitive ratio that decays exponentially in $w$. 

In addition to the stream of work focused on competitive ratio, there is a separate stream of work focusing on the development of algorithms with small regret.  With respect to classical \emph{static} regret, where the comparison is with the  fixed, static offline optimal, \cite{andrew2013} showed that SOCO is no more challenging than OCO.  In fact, many OCO algorithms, e.g., Online Gradient Descent (OGD), obtain bounds on regret of the same asymptotic order for SOCO as for OCO.  However, the task of bounding \emph{dynamic} regret in SOCO is more challenging and, to this point, the only positive results for dynamic regret rely on the use of predictions.  %In particular, \cite{li2018online} gives a receding horizon gradient descent algorithm that has dynamic regret that shrinks exponentially in the size of the lookahead $w$.  But, we are not aware of any positive results for dynamic regret that do not use predictions. \niangjun{commented out as we already talked about this work in the previous paragraph.}

There have been a number of attempts to connect the communities focusing on regret and competitive ratio over the years.  \cite{Blum2000} initiated this direction by providing an analytic framework that connects OCO algorithms with MTS algorithms, allowing the derivation of regret bounds for MTS algorithms in the OCO framework and competitive analysis of OCO algorithms in the MTS framework.  Two breakthroughs in this direction occurred recently.  First, \cite{buchbinder2012unified} used a primal-dual technique to develop an algorithm that, for the first time, provided a unified approach for algorithm design across competitive ratio and regret in the MTS setting, over a discrete action space. Second, a series of recent papers \citep{abernethy2010regularization, buchbinder2014competitive, bubeck2017} used techniques based on Online Mirror Descent (OMD) to provide significant advances in the analysis of the $k$-server and MTS problems. However, again there is a fundamental limit to these unifying approaches in the setting of SOCO. \cite{andrew2013} shows that no individual algorithm can simultaneously be constant competitive and have sublinear regret.  Currently, the only unifying frameworks for SOCO rely on the use of predictions, and use approaches based on receding horizon control, e.g., \cite{chen2015,badiei2015online, chen2016,li2018online}. 

\paragraph{Contributions of this paper.} The prior discussion highlights the challenges associated with designing algorithms for high-dimensional SOCO problems,
%In particular, the development of algorithms for high-dimensional SOCO remains an open and active topic, 
both in terms of competitive ratio and dynamic regret.  In this paper, we introduce a new, general algorithmic framework, \ouralg\ (\ourack), that yields (i) an algorithm with a dimension-free, constant competitive ratio for locally polyhedral cost functions and $\ell_2$ switching costs and (ii) an algorithm with a dimension-free, sublinear static regret that does not depend on the size of the gradients of the cost functions. In both cases, \ourack\ achieves these results without relying on predictions of future cost functions -- the first algorithm to achieve such a bound on competitive ratio outside of the one-dimensional setting.

The key idea behind \ourack\ is %that, while many online optimization algorithms descend toward the minimizer of the cost function in each round, it is \niangjun{commented out as OGD and other online alg doesn't really move towards minimum at each step, only the 1-d memoryless alg. in Bansal2015.}
%to focus on the geometry of the level sets to guide the choice of an action in each round.  This insight leads \ourack\ 
to move using a projection onto a carefully chosen level set at each step chosen to ``balance'' the switching and hitting costs incurred.  The 
%projection is performed using a mirror map, as in Online Mirror Descent (OMD), and the \niangjun{commented out since mirror projection is quite common in the learning field.}
form of ``balance'' is chosen carefully based on the performance metric.  In particular, our results use a ``balance'' of the switching and hitting costs in the primal space to obtain results for the competitive ratio and a ``balance''  of the switching costs and the gradient of the hitting costs in the dual space to obtain results for dynamic regret. The resulting \ourack\ algorithms are efficient to implement, even in high dimensions. They are also \emph{memoryless}, i.e., do not use any information about previous cost functions. 

The technical results of the paper bound the competitive ratio and dynamic regret of \ourack.  In both cases we obtain results that improve the state-of-the-art. In the case of \emph{competitive ratio}, we obtain the first results that break through the $\sqrt{d}$ barrier without the use of predictions.  In particular, we show that \ourack\ with $\ell_2$ switching costs yields a constant, dimension-free competitive ratio for locally polyhedral cost functions, i.e. functions which grow at least linearly away from their minimizer.  Specifically, in Theorem \ref{threeCR} we show that \ourack\ has a competitive ratio of $3+O(1/\alpha)$, where $\alpha$ bounds the ``steepness'' of the costs.  Note that \cite{bansal2015} shows that no memoryless algorithm can achieve a competitive ratio better than $3$ for locally polyhedral functions. 
%Our approach extends to more general classes of cost functions and switching costs as well; we give the first competitive algorithm when the cost functions and switching costs are arbitrary norms 
By equivalence of norms in finite dimensional space, our algorithm is also competitive when the switching costs are arbitrary norms (though the exact competitive ratio may depend on $d$).  Our proof of this result depends crucially on the geometry of the level sets. 
%The fact that the cost functions are locally polyhedral gives that the level sets are not too narrow, and the key geometric insight in our analysis is that this roundness implies bounds on the deviation from the optimal offline costs at each step. Lemma  \ref{lem: potential-change} is the key technical result capturing this insight.  \niangjun{commented out as it is too early for reader to understand this detail of the proof.}

%Our proof technique uses a potential function argument; we break the per-round analysis into two cases depending on whether our algorithm or the offline optimal is closer to the minimizer, and bound the change in potential in each case. The first case is fairly simple; due to the fact that our algorithm balances the hit cost and movement cost, it is straightforward to show that the per-step cost we incur is at most a constant times the cost incurred by the offline optimal. The second case is more involved. The key geometric insight in our analysis is captured by Lemma  \ref{lem: potential-change}, where we show that in the second case the change in potential is actually negative. This offsets the hit cost and movement cost incurred by our online algorithm, so the total per-step cost we incur is actually non-positive, allowing us to sidestep a direct comparison with the offline cost.
  

In the case of \emph{dynamic regret}, we obtain the first results that provide sub-linear dynamic regret without the use of predictions.  Further, the bounds on dynamic regret we prove are independent of the size of the gradient of the cost function. %, something that current state-of-the-art results in OCO do not achieve.  \niangjun{commented out to avoid triggering the hardcore learning theory people into pointing out that we cheat by having one-step advantage.}
Specifically, in Corollary \ref{cor: online-projection-regret} we show that \ourack\ has dynamic regret bounded by $O(\sqrt{LT})$, where $L$ is the total distance traveled by the offline optimal. When comparing to a static optimal, \ourack\ achieves sublinear regret of $O(\sqrt{DT})$ where $D$ is the diameter of the feasible set. The proof again makes use of a geometric interpretation of \ourack\ in terms of the level sets.  In particular, the projection onto the level sets allows \ourack\ to be ``one step ahead'' of Online Mirror Descent. Further, \ourack\ carefully choses the step sizes to balance the switching cost and marginal hitting cost in the dual space. 


%In Section \ref{sec: alg-cr}, we show that by carefully balancing the movement cost and the hit cost, we can obtain a competitive online algorithm when the cost functions are \textit{locally polyhedral}, which intuitively means that they grow at least linearly as one moves away from their minimizer. Our main result is an algorithm whose competitive ratio is $3+O(1/\alpha)$, where $\alpha$ is a parameter measuring how steep the cost functions are. This is very close to the known lower bound of 3 for memoryless algorithms \cite{bansal2015}. Our proof technique uses a potential function argument; we break the per-round analysis into two cases depending on whether our algorithm or the offline optimal is closer to the minimizer, and bound the change in potential in each case. The first case is fairly simple; due to the fact that our algorithm balances the hit cost and movement cost, it is straightforward to show that the per-step cost we incur is at most a constant times the cost incurred by the offline optimal. The second case is more involved. The key geometric insight in our analysis is captured by Lemma  \ref{lem: potential-change}, where we show that in the second case the change in potential is actually negative. This offsets the hit cost and movement cost incurred by our online algorithm, so the total per-step cost we incur is actually non-positive, allowing us to sidestep a direct comparison with the offline cost.
  
%In Section \ref{sec: alg-regret}, we show that by balancing the movement cost and the gradient, we can achieve low dynamic regret that is independent of the upper bound of the cost functions. In particular, Theorem \ref{thm: online-projection-regret} and Corollary \ref{cor: online-projection-regret} shows that, given the total movement cost of the offline optimal $L$ and the size of feasible set $D$, the dynamic regret of  $\ouralg$ is upper bounded by $O(\sqrt{TL})$. \gautam{We need to expand this}



 
 
 
 
 
 
 

 


