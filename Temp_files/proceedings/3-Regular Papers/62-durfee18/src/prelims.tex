\section{Preliminaries}\label{sec:prelims}

In this section, we describe some of the notation and important definitions we use in the paper. We represent matrices and vectors using bold variables. We let $\AA_{i,:}$ denote the $i^{th}$ row of a matrix $\AA$, and we use $nnz(\AA)$ to denote the number of non-zero elements in $\AA$.
$\AA^{\dagger}$ refers to the Moore-Penrose pseudoinverse of $\AA$. When $\AA$ has linearly-independent columns,
$\AA^{\dagger} = (\AA^T \AA)^{-1} \AA^T$.
Also, we assume that the input $\AA$ has full rank.


\begin{definition}[$\ell_p$-norm]
	The $\ell_p$ norm of a vector $\vv \in \R^n$
	is defined as
	\begin{align*}
	\textstyle{\norm{\vv}_p \defeq \left(\sum_{i=1}^n \vv_i^p \right)^{1/p}}.
	\end{align*} 
	Accordingly, the $\ell_p$ norm of a matrix $\AA \in \R^{n \times d}$
	is defined as
	\begin{align*}
	\norm{\AA}_p \defeq \sup_{\xx \in \R^d, \xx \neq 0} \dfrac{\norm{\AA \xx}_p}{\norm{\xx}_p}.
	\end{align*} 
\end{definition}

\begin{definition}[Matrix approximation]
	We say that $\AA \approx_{\kappa} \BB$ if and only if
	\begin{align*}
	\dfrac{1}{\kappa} \BB \preceq \AA \preceq \kappa \BB.
	\end{align*}
	Here, $\preceq$ refers to the L\"{o}wner partial ordering of matrices,
	where we say that $\AA \preceq \BB$ if $\BB - \AA$ is positive semi-definite.
\end{definition}

Note that we also use $\approx$ similarly in the case of scalars, as is commonplace.

\begin{definition}[IRB]\label{def:good} A matrix $\AA \in \R^{n\times d}$ with $n \ge d$ is said to be \textit{isotropic row-bounded} (IRB) if the following hold:
	\begin{enumerate}
		\item{$\AA^T \AA = \II$},
		\item{For all rows of $\AA$, $\norme{\AA_{i,:}}^2 \leq O(d/n)$}.
	\end{enumerate}
\end{definition}

\begin{definition}\label{def:levScore}
	Given a matrix $\AA$, we define the \textit{statistical leverage score} of row $\AA_{i,:}$ to be 
	\[\tau_i(\AA) \defeq \AA_{i,:}\left(\AA^T \AA\right)^{-1}\AA_{i,:}^T = \norme{\left(\AA^T\AA\right)^{-1/2}\AA_{i,:}^T}^2. \]
\end{definition}


\begin{definition}\label{def:lewis}
	For a matrix $\AA$, the $\ell_1$ \textit{Lewis weights} $\lw$ are the unique weights such that for each row $i$ we have 
	\[\lw_i = \tau_i\left(\LW^{-1/2}\AA\right) 
	\]
	or equivalently
	\[\lw^2 = \AA_{i,:}\left(\AA^T\LW^{-1}\AA\right)^{-1}\AA_{i,:}^T\]
	where $\LW$ is the diagonal matrix formed by putting the elements of $\lw$ on the diagonal.
\end{definition}


\begin{definition}\label{def:smooth}
	A function $f$ is $L$-\textit{smooth} if for any $x,y \in \mathbb{R}^d$, $||\nabla f(x) - \nabla f(y)||_2 \leq L||x-y||_2.$
\end{definition}

\begin{definition}\label{def:strong_convex}
	A function $f$ is $\sigma$-\textit{strongly convex} if for any $x,y \in \mathbb{R}^d$,
	\begin{equation*}
	\textstyle{f(y) \geq f(x) + \langle \nabla f(x),y-x\rangle + \frac{\sigma}{2}||x-y||_2^2}.
	\end{equation*}
\end{definition}

\begin{definition}\label{def:lipsCont}
	A function $f$ is $G$-\textit{Lipschitz continuous} if for any $x,y \in \mathbb{R}^d$, 	
	\[ ||f(x) - f(y)||_2 \leq G||x-y||_2.\] 	
\end{definition}

