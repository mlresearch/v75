#
#	Machine Learning (++) Bibliography
#

@string{aistat07 = {Processing of 11th International Conference on
Artificial Intelligence and Statistics}}
@string{aistat10 = {Proceedings of the 13th International Conference
on Artificial Intelligence and Statistics}}
@string{aistat11 = {Proceedings of the 14th International Conference
on Artificial Intelligence and Statistics}}
@string{aistat12 = {Proceedings of the 15th International Conference
on Artificial Intelligence and Statistics}}
@string{aistat13 = {Proceedings of the 16th International Conference
on Artificial Intelligence and Statistics}}
@string{aistat14 = {Proceedings of the 17th International Conference
on Artificial Intelligence and Statistics}}
@string{aistat15 = {Proceedings of the 18th International Conference
on Artificial Intelligence and Statistics}}

@string{colt88 = {Proceedings of the 1988 Workshop on Computational
 		  Learning Theory}}
@string{colt89 = {Proceedings of the Second Annual Workshop on Computational
		  Learning Theory}}
@string{colt90 = {Proceedings of the Third Annual Workshop on Computational
		  Learning Theory}}
@string{colt91 = {Proceedings of the Fourth Annual Workshop on
		  Computational Learning Theory}}
@string{colt92 = {Proceedings of the Fifth Annual ACM Workshop on
		  Computational Learning Theory}}
@string{colt93 = {Proceedings of the Sixth Annual ACM Conference on
		  Computational Learning Theory}}
@string{colt94 = {Proceedings of the Seventh Annual ACM Conference on
		  Computational Learning Theory}}
@string{colt95 = {Proceedings of the Eighth Annual Conference on
		  Computational Learning Theory}}
@string{colt96 = {Proceedings of the Ninth Annual Conference on
		  Computational Learning Theory}}
@string{colt97 = {Proceedings of the Tenth Annual Conference on
		  Computational Learning Theory}}
@string{colt98 = {Proceedings of the Eleventh Annual Conference on
		  Computational Learning Theory}}
@string{colt99 = {Proceedings of the Twelfth Annual Conference on
		  Computational Learning Theory}}
@string{colt00 = {Proceedings of the Thirteenth Annual Conference on
		  Computational Learning Theory}}
@string{colt01 = {Proceedings of the Fourteenth Annual Conference on
		  Computational Learning Theory}}
@string{colt02 = {Proceedings of the Fifteenth Annual Conference on
		  Computational Learning Theory}}
@string{colt03 = {Proceedings of the Sixteenth Annual Conference on
		  Computational Learning Theory}}
@string{colt04 = {Proceedings of the Seventeenth Annual Conference on
		  Computational Learning Theory}}
@string{colt05 = {Proceedings of the Eighteenth Annual Conference on
		  Computational Learning Theory}}
@string{colt06 = {Proceedings of the Nineteenth Annual Conference on
		  Computational Learning Theory}}
@string{colt07 = {Proceedings of the Twentieth Annual Conference on
		  Computational Learning Theory}}
@string{colt08 = {Proceedings of the Twenty First Annual Conference on
		  Computational Learning Theory}}
@string{colt09 = {Proceedings of the Twenty Second Annual Conference on
		  Computational Learning Theory}}
@string{colt10 = {Proceedings of the Twenty Third Annual Conference on
		  Computational Learning Theory}}
@string{colt11 = {Proceedings of the Twenty Fourth Annual Conference on
		  Computational Learning Theory}}
@string{colt12 = {Proceedings of the Twenty Fifth Annual Conference on
		  Computational Learning Theory}}
@string{colt13 = {Proceedings of the Twenty Sixth Annual Conference on
		  Computational Learning Theory}}
@string{colt14 = {Proceedings of the Twenty Seventh Annual Conference on
		  Computational Learning Theory}}
@string{colt15 = {Proceedings of the Twenty Eighth Annual Conference on
		  Computational Learning Theory}}
@string{colt16 = {Proceedings of the Twenty Ninth Annual Conference on
		  Computational Learning Theory}}



@string{emnlp = {Proceedings of Empirical Methods for Natural Language
                 Processing}}

@string{eurocolt93 = {Computational Learning Theory: EuroCOLT '93}}
@string{eurocolt95 = {Computational Learning Theory: Second European
			Conference, EuroCOLT~'95}}
@string{eurocolt99 = {Computational Learning Theory: Fourth European
			Conference, EuroCOLT~'99}}

@string{esann99 = {Proceedings of the Seventh European Symposium on
                   Artificial Neural Networks}}

@string{focs78 = {19th Annual Symposium on Foundations of Computer Science}}
@string{focs79 = {20th Annual Symposium on Foundations of Computer Science}}
@string{focs80 = {21st Annual Symposium on Foundations of Computer Science}}
@string{focs81 = {22nd Annual Symposium on Foundations of Computer Science}}
@string{focs82 = {23rd Annual Symposium on Foundations of Computer Science}}
@string{focs83 = {24th Annual Symposium on Foundations of Computer Science}}
@string{focs84 = {25th Annual Symposium on Foundations of Computer Science}}
@string{focs85 = {26th Annual Symposium on Foundations of Computer Science}}
@string{focs86 = {27th Annual Symposium on Foundations of Computer Science}}
@string{focs87 = {28th Annual Symposium on Foundations of Computer Science}}
@string{focs88 = {29th Annual Symposium on Foundations of Computer Science}}
@string{focs89 = {30th Annual Symposium on Foundations of Computer Science}}
@string{focs90 = {31st Annual Symposium on Foundations of Computer Science}}
@string{focs91 = {32nd Annual Symposium on Foundations of Computer Science}}
@string{focs92 = {33rd Annual Symposium on Foundations of Computer Science}}
@string{focs93 = {34th Annual Symposium on Foundations of Computer Science}}
@string{focs94 = {35th Annual Symposium on Foundations of Computer Science}}
@string{focs95 = {36th Annual Symposium on Foundations of Computer Science}}
@string{focs96 = {37th Annual Symposium on Foundations of Computer Science}}
@string{focs97 = {38th Annual Symposium on Foundations of Computer Science}}
@string{focs98 = {39th Annual Symposium on Foundations of Computer Science}}
@string{focs99 = {40th Annual Symposium on Foundations of Computer Science}}
@string{focs00 = {41st Annual Symposium on Foundations of Computer Science}}
@string{focs01 = {42nd Annual Symposium on Foundations of Computer Science}}
@string{focs02 = {43rd Annual Symposium on Foundations of Computer Science}}
@string{focs03 = {44th Annual Symposium on Foundations of Computer Science}}
@string{focs04 = {45th Annual Symposium on Foundations of Computer Science}}
@string{focs05 = {46th Annual Symposium on Foundations of Computer Science}}
@string{focs06 = {47th Annual Symposium on Foundations of Computer Science}}
@string{focs07 = {48th Annual Symposium on Foundations of Computer Science}}
@string{focs08 = {49th Annual Symposium on Foundations of Computer Science}}
@string{focs09 = {50th Annual Symposium on Foundations of Computer Science}}
@string{focs10 = {51st Annual Symposium on Foundations of Computer Science}}
@string{focs11 = {52nd Annual Symposium on Foundations of Computer Science}}
@string{focs12 = {53rd Annual Symposium on Foundations of Computer Science}}
@string{focs13 = {54th Annual Symposium on Foundations of Computer Science}}

@string{soda90 = {Proceedings of the First Annual ACM-SIAM Symposium on
		  Discrete Algorithms (SODA)}}
@string{soda91 = {Proceedings of the Second Annual ACM-SIAM Symposium on
		  Discrete Algorithms (SODA)}}
@string{soda13 = {Proceedings of the Twenty-Fourth ACM-SIAM Symposium on
		  Discrete Algorithms (SODA)}}
@string{soda14 = {Proceedings of the Twenty-Fifth ACM-SIAM Symposium on
		  Discrete Algorithms (SODA)}}

@string{stoc79 = {Proceedings of the Eleventh Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc80 = {Proceedings of the Twelfth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc81 = {Proceedings of the Thirteenth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc82 = {Proceedings of the Fourteenth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc83 = {Proceedings of the Fifteenth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc84 = {Proceedings of the Sixteenth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc85 = {Proceedings of the Seventeenth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc86 = {Proceedings of the Eighteenth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc87 = {Proceedings of the Nineteenth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc88 = {Proceedings of the Twentieth Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc89 = {Proceedings of the Twenty First Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc90 = {Proceedings of the Twenty Second Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc91 = {Proceedings of the Twenty Third Annual ACM Symposium on
		  Theory of Computing}}
@string{stoc92 = {Proceedings of the Twenty-Fourth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc93 = {Proceedings of the Twenty-Fifth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc94 = {Proceedings of the Twenty-Sixth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc95 = {Proceedings of the Twenty-Seventh Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc96 = {Proceedings of the Twenty-Eighth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc97 = {Proceedings of the Twenty-Ninth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc98 = {Proceedings of the Thirtieth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc02 = {Proceedings of the Thirty-Fourth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc07 = {Proceedings of the Thirty-Ninth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc08 = {Proceedings of the Fortieth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc09 = {Proceedings of the Forty-First Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc10 = {Proceedings of the Forty-Second Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc11 = {Proceedings of the Forty-Third Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc12 = {Proceedings of the Forty-Fourth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc13 = {Proceedings of the Forty-Fifth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc14 = {Proceedings of the Forty-Sixth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc15 = {Proceedings of the Forty-Seventh Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc16 = {Proceedings of the Forty-Eighth Annual ACM
		  Symposium on the Theory of Computing}}
@string{stoc17 = {Proceedings of the Forty-Ninth Annual ACM
		  Symposium on the Theory of Computing}}

@string{pods02 = {Proceedings of the Twenty-First ACM SIGMOD-SIGACT-SIGART
  Symposium on Principles of Database Systems}}

@string{ml94 =	{Machine Learning: Proceedings of the Eleventh
		 International Conference}}
@string{ml95 =	{Proceedings of the Twelfth International Conference
		 on Machine Learning}}
@string{ml96=	{Machine Learning: Proceedings of the Thirteenth
		 International Conference}}
@string{ml97=	{Machine Learning: Proceedings of the Fourteenth
		 International Conference}}
@string{ml98=	{Machine Learning: Proceedings of the Fifteenth
		 International Conference}}
@string{ml99=	{Machine Learning: Proceedings of the Sixteenth
		 International Conference}}
@string{ml00=	{Machine Learning: Proceedings of the Seventeenth
		 International Conference}}
@string{ml02=	{Machine Learning: Proceedings of the Nineteenth
		 International Conference}}

@string{ecml94=	{Machine Learning: ECML-94}}
@string{aaai97= {Proceedings of the Fourteenth National Conference on
		  Artificial Intelligence}}
@string{aaai98= {Proceedings of the Fifteenth National Conference on
		  Artificial Intelligence}}
@string{aaai99= {Proceedings of the Sixteenth National Conference on
		  Artificial Intelligence}}
@string{aaai15= {Proceedings of the Thirty-Second National Conference on
		  Artificial Intelligence}}

@string{anprob=	{Annals of Probability}}
@string{anappprob={Annals of Applied Probability}}
@string{aoap = {Annals of Applied Probability}}
@string{annstat={The Annals of Statistics}}
@string{aoms = {Annals of Mathematical Statistics}}
@string{aos = {Annals of Statistics}}
@string{aop = {Annals of Probability}}
@string{bams = {Bulletin of the American Mathematical Society}}
@string{cacm =	{Communications of the ACM}}
@string{eurosam79={Symbolic and Algebraic Computation}}
@string{icalp92 = {Automata, Languages and Programming: 19th
		   International Colloquium}}
@string{ijcai85 = {Proceedings of the 9th International Joint
		   Conference on Artificial Intelligence}}
@string{ijcai03 = {Proceedings of the 18th International Joint
                   Conference on Artificial Intelligence}}
@string{infcomp={Information and Computation}}
@string{infctrl={Information and Control}}
@string{ieeeit=	{IEEE Transactions on Information Theory}}
@string{ieeenn=	{IEEE Transactions on Neural Networks}}
@string{ieeesp = {IEEE Transactions on Signal Processing}}
@string{ieeetac= {IEEE Transactions on Automatic Control}}
@string{jacm =	{Journal of the Association for Computing Machinery}}
@string{jair =	{Journal of Artificial Intelligence Research}}
@string{jams =	{Journal of the American Mathematical Society}}
@string{jasa =	{Journal of the American Statistical Association}}
@string{jcss = 	{Journal of Computer and System Sciences}}
@string{jmlr =	{Journal of Machine Learning Research}}
@string{jrss = {Journal of the Royal Statistical Society}}
@string{jrssb = {Journal of the Royal Statistical Society, Series B}}
@string{mathprog = {Mathematical Programming}}
@string{mathprogc = {Mathematical Programming Computation}}
@string{mathproga = {Mathematical Programming, Series A}}
@string{mathprogb = {Mathematical Programming, Series B}}
@string{mathprog = {Mathematical Programming}}
@string{mit =	{Massachusetts Institute of Technology}}
@string{mitlcs=	{MIT Laboratory for Computer Science}}
@string{ml =	{Machine Learning}}
@string{pnas =  {Proceedings of the National Academy of Sciences}}
@string{sicomp ={SIAM Journal on Computing}}
@string{statsci = {Statistical Science}}
@string{symcomp={Journal of Symbolic Computation}}
@string{tams = {Transactions of the American Mathematical Society}}
@string{tcs =	{Theoretical Computer Science}}
@string{ucsccrl={University of California Santa Cruz,
		 Computer Research Laboratory}}

@string{nips5=	{Advances in Neural Information Processing Systems 5}}
@string{nips7=	{Advances in Neural Information Processing Systems 7}}
@string{nips8=	{Advances in Neural Information Processing Systems 8}}
@string{nips10=	{Advances in Neural Information Processing Systems 10}}
@string{nips11=	{Advances in Neural Information Processing Systems 11}}
@string{nips12=	{Advances in Neural Information Processing Systems 12}}
@string{nips13=	{Advances in Neural Information Processing Systems 13}}
@string{nips14=	{Advances in Neural Information Processing Systems 14}}
@string{nips15=	{Advances in Neural Information Processing Systems 15}}
@string{nips16=	{Advances in Neural Information Processing Systems 16}}
@string{nips17=	{Advances in Neural Information Processing Systems 17}}
@string{nips18=	{Advances in Neural Information Processing Systems 18}}
@string{nips19= {Advances in Neural Information Processing Systems 19}}
@string{nips20= {Advances in Neural Information Processing Systems 20}}
@string{nips21= {Advances in Neural Information Processing Systems 21}}
@string{nips22= {Advances in Neural Information Processing Systems 22}}
@string{nips23= {Advances in Neural Information Processing Systems 23}}
@string{nips24= {Advances in Neural Information Processing Systems 24}}
@string{nips25= {Advances in Neural Information Processing Systems 25}}
@string{nips26= {Advances in Neural Information Processing Systems 26}}
@string{nips27= {Advances in Neural Information Processing Systems 27}}
@string{nips28= {Advances in Neural Information Processing Systems 28}}
@string{nips29= {Advances in Neural Information Processing Systems 29}}
@string{nips30= {Advances in Neural Information Processing Systems 30}}

@string{nips5eds={Stephen Jos\'e Hanson and Jack D. Cowan and C. Lee Giles}}

@string{sigir88={Proceedings of the 11th Annual International
		  ACM SIGIR Conference on Research and Development in
		  Information Retrieval}}
@string{sigir94={Proceedings of the 17th Annual International
		  ACM SIGIR Conference on Research and Development in
		  Information Retrieval}}
@string{sigir95={Proceedings of the 18th Annual International
		  ACM SIGIR Conference on Research and Development in
		  Information Retrieval}}
@string{sigir96={Proceedings of the 19th Annual International
		  ACM SIGIR Conference on Research and Development in
		  Information Retrieval}}
@string{sigir97={Proceedings of the 20th Annual International
		  ACM SIGIR Conference on Research and Development in
		  Information Retrieval}}
@string{sigir02={Proceedings of the 25th Annual International
		  ACM SIGIR Conference on Research and Development in
		  Information Retrieval}}

@string{simat={SIAM Journal on Matrix Analysis and Applications}}
@string{siopt={SIAM Journal on Optimization}}
@string{sicon={SIAM Journal on Control and Optimization}}

@string{www09 ={Proceedings of the 18th International Conference on World
               Wide Web, WWW 2009, Madrid, Spain, April 20-24, 2009}}

@string{icml96 = {Proceedings of the Thirteenth International Conference on Machine Learning}}
@string{icml97 = {Proceedings of the Fourteenth International Conference on Machine Learning}}
@string{icml98 = {Proceedings of the Fifteenth International Conference on Machine Learning}}
@string{icml00 = {Proceedings of the Seventeenth International Conference on Machine Learning}}
@string{icml01 = {Proceedings of the Eighteenth International Conference on Machine Learning}}
@string{icml02 = {Proceedings of the Nineteenth International Conference on Machine Learning}}
@string{icml03 = {Proceedings of the Twentieth International Conference on Machine Learning}}
@string{icml04 = {Proceedings of the Twenty-First International Conference on Machine Learning}}
@string{icml05 = {Proceedings of the 22nd International Conference on Machine Learning}}
@string{icml06 = {Proceedings of the 23rd International Conference on Machine Learning}}
@string{icml07 = {Proceedings of the 24th International Conference on Machine Learning}}
@string{icml08 = {Proceedings of the 25th International Conference on Machine Learning}}
@string{icml09 = {Proceedings of the 26th International Conference on Machine Learning}}
@string{icml10 = {Proceedings of the 27th International Conference on Machine Learning}}
@string{icml11 = {Proceedings of the 28th International Conference on Machine Learning}}
@string{icml12 = {Proceedings of the 29th International Conference on Machine Learning}}
@string{icml13 = {Proceedings of the 30th International Conference on Machine Learning}}
@string{icml14 = {Proceedings of the 31st International Conference on Machine Learning}}
@string{icml15 = {Proceedings of the 32nd International Conference on Machine Learning}}
@string{icml16 = {Proceedings of the 33rd International Conference on Machine Learning}}
@string{icml17 = {Proceedings of the 34th International Conference on Machine Learning}}

@string{allerton10 = {The 48th Allerton Conference on Communication, Control,
 and Computing}}
@string{allerton11 = {The 49th Allerton Conference on Communication, Control,
 and Computing}}
@string{allerton12 = {The 50th Allerton Conference on Communication, Control,
 and Computing}}
@string{allerton15 = {The 53rd Allerton Conference on Communication, Control,
 and Computing}}
@string{allerton16 = {The 54th Allerton Conference on Communication, Control,
 and Computing}}
@string{allerton17 = {The 55th Allerton Conference on Communication, Control,
 and Computing}}

@string{cdc2011 = {50th IEEE Conference on Decisions and Control}}
@string{cdc2012 = {51st IEEE Conference on Decisions and Control}}
@string{cdc2013 = {52nd IEEE Conference on Decisions and Control}}
@string{cdc2014 = {53rd IEEE Conference on Decisions and Control}}

@string{focm = {Foundations of Computational Mathematics}}
@string{wiley=	{John Wiley \& Sons}}
@string{cvpr = "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}
@string{iccv = "Proceedings of the International Conference on Computer Vision"}
@string{siopt = {SIAM Journal on Optimization}}
@string{jota = {Journal of Optimization Theory and Applications}}

@phdthesis{Abbeel08,
author = {P. Abbeel},
title = {Apprenticeship Learning and Reinforcement Learning with Application
to Robotic Control},
year = 2008,
school = {Stanford University},
}

@inproceedings{Abe89,
author = 	{Naoki Abe},
title = 	{Polynomial Learnability of Semilinear Sets (Extended
		 Abstract)},
booktitle = 	colt89,
month=		jul,
year = 		{1989}
}

@article{Abelson80,
  title={Lower bounds on information transfer in distributed computations},
  author={Abelson, Harold},
  journal=jacm,
  volume={27},
  number={2},
  pages={384--392},
  year={1980},
}

@inproceedings{AbeMa99,
	author = "Naoki Abe and Hiroshi Mamitsuka",
	title = "Query Learning Strategies using Boosting and Bagging",
	booktitle = ml98,
	year = 1998
}

@inproceedings{AbeTaWa91,
author=		{Naoki Abe and {Jun-ichi} Takeuchi and Manfred~K. Warmuth},
title=		{Polynomial Learnability of Probabilistic Concepts
		 with Respect to the {K}ullback-{L}iebler Divergence},
year=		1991,
month=		aug,
pages=		{277--289},
booktitle=	colt91
}

@article{AbeWa92,
author=		{Naoki Abe and Manfred K. Warmuth},
title=		{On the Computational Complexity of Approximating
		 Distributions by Probabilistic Automata},
journal=	ml,
volume=		9,
number=		{2--3},
year=		1992,
pages=		{205--260}
}

@inproceedings{AbernethyAmDrKe13,
author = {Jacob Abernethy and Kareem Amin and Moez Draief and Michael Kearns},
title = {Large-Scale Bandit Problems and {KWIK} Learning},
year = 2013,
booktitle = icml13,
comment = {Shows how to reduce Multi-armed bandit problems, with
  covariates, to the Li, Littman, and Walsh KWIK (Knows what it knows) setting
  of learning. In particular, assumes we observe
  $f_\theta(x, a) + \varepsilon$, where
  $\varepsilon$ is zero mean noise, and asks a KWIK algorithm to either
  give outputs for each value of $\{f_\theta(x, a), a \in \mc{A}\}$ or
  ask for a label. We must learn $f_\theta$ by selection
  $\theta \in \Theta$, which it is assumed
  KWIK can do given sufficient data. },
}

@InProceedings{AbneyScSi99,
  author = 	 {Steven Abney and Robert E. Schapire and Yoram Singer},
  title = 	 {Boosting applied to tagging and {PP} attachment},
  booktitle = 	 {Proceedings of the Joint SIGDAT Conference on
                  Empirical Methods in Natural Language Processing and
                  Very Large Corpora},
  year =	 1999
}

@book{AbramowitzSt65,
editor = {Milton Abramowitz and Irene Stegun},
title = {Handbook of Mathematical Functions: with Formulas, Graphs,
and Mathematical Tables},
publisher = {Dover},
year = 1965,
}

@article{AbsilKu06,
author = {Pierre-Antoine Absil and Krzysztof Kurdyka},
title = {On the stable equilibrium points of gradient systems},
year = 2006,
journal = {Systems and Control Letters},
volume = 55,
number = 7,
pages = {573--577},
comment = {Shows that a global minimum of a gradient ODE system may be
  locally unstable, even if the gradient is that of a $C^\infy$
  function. This does not occur for analytic functions.}
}

@article{Acerbi02,
  title={Spectral measures of risk: a coherent representation of subjective risk aversion},
  author={Acerbi, Carlo},
  journal={Journal of Banking \& Finance},
  volume=26,
  number=7,
  pages={1505--1518},
  year=2002,
  publisher={Elsevier}
}

@article{Achlioptas03,
author = {Dimitris Achlioptas},
title = {Database-friendly random projections: {J}ohnson-{L}indenstrauss
with binary coins},
year = 2003,
journal = {Journal of Computer and System Sciences},
pages = {671--687},
volume = 66,
}

@article{Adelman-McCarthy08,
   author = {{Adelman-McCarthy}, J.~K. and {Ag{\"u}eros}, M.~A. and {Allam}, S.~S.
 and {Allende Prieto}, C. and {Anderson}, K.~S.~J. and {Anderson}, S.~F. and
{Annis}, J. and {Bahcall}, N.~A. and {Bailer-Jones}, C.~A.~L. and
{Baldry}, I.~K. and {Barentine}, J.~C. and {Bassett}, B.~A. and {Becker},
A.~C. and {Beers}, T.~C. and {Bell}, E.~F. and {Berlind}, A.~A. and
{Bernardi}, M. and {Blanton}, M.~R. and {Bochanski}, J.~J. and {Boroski},
W.~N. and {Brinchmann}, J. and {Brinkmann}, J. and {Brunner}, R.~J. and
{Budav{\'a}ri}, T. and {Carliles}, S. and {Carr}, M.~A. and {Castander},
F.~J. and {Cinabro}, D. and {Cool}, R.~J. and {Covey}, K.~R. and {Csabai},
I. and {Cunha}, C.~E. and {Davenport}, J.~R.~A. and {Dilday}, B. and {Doi},
M. and {Eisenstein}, D.~J. and {Evans}, M.~L. and {Fan}, X. and {Finkbeiner},
D.~P. and {Friedman}, S.~D. and {Frieman}, J.~A. and {Fukugita}, M. and
{G{\"a}nsicke}, B.~T. and {Gates}, E. and {Gillespie}, B. and {Glazebrook},
K. and {Gray}, J. and {Grebel}, E.~K. and {Gunn}, J.~E. and {Gurbani},
V.~K. and {Hall}, P.~B. and {Harding}, P. and {Harvanek}, M. and {Hawley},
S.~L. and {Hayes}, J. and {Heckman}, T.~M. and {Hendry}, J.~S. and {Hindsley},
R.~B. and {Hirata}, C.~M. and {Hogan}, C.~J. and {Hogg}, D.~W. and {Hyde},
J.~B. and {Ichikawa}, S.-i. and {Ivezi{\'c}}, {\v Z}. and {Jester}, S. and
{Johnson}, J.~A. and {Jorgensen}, A.~M. and {Juri{\'c}}, M. and {Kent},
S.~M. and {Kessler}, R. and {Kleinman}, S.~J. and {Knapp}, G.~R. and {Kron},
R.~G. and {Krzesinski}, J. and {Kuropatkin}, N. and {Lamb}, D.~Q. and
{Lampeitl}, H. and {Lebedeva}, S. and {Lee}, Y.~S. and {Leger}, R.~F. and
{L{\'e}pine}, S. and {Lima}, M. and {Lin}, H. and {Long}, D.~C. and {Loomis},
C.~P. and {Loveday}, J. and {Lupton}, R.~H. and {Malanushenko}, O. and
{Malanushenko}, V. and {Mandelbaum}, R. and {Margon}, B. and {Marriner},
J.~P. and {Mart{\'{\i}}nez-Delgado}, D. and {Matsubara}, T. and {McGehee},
P.~M. and {McKay}, T.~A. and {Meiksin}, A. and {Morrison}, H.~L. and {Munn},
J.~A. and {Nakajima}, R. and {Neilsen}, Jr., E.~H. and {Newberg}, H.~J. and
{Nichol}, R.~C. and {Nicinski}, T. and {Nieto-Santisteban}, M. and {Nitta},
A. and {Okamura}, S. and {Owen}, R. and {Oyaizu}, H. and {Padmanabhan}, N. and
{Pan}, K. and {Park}, C. and {Peoples}, Jr., J. and {Pier}, J.~R. and {Pope},
A.~C. and {Purger}, N. and {Raddick}, M.~J. and {Re Fiorentin}, P. and
{Richards}, G.~T. and {Richmond}, M.~W. and {Riess}, A.~G. and {Rix},
H.-W. and {Rockosi}, C.~M. and {Sako}, M. and {Schlegel}, D.~J. and
{Schneider}, D.~P. and {Schreiber}, M.~R. and {Schwope}, A.~D. and {Seljak},
U. and {Sesar}, B. and {Sheldon}, E. and {Shimasaku}, K. and {Sivarani},
T. and {Smith}, J.~A. and {Snedden}, S.~A. and {Steinmetz}, M. and {Strauss},
M.~A. and {SubbaRao}, M. and {Suto}, Y. and {Szalay}, A.~S. and {Szapudi},
I. and {Szkody}, P. and {Tegmark}, M. and {Thakar}, A.~R. and {Tremonti},
C.~A. and {Tucker}, D.~L. and {Uomoto}, A. and {Vanden Berk}, D.~E. and
{Vandenberg}, J. and {Vidrih}, S. and {Vogeley}, M.~S. and {Voges}, W. and
{Vogt}, N.~P. and {Wadadekar}, Y. and {Weinberg}, D.~H. and {West}, A.~A. and
{White}, S.~D.~M. and {Wilhite}, B.~C. and {Yanny}, B. and {Yocum}, D.~R. and
{York}, D.~G. and {Zehavi}, I. and {Zucker}, D.~B.},
    title = {The Sixth Data Release of the Sloan Digital Sky Survey},
  journal = {The Astrophysical Journal Supplement Series},
archivePrefix = {arXiv},
   eprint = {0707.3413},
 keywords = {Atlases, Catalogs, Surveys},
     year = 2008,
   volume = 175,
   number = 2,
    pages = {297--313},
      doi = {10.1086/524984},
   adsurl = {http://adsabs.harvard.edu/abs/2008ApJS..175..297A},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
}

@article{Adelman-McCarthyEtAl08,
author = {J.\ {Adelman-McCarthy \emph{et al.}}},
    title = {The Sixth Data Release of the {Sloan Digital Sky Survey}},
  journal = {The Astrophysical Journal Supplement Series},
archivePrefix = {arXiv},
   eprint = {0707.3413},
 keywords = {Atlases, Catalogs, Surveys},
     year = 2008,
   volume = 175,
   number = 2,
    pages = {297--313},
      doi = {10.1086/524984},
   adsurl = {http://adsabs.harvard.edu/abs/2008ApJS..175..297A},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
}

@article{AdlerBlLi12,
  title={Efficient Monte Carlo for high excursions of Gaussian random fields},
  author={Adler, Robert J and Blanchet, Jose H and Liu, Jingchen and others},
  journal={The Annals of Applied Probability},
  volume=22,
  number=3,
  pages={1167--1214},
  year=2012,
  publisher={Institute of Mathematical Statistics}
}

@article{AdlerPr92
,author=	{Michael Adler and Bhaskar Prasad}
,title=		{On universal currency hedges}
}

@book{AdlerTa09,
  title={Random fields and geometry},
  author={Robert J. Adler and Jonathan E. Taylor},
  volume=115,
  year=2009,
  publisher={Springer}
}

@article{AeronSaZh10,
author = {Shuchin Aeron and Venkatech Saligrama and Manqi Zhao},
title = {Information Theoretic Bounds for Compressed Sensing},
year = 2010,
journal = ieeeit,
volume = 56,
number = 10,
}

@inproceedings{AhaBa97,
author = {D. W. Aha and R. L. Bankert},
title = {Cloud classification using error-correcting output codes},
booktitle = {Artificial Intelligence Applications: Natural Science, Agriculture,
and Environmental Science},
pages = {13-28},
volume = {11},
year = {1997}
}

@article{AhlswedeGa76,
author = {Rudolf Ahlswede and P\'eter G\'acs},
title = {Spreading of sets in product space and hypercontraction of the
{M}arkov operator},
year = 1976,
journal = aop,
volume = 4,
number = 6,
pages = {925--939},
}

@article{AhlswedeWi02,
author = {R. Ahlswede and A. Winter},
title = {Strong converse for identification via quantum channels},
journal = ieeeit,
pages = {569--579},
volume = 48,
NUMBER = 3,
MONTH = "March",
year = 2002
}

@article{Ahookhosh14,
author = {Masoud Ahookhosh},
title = {Optimal subgradient algorithms with application to large-scale
  linear inverse problems},
year = 2014,
journal = {arXiv:1402.7291 [math.OC]},
url = {http://arxiv.org/abs/1402.7291},
}

@article{AhookhoshNe15a,
author = {Masoud Ahookhosh and Arnold Neumaier},
title = {Solving nonsmooth convex optimization with complexity
   ${O}(\varepsilon^{-1/2})$},
year = 2015,
journal = {Optimization Online},
url = {http://www.optimization-online.org/DB\_HTML/2015/05/4900.html},
}

@article{AhookhoshNe15b,
author = {Masoud Ahookhosh and Arnold Neumaier},
title = {An optimal subgradient algorithm with subspace search for large-scale
  bound-constrained convex optimization},
year = 2015,
journal = {arXiv:1501.01497 [math.OC]},
url = {http://arxiv.org/abs/1501.01497},
}

@article{AhujaOr01,
author = {R. Ahuja and J. Orlin},
title = {Inverse Optimization},
year = 2001,
journal = {Operations Research},
volume = 49,
number = 5,
pages = {771--783},
comment = {Discusses perturbation of the data in a linear program so that
the LP has a particular desired vector x_0 as its solution},
}

@inproceedings{AgarwalAlBuHaMa17,
author = {Naman Agarwal and Zeyuan Allen-Zhu and Brian Bullins
  and Elad Hazan and Tengyu Ma},
title = {Finding Approximate Local Minima Faster than Gradient Descent},
year = 2017,
booktitle = stoc17,
}

@article{AgarwalBaDu12,
author = {Alekh Agarwal and Peter L. Bartlett and John Duchi},
title = {Oracle inequalities for computationally adaptive model selection},
year = 2012,
journal = {arXiv:1208.0129 [stat.ML]},
comment = {url = {http://arxiv.org/abs/1208.0129}},
}

@article{AgarwalBaRaWa12,
author = {Alekh Agarwal and Peter L. Bartlett and Pradeep Ravikumar
 and Martin J. Wainwright},
title = {Information-theoretic lower bounds on the oracle complexity of
convex optimization},
year = 2012,
journal = ieeeit,
VOLUME = 58,
NUMBER = 5,
PAGES = "3235--3249",
comment = {
  Shows how to obtain lower bounds for stochastic convex optimization. The
  argument proceeds in two phases: (1) they construct a packing set of the
  d-dimensional hypercube {-1, 1}^d, associating the function
  f_\alpha(x) = ||x - \alpha||_1 for each corner \alpha in the packing set.
  The packing set is chosen so that if x minimizes f_\alpha for one \alpha,
  it does badly on others, which allows us to reduce the optimization problem
  to a testing problem of identifying the corner of the hypercube chosen.

  Then (2) they use a coin-flipping based oracle--i.e. random functions
  are based on biased coins flipped according to the corner of the hypercube
  chosen--and use Fano's inequality to give lower bounds on the amount of
  time it takes to estimate the biases of the coins being flipped. This
  corresponds to the testing problem of identifying the corner, giving a
  lower bound. The amount of bias must be carefully chosen to give the right
  rates. They also have the right (optimal) dimension dependence.
}
}

@inproceedings{AgarwalDeXi10,
author = {Alekh Agarwal and Ofer Dekel and Lin Xiao},
title = {Optimal Algorithms for Online Convex Optimization with Multi-Point
 Bandit Feedback},
year = 2010,
booktitle = colt10,
pages = {28--40},
comment = {Builds on the insight of Flaxman, Kalai, and McMahan to use
a perturbation approach to obtain gradients of Lipschitz continuous functions.
That is, if f_u(x) = E[f(x + uZ)], where Z is distributed in the \ell_2 ball
of radius 1, then the quantity (d/u) E[f(x + uZ')Z'], where Z' is uniform
on the surface of the \ell_2 sphere, is an unbiased gradient estimate for
f_u. The insight here is that though the quantity (d/u) f(x + uZ')Z' could
be quite large, the quantity (d/u)(f(x + uZ')Z' - f(x) Z') is bounded and
small whenever f is Lipschitz continuous. Then the standard online convex
optimization guarantees apply straightforwardly, and everyone is happy.
The paper does not provide lower bounds, and also does not *really* consider
distributions other than uniform on the \ell_2 ball (so in particular, no
geometric considerations or high-dimensional problems are considered).
url = {http://www.eecs.berkeley.edu/~alekh/bandits-colt.pdf},
},
}

@inproceedings{AgarwalDu11,
author = {Alekh Agarwal and John C. Duchi},
title = {Distributed Delayed Stochastic Optimization},
year = 2011,
booktitle = nips24,
}

@article{AgarwalDu13,
author = {Alekh Agarwal and John C. Duchi},
title = {The Generalization Ability of Online Algorithms for Dependent Data},
year = 2013,
journal = ieeeit,
volume = 59,
number = 1,
pages = {573--587},
}

@inproceedings{AgarwalDuBaLe11,
author = {Alekh Agarwal and John C. Duchi and Peter Bartlett and Clement
Levrard},
title = {Oracle Inequalities for Computationally Budgeted Model Selection},
year = 2011,
booktitle = colt11,
}

@article{AgarwalFoHsKaRa13,
author = {Alekh Agarwal and Dean P. Foster and Daniel Hsu and Sham M. Kakade
 and Alexander Rakhlin},
title = {Stochastic convex optimization with bandit feedback},
year = 2013,
journal = siopt,
volume = 23,
number = 1,
pages = {213--240},
comment = {url = {http://arxiv.org/abs/1107.1744}},
}

@article{AgarwalGrHeHaRo05,
author = {S. Agarwal and T. Graepel and R. Herbrich and S. Har-Peled and
          D. Roth},
title = {Generalization bounds for the area under the {ROC} curve},
journal = jmlr,
year = 2005,
pages = {393--425},
volume = 6,
}

@article{AgarwalNeWa12,
author = {Alekh Agarwal and Sahand Negahban and Martin Wainwright},
title = {Fast global convergence of gradient methods for high-dimensional
statistical recovery},
year = 2012,
journal = aos,
volume = 40,
number = 5,
}

@inproceedings{AgarwalNi05,
author = {S. Agarwal and P. Niyogi},
title = {Stability and generalization of bipartite ranking algorithms},
booktitle = colt05,
pages = {32--47},
year = {2005}
}

@article{AgarwalNi09,
author = {S. Agarwal and P. Niyogi},
title = {Generalization bounds for ranking algorithms via algorithmic
  stability},
journal = jmlr,
year = 2009,
volume = 10,
pages = {441--474},
}

@article{Agmon54,
author = "S. Agmon",
title = "The relaxation method for linear inequalities",
journal = "Canadian Journal of Mathematics",
volume = 6,
number = 3,
pages = "382--392",
year = 1954
}

@inproceedings{AgrawalAg01,
author = {Dakshi Agrawal and Charu Aggarwal},
title = {On the design and quantification of privacy preserving data
 mining algorithms},
year = 2001,
booktitle = {Proceedings of the Twentieth ACM Symposium on
 Principles of Database Systems},
pages = {247--255},
comment = {
  Simple idea of perturbing input data with some noise, using mutual
  information as a measure of amount of privacy (differential entropy, really),
  then using EM to estimate the distribution from which data is sampled
  by computing a histogram estimate. A few experiments.
},
}

@inproceedings{AgrawalGo12,
author = {Shipra Agrawal and Navin Goyal},
title = {Analysis of {T}hompson sampling for the multi-armed bandit problem},
year = 2012,
booktitle = colt12,
}

@article{AguehCa11,
author = {Martial Agueh and Guillaume Carlier},
title = {Barycenters in the {W}asserstein space},
year = 2011,
journal = {SIAM Journal on Mathematical Analysis},
volume = 43,
number = 2,
pages = {904--924},
comment = {Studies the problem of existence and uniqueness of the minimizer
 $\sum_{i=1}^p \lambda_i W_2^2(\nu_i, \nu)$, where $W_2$ is defined as
 the Wasserstein metric $W_2(\mu, \nu)
  = \inf_{\gamma} \E_\gamma[||X - Y||_2^2]$, where the infimum over $\gamma$
 is over the set of couplings of $\mu$ and $\nu$. Uses nice analytical
 techniques based on optimal transport to derive the dual of the problem,
 and shows that if one of the measures $\nu_i$ has the property that
 $d-1$ dimensional sets have 0 measure (so, for example, if $\nu_i$
 is absolutely continuous w.r.t. Lebesgue measure) then the minimizer
 is unique. (The minimizers always exist, as do solutions of the dual
 problem.) },
}

@inproceedings{AielloMi91,
author=		{William Aiello and Milena Mihail},
title=		{Learning the {F}ourier Spectrum of Probabilistic
		 Lists and Trees},
year=		1991,
month=		jan,
booktitle=	soda91
}

@article{AilonCh09,
author = {Nir Ailon and Bernard Chazelle},
title = {The fast {J}ohnson-{L}indenstrauss transform and approximate
nearest neighbors},
year = 2009,
journal = {SIAM Journal on Computing},
volume = 39,
number = 1,
pages = {302--322},
}

@inproceedings{AilonMo08,
author = {N. Ailon and M. Mohri},
title = {An efficient reduction of ranking to classification},
year = 2008,
booktitle = colt08,
}

@Article{AizermanBrRo64,
  author = 	 {M. A. Aizerman and E. M. Braverman and L. I. Rozonoer},
  title = 	 {Theoretical foundations of the potential function
                  method in pattern recognition learning},
  journal = 	 {Automation and Remote Control},
  year = 	 1964,
  volume =	 25,
  pages =	 {821-837}
}

@article{Akaike74,
  author = {H. Akaike},
  journal = {IEEE Transactions on Automatic Control},
  number = 6,
  pages = {716--723},
  publisher = {IEEE},
  title = {{A new look at the statistical model identification}},
  volume = 19,
  year = 1974,
  month = {December},
}

@inproceedings{AldousVa90,
author=		{David Aldous and Umesh Vazirani},
title=		{A {M}arkovian Extension of {V}aliant's Learning
		 Model},
booktitle=	focs90,
month=		oct,
year=		1990,
pages=		{392--404}
}

@inproceedings{AleliunasKaLiLoRa79,
author=   	{Aleliunas, Romas and Richard M. Karp and Richard J. Lipton and
          	Laszlo Lov\'asz and Charles Rackoff},
title=    	{Random Walks, Universal Traversal Sequences, and the
		Complexity of Maze Problems},
booktitle= 	focs79,
year=     	1979,
month=    	Oct,
pages=    	{218--223}
}

@article{Algoet92
,author=	{Paul Algoet}
,title=		{Universal schemes for prediction, gambling and
		 portfolio selection}
}

@article{Algoet94
,author=	{Paul H. Algoet}
,title=		{The Strong Law of Large Numbers for Sequential
		 Decisions Under Uncertainty}
,journal=	ieeeit
,volume=	40
,number=	3
,year=		1994
,month=		may
,pages=		{609--633}
}

@article{AlgoetCo88
,author=	{P. Algoet and T. M. Cover}
,title=		{Asymptotic optimality and aymptotic equipartition
		property of log-optimal investment}
,journal=	{Annals of Probability}
,volume=	16
,pages=		{876--898}
,year=		1988
}

@article{AliSi66,
author = {S. M. Ali and S. D. Silvey},
title = {A general class of coefficients of divergence of one distribution
  from another},
year = 1966,
journal = {Journal of the Royal Statistical Society, Series B},
volume = 28,
pages = {131--142},
}

@article{AlizadehGo01,
author = {F. Alizadeh and Donald Goldfarb},
title = {Second-order cone programming},
year = 2001,
journal = {Mathematical Programming, Series B},
volume = 95,
pages = {3--51},
comment = {Surveys results on SOCPs, including a variety of problems
  that may be formulated as SOCPs, some duality results, results on
  algebraic structure of SOCPs, and log barriers},
}

@article{AllenYu15,
  title={Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling},
  author={Allen-Zhu, Zeyuan and Yuan, Yang},
  journal={arXiv preprint arXiv:1512.09103},
  year=2015
}

@inproceedings{AllenHa16,
	title = 	 {Variance Reduction for Faster Non-Convex Optimization},
	author = 	 {Zeyuan Allen-Zhu and Elad Hazan},
	booktitle = icml16,
	year=2016,
}
}

@article{Allen17a,
Author = {Allen-Zhu, Zeyuan},
Journal = {arXiv:1702.00763 [math.OC]},
Title = {Natasha: Faster stochastic non-convex optimization via
   strongly non-convex parameter},
Year = {2017}
}

@article{Allen17b,
  Author = {Allen-Zhu, Zeyuan},
  Journal = {arXiv:1708.08694 [math.OC]},
  Title = {Natasha 2: Faster Non-Convex Optimization than {SGD}},
  Year = {2017},
}


@InProceedings{AllweinScSi00,
        author = "E.~L. Allwein and R.E. Schapire and Y. Singer",
        title = "Reducing multiclass to binary:
                A unifying approach for margin classifiers",
	booktitle = ml00,
        year = 2000
}

@article{AllweinScSi00a,
        author = "E.~L. Allwein and R.E. Schapire and Y. Singer",
        title = "Reducing multiclass to binary:
                A unifying approach for margin classifiers",
	journal = "Journal of Machine Learning Research",
	volume = 1,
	pages = "113--141",
        year = 2000
}

@article{Alon86,
author = {N. Alon},
title = {Eigenvalues and expanders},
year = 1986,
journal = {Combinatorica},
volume = 6,
pages = {83--96},
}

@article{AlonMaSz99,
author = {Noga Alon and Yossi Matias and Mario Szegedy},
title = {The space complexity of approximating the frequency moments},
journal = jcss,
volume = 58,
number = 1,
pages = {137--147},
year = 1999,
}

@book{AlonSp00,
author=         {N.~Alon and J.~H.~Spencer},
title=          {The Probabilistic Method},
publisher=      {Wiley-Interscience},
year=           2000,
edition=        {Second}
}

@InProceedings{AltunTsHo03,
  author = 	 {Y.~Altun and I.~Tsochantaridis and T.~Hofmann},
  title = 	 {Hidden markov support vector machines},
  booktitle =    icml03,
  year = 	 {2003}
}

@book{AmariNa00,
author = {{Shun-ichi} Amari and Hiroshi Nagaoka},
title = {Methods of Information Geometry},
series = {Translations of Mathematical Monographs},
volume = 191,
publisher = {American Mathematical Society},
year = 2000,
}

@InProceedings{AminiGa03,
        author = "M.R. Amini , P. Gallinari",
        title = "Semi-Supervised Learning with an Explicit
                 Label-error Model for Misclassified Data",
	booktitle = ijcai03,
        year = 2003
}

@article{AminiWa09,
author = {Arash Amini and Martin J. Wainwright},
title = {High-dimensional analysis of semidefinite relaxations for
sparse principal components},
year = 2009,
journal = aos,
volume = 37,
number = {5B},
pages = {2877--2921},
}

@Article{AmitGe97,
  author = 	 {Yali Amit and Donald Geman},
  title = 	 {Shape quantization and recognition with randomized trees},
  year = 	 1997
}

@inproceedings{AmitShSi06,
  author = 	 {Y. Amit and S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Online Classification for Complex Problems Using Simultaneous Projections},
  booktitle = nips19,
  year = 	 {2006}
}

@inproceedings{AmitDeSi07,
  author = {Y. Amit and O.~Dekel and Y.~Singer},
  title = {A Boosting Algorithm for Label Covering in Multilabel Problems},
  booktitle =  {aistat07},
  year = 	 {2007}
}

@inproceedings{AmmarSh11,
author = {A.~Ammar and D.~Shah},
title = {Ranking: compare, don't score},
year = 2011,
booktitle = {The 49th Allerton Conference on Communication, Control, and
Computing},
}

@mastersthesis{Amsterdam88,
author=   	{Amsterdam, Jonathan},
title=    	{The Valiant Learning Model:  Extensions and Assessment},
school=   	mit,
year=     	1988,
month=    	Jan
}

@inproceedings{Amsterdam88b,
author = 	{Amsterdam, Jonathan},
title = 	{Some Philosophical Problems with Formal Learning Theory},
booktitle = 	{Proceedings AAAI-88},
year = 		{1988},
pages = 	{580--584},
organization = 	{American Association for Artificial Intelligence},
address = 	{Saint Paul, Minn.},
month = 	{aug},
comment = 	{A philosophical attack on computational learning theory}
}

@article{AnandkumarGe16,
author = {Anandkumar, Anima and Ge, Rong},
title = {Efficient approaches for escaping higher order saddle points
   in non-convex optimization},
Year = {2016},
journal = {arXiv:1602.05908 [math.OC]},
}

@article{AnandkumarGeHsKaTe12,
author = {Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade
  and Matus Telgarsky},
title = {Tensor decompositions for learning latent variable models},
year = 2012,
journal = {arXiv:1210.7559 [cs.LG]},
url = {http://arxiv.org/abs/1210.7559},
}

@article{AnandkumarGeHsKaTe14,
author = {Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade
  and Matus Telgarsky},
title = {Tensor decompositions for learning latent variable models},
year = 2014,
journal = jmlr,
url = {http://arxiv.org/abs/1210.7559},
volume = 15,
pages = {2773--2832}
}

@article{AnantharamGoKaNa13,
author = {Venkat Anantharam and Amin Gohari and Sudeep Kamath
and Chandra Nair},
year = 2013,
title = {On Maximal Correlation, Hypercontractivity, and
  the Data Processing Inequality studied by {E}rkip and
  {C}over},
journal = {arXiv:1304.6133 [cs.IT]},
url = {http://arxiv.org/abs/1304.6133},
}

@article{AndersonHaTi94,
author = {Niall H. Anderson and Peter Hall and D. M. Titterington},
title = {Two-Sample Test Statistics for Measuring Discrepancies Between
 Two Multivariate Probability Density Functions Using Kernel-Based Density
 Estimates},
year = 1994,
journal = {Journal of Multivariate Analysis},
volume = 50,
pages = {41--54},
}

@book{AndersonRo88,
editor=   	{Anderson, James A. and Rosenfeld, Edward},
title=    	{Neurocomputing: Foundations of Research},
publisher=	{MIT Press},
year=     	1988
}

@techreport{Andreae85,
author=   	{Andreae, Peter Merrett},
title=    	{Justified Generalization: Acquiring Procedures from Examples},
institution= 	{MIT Artificial Intelligence Laboratory},
year=     	1985,
month=    	Jan,
number=   	{AI-TR-834},
comment=  	{Ph.D. thesis.  Examines traces of a correct procedure
		(physical motion procedure) to infer loops, etc.}
}

@incollection{AndoniDaImInMi06,
author = {A. Andoni and M. Datar and N. Immorlica and P. Indyk and V. Mirrokni},
title = {Locality-sensitive hashing using stable distributions},
booktitle = {Nearest Neighbor Methods in Learning and Vision: Theory and
Practice},
publisher = {MIT Press},
editor = {Trevor Darrell and Piotr Indyk and Greg Shakhnarovich},
year = 2006,
}

@article{AndoZh05,
author = {Rie Ando and Tong Zhang},
title = {A Framework for Learning Predictive Structures from
Multiple Tasks and Unlabeled Data},
year = 2005,
journal = jmlr,
volume = 6,
pages = {1817--1853},
}

@article{AndrewsPo94,
  title={An introduction to functional central limit theorems for dependent stochastic processes},
  author={Andrews, Donald WK and Pollard, David},
  journal={International Statistical Review/Revue Internationale de Statistique},
  pages={119--132},
  year=1994,
  publisher={JSTOR}
}

@article{Angluin78,
author=   	{Angluin, Dana},
title=    	{On the complexity of minimum inference of regular sets},
journal=  	infctrl,
volume=   	39,
year=     	1978,
pages=    	{337--350}
}

@article{Angluin80,
author=   	{Angluin, Dana},
title=    	{Inductive Inference of Formal Languages from Positive Data},
journal=  	infctrl,
year=     	1980,
month=    	May,
volume=   	45,
number=   	2,
pages=    	{117--135},
comment=  	{Can be done iff each language Li contains a finite subset Ti
		such that Ti is a subset of Li and if i!=j and Ti is a subset
		of Lj, then Lj is not a proper subset of Li; and Ti is
		computable from i.}
}

@article{Angluin80b,
author=   	{Angluin, Dana},
title=    	{Finding patterns common to a set of strings},
journal=  	jcss,
number=		1,
volume=  	21,
month=		aug,
year=     	1980,
pages=    	{46--62}
}

@article{Angluin81,
author=   	{Angluin, Dana},
title=    	{A note on the number of queries needed to identify regular
		languages},
journal=  	infctrl,
volume=   	51,
year=     	1981,
pages=    	{76--87}
}

@article{Angluin82,
author=   	{Angluin, Dana},
title=    	{Inference of Reversible Languages},
journal=  	jacm,
year=     	1982,
volume=  	29,
number=   	3,
month=    	Jul,
pages=    	{741--765}
}

@techreport{Angluin86a,
author=   	{Angluin, Dana},
title=    	{Learning Regular Sets from queries and counter-examples},
institution= 	{Yale University Department of Computer Science},
number=   	{YALEU/DCS/TR-464},
year=     	1986,
month=    	Mar,
comment=  	{Learning regular sets from a teacher who answers membership
		queries, and responds to false conjectures with
		counterexamples.  Based on Gold's approach.  Also learning
		context-free languages from teacher.}
}

@techreport{Angluin86b,
author=   	{Angluin, Dana},
title=    	{Types of queries for concept learning},
institution=  	{Yale University Department of Computer Science},
address=	{New Haven, CT},
number=   	{YALEU/DCS/TR-479},
year=     	1986,
month=    	Jun,
comment=  	{Surveys kinds of learning possible with equivalence,
		membership, subset, superset, and disjointness queries, and
		with random samplying.}
}

@article{Angluin87,
author = 	{Angluin, Dana},
title =		{Learning Regular Sets from Queries and Counterexamples},
journal = 	infcomp,
year = 		1987,
month = 	Nov,
volume = 	75,
pages = 	{87--106},
comment=  {Learning regular sets from a teacher who answers membership queries,
	  and responds to false conjectures with counterexamples.  Based on
	  Gold's approach.  Also learning context-free languages from teacher.}
}

@unpublished{Angluin87b,
author=   	{Angluin, Dana},
title=    	{A Note on Diversity},
month=    	Dec,
year=     	1987,
note=     	{Unpublished}
}

@techreport{Angluin88,
author=   	{Angluin, Dana},
title=    	{Negative results for equivalence queries},
institution=   	{Yale University Department of Computer Science},
number=   	{YALEU/DCS/RR-648},
year=     	1988,
month=   	Sep
}

@article{Angluin88b,
author=		{Angluin, Dana},
title=		{Queries and Concept Learning},
journal=	ml,
volume=		2,
number=		4,
month=		apr,
pages=		{319--342},
year=		1988
}

@article{Angluin90,
author=   	{Angluin, Dana},
title=    	{Negative results for equivalence queries},
journal=	ml,
year=     	1990,
volume=		5,
number=		2,
pages=		{121--150}
}

@inproceedings{AngluinFrPi90,
author=		{Dana Angluin and Michael Frazier and Leonard Pitt},
title=		{Learning Conjunctions of {H}orn Clauses},
booktitle=	focs90,
pages=		{186--192},
month=		oct,
year=		1990
}

@article{AngluinFrPi92,
author=		{Dana Angluin and Michael Frazier and Leonard Pitt},
title=		{Learning Conjunctions of {H}orn Clauses},
journal=	ml,
volume=		9,
number=		{2/3},
pages=		{147--164},
year=		1992
}

@techreport{AngluinGaSm87,
author=		{Angluin, Dana and William I. Gasarch and Carl H. Smith},
title=		{Training Sequences},
institution =	{University of Maryland Institute for Advanced Computer
		Studies},
number=		{UMIACS-TR-87-37},
year=		1987,
month=		Aug,
comment =	{Shows how to learn hard total functions by being taught
		relevant other functions first.}
}

@techreport{AngluinHeKa89,
author= "Angluin, Dana and Lisa Hellerstein and Marek Karpinski",
title= "Learning Read-Once Formulas with Queries",
institution= "University of California Berkeley, Computer Science Division",
number=    "UCB/CSD 89/528",
year=      1989,
month=		aug,
note=		{To appear, {\it Journal of the Association for
		 Computing Machinery}}
}

@article{AngluinHeKa93,
author= "Angluin, Dana and Lisa Hellerstein and Marek Karpinski",
title= "Learning Read-Once Formulas with Queries",
journal=	jacm,
year=		1993,
volume=		40,
number=		1,
pages=		{185--210}
}

@inproceedings{AngluinKh91
,author=	{Dana Angluin and Michael Kharitonov}
,title=		{When won't membership queries help?}
,booktitle=	stoc91
,year=		1991
,month=		may
,pages=		{444--454}
}

@techreport{AngluinLa86,
author=  	{Angluin, Dana and P. D. Laird},
title=    	{Identifying k-CNF formulas from noisy examples},
institution=  	{Yale University Department of Computer Science},
number=   	{YALEU/DCS/TR-478},
year=     	1986,
month=    	Jun,
comment=  	{Error model assumes random error rate < 1/2 in classifications
		provided for examples. Algorithm tries to minimize number of
		examples which are misclassified by chosen hypothesis.}
}

@article{AngluinLa88,
author=   	{Angluin, Dana and Philip Laird},
title=    	{Learning from noisy examples},
journal=  	ml,
year=     	1988,
volume=   	2,
number=   	4,
pages=    	{343--370},
comment=  	{Error model assumes random error rate < 1/2 in classifications
		provided for examples. Algorithm tries to minimize number of
		examples which are misclassified by chosen hypothesis.}
}

@inproceedings{AngluinSl91,
author=		{Dana Angluin and Donna K. Slonim},
title=		{Learning Monotone {DNF} with an Incomplete Membership
		 Oracle},
booktitle=	colt91,
month=		aug,
year=		1991,
pages=		{139--146}
}

@article{AngluinSm83,
author=   	{Angluin, Dana and Carl H. Smith},
title=    	{Inductive Inference: Theory and Methods},
journal=  	{Computing Surveys},
year=     	1983,
month=    	Sep,
volume=   	15,
number=   	3,
pages=    	{237--269},
comment=  	{Comprehensive survey of inductive inference a la Gold [Go67].}
}

@article{AngluinVa79,
author=    	{Angluin, Dana and Leslie G. Valiant},
title=     	{Fast probabilistic algorithms for {H}amiltonian circuits and
		matchings},
journal=   	jcss,
volume=    	18,
number=    	2,
pages=     	{155--193},
year=      	1979,
month=     	Apr,
comment=   	{States nice form of Chernoff bounds.}
}

@book{AngristPi09,
author = {Joshua Angrist and J\"orn-Steffen Pischke},
title = {Mostly Harmless Econometrics: An Empiricist's Companion},
year = 2009,
publisher = {Princeton University Press},
}

@Article{AnlaufBi89,
  author = 	 {J. K. Anlauf and M. Biehl},
  title = 	 {The AdaTron: an adaptive perceptron algorithm},
  journal = 	 {Europhysics Letters},
  year = 	 1989,
  volume =	 10,
  number =	 7,
  month =	 {Dec},
  pages =	 {687--692}
}

@article{Anonymous16,
author = {Authors Anonymous},
title = {Identity Compromising Title},
year = 2016,
journal = {arXiv},
}

@book{AnthonyBa99
,author=	{Martin Anthony and Peter Bartlet}
,title=		{Neural Network Learning: Theoretical Foundations}
,year=		1999
,publisher=	{Cambridge University Press}
}

@article{AnthonySh93,
author = {Martin Anthony and John Shawe-Taylor},
title = {A result of {V}apnik with applications},
year = 1993,
journal = {Discrete Applied Mathematics},
volume = 47,
pages = {207--217},
}

@Article{AntosDeGy99,
  author = 	 {A.~Antos and L.~Devroye and L.~Gyorfi},
  title = 	 {Lower bounds for bayes error estimation},
  journal = 	 {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = 	 {1999},
  volume = 	 {21},
  number = 	 {7}
}

@Article{AntosKo01,
  author = 	 {A.~Antos and I.~Kontoyiannis},
  title = 	 {Convergence properties of functional estimates for discrete
  distributions},
  journal = 	 {Random Struct. Algorithms},
  year = 	 {2001},
  volume = 	 {19},
  number = 	 {3-4}
}

@Article{ApostolicoBe00,
  author = 	 {G. Bejerano and A. Apostolico},
  title = 	 {Optimal amnesic probabilistic automata, or, how to learn and classify proteins in linear time and space},
  journal = 	 {Journal of Computational Biology},
  year = 	 {2000},
  volume = 	 {7},
  number = 	 {3/4},
  pages = 	 {381-393},
}

@misc{ApplePrivacy17,
author = {{Apple Differential Privacy Team}},
title = {Learning with Privacy at Scale},
year = 2017,
note = {Available at
 \url{https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html}},
}

@inproceedings{ApteDaWe94,
	author = {Chidanand {Apt\'e} and Fred Damerau and Sholom M. Weiss},
	booktitle = sigir94,
	pages = {23--30},
	title = {Towards Language Independent Automated Learning of
		Text Categorization Models},
	year = {1994}
}

@article{ArconesYu94,
  title={Central limit theorems for empirical and {U}-processes of
                  stationary mixing sequences},
  author={Arcones, Miguel Angel and Yu, Bin},
  journal={Journal of Theoretical Probability},
  volume=7,
  number=1,
  pages={47--71},
  year=1994,
  publisher={Springer},
  comment={Donsker theorem for beta-mixing (absolutely regular)
                  sequences and VC class of functions. Requires beta_n
                  = n^{-r} with r > 1. For 0 <= r < 1, Yu94 shows a
                  deterioration in the rate.}
}

@article{ArgamonDa99,
	author = "S. Argamon-Engelson and I. Dagan",
	title = "Committee-bsed sample selection for probabilistic classifiers",
	journal = jair,
	volume = 11,
	pages = "335--360",
	year = 1999
}

@article{ArjevaniShSh16,
	author  = {Yossi Arjevani and Shai Shalev-Shwartz and Ohad Shamir},
	title   = {On Lower and Upper Bounds in Smooth and Strongly Convex Optimization},
	journal = jmlr,
	year    = {2016},
	volume  = {17},
	number  = {126},
	pages   = {1-51},
}

@article{ArjevaniShSh17,
	title={Oracle Complexity of Second-Order Methods
	for Smooth Convex Optimization},
	author={Arjevani, Yossi and Shamir, Ohad and Shiff, Ron},
	journal={arXiv:1705.07260 [math.OC]},
	year=2017
}

@article{Arias-CastroCaDa13,
author = {Ery Arias-Castro and Emmanuel Cand\'es and Mark Davenport},
title = {On the Fundamental Limits of Adaptive Sensing},
year = 2013,
journal = ieeeit,
volume = 59,
number = 1,
pages = {472--481},
comment = {For solving sparse version of Ax = b, shows why lower bounds by
  Fano's method break down in the case of adaptive
  measurements, because covariance structures are no longer boundable. Then
  uses Assouad-type argument, after a clever bound on coordinate-total
  variation-distances, to prove nearly tight lower bounds. They are
  off by only log(d) from the usual (non-adaptive) case.
},
}


@inproceedings{ArLiRuSu92,
author=		{Sigal Ar and Richard J. Lipton and Ronitt Rubinfeld
		 and Madhu Sudan},
title=		{Reconstructing Algebraic Functions from Mixed Data},
booktitle=	focs92,
year=		1992,
month=		oct,
pages=		{503--512}
}

@article{Aronszajn50,
title = "Theory of reproducing kernels",
author = "N.~Aronszajn",
journal = "Transactions of the American Mathematical Society",
year = 1950,
month = May,
pages = {337--404},
volume = 68,
number = 3
}

@book{AroraBa09,
author = {Sanjeev Arora and Boaz Barak},
title = {Computational Complexity: A Modern Approach},
year = 2009,
publisher = {Cambridge University Press},
}

@article{AroraHaKa12,
title = {The multiplicative weights update method: a meta algorithm and
applications},
author = {S. Arora and E. Hazan and S. Kale},
year = 2012,
journal = {Theory of Computing},
volume = 8,
number = 1,
pages = {121--164},
}

@book{Arrow51,
author = {Kenneth Joseph Arrow},
title = {Social Choice and Individual Values},
publisher = {Wiley},
address = {New York},
year = {1951},
type = {Book},
}

@article{ArtsteinBaBaNa04,
author = {Shiri Artstein and Keith Ball and Franck Barthe and
Asaf Naor},
title = {Solution of {S}hannon's problem on the monotonicity of entropy},
year = 2004,
journal = jams,
volume = 17,
number = 4,
pages = {975--982},
}

@article{ArtznerDeEbHe99,
  title={Coherent measures of risk},
  author={Artzner, Philippe and Delbaen, Freddy and Eber, Jean-Marc and Heath, David},
  journal={Mathematical Finance},
  volume=9,
  number=3,
  pages={203--228},
  year=1999,
  publisher={Wiley Online Library}
}

@techreport{AslamDe94
,author=	{Javed A. Aslam and Scott E. Decatur}
,title=		{Improved noise-tolerant learning and generalized
		 statistical queries}
}

@unpublished{AslamDe95
,author=	{Javed A. Aslam and Scott E. Decatur}
,title=		{General bounds on statistical query learning and
		 {PAC} learning with noise via hypothesis boosting}
,year=		1995
}

@Article{AslamDe96,
title={On the sample complexity of noise-tolerant learning},
author={Javed A. Aslam and Scott E. Decatur},
pages={189--195},
journal=ipl,
month={26~} # feb,
year=1996,
volume=57,
number=4
}

@book{Asmussen00,
  title={Ruin probabilities},
  author={Asmussen, S{\o}ren},
  volume=2,
  year=2000,
  publisher={World scientific}
}

@book{AsmussenGl07,
author = {Soren Asmussen and Peter W. Glynn},
title = {Stochsatic Simulation: Algorithms and Analysis},
year = 2007,
publisher = {Springer},
}

@article{AsmussenKrRu05,
  title={Heavy tails, importance sampling and cross--entropy},
  author={Asmussen, S{\o}ren and Kroese, Dirk P and Rubinstein, Reuven Y},
  journal={Stochastic Models},
  volume=21,
  number=1,
  pages={57--76},
  year=2005,
  publisher={Taylor \& Francis}
}

@article{Assouad83,
author = {P. Assouad},
year = 1983,
title = {Deux remarques sur l'estimation},
journal = {Comptes Rendus des S\'eances de l'Acad\'emie des Sciences, S\'erie I},
volume = 296,
number = 23,
pages = {1021--1024},
}

@misc{AsuncionNe07,
author = {A. Asuncion and D. J. Newman},
year = 2007,
title = {{UCI} Machine Learning Repository},
url = {http://www.ics.uci.edu/$\sim$mlearn/{MLR}epository.html},
institution = {University of California, Irvine, School of Information and Computer Sciences},
}

@article{AtlasonEpHe04,
  title={Call center staffing with simulation and cutting plane methods},
  author={Atlason, J{\'u}l{\'\i}us and Epelman, Marina A and
                  Henderson, Shane G},
  journal={Annals of Operations Research},
  volume=127,
  number=1,
  pages={333--358},
  year=2004,
  publisher={Springer}
}

@book{AubinCe84,
author = {Jean-Pierre Aubin and Arrigo Cellina},
title = {Differential Inclusions: Set-Valued Maps and Viability Theory},
year = 1984,
publisher = {Springer-Verlag},
}

@techreport{AudibertMuSz07,
title = {Variance estimates and exploration function in multi-armed bandit},
author = {J. Audibert and R. Munos and C. Szepesv\'ari},
moth = apr,
year = 2007,
institution = {CERTIS Research Report},
number = {07-31}}

@inproceedings{AudibertBu09,
author = {Jean-Yves Audibert and S\'ebastien Bubeck},
title = {Minimax policies for adversarial and stochastic bandits},
year = 2009,
booktitle = colt09,
pages = {217--226},
comment = {Shows a regret bound of $\sqrt{nK}$ for stochastic $K$-armed
  bandits, which removes a log factor that was part of results previously.},
}

@inproceedings{AudibertBu10,
author = {Jean-Yves Audibert and S\'ebastien Bubeck},
title = {Regret bounds and minimax policies under partial monitoring},
year = 2010,
booktitle = jmlr,
pages = {2635--2686},
comment = {Shows a regret bound of $\sqrt{nK}$ for stochastic $K$-armed
  bandits, which removes a log factor that was part of results previously.},
}

@article{AuerCeFi02,
 author = {Auer, Peter and Cesa-Bianchi, Nicol\`{o} and Fischer, Paul},
 title = {Finite-time Analysis of the Multiarmed Bandit Problem},
 journal = {Machine Learning},
 volume = {47},
 number = {2-3},
 year = {2002},
 pages = {235--256},
comment = { issn = {0885-6125}} ,
}

@inproceedings{AuerCeFrSc95
,author=	{Peter Auer and Nicol\`o Cesa-Bianchi and Yoav Freund
		 and Robert E. Schapire}
,title=		{Gambling in a rigged casino: The adversarial
		 multi-armed bandit problem}
,pages=		{322-331}
,booktitle=	focs95
,year=		1995
}

@article{AuerCeFrSc02,
 author = {Peter Auer and Nicol'o Cesa-Bianchi and Yoav Freund
        and Robert E. Schapire},
 title = {The Nonstochastic Multiarmed Bandit Problem},
 journal = {SIAM Journal on Computing},
 volume = {32},
 number = {1},
 year = {2002},
 pages = {48--77},
}

@Article{AuerCeGe02,
author={P.~Auer and N.~Cesa-Bianchi and C.~Gentile},
title={Adaptive and self-confident on-line learning algorithms},
journal={Journal of Computer and System Sciences},
volume={64},
number={1},
pages={48--75},
year={2002}
}

@inproceedings{AuerGe00,
author = {P. Auer and C. Gentile},
title = {Adaptive and self-confident online learning algorithms},
year = 2000,
booktitle = colt00,
}

@book{AumannHa92
,editor=	{Robert J. Aumann and Sergiu Hart}
,title=		{Handbook of Game Theory with Economic Applications}
,year=		1992
,publisher=	{North-Holland}
,volume=	1
}

@inproceedings{AzarBrKaLiPh92,
author=		{Yossi Azar and Andrei Z. Broder and Anna R. Karlin and
			Nathan Linial and Steven Phillips},
title=		{Biased Random Walks},
booktitle=	stoc92,
pages=		{1--9},
month=		may,
year=		1992
}

@article{AzouryWa01,
	author = "K. Azoury  and M. Warmuth",
	title = "Relative Loss Bounds for On-Line Density Estimation
		with the Exponential Family of Distributions",
	journal = "Machine Learning",
	volume = 43,
	number = 3,
	pages = "211--246",
	year = 2001
}

@article{Azuma67,
author = "K.~Azuma",
title = "Weighted sums of certain dependent random variables",
journal = "Tohoku Mathematical Journal",
volume = 68,
pages = "357--367",
year = 1967
}

@book{Baayen01,
author = {R. H. Baayen},
title = {Word Frequency Distributions},
publisher = {Kluwer Academic},
year = 2001,
}

@inproceedings{BabcockBaDaMoWi02,
author = {Brian Babcock and Shivnath Babu and Mayur Datar
   and Rajeev Motwani and Jennifer Widom},
title = {Models and Issues in Data Stream Systems},
year = 2002,
booktitle = pods02,
pages = {1--16},
}

@article{Bach08,
author = {F. Bach},
title = {Consistency of trace norm minimization},
year = 2008,
journal = jmlr,
pages = {1019--1048},
}

@inproceedings{BachrachFiSh99,
	author = "R. Bachrach and S. Fine and E. Shamir",
	title = "Query by commitee, linear seperators, and random walks",
	booktitle = eurocolt99,
	year = 1999
}

@article{Baggerly98,
  title={Empirical likelihood as a goodness-of-fit measure},
  author={Baggerly, Keith A},
  journal={Biometrika},
  volume=85,
  number=3,
  pages={535--547},
  year=1998,
  publisher={Biometrika Trust}
}

@article{BahlJeMe83,
author=   	{Bahl, Lalit R. and Frederick Jelinek and Robert L. Mercer},
title=    	{A Maximum Likelihood Approach to Continuous Speech
		Recognition},
journal=  	{IEEE Transactions on Pattern Analysis and Machine
		Intelligence},
year=     	1983,
month=    	Mar,
volume=   	{PAMI-5},
number=   	2,
pages=    	{179--190},
comment=  	{Describes Markov modeling and analysis techniques.}
}

@article{BaiSa96,
  title={Effect of high dimension: by an example of a two sample problem},
  author={Bai, Zhidong D and Saranadasa, Hewa},
  journal={Statistica Sinica},
  volume=6,
  number=2,
  pages={311--329},
  year=1996,
  publisher={C/O DR SW CHENG, MANAG EDITOR DEPT STAT UNIV MANTOBA, WINNIPEG MB R3T 2N2, CANADA}
}

@incollection{Bainbridge77,
author=		{E. S. Bainbridge},
title=		{The fundamental duality of system theory},
editor=		{W. E. Hartnett},
booktitle=	{Systems: Approaches, Theories, Applications},
pages=		{45--61},
publisher=	{Reidel},
year=		1977
}

@article{BalakrishnanWaYu17,
author = {Sivaraman Balakrishnan and Martin James Wainwright and Bin Yu},
year = 2017,
title = {Statistical Guarantees for the {EM} Algorithm:
 From Population to Sample-based Analysis},
journal = aos,
volume = 45,
number = 1,
pages = {77--120},
}

@article{BalanCaEd06,
author = {Radu Balan and Pete Casazza and Dan Edidin},
title = {On signal reconstruction without phase},
year = 2006,
journal = {Applied and Computational Harmonic Analysis},
pages = {345--356},
volume = 20,
comment = {Shows that for generic measurements in $\R$ in phase
 retrieval, $2n - 1$ measurements give injectivity. (Theorem 2.2)}
}

@unpublisheD{BalcanBlFiMa12,
author = {Maria-Florina Balcan and Avrim Blum and Shai Fine and
 Yishay Mansour},
title = {Distributed Learning, Communication Complexity and Privacy},
year = 2012,
url = {http://arxiv.org/abs/1204.3514},
note = {URL \url{http://arxiv.org/abs/1204.3514}},
comment = {
  Studies PAC learning from distributed datasets and attempts to show how
  low communication learning may be possible in certain models.
  Main lower bound result shows that metric entropy (to radius
  \epsilon) bits are required to learn with error \epsilon, while
  \log|hypothesis class| is required for proper learning (otherwise hypotheses
  cannot be distinguished).
  Goes through many PAC learning examples to show how learning is possible.
  Two main examples are boosting and margin-based learners.
  For margin-based learners, uses a cyclic protocol of passing
  a hyperplane/hypothesis vector around that makes similar
  numbers of mistakes to a standard perceptron. When the data is reasonably
  well spread out, this works nicely, since for well-spread data one
  sees most of the statistical juice quickly.
  For boosting, the central algorithm maintains weights over each of its
  workers, performing boosting over them, asking them for samples in
  proportion to their weights.
  Finishes with privacy story (based on statistical query model), which
  increases communication.
},
}

@InProceedings{BalcanBlVe04,
  author = 	 {M-F. Balcan and A. Blum and S. Vempala},
  title = 	 {Kernels as Features: On Kernels, Margins, and Low-dimensional Mappings},
  booktitle = 	 {Proceedings of the 15th International Conference on Algorithmic Learning Theory (ALT '04)},
  year = 	 {2004},
}

@inproceedings{BalcanCoIwWa12,
author = {Maria Florina Balcan and Florin Constantin and Storu Iwata
  and Lei Wang},
title = {Learning Valuation Functions},
year = 2012,
booktitle = colt12,
}

@inproceedings{BalcanHa11,
author = {Maria Florina Balcan and Nicholas J.\ Harvey},
title = {Learning submodular functions},
year = 2011,
booktitle = stoc11,
}

@inproceedings{BalcanLo13,
  title={Active and passive learning of linear separators under
    log-concave distributions},
  author={Balcan, Maria-Florina and Long, Philip M},
  booktitle=colt13,
  pages={288--316},
  year={2013},
}

@article{BaldiSaWh14,
author = {Pierre Baldi and Peter Sadowski and Daniel Whiteson},
year = 2014,
title = {Searching for Exotic Particles in High-Energy Physics with Deep Learning},
journal = {Nature Communications},
volume = 5,
month = {July},
}

@incollection{Ball97,
author = {Keith Ball},
title = {An Elementary Introduction to Modern Convex Geometry},
year = 1997,
booktitle = {Flavors of Geometry},
publisher = {MSRI Publications},
pages = {1--58},
editor = {Silvio Levy},
comment = {volume = {31}},
}

@article{BallardDeHoSc11,
author = {Grey Ballard and James Demmel and Olga Holtz and Oded Schwartz},
title = {Minimizing Communication in Numerical Linear Algebra},
year = 2011,
journal = simat,
volume = 32,
number = 3,
pages = {866--901},
comment = {Uses Loomis-Whitney inequality to show lower bounds on amount
  of communication between levels of processors in a numerical linear
  algebra system. Arguments are (nicely) quite simple; lower bounds apply
  given \emph{any} particular algorithm.},
}

@unpublished{Balsubramani14,
author = {Akshay Balsubramani},
title = {The Utility of Abstaining in Binary Classification},
year = 2014,
note = {Master's thesis survey probably},
comment = {Survey of abstention in binary classification, focusing
  on KWIK (knows what it knows) settings mostly.
  Covers a variety of algorithms for this setting, including the simplest
  "predict if all $h$ agree, otherwise ask". Shows results
  by Avrim Blum and others that show there are natural tradeoffs if
  one is allowed to make mistakes and there is a perfect classifier,
  so you make at most $k$ mistakes and abstain $k |H|^{1/k}$ times.
  (Take $k = \log|H|$ to get both logarithmic.) No notion of confidence,
  but some treatment of models that trade between abstention and risk.
  Evidently the paper of El-Yaniv and Wiener, "Foundations of noise free
  selective classification" and follow-ups "Active Learning via perfect
  selective classification" and "Agnostic selective classification"
  give explicit tradeoffs between abstention and risk.
  Also states a result (ASC paper) that shows how abstentions of an empirical
  minimization-based procedure occur only when a classifier with small
  risk to the optimal $h^*$ exists that disagrees with $h^*$ on a particular
  $x$ (i.e. there is some confusion; see also BeygelzimerHsLaZh10 for the
  active learning analogue of this idea).
},
}

@article{Bandeira15,
  title={Random Laplacian matrices and convex relaxations},
  author={Bandeira, Afonso S},
  journal={Foundations of Computational Mathematics},
  pages={1--35},
  year={2015},
  publisher={Springer}
}

@article{BandeiraCaMiNe14,
author = {Afonso Bandeira and Jameson Cahill and Dustin Mixon and Aaron Nelson},
title = {Saving phase: Injectivity and stability for phase retrieval},
year = 2014,
journal = {Applied and Computational Harmonic Analysis},
volume = 37,
number = 1,
pages = {106--125},
}

@article{Banos68
,author=   	{Alfredo Ba{\~{n}}os}
,title=		{On pseudo-games}
,journal=       {The Annals of Mathematical Statistics}
,volume=        {39}
,number=        {6}
,pages=         {1932--1945}
,year=          {1968}
}


@inproceedings{BakiriDi99,
author = {Ghulum Bakiri Thomas G. Dietterich},
title = {Achieving High-Accuracy Text-to-Speech with Machine Learning},
year = {1999},
booktitle = {Data mining in speech synthesis}
}

@InProceedings{BarHillelHeShWe03,
  author = 	 {A. Bar-Hillel and T. Hertz and N. Shental and D. Weinshall},
  title = 	 {Learning Distance Functions Using Equivalence Relations},
  booktitle = icml03,
  year = 	 {2003},
}

@article{Bar-YossefJaKuSi04,
author = {Ziv Bar-Yossef and T. S. Jayram and Ravi Kumar and D. Sivakumar},
title = {An information statistics approach to data stream and
  communication complexity},
year = 2004,
journal = jcss,
number = 4,
volume = 68,
pages = {702--732},
}

@inproceedings{BarakChDwKaMcTa07,
author = {Boaz Barak and Kamalika Chaudhuri and Cynthia Dwork and
       Satyen Kale and Frank McSherry and Kunal Talwar},
title = {Privacy, Accuracy, and Consistency Too:
   A Holistic Solution to Contingency Table Release},
booktitle = {Proceedings of the 26th ACM
 Symposium on Principles of Database Systems},
year = 2007,
comment = {Show how adding Laplace noise to contingency tables gives privacy.
  Also show that doing a Fourier transform, then adding noise to Fourier
  coefficients, and projecting back to the space of consistent contingency
  tables (though with non-integer counts) gives better bounds in this case.
  Section 1.2.1 gives a nice comparison of differential privacy to other
  definitions of privacy, explaining how differential privacy protects against
  attacks with side information.
  Show that noise error (in terms of \ell_1-norm of a marginal in the table)
  can be taken to
  be of size O(2^k |C| / \epsilon), where k is the number of attributes over
  which marginals are computed in the table, and |C| is the number of
  requested marginals.},
}

@article{BarberDu14a,
author = {Rina Foygel Barber and John C. Duchi},
title = {Privacy and Statistical Risk: Formalisms and Minimax Bounds},
year = 2014,
journal = {arXiv:1412.4451 [math.ST]},
}

@inproceedings{BarberDu14,
author = {Rina Foygel Barber and John C. Duchi},
title = {Privacy: A Few Definitional Aspects and Consequences for Minimax Mean-Squared Error},
booktitle = cdc2014,
year = 2014,
}

@techreport{BarenboimPe15,
author = {Elias Barenboim and Judea Pearl},
title = {Causal inference from big data: Theoretical
  foundations and the data-fusion problem},
year = 2015,
institution = {University of California, Los Angeles},
number = {R-450},
}

@article{BarkaiSeSo94
,author=	{N. Barkai and H. S. Seung and H. Sompolinsky}
,title=		{On-line learning of dichotomies}
}

@unpublished{BarkaiSo??
,author=	{N. Barkai and H. Sompolinsky}
,title=		{Statistical mechanics of maximum-likelihood density
		 estimation}
}

@book{Barndorff-Nielsen78,
author = {Ole Barndorff-Nielsen},
title = {Information and Exponential Families in Statistical Theory},
year = 1978,
publisher = {Wiley},
}

@misc{Barney11,
author = {B.\ Barney},
title = {{POSIX} Threads Programming},
year = 2011,
note = {URL \url{https://computing.llnl.gov/tutorials/pthreads/}, retrieved
    August 30, 2011},
comment = {Well-written tutorial on programming with Pthreads and their methods},
}

@article{Barron86,
author = {Andrew Barron},
title = {Entropy and the Central Limit Theorem},
year = 1986,
journal = aop,
volume = 14,
number = 1,
pages = {336--342},
}

@incollection{Barron91,
author = {Andrew R. Barron},
title = {Complexity regularization with application to artificial neural
networks},
year = 1991,
booktitle = {Nonparametric Functional Estimation and Related Topics},
pages = {561--576},
publisher = {Kluwer Academic},
}

@Article{Barron93,
  author = 	 {Andrew R. Barron},
  title = 	 {Universal approximation bounds for superposition of
                  a sigmoidal function},
  journal = 	 ieeeit,
  year = 	 1993,
  volume =	 39,
  number =       3,
  pages =	 {930--945}
}

@unpublished{Barron97
,author=         {Andrew R. Barron}
,title=          {Information theory in probability, statistics,
                  learning, and neural nets}
}

@article{BarronCo91,
author = {Andrew R. Barron and Thomas M. Cover},
title = {Minimum complexity density estimation},
journal = ieeeit,
volume = 37,
year = 1991,
pages = {1034--1054},
}

@article{BarronBiMa99,
author = {Andrew Barron and Lucien Birg\'e and Pascal Massart},
title = {Risk bounds for model selection via penalization},
journal = {Probability Theory and Related Fields},
volume = 113,
pages = {301--413},
year = 1999,
}

@inproceedings{BartellCoBe94,
	Author = "Brian T. Bartell and Garrison W. Cottrell and Richard K. Belew",
	Title = "Automatic combination of multiple ranked retrieval systems",
	Booktitle=sigir94,
	Year=1994
}

@article{BartholdiToTr89,
author = {J.~J.\ Bartholdi and C.~A.\ Tovey and M.~A.\ Trick},
title = {Voting schemes for which it can be difficult to tell who won
the election},
year = 1989,
journal = {Social Choice and Welfare},
volume = 6,
number = 2,
pages = {157--165},
}

@article{Bartlett52,
author=   	{Bartlett, M. S.},
title=    	{The Statistical Significance of Odd Bits of Information},
journal=  	{Biometrika},
year=     	1952,
volume=   	39,
pages=    	{228--237},
comment=  	{Variation on likelihood measure proposed.}
}

@InProceedings{Bartlett96,
  author =       "Peter L. Bartlett",
title =        "For valid generalization, the size of the weights is
  more important than the size of the network",
  booktitle =    "Advances in Neural Information Processing
		Systems 9",
  year =         "1997",
}

@article{Bartlett98,
author = "P.L.~Bartlett",
title = "The sample complexity of pattern classification with neural
    networks: the size of the weights is more important than the size
    of the network",
journal = ieeeit,
volume = 44,
number= 2,
month= mar,
pages={525-536},
year = 1998
}

@article{Bartlett08,
author = {Peter L. Bartlett},
title = {Fast rates for estimation error and oracle inequalities for
model selection},
year = 2008,
journal = {Econometric Theory},
volume = 24,
number = 2,
pages = {545--552},
}

@article{BartlettBoLu02,
  author = {Peter L. Bartlett and Stephane Boucheron and Gabor Lugosi},
  title = {Model selection and error estimation},
  journal = {Machine Learning},
  url = {http://www.stat.berkeley.edu/~bartlett/papers/bbl-msee.ps.gz},
  volume = {48},
  pages = {85--113},
  year = {2002}
}

@article{BartlettBoMe05,
author = {Peter L. Bartlett and Olivier Bousquet and Shahar Mendelson},
title = "Local {R}ademacher Complexities",
journal = aos,
volume = 33,
number = 4,
pages = "1497--1537",
year = 2005
}

@inproceedings{BartlettDaHaKaRaTe08,
author = {Peter L. Bartlett and Varsha Dani and Thomas P. Hayes and
Sham M. Kakade and Alexander Rakhlin and Ambuj Tewari},
title = {High-Probability Regret Bounds for Bandit Online Linear Optimization},
year = 2008,
booktitle = colt08,
pages = {335--342},
}

@inproceedings{BartlettHaRa07,
author = {P. L. Bartlett and E. Hazan and A. Rakhlin},
title = {Adaptive Online Gradient Descent},
year = 2007,
booktitle = nips20,
}

@Article{BartlettJoMc06,
  author = 	 {P. L. Bartlett and M. I. Jordan and J. McAuliffe},
  title = 	 {Convexity, classification, and risk bounds},
  journal = 	 {Journal of the American Statistical Association},
  year = 	 {2006},
  volume = 	 {101},
  pages = 	 {138--156},
}

@inproceedings{BartlettMe01,
    author = "P. L. Bartlett and S. Mendelson",
    title = "Rademacher and {G}aussian Complexities:
		{R}isk Bounds and Structural Results",
    booktitle = "14th Annual Conference on Computational Learning Theory,
		{COLT} 2001",
    volume = "2111",
    publisher = "Springer, Berlin",
    pages = "224--240",
    year = "2001"
}

@article{BartlettMe02,
    author = "P. L. Bartlett and S. Mendelson",
    title = "Rademacher and {G}aussian Complexities:
		{R}isk Bounds and Structural Results",
    journal = jmlr,
    volume = 3,
    pages = "463--482",
    year = "2002"
}

@article{BartlettMe06,
author = {Peter L. Bartlett and Shahar Mendelson},
title = {Empirical minimization},
journal = {Probability Theory and Related Fields},
volume = 135,
number = 3,
pages = {311--334},
year = 2006,
}

@inproceedings{BartlettTe04,
    author = "P.~Bartlett and A.~Tewari",
    title = "Sparseness vs estimating conditional probabilities: Some asymptotic results",
    booktitle = colt04,
    pages = {564--578},
    year =2004
}

@article{Barzdin70,
author=		{Ya. M. Barzdin'},
title=		{Deciphering of Sequential Networks in the Absence of
		 an Upper Limit on the Number of States},
journal=	{Soviet Physics Doklady},
volume=		15,
number=		2,
month=		aug,
year=		1970,
pages=		{94--97}
}

@article{BarzdinFr72,
author = 	{J. M. Barzdin and R. V. Frievald},
title = 	{On the prediction of general recursive functions},
journal = 	{Soviet Mathematics Doklady},
year = 		{1972},
volume = 	{13},
pages = 	{1224--1228},
comment = 	{Introduces the on-line mistake bound learning model
		 (although in a Gold-style framework)}
}

@book{BasarBe08,
author={Ba{\c{s}}ar, Tamer and Bernhard, Pierre},
title={H-infinity optimal control and related minimax design problems: a dynamic game approach},
year=2008,
publisher={Springer Science \& Business Media}
}

@inproceedings{BassilyGrKaSm13,
author = {Raef Bassily and Adam Groce and Jonathan Katz and Adam Smith},
title = {Coupled-Worlds Privacy: Exploiting Adversarial Uncertainty
   in Statistical Data Privacy},
year = 2013,
booktitle = focs13,
}

@article{BassilySmStUl15,
author = {Raef Bassily and Adam Smith and Thomas Steinke and Jonathan Ullman},
title = {More General Queries and Less Generalization Error in
   Adaptive Data Analysis},
year = 2015,
journal = {arXiv:1503.04843 [cs.LG]},
comment = {Uses a simulation and generalization argument to show that
   any private procedure that can answer queries adaptively on its sample
   also does so on the population.},
}

@inproceedings{BassilyNiSmStStUl16,
author = {Raef Bassily and Kobbi Nissim and Adam Smith and Thomas Steinke and
   Uri Stemmer and and Jonathan Ullman},
year = 2016,
title = {Algorithmic stability for adaptive data analysis},
booktitle = stoc16,
pages = {1046--1059},
}

@article{BauschkeBo97,
    author = "H.H. Bauschke and J.M. Borwein",
    title = "Legendre functions and the method of random Bregman projections",
    journal = "Journal of Convex Analysis",
    volume = "4",
    pages = " 27--67",
    year = 1997
}

@incollection{BauschkeBo00,
author = {Heinz Bauschke and Jonathan Borwein},
title = {Joint and separate convexity of the {B}regman distance},
year = 2000,
booktitle = {Inherently Parallel Algorithms in Feasibility and Optimization
  and their Applications},
editors = {D. Butnariu and Y. Censor and S. Reich},
publisher = {Elsevier},
pages = {23--36},
comment = {Gives equivalent conditions to a Bregman divergence being
  jointly or separately convex in its two arguments. Specifically shows that
  D_f(x, y) is jointly convex if and only if h = f'' satisfies 1/h is concave,
  which can be done via a Schur-complement argument. The same is true
  for x, y vectors, where we see that h = \nabla^2 f must satisfy
  h^{-1} is operator concave.},
}

@article{BauschkeBo96,
    author = "H.H.~Bauschke and J.M.~Borwein",
    title = "On Projection Algorithms for Solving Convex Feasibility Problems",
    journal = "SIAM Review",
    volume = "38",
    number = "3",
    pages = "367--426",
    year = "1996",
    url = "citeseer.nj.nec.com/bauschke96projection.html"
}


@article{BauerKo99,
  author = 	 {Eric Bauer and Ron Kohavi},
  title = 	 {An empirical comparison of voting classification
                  algorithms: Bagging, boosting, and variants},
  journal=       ml,
  year =	 1999,
  volume=        36,
  number=        {1/2},
  pages=         {105-139}
}

@article{Baum72,
author=   	{Baum, Leonard E. and J. A. Eagon},
title=    	{An Inequality with Applications to Statistical Estimation for
  	  	Probabilistic Functions of Markov Processes and to a Model for
		Ecology},
journal=  	bams,
year=     	1967,
volume=   	73,
pages=    	{360--363},
comment=  	{Gives a technique for maximizing a polynomial with
		nonnegative coefficients and homogeneous of degree d.}
}

@unpublished{Baum89b,
author=		{Baum, Eric B.},
title=		{The Perceptron Algorithm Is Fast for
		 Non-malicious Distributions},
year=		1989,
month=		Jul,
note=		{Unpublished manuscript}
}

@article{Baum90,
author=		{Baum, Eric B.},
title=		{On Learning a Union of Half Spaces},
journal=	{Journal of Complexity},
month=		mar,
year=		1990,
volume=		6,
number=		1,
pages=		{67--101}
}

@Article{BaumHa89,
author = 	{Baum, Eric B. and David Haussler},
title = 	{What Size Net Gives Valid Generalization?},
  journal = 	 {Neural Computation},
  year = 	 1989,
  volume =	 1,
  number =	 1,
  pages =	 {151--160}
}

@inproceedings{Baxter95,
author = "J.~Baxter",
title = "Learning Internal Representations",
booktitle = colt95,
year = 1995
}

@article{Baxter00,
author = "J.~Baxter",
title = "A Model of Inductive Bias Learning",
journal = jair,
volume = 12,
pages= "149--198",
year = 2000,
}

@article{Bayer72,
	author = {R.~Bayer},
	title = {Symmetric Binary B-Trees: Data Structures and Maintenance
		Algorithms},
	journal = {Acta Informatica},
	volume = 1,
	pages = {290--306},
	year = 1972
}
@article{BearCoEb87,
author = 	{Mark F. Bear and Leon N. Cooper and Ford F. Ebner},
title = 	{A Physiological Basis for a Theory of Synapse Modification},
journal = 	{Science},
volume = 	237,
year = 		1987,
month = 	{July 3},
pages = 	{42--48},
comment = 	{Proposes that change in weight w_ij from i to j goes as
			 d(w_ij)/dt = \phi(a_i,avg(a_i)) a_j
		 where \phi is negative below (say) avg(a_i)**2, and positive
		 above it.}
}

@inproceedings{BeckerFa12,
author = {Stephen Becker and Jalal Fadili},
title = {A quasi-{N}ewton proximal splitting method},
year = 2012,
booktitle = nips25,
}

@article{BeckTe03,
  author = 	 {A. Beck and M. Teboulle},
  title = 	 {Mirror Descent and Nonlinear Projected Subgradient Methods for Convex Optimization},
  journal = 	 {Operations Research Letters},
  year = 	 {2003},
  volume = 	 {31},
  pages = 	 {167--175}
}

@article{BeckTe09,
author = {Amir Beck and Marc Teboulle},
title = {A fast iterative shrinkage-thresholding algorithm for linear
inverse problems},
year = 2009,
journal = {SIAM Journal of Imaging Sciences},
volume = 2,
number = 1,
pages = {183--202},
}

@article{BeckTe12,
author = {Amir Beck and Marc Teboulle},
title = {Smoothing and first order methods: a unified framework},
year = 2012,
journal = siopt,
pages = {557--580},
volume = 22,
number = 2,
comment = {Uses an optimization technique of balancing a uniform approximation
term with a gradient smoothness term--similar to what we do in the
paper DuchiBaWa12--to show how smoothing gives 1 / \epsilon convergence
rates. Gives a few theorems on inf-convolution and similar smoothing
operators.},
}

@article{BeckTe13,
  title={On the convergence of block coordinate descent type methods},
  author={Beck, Amir and Tetruashvili, Luba},
  journal={SIAM Journal on Optimization},
  volume=23,
  number=4,
  pages={2037--2060},
  year=2013,
  publisher={SIAM}
}

@phdthesis{Beer89,
author = 	{Randall Dean Beer},
title = 	{Intelligence as Adaptive Behavior: An Experiment in
		 Computational Neuroethology},
school = 	{Case Western Reserve University},
year = 		1989,
month = 	Aug,
comment = 	{Simulates a cockroach using specially-designed neural
		circuitry}
}

@inproceedings{BeimelKaNi10,
author = {Amos Beimel and Shiva Prasad Kasiviswanathan and Kobbi Nissim},
title = {Bounds on the Sample Complexity for Private Learning and Private
  Data Release},
year = 2010,
booktitle = {Proceedings of the 7th Theory of Cryptography Conference},
pages = {437--454},
comment = {Shows a lower bound that scales as something like the VC dimension
  for learning with privacy, but only in the PAC model. Also, does not handle
  cases with learners that do not attain 100\% accuracy, and main lower bound
  does not depend on accuracy to which problem is solved in a clear way.},
}

@article{BeimelBrKaNi13,
author = {Amos Beimel and Hai Brenner and Shiva Prasad Kasiviswanathan
  and Kobbi Nissim},
title = {Bounds on the Sample Complexity for Private Learning and Private
  Data Release},
journal = ml,
year = 2013,
pages = {To appear},
comment = {
  Shows lower bounds in PAC model for learning with privacy. Has one argument
  (Lemma 3.9) for learning a class that shows learning error must scale as
  $\log|H| / (n \alpha)$, where $H$ is the hypothesis class. The technique
  for proving this is similar to the lower bounds for estimating a particular
  sample. They construct distributions for which samples are likely of the
  form $(x, x, x, x, 0, \ldots, 0)$, for some specified number of $x$
  observations. Then they show any private estimator is likely to output
  a nearby parameter that would be that based on $(x', x', x', 0, \ldots, 0)$.
  By careful scaling of the number of special $x$ and $x'$ observations,
  the right rates are attainable.
  They specifically focus on learning classes like "point" and "interval,"
  which are specially constructed concept classes to show their results.
},
url = {http://www.cse.psu.edu/~kasivisw/lower.pdf},
}

@inproceedings{BeimelNiOm08,
author = {Amos Beimel and Kobbi Nissim and Eran Omri},
title = {Distributed private data analysis: Simultaneously solving
  how and what},
year = 2008,
booktitle = {Advances in Cryptology},
pages = {451--468},
series = {Lecture Notes in Computer Science},
volume = 5157,
publisher = {Springer},
comment = {Considers some distributed differential privacy ideas (something
  about combining secure function evaluation with differential privacy).
  Didn't really understand the distributed part. Shows a lower bound on
  computing the sum \sum_{i=1}^n x_i in the local privacy model, when we assume
  that x_i \in \{0, 1\}. The lower bound is of order \sqrt{n} / (\epsilon l)
  for an l-round protocol, where \epsilon is differential privacy level.
  Proof technique is by showing that under local privacy, with high probability
  deviation is of order \sqrt{n}, so the all-0s vector is indistinguishable
  (with constant probability) from a vector with P(x_i = 1) = 1/\sqrt{n}. A
  bit of a weakness in that doesn't really tackle statistical problem
  underlying the setting and doing more rounds reduces lower bound. (Don't
  quite get that one.)},
}

@article{BeirlantVyTe96,
  title={Tail index estimation, {P}areto quantile plots regression diagnostics},
  author={Beirlant, Jan and Vynckier, Petra and Teugels, Jozef L},
  journal=jasa,
  volume=91,
  number=436,
  pages={1659--1667},
  year=1996,
  publisher={Taylor \& Francis Group}
}

@book{Bellman61,
author =        {R.~Bellman},
title =         {Adaptive Control Processes: A Guided Tour},
publisher =     {Princeton University Press},
year =          {1961}
}

@article{Ben-ArousBoMo05,
  title={Limit theorems for sums of random exponentials},
  author={Ben Arous, G{\'e}rard and Bogachev, Leonid V and Molchanov, Stanislav A},
  journal={Probability theory and related fields},
  volume=132,
  number=4,
  pages={579--612},
  year=2005,
  publisher={Springer}
}

@article{Ben-DavidBlCrPeVa10,
title = {A theory of learning from different domains},
author  = {Shai Ben-David and John Blitzer and Koby Crammer and 
    Alex Kulesza and Fernando Pereira and Jennifer Vaughan},
year  = 2010,
journal = {Machine Learning},
pages = {151--175},
volume  = {79}
}

@inproceedings{Ben-DavidChGoLu89,
author=   	{Shai Ben-David and Benny Chor and Oded Goldreich and
		Michael Luby},
title=    	{On the Theory of Average Case Complexity},
booktitle=      stoc89,
month=          May,
year = 		1989,
pages=		{204--216}
}

@article{Ben-DavidChGoLu92,
author=   	{Shai Ben-David and Benny Chor and Oded Goldreich and
		Michael Luby},
title=    	{On the Theory of Average Case Complexity},
journal=	jcss,
volume=		44,
number=		2,
year=		1992,
pages=		{193--219}
}

@inproceedings{Ben-DavidSc03,
author=   	"S.~Ben-David and R.~Schuller",
title=    	"Exploiting Task Relatedness for Multiple Task Learning",
booktitle =     colt03,
year=		2003
}

@article{Ben-TalBoNe06,
  title={Extending scope of robust optimization: Comprehensive robust counterparts of uncertain problems},
  author={Ben-Tal, Aharon and Boyd, Stephen and Nemirovski, Arkadi},
  journal={Mathematical Programming},
  volume=107,
  number={1-2},
  pages={63--89},
  year=2006,
  publisher={Springer}
}

@article{Ben-TalHaKoMa15,
  title={Oracle-based robust optimization via online learning},
  author={Ben-Tal, Aharon and Hazan, Elad and Koren, Tomer and
  Mannor, Shie},
  journal={Operations Research},
  volume=63,
  number=3,
  pages={628--638},
  year=2015,
  publisher={INFORMS},
  comment={Solution methods for RO based on oracles for the original
                  problem. Uses Online Gradient Descent and Follow the
                  Perturbed Leader type algorithms on the uncertainty
                  parameter while solving the problem on the updated
                  value. They focus on robust feasibility problems
                  which is more general than RO. This is in contrast
                  to Nemirovski et al.'s mirror descent-ascent
                  algorithm for the saddle point where they use an
                  inexact oracle (SGD) to update the original problem's
                  solution.}
}

@article{Ben-TalMaNe01,
author = {Aharon Ben-Tal and T. Margalit and Arkadi Nemirovski},
title = {The ordered subsets mirror descent optimization method with
    applications to tomography},
journal = siopt,
year = 2001,
pages = {79--108},
volume = 12,
}

@article{Ben-TalHeWaMeRe13,
author = {Aharon Ben-Tal and Dick den Hertog and Anja De Waegenaere
 and Bertrand Melenberg and Gijs Rennen},
title = {Robust Solutions of Optimization Problems Affected by
  Uncertain Probabilities},
year = 2013,
volume = 59,
number = 2,
pages = {341--357},
journal = {Management Science},
}

@book{Ben-TalGhNe09,
author = {Aharon Ben-Tal and Laurent El Ghaoui and Arkadi Nemirovski},
title = {Robust Optimization},
year = 2009,
publisher = {Princeton University Press},
}

@book{Ben-TalNe01,
author = {A. Ben-Tal and A. Nemirovski},
title = {Lectures on Modern Convex Optimization},
publisher = {SIAM},
year = {2001},
}

@techreport{Ben-TalRo94
,author=	{Aharon Ben-Tal and Gil Roth}
,title=		{A truncated log barrier algorithm for large scale
		 convex programming and minmax problems:
		 implementation and computational results}
,year=		1994
}

@incollection{Ben-TalTe89,
author = {A. Ben-Tal and M. Teboulle},
title = {A smoothing technique for nondifferentiable optimization problems},
year = 1989,
booktitle = {Optimization},
series = {Lecture Notes in Mathematics 1405},
pages = {1--11},
publisher = {Springer Verlag},
}

@article{BenaimHoSo05,
author = {Michel Bena\"{i}m and Josef Hofbauer and Sylvan Sorin},
title = {Stochastic Approximations and Differential Inclusions},
year = 2005,
journal = sicon,
pages = {328--348},
number = 1,
volume = 44,
}

@article{BenderWi85,
author=		{Edward A. Bender and Herbert S.Wilf},
title=		{A theoretical analysis of backtracking in the graph
		coloring problem},
journal=	{Journal of Algorithms},
volume=		6,
number=		2,
month=		jun,
year=		1985,
pages=		{275--282}
}

@unpublished{Benedek88,
author=   	{Benedek, Gyora M.},
title=    	{Ph.D. dissertation, in preparation},
year=     	1988,
note = 	  	{(To appear.)}
}

@inproceedings{BenedekIt88,
author=   	{Benedek, Gyora M. and Alon Itai},
title=    	{Nonuniform Learnability},
booktitle=	{ICALP},
month=    	Jul,
year=     	1988,
pages=    	{82--92}
}

@inproceedings{BenedekIt88a,
author = 	{Gyora M. Benedek and Alon Itai},
title =	        {Learnability by Fixed Distributions},
booktitle = 	colt88,
year = 		{1988},
month = 	aug,
pages = 	{80--90},
}

@article{BenedekIt91,
author = 	{Gyora M. Benedek and Alon Itai},
title =	        {Learnability with Respect to Fixed Distributions},
journal=	tcs,
year = 		1991,
volume=		86,
number=		2,
month = 	sep,
pages = 	{377--389}
}

@article{BenezitDiThVe08,
author = {F. B\'en\'ezit and A. Dimakis and P. Thiran and M. Vetterli},
title = {Order-optimal consensus through randomized path averaging},
year = 2010,
journal = {IEEE Transactions on Information Theory},
volume = 56,
number = 10,
pages = {5150--5167},
}

@article{BenjaminiHo95,
author = {Yoav Benjamini and Yosef Hochberg},
title = {Controlling the false discovery rate: a practical and powerful
   approach to multiple testing},
year = 1995,
journal = jrssb,
volume = 57,
number = 1,
pages = {289--300},
}

@inproceedings{BengioMaKe05,
author =        {S. Bengio and J. Mar\'ethoz and M. Keller},
title =         {The expected performance curve},
booktitle =     icml05,
year =          {2005}
}

@article{Bennett62,
author = {G. Bennett},
title = {Probability inequalities for the sum of independent random variables},
journal = {Journal of the American Statistical Association},
volume = 57,
number = 297,
month = mar,
year = 1962,
pages = {33--45}}

@techreport{Bennett92
,author=	{Kristin P. Bennett}
,title=		{Decision tree construction via linear programming}
}


@techreport{Bennett92
,author=	{Kristin P. Bennett}
,title=		{Decision tree construction via linear programming}
}

@incollection{Bennett99,
    author = {K.P.~Bennett},
    title = {Combining support vector and mathematical programming methods for classification},
    booktitle = {Advances in kernel methods: support vector learning},
    year = {1999},
    pages = {307--326},
    publisher = {MIT Press},
}

@book{BennettSh88,
author = {C.~Bennett and R.~Sharpley},
title = {Interpolation of Operators},
year = {1998},
publisher = {Academic Press}
}

@inproceedings{BenorTi88,
author=		{Michael Ben-Or and Prasoon Tiwari},
title=		{A deterministic algorithm for sparse multivariate
		 polynomial interpolation},
booktitle=	stoc88,
year=		1988,
month=		may,
pages=		{301--309}
}

@article{BentkusGo96,
  title={The Berry-Esseen bound for Student's statistic},
  author={Bentkus, Vidmantas and Gotze, F},
  journal={The Annals of Probability},
  pages={491--503},
  year=1996,
  publisher={JSTOR}
}

@article{Bentkus03,
  title={On the dependence of the Berry--Esseen bound on dimension},
  author={Bentkus, Vidmantas},
  journal={Journal of Statistical Planning and Inference},
  volume=113,
  number=2,
  pages={385--402},
  year=2003,
  publisher={Elsevier}
}

@article{Berbee79,
  title={Random walks with stationary increments and renewal theory},
  author={Berbee, Henry CP},
  journal={MC Tracts},
  volume=112,
  pages={1--223},
  year=1979,
  publisher={Centrum Voor Wiskunde en Informatica},
  comment={Coupling argument for beta-mixing (absolutely regular)
                  sequences. An independent block can be generated on
                  which typical iid arguments can be applied.}
}

@article{BerendTa10,
author = {Daniel Berend and Tamir Tassa},
year = 2010,
title = {Improved bounds on {B}ell numbers and on moments of sums
  of random variables},
journal = {Probability and Mathematical Statistics},
volume = 30,
number = 2,
pages = {185--205},
}

@book{Berger85,
author = {James O. Berger},
title = {Statistical Decision Theory and Bayesian Analysis},
edition = {2nd},
year = 1985,
publisher = {Springer},
}

@inproceedings{Berger99,
	author = "A. Berger",
	title = "Error-correcting output coding for text classification",
	booktitle = "{IJCAI'99}: Workshop on machine learning for
		information filtering",
	year = 1999
}

@article{Berger06,
author = {James O. Berger},
title = {The Case for Objective {B}ayesian Analysis},
year = 2006,
journal = {Bayesian Analysis},
number = 3,
volume = 1,
pages = {385--402},
}

@misc{BerkeleyPayroll14,
author = {University of California},
title = {2010 Annual Report on Employee Compensation},
year = 2014,
url = {http://compensation.universityofcalifornia.edu/payroll2014/},
}

@article{BerlekampMcTi78,
author=		{E. Berlekamp and R. McEliece and H. van Tilborg},
title=		{On the inherent intractability of certain coding
		 problems},
journal=	{IEEE Transactions on Information Theory},
volume=		24,
year=		1978
}

@techreport{BerlinerGo84,
author=   	{Berliner, Hans and Gordon Goetsch},
title=    	{A Quantitative Study of Search Methods and the Effect of
	  	Constraint Satisfaction},
institution= 	{CMU Computer Science Department},
year=     	1984,
month=    	Jul,
number=   	{CMU-CS-84-147},
comment=  	{Empirical comparative study of search heuristics for
		Superpuzz, a card solitaire game.}
}

@book{BerlinetAg04,
author = {Alain Berlinet and Christine Thomas-Agnan},
title = {Reproducing Kernel Hilbert Spaces in Probability and Statistics},
year = 2004,
publisher = {Kluwer Academic Publishers},
}

@book{BermanPl79,
author=		{Abraham Berman and Robert J. Plemmons},
title=		{Nonnegative Matrices in the Mathematical Sciences},
publisher=	{Academic Press},
year=		1979
}

@incollection{Bernardo05,
author = {Jos\'e M. Bernardo},
title = {Reference Analysis},
booktitle = {Bayesian Thinking, Modeling and Computation},
year = 2005,
pages = {17--90},
publisher = {Elsevier},
series = {Handbook of Statistics},
chapter = 2,
volume = 25,
editor = {Dipak Day and C. R. Rao},
}

@article{Bernstein24,
author = {S.~N. Bernstein},
title = {On a modification of Chebyshev’s inequality and of the error formula of Laplace},
journal = {Annals Science Institute Sav. Ukraine},
volume = {Sect. Math. 1},
year = 1924}

@inproceedings{BernsteinVa93
,author=	{Ethan Bernstein and Umesh Vazirani}
,title=		{Quantum complexity theory}
,booktitle=	stoc93
,year=		1993
,month=		may
,pages=		{11--20}
}

@book{Bernstein46,
author = {S. Bernstein},
title = {The Theory of Probabilities},
publisher= {Gastehizdat Publishing House, Moscow},
year = {1946}
}

@article{Bertail06,
title={Empirical likelihood in some semiparametric models},
author={Bertail, Patrice},
journal={Bernoulli},
volume=12,
number=2,
pages={299--331},
year=2006,
publisher={Bernoulli Society for Mathematical Statistics and Probability},
comment = {Considers Hadamard differentiable estimating equations in the
 empirical likelihood setting. Extensions to semiparametric models are given.
States the results in a  modern language and shows that the confidence
 region of measures around the empirical distribution are Donsker's uniformly
 within the set. The proof for Hadamard differentiability is incorrect as it
 only shows convergence in Hausdorff distance.},
}

@incollection{BertailGaHa14,
  title={Empirical $\varphi^*$-Divergence Minimizers for
     Hadamard Differentiable Functionals},
  author={Bertail, Patrice and Gautherat, Emmanuelle and Harari-Kermadec, Hugo},
  booktitle={Topics in Nonparametric Statistics},
  pages={21--32},
  year=2014,
  publisher={Springer},
  comment={Considers calibration of unnormalized empirical
    likelihood with general f-divergences for Hadamard differentiable
    functionals. Proof is incorrect as it only shows convergence in Hausdorff
    distance.}
}

@article{BertailHaRa07,
  title={$\varphi$-Divergence empirique et vraisemblance empirique generalisee},
  author={Bertail, Patrice and Harari-Kermadec, Hugo and Ravaille, Denis},
  journal={Annales d'Economie et de Statistique},
  pages={131--157},
  year=2007,
  publisher={JSTOR},
  comment={Shows calibration of unnormalized empirical
  likelihood with general f-divergencs. Proof is easier
  in this case compared to that of normalized probabilities
  as the dual variable "eta" for the normalization constraint disappears.}
}

@article{BerthetRi13,
author = {Quentin Berthet and Philippe Rigollet},
title = {Optimal detection of sparse principal components in high dimension},
year = 2013,
journal = aos,
volume = 41,
number = 1,
pages = {1780--1815},
comment = {Considers polynomial time type separations for testing whether
  a series of samples comes from a distribution N(0, I) or
  N(0, I + \theta vv^T), where v is k-sparse and has \ell_2-norm 1. Shows
  that the minimax rate of error for testing (or signal size \theta) scales
  roughly as \sqrt{k \log (p/k) / n}, while no SDP relaxation can have
  identification when the SNR is less than \sqrt{k^2 \log(p/k) / n} so
  long as the planted clique problem is hard. Has elegant simple
  proofs of the success of the SDP-based and enumeration-based tests,
  and lower bound is based on \chi^2 divergences (a la Tsybakov).
  Polynomial separation in this paper appears to apply only to SDP
  relaxation in some strange way.
  url = {http://arxiv.org/abs/1202.5070}},
}

@inproceedings{BerthetRi13_colt,
author = {Quentin Berthet and Philippe Rigollet},
title = {Complexity theoretic lower bounds for sparse principal component
detection},
booktitle = colt13,
year = 2013,
}

@article{Bertsekas73,
author = {D. P. Bertsekas},
title = {Stochastic optimization problems with nondifferentiable cost
 functionals},
year = 1973,
journal = {Journal of Optimization Theory and Applications},
volume = 12,
number = 2,
pages = {218--231}
}

@article{Bertsekas77,
author = {Dmitri P. Bertsekas},
title = {Approximation Procedures Based on the Method of Multipliers},
year = 1977,
journal = jota,
volume = 23,
number = 4,
pages = {487--510},
comment = {Studies minimization problems with objectives of the composite
  form $f(x) = h(c(x))$, where $h$ is convex and $c$ is smooth. Implicitly
  seems to be assuming that $c$ is actually linear. Develops a method
  of multipliers methods that roughly proceeds as follows: introducing
  $u \in \R^m$, solve $\min. h(c(x) + u) + y^T u + \half \ltwo{u}^2$, where
  $y$ is a dual multiplier being updated to force $u = 0$. This smooths
  $h$ and makes the problem easier (it is the natural smoothing of $h$).
  See also the paper Polyak79. },
}

@book{Bertsekas99,
author = {D.P. Bertsekas},
title = {Nonlinear Programming},
publisher = {Athena Scientific},
year = {1999}
}

@book{Bertsekas09,
author = {Dimitri P. Bertsekas},
title = {Convex Optimization Theory},
year = 2009,
publisher = {Athena Scientific},
}

@article{Bertsekas11,
author = {Dimitri P. Bertsekas},
title = {Incremental proximal methods for large scale convex optimization},
year = 2011,
journal = mathprogb,
volume = 129,
pages = {163--195},
}

@book{BertsekasTs89,
author = {Bertsekas, D. P. and Tsitsiklis, J. N.},
 title = {Parallel and Distributed Computation: Numerical Methods},
 year = {1989},
 publisher = {Prentice-Hall, Inc.},
}

@article{BertsekasTs00,
author = {Dmitri P. Bertsekas and John N. Tsitsiklis},
title = {Gradient convergence in gradient methods with errors},
year = 2000,
pages = {627--642},
volume = 10,
number = 3,
journal = siopt,
}

@article{BertsimasBr09,
  title={Constructing uncertainty sets for robust linear optimization},
  author={Bertsimas, Dimitris and Brown, David B},
  journal={Operations research},
  volume=57,
  number=6,
  pages={1483--1495},
  year=2009,
  publisher={INFORMS}
}

@article{BertsimasBrCa11,
  title={Theory and applications of robust optimization},
  author={Bertsimas, Dimitris and Brown, David and Caramanis, Constantine},
  journal={SIAM Review},
  volume=53,
  number=3,
  pages={464--501},
  year=2011,
  publisher={SIAM}
}

@article{BertsimasGuKa13,
  title={Data-driven robust optimization},
  author={Bertsimas, Dimitris and Gupta, Vishal and Kallus, Nathan},
  journal={arXiv:1401.0212 [math.OC]},
  url = {http://arxiv.org/abs/1401.0212},
  year=2013
}

@article{BertsimasGuKa14,
  title={Robust {SAA}},
  author={Bertsimas, Dimitris and Gupta, Vishal and Kallus, Nathan},
  journal={arXiv:1408.4445 [math.OC]},
  url = {http://arxiv.org/abs/1408.4445},
  year=2014,
}

@inproceedings{BeygelzimerHsLaZh10,
author = {Alina Beygelzimer and Daniel Hsu and John Langford and Tong Zhang},
title = {Agnostic Active Learning Without Constraints},
year = 2010,
booktitle = nips23,
comment = {
  Studies active learning, where we can query labels according to a particular
  probability, and proves generalization guarantees for finite hypothesis classes.
  In particular, shows that a procedure that, roughly, chooses to *not* query
  an example if choosing hypotheses that differ on its value lead to large
  changes in empirical risk--that is, minimizing empirical risk (ignoring recent
  example $X_k$) to get $h_k$, then choosing some $h_k'$ that disagrees with
  $h_k(X_k)$ does not increase the empirical risk means that we are very
  uncertain about $X_k$ and so should ask for a label; if the risk increases,
  then the set of hypotheses that agree with $h_k(X_k)$ should (roughly) be
  the true minimizers. Shows that the probability of sampling an example
  $i$ is $P_i \ge 1/2$ only when hypotheses $h_n$ disagree with $h^*$. Uses an
  inductive argument with martingales.
  To show that not too many labels are queried requires controlling the
  probablity of data $x$ for which there exist $h$ that are close to $h^*$
  in general but for which $h(x) \neq h^*(x)$. If most data satisfy this,
  then it is hard to find $h^*$ without querying many labels.
},
}

@book{Bhatia97,
author = {Rajendra Bhatia},
year = 1997,
title = {Matrix Analysis},
publisher = {Springer},
}

@book{Bhatia07,
author = {Rajendra Bhatia},
year = 2007,
title = {Positive Definite Matrices},
publisher = {Princeton University Press},
series = {Princeton Series in Applied Mathematics},
}

@article{BhattacharyaGh88,
  title={On moment conditions for valid formal Edgeworth expansions},
  author={Bhattacharya, Rabi N and Ghosh, JK},
  journal={Journal of multivariate analysis},
  volume=27,
  number=1,
  pages={68--79},
  year=1988,
  publisher={Elsevier}
}

@inproceedings{BhojanapalliNeSr16,
  title={Global optimality of local search for low rank matrix
                  recovery}, 
  author={Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro,
                  Nati}, 
  booktitle={Advances in Neural Information Processing Systems},
  pages={3873--3881},
  year={2016}
}

@article{Bianchi16,
author = {Pascal Bianchi},
title = {Ergodic convergence of a stochastic proximal point algorithm},
year = 2016,
journal = siopt,
volume = 26,
number = 4,
pages = {2235--2260},
}

@article{BianconciniLiMoSc15,
  title={On the use of iterative methods in cubic regularization for unconstrained optimization},
  author={Bianconcini, Tommaso and Liuzzi, Giampaolo and Morini, Benedetta and Sciandrone, Marco},
  journal={Computational Optimization and Applications},
  volume={60},
  number={1},
  pages={35--57},
  year={2015},
  publisher={Springer}
}

@inproceedings{BiBe03,
author=	        {Jinbo Bi and Kristin P. Bennett},
title=		{A Geometric Approach to Support Vector Regression},
booktitle=	{Neurocomputing, special issue on support vector machines},
volume=         55,
pages=          {79-108},
month=          sep,
year=		2003
}

@book{BickelKlRiWe98,
author = {Peter Bickel and C. A. J. Klaassen and Yaacov Ritov and Jon Wellner},
title = {Efficient and Adaptive Estimation for Semiparametric Models},
year = 1998,
publisher = {Springer Verlag},
}

@article{BickelLe08,
author = {Peter Bickel and Elizaveta Levina},
year = 2008,
title = {Covariance regularization by thresholding},
journal = aos,
volume = 36,
number = 6,
pages = {2577--2604},
}

@article{BickelRiTs09,
author = {Peter Bickel and Yaacov Ritov and Alexandre Tsybakov},
title = {Simultaneous analysis of {L}asso and {D}antzig selector},
journal = aos,
year = 2009,
volume = 37,
number = 4,
pages = {1705--1732},
}


@ARTICLE{Birge05,
AUTHOR = "Lucien Birg\'{e}",
TITLE = "A new lower bound for multiple hypothesis testing",
JOURNAL = ieeeit,
VOLUME = 51,
NUMBER = 4,
PAGES = "1611--1614",
YEAR = 2005
}


@article{Birge83,
author = {Lucien Birg\'e},
title = {Approximation dans les espaces m\'etriques et th\'eorie de
  l'estimation},
year = 1983,
journal = {Zeitschrift f\"ur Wahrscheinlichkeitstheorie und verwebte Gebiet},
volume = 65,
pages = {181--238},
}

@article{BirginMaRa00,
author = {Ernesto G. Birgin and Jos\'e Mario Mart\'inez and Marcos Raydan},
title = {Nonmonotone Spectral Projected Gradient Methods on Convex Sets},
year = 2000,
journal = siopt,
volume = 10,
number = 4,
pages = {1196--1211},
comment = {Presents a projected gradient method using Barzilai-Borwein-type
  stepsizes and a non-monotone line search (which generalized Armijo-type
  line-searches), showing that the algorithm is convergent and has good
  numerical properties. The Barzilai-Borwein stepsizes are based on secant
  approximations to quadratic models and apepar to give good performance.
  See also the survey BirginMaRa14.},
}

@article{BirginGaMaSaTo17,
Author = {Ernesto G. Birgin and John L. Gardenghi
   and Jos\'{e} Martio Mart\'inez
   and Sandra A. Santos and Philippe L. Toint},
Title = {Worst-case evaluation complexity for unconstrained nonlinear
 optimization using high-order regularized models},
Journal = mathprog,
volume = 163,
number = {1--2},
pages = {359--368},
Keywords = {nonconvex},
Year = {2017},
}

@article{BirginMaRa14,
author = {Ernesto G. Birgin and Jos\'e Mario Mart\'inez and Marcos Raydan},
title = {Spectral Projected Gradient Methods: Review and Perspectives},
year = 2014,
journal = {Journal of Statistical Software},
volume = 60,
number = 3,
comment = {Survey on "spectral" gradient methods, whose convergence depends
  on matching well the spectrum of the Hessian of the objective. These methods
  have good performance, and choose stepsizes based on secant approximations.},
}

@article{BirmanSo67,
author = {M. Birman and M. Solomjak},
title = {Piecewise-polynomial approximations of functions of the classes
${W}^\alpha_p$},
year = 1967,
journal = {Sbornik: Mathematics},
volume = 2,
number = 3,
pages = {295--317},
}

@InProceedings{BiZh04,
  author = 	 {J. Bi and T. Zhang},
  title = 	 {Support vector classification with input data uncertainty},
  booktitle =  nips17,
  year = 	 {2004},
}

@inproceedings{BiebricherFuLuScKn88
,author=        {Peter Biebricher and Norbert Fuhr and Gerhard Lustig
                  and Michael Schwantner and Gerhard Knorz}
,title=         {The automatic indexing system {AIR/PHYS} --- from
                  research to application}
,booktitle=     sigir88
,pages=         {333-342}
,year=          1988
}

@book{Billingsley86,
author=		{P. Billingsley},
title=		{Probability and Measure},
edition=	{{S}econd},
publisher=	{Wiley},
year=		1986,
comment=	{addess= New York}
}

@book{Billingsley99,
author = {Patrick Billingsley},
title = {Convergence of Probability Measures},
year = 1999,
edition = {{S}econd},
publisher = {Wiley},
comment = {Excellent introduction to the convergence of probability
  measures in general metric spaces. First part deals with Portmanteau
  lemma and definitions of weak convergence. Moves to a nice construction of
  Brownian motion by arguing about tightness of a series of measures on
  a function space (via Arzela-Ascoli theorem). After that, spends time
  on topology of right-continuous functions (Skorohod topology)
  and weak convergence there, which gives different versions of Brownian
  motion, uniform CLTs via Donsker's theorem, etc.},
}

@techreport{Bilmes98,
author = {Jeff A. Bilmes},
title = {A gentle tutorial of the {EM} Algorithm and its Application to
 Parameter Estimation for {G}aussian Mixture and Hidden {M}arkov Models},
year = 1998,
institution = {Computer Science Division, University of California Berkeley},
number = {TR-97-021},
}

@book{Black58,
author = {D.\ Black},
title = {The Theory of Committees and Elections},
year = 1958,
publisher = {Cambridge University Press},
}

@article{Black76,
  title={Stuedies of stock price volatility changes},
  author={Black, Fischer},
  year={1976},
  journal={In Proceedings of the 1976 Meetings of the American
                  Statistical Association, Business and Economics
                  Statistics Section, pp. 177-181}
}

@inproceedings{Blackwell51,
author = {David Blackwell},
title = {Comparison of experiments},
year = 1951,
booktitle = {Proceedings of the 2nd Berkeley Symposium on Probability and
  Statistics},
pages = {93--102},
publisher = {University of California Press},
}

@article{Blackwell56
,author=	{D. Blackwell}
,title=		{An analog of the minimax theorem for vector payoffs}
,year=		1956
,journal=	{Pacific Journal of Mathematics}
,volume=	6
,number=	1
,month=		{Spring}
,pages=		{1--8}
}

@Misc{Blackwell56b,
  author =	 {David Blackwell},
  title =	 {Controlled random walks},
  howpublished = {invited address, Institute of Mathematical
		  Statistics Meeting, Seattle, Washington},
  year =	 1956
}

@Book{BlackwellGi54,
  author = 	 {David Blackwell and M.A. Girshick},
  title = 	 {Theory of games and statistical decisions},
  publisher = 	 {dover},
  year = 	 1954
}

@inproceedings{BlanchardKr2010,
  author = {Gilles Blanchard and Nicole Kr\"amer},
  title = {Optimal learning rates for Kernel Conjugate Gradient regression},
  booktitle = nips23,
  year = {2010},
  comment = {Considers performing conjugate gradient method for kernel
  regression. Uses a combination of concentration--so the empirical kernel
  behaves like the true kernel in operator norm--and analysis by Nemirovski
  of conjugate gradients with inexact data (as compared to exact data) to
  show that an early-stopped conjugate gradient method applied to the
  kernel matrix can get optimal convergence rates.},
}

@article{BlanchardLeSc10,
author = {Gilles Blanchard and Gyemin Lee and Clayton Scott},
title = {Semi-Supervised Novelty Detection},
year = 2010,
journal = jmlr,
volume = 11,
}

@article{BlanchetGl08,
author = {Jose Blanchet and Peter Glynn},
title = {Efficient rare-event simulation for the maximum of
  heavy-tailed random walks},
year = 2008,
journal = aoap,
volume = 18,
number = 4,
pages = {1351--1378},
}

@article{BlanchetMu16,
  title={Quantifying Distributional Model Risk Via Optimal Transport},
  author={Blanchet, Jose and Murthy, Karthyek},
  year=2016,
journal = {arXiv:1604.01446 [math.PR]},
url = {https://arxiv.org/abs/1604.01446},
}

@Article{Block62,
  author = 	 {H. D. Block},
  title = 	 {The Perceptron: A Model for Brain Functioning},
  journal = 	 {Reviews of Modern Physics},
  year = 	 1962,
  volume =	 34,
  pages =	 {123--135},
  note =         {Reprinted in "Neurocomputing" by Anderson and Rosenfeld}
}

@incollection{BloomRi12,
author = {Joshua S. Bloom and Joseph W. Richards},
title = {Data Mining and Machine-Learning in Time-Domain Discovery and
  Classification},
booktitle = {Advances in Machine Learning and Data Mining for Astronomy},
editor = {Michael Way and Jeff Scargle and Kamal Ali and Ashok Srivastava},
year = 2012,
publisher = {CRC Press},
chapter = 1,
}


@mastersthesis{Blum89,
author=   	{Blum, Avrim},
title=    	{On the Computational Complexity of Training Simple
		Neural Networks},
school=   	{MIT Department of Electrical Engineering and Computer
		Science},
year=     	1989,
month=    	May,
note = 		{(Published as Laboratory for Computer Science Technical
		  Report MIT/LCS/TR-445 (May, 1989).)}
}

@inproceedings{Blum90,
author=		{Avrim Blum},
title=		{Separating Distribution-free and Mistake-bound
		 Learning Models over the {B}oolean Domain},
booktitle=	focs90,
pages=		{211--218},
month=		oct,
year=		1990
}

@inproceedings{Blum90b,
author=		{Avrim Blum},
title=		{Some Tools for Approximate 3-Coloring},
booktitle=	focs90,
pages=		{554--562},
month=		oct,
year=		1990
}

@article{Blum92,
author=		{Avrim Blum},
title=		{Learning Boolean Functions in an Infinite Attribute
		 Space},
journal=	ml,
volume=		9,
number=		4,
year=		1992,
pages=		{373--386}
}

@article{Blum95,
  author = 	 {Avrim Blum},
  title = 	 {Empirical support for Winnow and Weighted-Majority based
          		algorithms: results on a calendar scheduling domain},
  journal =	"Machine Learning",
  volume =	26,
  pages =	{5-23},
  year =	1997
}

@article{BlumBl75,
author=   	{Blum, Lenore and Manuel Blum},
title=    	{Toward a Mathematical Theory of Inductive Inference},
journal=  	InfCtrl,
year=     	1975,
month=   	Jun,
volume=   	28,
number=   	2,
pages=    	{125--155},
comment=  	{Recursion-theoretic, a la Gold [Go67].}
}

@article{BlumBlSh86
,author=	{L. Blum and M. Blum and M. Shub}
,title=		{A simple unpredictable pseudo-random number
		 generator}
,journal=	sicomp
,volume=	15
,number=	2
,pages=		{364--383}
,month=		may
,year=		1986
}

@inproceedings{BlumCh92,
author=		{Avrim Blum and Prasad Chalasani},
title=		{Learning Switching Concepts},
booktitle=	colt92,
year=		1992,
month=		jul,
pages=		{231--242}
}

@InProceedings{BlumDu02,
  author = 	 {A. Blum and J.D. Dunagan},
  title = 	 {Smoothed Analysis of the Perceptron Algorithm for Linear Programming},
  booktitle = {SODA},
  year = 	 {2002}
}

@inproceedings{BlumFuKeLi93,
author=		{Avrim Blum and Merrick Furst and Michael Kearns and
		 Richard J. Lipton},
title=		{Cryptographic Primitives Based on Hard Learning Problems},
booktitle=	{Pre-Proceedings of CRYPTO~'93},
year=		1993,
pages=		{24.1--24.10}
}

@InProceedings{BlumKa97,
  author = 	 {Avrim Blum and Adam Kalai},
  title = 	 {Universal Portfolios With and Without Transaction Costs},
  booktitle = 	 colt97,
  year =	 1997,
  pages =	 {309-313}
}

@inproceedings{BlumLiRo08,
author = {Avrim Blum and Katrina Ligett and Aaron Roth},
title = {A learning theory approach to non-interactive database privacy},
year = 2008,
booktitle = stoc08,
comment = {
Studies learning from a dataset using queries from VC spaces.
The method is to sanitize the database in some way, then release a
perturbed version of the database that is suitable for certain queries.
They show how to do half-space queries in some polynomial of all the
problem parameters while maintaining "usefulness."
Survey by Dwork helps explain some of this. Also shows loose
upper bounds of O(d V / (\epsilon^3 \alpha)), where V is the VC dimension,
d is the dimension, \epsilon is the desired accuracy of queries, and
\alpha is the differential privacy, on the size of a dataset necessary
for learning. Gives a lower bound of 1/\epsilon^2.
},
}

@Article{BlumMa07,
  author = 	 {A. Blum and Y. Mansour},
  title = 	 {From External to Internal Regret},
  journal = 	 {Journal of Machine Learning Research},
  year = 	 {2007},
  volume = 	 {8},
  pages = 	 {1307--1324},
  month = 	 {Jun}
}

@inproceedings{BlumMi98,
	author = "A. Blum and T. Mitchell",
	title = "Combining Labeled and Unlabeled Data with Co-Training",
	booktitle = colt98,
	pages = "92--100",
	year = 1998
}

@incollection{BlumRi89,
author =	{Blum, Avrim and Ronald L. Rivest},
title = 	{Training a 3-node neural net is {NP-Complete}},
booktitle = 	{Advances in Neural Information Processing Systems I},
publisher = 	{Morgan Kaufmann},
year = 		1989,
editor = 	{David S. Touretzky},
pages = 	{494--501}
}

@inproceedings{BlumSi90,
author=		{Avrim Blum and Mona Singh},
title=		{Learning functions of {$k$} terms},
booktitle=	colt90,
year=		1990,
month=		aug,
pages=		{144--153}
}

@inproceedings{BlumerEhHaWa86a,
author=   	{Blumer, Anselm and Andrzej Ehrenfeucht and David Haussler and
	   	Manfred K. Warmuth},
title=    	{Classifying Learnable Geometric Concepts with the
	  	{V}apnik-{C}hervonenkis Dimension},
booktitle= 	stoc86,
address=  	{Berkeley, California},
year=     	1986,
month=    	May,
pages=    	{273--282},
comment=  	{Shows equivalence between finite VC dimension and
		learnability of geometric concepts.}
}

@techreport{BlumerEhHaWa86b,
author=   	{Blumer, Anselm and Andrzej Ehrenfeucht and David Haussler and
	   	Manfred K. Warmuth},
title=    	{Occam's Razor},
institution= 	ucsccrl,
number=  	{UCSC-CRL-86-2},
year=     	1986,
month=    	Feb,
comment=  	{Defines `Occam-algorithm' which may produce a hypothesis of
	   	complexity $n^c m^\alpha$ for fixed $c$ and $\alpha < 1$, and
	   	shows that Occam-algorithms need only polynomially many
		samples.}
}

@article{BlumerEhHaWa87,
author=   	{Blumer, Anselm and Andrzej Ehrenfeucht and David Haussler and
	   	Manfred K. Warmuth},
title=    	{Occam's Razor},
journal=  	{Information Processing Letters},
volume=   	24,
number=		6,
year=     	1987,
month=    	Apr,
pages=    	{377--380},
comment=  	{Defines `Occam-algorithm' which may produce a hypothesis of
	   	complexity $n^c m^\alpha$ for fixed $c$ and $\alpha < 1$, and
	   	shows that Occam-algorithms need only polynomially many
		samples.}
}

@techreport{BlumerEhHaWa87b,
author=   	{Blumer, Anselm and Andrzej Ehrenfeucht and David Haussler and
	   	Manfred K. Warmuth},
title=    	{Learnability and the
	  	{V}apnik-{C}hervonenkis Dimension},
institution= 	ucsccrl,
number=   	{UCSC-CRL-87-20},
year=     	1987,
month=   	Nov,
}

@article{BlumerEhHaWa89,
author=   	{Blumer, Anselm and Andrzej Ehrenfeucht and David Haussler and
	   	Manfred K. Warmuth},
title=    	{Learnability and the {V}apnik-{C}hervonenkis Dimension},
journal= 	jacm,
month=		Oct,
year=		1989,
volume=		36,
number=		4,
pages=		{929--965},
comment=	{An earlier version is available as
		U. C. Santa Cruz Computer Science Laboratory Tech.\ Report
		UCSC-CRL-87-20, November, 1987.}
}

@phdthesis{Board90
,author=	{Raymond Acton Board}
,title=		{Topics in computational learning theory and graph
		 algorithms}
,year=		1990
,month=		jul
,school=	{University of Illinois at Urbana-Champaign}
,note=		{Available as technical report UIUCDCS-R-90-1611}
}

@inproceedings{BoardPi90,
author=		{Board, Raymond and Leonard Pitt},
title=		{On the Necessity of {O}ccam Algorithms},
booktitle=	stoc90,
year=		1990,
month=		May,
pages=		{54--63}
}

@inproceedings{BottouBo07,
author = 	{L. Bottou and O. Bousquet},
title = 	{The Tradeoffs of Large Scale Learning},
booktitle=	nips20,
year = 		{2007}
}



@InBook{BottouLi07,
  author = 	 {L. Bottou and C.J. Lin},
  title = 	 {Large Scale Kernel Machines,
L. Bottou, O. Chapelle, D. DeCoste, and J. Weston editors},
  chapter = 	 {Support Vector Machine Solvers},
  publisher = 	 {Cambridge},
  year = 	 {2007}
}

@article{BoardPi92,
author=		{Board, Raymond and Leonard Pitt},
title=		{On the Necessity of {O}ccam Algorithms},
journal=	tcs,
year=		1992,
volume=		100,
number=		1,
pages=		{157--184}
}

@article{BohanecBr94
,author=        {Marko Bohanec and Ivan Bratko}
,title=         {Trading accuracy for simplicity in decision trees}
}

@article{BollobasTh95,
author = {B\'ela Bollob\'as and Andrew Thomason},
year = 1995,
title = {Projections of bodies and hereditary properties of hypergraphs},
journal = {Bulletin of the London Mathematical Society},
volume = 27,
pages = {471--424},
comment = {Shows a type of isoperimetric inequality: a box is in
  some sense the largest set with prescribed coordinate projected volumes.
  That is, if $K$ is a body in $\R^n$ and $K_A$ denotes its projection along
  the axes in a set $A$, there is a box $B$ with $\vol(B) = \vol(K)$ and
  $\vol(B_A) \le \vol(K_A)$ for any $A$. The proof is an
  elegant induction (proof is trivial for $n = 1$) coupled with Holder's
  inequality. As a consequence, if a collection of sets $\mc{C}$ is such
  that each index $i \in [n]$ appears $k$ times in the collection (a
  $k$-cover), we have $\vol(K)^k \le \prod_{A \in \mc{C}} \vol(K_A)$. },
}

@article{BolteDaLeMa09,
author = {J\'{e}r\^{o}me Bolte and Aris Daniilidis and Olivier Ley and
  Laurent Mazet},
year = 2009,
title = {Characterizations of {\L}ojasiewicz inequalities: subgradient
                  flows, talweg, convexity},
journal = tams,
pages = {3319--3363},
volume = 362,
number = 6,
comment = {Shows how convergence of subgradient descent is nice for
  a lot of functions that are "near" convex or "semi" convex.},
}

@article{BolteDaLe11,
author = {J\'{e}r\^{o}me Bolte and Aris Daniilidis and Adrian S. Lewis},
title = {Generic Optimality Conditions for Semialgebraic Convex Programs},
journal = {Mathematics of Operations Research},
volume = {36},
number = {1},
pages = {55-70},
year = {2011},
comment = {doi = {10.1287/moor.1110.0481}},
    abstract = { We consider linear optimization over a nonempty convex 
semialgebraic feasible region F. Semidefinite programming is an example.
 If F is compact, then for almost every linear objective there is a
 unique optimal solution, lying on a unique “active” manifold, around
 which F is “partly smooth,” and the second-order sufficient conditions hold.
 Perturbing the objective results in smooth variation of the optimal solution.
 The active manifold consists, locally, of these perturbed optimal solutions; 
it is independent of the representation of F and is eventually identified by a
variety of iterative algorithms such as proximal and projected gradient
 schemes. These results extend to unbounded sets F. }
}

@book{Bongard??,
author=   	{Bongard, M.},
title=    	{Pattern Recognition},
publisher= 	{Spartan Books},
year=      	{19??}
}

@book{BonnansSh13,
  title={Perturbation analysis of optimization problems},
  author={Bonnans, J Fr{\'e}d{\'e}ric and Shapiro, Alexander},
  year=2013,
  publisher={Springer Science \& Business Media}
}

@article{BonnansSh98,
  title={Optimization problems with perturbations: A guided tour},
  author={Bonnans, J Fr{\'e}d{\'e}ric and Shapiro, Alexander},
  journal={SIAM review},
  volume=40,
  number=2,
  pages={228--264},
  year=1998,
  publisher={SIAM}
}

@inproceedings{Boppana85,
author=		"Boppana, Ravi B.",
title=		"Amplification of Probabilistic {B}oolean Formulas",
booktitle=	focs85,
year=		1985,
month=		Oct,
pages=		"20--29"
}

@phdthesis{Boppana86,
author=		{Ravi Babu Boppana},
title=		{Lower Bounds for Monotone Circuits and Formulas},
year=		1986,
school=		mit
}

@incollection{Boppana89,
author=		"Boppana, Ravi B.",
title=		"Amplification of Probabilistic {B}oolean Formulas",
booktitle=	{Advances in Computing Research 5: Randomness and Computation},
editor=		{S. Micali},
year=		1989,
publisher=	{JAI Press},
pages=		{27--45}
}

@book{Borda1781,
    address = {Paris},
    author = {de Borda, Jean C.},
    publisher = {Histoire de l'Academie Royale des Sciences},
    title = {{Memoire sur les Elections au Scrutin}},
    year = {1781}
}

@unpublished{BorgersSa94
,author=	{Tilman B\"orgers and Rajiv Sarin}
,title=		{Learning through reinforcement and replicator dynamics}
}

@unpublished{BorgersSa95
,author=	{Tilman B\"orgers and Rajiv Sarin}
,title=		{Naive reinforcement learning with endogenous
		aspirations}
}

@book{Borkar08,
  title={Stochastic Approximation},
  author={Vivek Borkar},
  year={2008},
  publisher={Cambridge University Press}
}

@article{BorweinCh09,
author = {Jonathan M. Borwein and O-Yeat Chan},
title = {Uniform Bounds for the Incomplete Complementary {G}amma Function},
journal = {Mathematical Inequalities and Applications},
volume = 12,
year = 2009,
pages = {115--121},
}

@article{BorweinGuHaVa09,
author = {J. Borwein and A. J. Guirao and P. H\'ajek and J.\ Vanderwerff},
title = {Uniformly convex functions on {B}anach spaces},
year = 2009,
journal = {Proceedings of the American Mathematical Society},
volume = 137,
number = 3,
pages = {1081--1091},
}

@book{BorweinLe06,
author = {J. Borwein and A. Lewis},
title = {Convex Analysis and Nonlinear Optimization},
publisher = {Springer},
year = {2006},
comment = {Fairly advanced book with general proofs of many convex analytic
  results. Nice proof of several fixed-point theorems, including
  Brouwer's, in Chapter 8.},
}

@book{BorodinEl98,
	author = "A. Borodin and R. El-Yaniv",
	title = "Online Computation and Competitive Analysis",
	publisher = "Cambridge University Press",
	year = 1998
}

@article{BorodinElGo04,
 author = {Allan Borodin and Ran El-YAniv and Vincent Gogan},
 title = {Can We Learn to Beat the Best Stock},
 journal = {Journal of Artificial Intelligence Research},
 volume = 21,
 year = 2004,
 pages = {579-594},
}

@InProceedings{BoserGuVa92,
  author = 	 {Bernhard E. Boser and Isabelle M. Guyon and Vladimir
		  N. Vapnik},
  title = 	 {A Training Algorithm for Optimal Margin Classifiers},
  booktitle = 	 colt92,
  year =	 1992,
  pages =	 {144-152}
}

@unpublished{Boucheron88,
author = 	{St\'ephane Boucheron},
title = 	{Learnability from positive examples in the {V}aliant
		framework},
note = 		{Unpublished manuscript},
year = 		{1988}
}

@inproceedings{BoucheronSa88,
author=   	{Boucheron, St\'ephane and Jean Sallantin},
title=    	{Some remarks about space-complexity of learning, and
		 circuit complexity of recognizing},
booktitle=	colt88,
month=    	Aug,
year=     	1988,
pages = 	{125--138}
}

@article{BoucheronBoLu05,
author = {St\'ephane Boucheron and Olivier Bousquet and G\'abor Lugosi},
title = {Theory of classification: a survey of some recent advances},
year = 2005,
journal = {ESAIM: Probability and Statistics},
volume = 9,
pages = {323--375},
comment = {Excellent survey of classification with a perspective of Rademacher
  complexity. Starts with simple examples to achieve 1/\sqrt{n} convergence,
  then expands to include some classification calibration. Spends time
  going over "sharp" rates--that depend on localization (and a very simple
  argument in the 0/1-VC case that does not require localization).
  Presentation is nicely high-level with proofs presented enough to be
  easily filled in. Also includes material on PAC-Bayes bounds and
  a nice treatment of model selection.},
}

@incollection{BoucheronBoLu04,
  author = 	 {S. Boucheron and O. Bousquet and G. Lugosi},
  title = 	 {Concentration Inequalities},
  booktitle = 	 { Advanced Lectures in Machine Learning},
  editor = {O. Bousquet and U.v. Luxburg  and G. Ratsch},
  publisher = {Springer},
  year = 	 {2004},
  pages = {208--240}
}

@article{Bouchard-CoteSaJo12,
author = {Alexandre Bouchard-C\^ot\'e and Sriram Sankararaman and Michael
I. Jordan},
title = {Phylogenetic Inference via Sequential Monte Carlo},
year = 2012,
journal = {Systematic Biology},
volume = {Advance access (to appear)},
}

@book{BoucheronLuMa13,
  title={Concentration Inequalities: a Nonasymptotic Theory of Independence},
  author={Boucheron, St{\'e}phane and Lugosi, G{\'a}bor and Massart, Pascal},
  year=2013,
  publisher={Oxford University Press},
}

@article{BoucheronLuMa03,
  title={Concentration inequalities using the entropy method},
  author={Boucheron, St{\'e}phane and Lugosi, G{\'a}bor and Massart, Pascal},
  journal={Annals of probability},
  pages={1583--1614},
  year=2003,
}

@article{BoucheronLuMa00,
author = {St\'ephane Boucheron and G\'abor Lugosi and Pascal Massart},
title = {A sharp concentration inequality with applications},
year = 2000,
journal = {Random Structures Algorithms},
volume = 16,
pages = {277--292}
}

@article{BoultonWa73,
author=   	{Boulton, D. M. and C. S. Wallace},
title=    	{An information measure for hierarchic classification},
journal=  	{The Computer Journal},
volume=   	16,
number=   	3,
year=     	1973,
month=    	Aug,
pages=    	{254--261}
}

@article{BoultonWa75,
author=   	{Boulton, D. M. and C. S. Wallace},
title=    	{An information measure for single-link classification},
journal=  	{The Computer Journal},
volume=   	18,
number=   	3,
year=     	1973,
month=    	Aug,
pages=    	{236--238}
}

@article{Boumal16,
author  = {Nicolas Boumal},
title   = {Nonconvex Phase Synchronization},
journal = siopt,
volume  = {26},
number  = {4},
pages   = {2355--2377},
year    = {2016},
}

@inproceedings{BoumalVoBa16,
  title={The non-convex {B}urer-{M}onteiro approach works on smooth
    semidefinite programs},
  author={Boumal, Nicolas and Voroninski, Vlad and Bandeira, Afonso}, 
  booktitle=nips29,
  pages={2757--2765},
  year={2016}
}

@phdthesis{Bousquet02thesis,
author = {Olivier Bousquet},
title = {Concentration inequalities and empirical processes theory applied
  to the analysis of learning algorithms},
year = 2002,
school = {L'Ecole Polytechnique},
}

@article{Bousquet02,
  title={A Bennett concentration inequality and its application to suprema of empirical processes},
  author={Bousquet, Olivier},
  journal={Comptes Rendus Mathematique},
  volume=334,
  number=6,
  pages={495--500},
  year=2002,
  publisher={Elsevier}
}

 @incollection{Bousquet03,
  title={Concentration inequalities for sub-additive functions using the entropy method},
  author={Bousquet, Olivier},
  booktitle={Stochastic inequalities and applications},
  pages={213--247},
  year=2003,
  publisher={Springer}
}

@article{BousquetEl02,
author = {O. Bousquet and A. Elisseeff},
title = {Stability and generalization},
year = 2002,
journal = jmlr,
volume = 2,
pages = {499--526},
comment = {Shows that stable learning algorithms--essentially those with
strongly convex regularizers--have good generalization performance since
they satisfy McDiarmid's inequality},
}

@InProceedings{BosquetHe02,
	author = "O. Bosquet and D.J.L. Herrmann",
	title = "On the Complexity of Learning the Kernel Matrix",
	booktitle = nips15,
	year = 2002
}

@techreport{BoyanFrJo94,
	Author = "Justin Boyan and Dane Freitag and Thorsten Joachims",
	Title = "A machine learning architecture for optimizing web search engines",
	Booktitle="Internet-based information systems",
	Number="WS-96-05",
	Institution="American Association of Artificial Intelligence",
	Year=1994
}

@article{BoydGhPrSh06,
author = {Stephen Boyd and Arpita Ghosh and Balaji Prabhakar
  and Devavrat Shah},
title = {Randomized gossip algorithms},
year = 2006,
journal = {IEEE Transactions on Information Theory},
volume = 52,
number = 6,
pages = {2508--2530},
}

@unpublisheD{BoydDuVa15_sub,
author = {Stephen Boyd and John Duchi and Lieven Vandenberghe},
title = {Subgradients},
year = 2015,
note = {Course notes for Stanford Course EE364b},
url = {http://web.stanford.edu/class/ee364b/lectures/subgradients_notes.pdf},
}

@unpublished{Boyd15,
author = {Stephen Boyd},
title = {Monotone Operators},
year = 2015,
note = {Course notes for Stanford Course EE364b},
url = {http://web.stanford.edu/class/ee364b/lectures/monotone_slides.pdf},
}

@unpublished{BoydMu07,
author = {Stephen Boyd and Almir Mutapcic},
title = {Stochastic Subgradient Methods},
year = {2007},
note = {Course notes for EE364b at Stanford, available at
http://www.stanford.edu/class/ee364b/notes/stoch\_subgrad\_notes.pdf}
}

@article{BoydPaChPeEc11,
author = {S. Boyd and N. Parikh and E. Chu and B. Peleato and J. Eckstein},
title = {Distributed Optimization and Statistical Learning via the
 Alternating Direction Method of Multipliers},
year = 2011,
journal = {Foundations and Trends in Machine Learning},
volume = 3,
number = 1,
}

@Book{BoydVa04,
  author =	 {Stephen Boyd and Lieven Vandenberghe},
  title = 	 {Convex Optimization},
  publisher = 	 {Cambridge University Press},
  year = 	 {2004}
}

@misc{BoydXiMuMa08,
author = {Stephn Boyd and Lin Xiao and Almir Mutapcic and Jacob Mattingley},
title = {Notes on Decomposition Methods},
year = 2008,
howpublished = {Lecture notes for EE364b, Stanford University},
}

@article{BoylanEl91
,author=	{Richard T. Boylan and Mahmoud A. El-Gamal}
,title=		{Fictitious play: a statistical study of multiple
		economic experiments}
}

@article{Boyles83,
    author = {R.A. Boyles},
    title = {On the convergence of the {EM} algorithm},
    journal = {Journal of the Royal Statistical Society},
    volume = {B45},
    year = {1983},
    pages = {47--50}
}

@article{Bradley05,
author = {R. C. Bradley},
title = {Basic properties of strong mixing conditions. A survey and some
open questions},
year = 2005,
journal = {Probability Surveys},
volume = 2,
pages = {107--144},
comment = {Not particularly eloquent or intuition-building survey of different
flavors of mixing for stochastic processes; surveys many many flavors
of mixing (e.g. $\phi$-mixing, $\beta$-mixing, $\alpha$-mixing, etc.).},
}

@inproceedings{BradleyKyBiGu11,
author = {Joseph K. Bradley and Aapo Kyrola
 and Danny Bickson and Carlos Guestrin},
title = {Parallel Coordinate Descent for L1-Regularized Loss Minimization},
booktitle = icml11,
year = 2011,
}

@article{BradleyMa00,
author=   	{P. S. Bradley and O. L. Mangasarian},
title=    	{Massive Data Discrimination via Linear Support Vector Machines},
journal =       {Optimization Methods and Software},
volume =        {13(1)},
year=     	2000,
pages=          {1--10}
}

@article{BradleyTe52,
author = {R.~A.\ Bradley and M.~E.\ Terry},
title = {Rank analysis of incomplete block designs: {I}. {T}he method
of paired comparisons},
journal = {Biometrika},
year = 1952,
volume = 39,
number = {3/4},
comment = {Introduces (roughly) a model of paired comparisons as coming
from latent scores passed through a logistic model.}
}

@article{BradtkeBa??
,author=	{Steven J. Bradtke and Andrew G. Barto}
,title=		{New Algorithms for temporal difference learning}
}

@inproceedings{BrantsPoXuOcDe07,
author = {Thorsten Brants and Ashok C. Popat and Peng Xu and Franz J. Och
 and Jeffrey Dean},
title = {Large Language Models in Machine Translation},
year = 2007,
booktitle = {Proceedings of the 2007 Joint Conference on Empirical Methods
 in Natural Language Processing and Computational Natural Language Learning
 (EMNLP-CoNLL)},
pages = {858--867},
}

@article{BraunGuPo17,
author = {G\'abor Braun and Crist\'obal Guzm\'an and Sebastian Pokutta},
title = {Lower Bounds on the Oracle Complexity of Nonsmooth Convex Optimization
   via Information Theory},
year = 2017,
journal = ieeeit,
volume = 63,
number = 7,
comment = {
  Studies oracle complexity of optimization problems using information
  theoretic tools. They construct oracles for optimization that reduce
  to the problem of identifying a random string $S \in \{0, 1\}^M$, for
  appropriate $M$, where querying the oracle for a subgradient is equivalent
  to querying the string by asking ``given a permutation $\sigma$ and string
  $s$, which coordinate $j$ is the first satisfying $s_{\sigma(j)} \neq
  S_{j}$.'' This oracle requires at least $M/2$ queries to solve when
  $S$ is uniform. The optimization oracle that is equivalent
  is given by maxima of particular collections of recursively-defined
  functions, where $f_s(x)$ can be specified by a particular (permuted)
  prefix of the string $s$ until enough queries have occured.
  arXiv:1407.5144 [math.OC]},
}

@article{BravermanGaMaNgWo15,
author = {Mark Braverman and Ankit Garg and Tengyu Ma and Huy L. Nguyen
  and David P. Woodruff},
title = {Communication Lower Bounds for Statistical Estimation Problems
  via a Distributed Data Processing Inequality},
year = 2015,
journal = {arXiv:1506.07216 [cs.LG]},
}

@article{Bravo03,
  title={Second-order power comparisons for a class of nonparametric likelihood-based tests},
  author={Bravo, Francesco},
  journal={Biometrika},
  volume=90,
  number=4,
  pages={881--890},
  year=2003,
  publisher={Biometrika Trust}
}

@article{Bravo06,
  title={Bartlett-type adjustments for empirical discrepancy test statistics},
  author={Bravo, Francesco},
  journal={Journal of statistical planning and inference},
  volume={136},
  number={3},
  pages={537--554},
  year={2006},
  publisher={Elsevier},
  comment={Gives Bartlett-type correction for empirical likelihood
  inference with general f-divergences. While \cite{Baggerly98}
  showed that EL is the only Bartlett correctable member in the
  Cressie-Read family and \cite{Corcoran} gave conditions for the
  Bartlett correction to hold, this result shows that we can
  still achieve a higher order accuracy by a nonlinear correction.}
}


@article{BredensteinerBe99,
	author = "E. J.  Bredensteiner and K. P. Bennet",
	title = "Multicategory Classification by Support Vector Machines",
	journal = "Computational Optimizations and Applications",
	volume = 12,
	year = 1999,
	pages = "53--79"
}

@article{Bregman67,
	author = "L. M. Bregman",
	title = "The relaxation method of finding the common point of convex
	sets and its application to the solution of problems in convex
	programming",
	journal = "{USSR} Computational Mathematics and Mathematical Physics",
	volume = 7,
	pages = "200--217",
	year = 1967
}

@article{BregmanCeRe99,
    author = "L.M. Bregman and Y. Censor and S. Reich",
    title = "Dykstra's algorithm as the nonlinear extension of {B}regman's
        optimization method",
    journal = "Journal of Convex Analysis",
    volume = 6,
    pages = "319--334",
    year = 1999
}

@article{BregmanCeReZe03,
    author = "L.M. Bregman and Y. Censor and S. Reich and Y.
        Zepkowitz-Malachi",
    title = "Finding the projection of a point onto the intersection of
        convex sets via projections onto halfspaces",
    journal = "Journal of Approximation Theory",
    volume = "124",
    pages = "194--218",
    year = 2003
}

@Book{Breiman92,
  author =	 {Leo Breiman},
  title = 	 {Probability},
  publisher = 	 {SIAM},
  year = 	 1992,
  edition =	 {Classics Edition, original edition first published 1968}
}

@techreport{Breiman96
,author=	{Leo Breiman}
,title=		{Bias, variance, and arcing classifiers}
,institution=	{Statistics Department, University of California at
		 Berkeley}
,year=		1996
,number=	460
,comment=	{Available from
		ftp://ftp.stat.berkeley.edu/pub/users/breiman/arcall.ps.Z.}
}

@article{Breiman96b
,author=	{Leo Breiman}
,title=		{Bagging predictors}
,journal=	ml
,volume=	24
,number=	2
,pages=		{123-140}
,year=		1996
}

@Article{Breiman96c,
  author = 	 {Leo Breiman},
  title = 	 {The heuristics of instability in model selection},
  journal = 	 annstat,
  year = 	 1996,
  volume =	 24,
  pages =	 {2350-2383}
}


@TechReport{Breiman97,
  author = 	 {Leo Breiman},
  title = 	 {Prediction games and arcing classifiers},
  institution =  {Statistics Department, University of California at Berkeley},
  year = 	 1997,
  number =	 504
}

@TechReport{Breiman97b,
  author = 	 {Leo Breiman},
  title = 	 {Arcing the Edge},
  institution =  {Statistics Department, University of California at Berkeley},
  year = 	 1997,
  number =	 486
}

@Article{Breiman98,
author=	{Leo Breiman},
title=		{Arcing classifiers},
  journal = 	 annstat,
volume=          26,
number=          3,
pages=           {801-849},
  year = 	 1998
}

@book{BreimanFrOlSt84,
author=   	{L.~Breiman and J.~H.~Friedman and R.~A.~Olshen and
		C.~J.~Stone},
title=    	{Classification and Regression Trees},
publisher= 	{Wadsworth \& Brooks},
year=      	1984,
comment=   {Review of procedures for inferring decision trees from data.}
}

@inproceedings{BreeseHeKa98,
	author = "J.S. Breese and D. Heckerman and C. Kadie",
	title = "Empirical analysis of predictive algorithms for
		collaborative filtering",
	booktitle = "Proceeding of the fourteenth confrence on Uncertainty
		in Artificial Intelligence (UAI)",
	pages = "43--52",
	year = 1998
}

@inproceedings{Brill92
,author=	{Eric Brill}
,title=		{A simple rule-based part of speech tagger}
}

@book{Brown86,
author = {Lawrence D. Brown},
title = {Fundamentals of Statistical Exponential Families},
year = 1986,
publisher = {Institute of Mathematical Statistics},
}

@article{BrownLo96,
author = {Lawrence D. Brown and Mark G. Low},
title = {A constrained risk inequality with applications
to nonparametric functional estimation},
year = 1996,
journal = aos,
volume = 24,
number = 6,
pages = {2524--2535},
}

@article{BrownNe??
,author=        {G. W. Brown and J. von Neumann}
,title=         {Solutions of games by differential equations}
}

@article{Brucker84,
author = {P. Brucker},
title = {An {$O(n)$} algorithm for quadratic knapsack problems},
year = 1984,
journal = {Operations Research Letters},
volume = 3,
number = 3,
pages = {163--166},
}

@Article{BrugnaraFaOm93,
  author = 	 {F. Brugnara and D. Falavigna and M. Omologo},
  title = 	 {Automatic segmentation and labeling of speech based on Hidden Markov Models},
  journal =  {Speech Communication},
  year = 	 1993,
  volume = {12},
  pages =	 {357-370}
}

@Proceedings{BrussFeSa90,
  title =        {Strategies for sequential Search and Selection in Real Time},
  year =         1990,
  editor =       {F. Thomas Bruss, Thomas S. Ferguson, Stephen M. Samuels},
  volume =       125,
  series =       {Contemporary Mathematics},
  publisher =    {American Mathematical Society}
}

@inproceedings{Bshouty93,
author=		{Nader H. Bshouty},
title=		{Exact Learning via the Monotone Theory},
booktitle=	focs93,
month=		nov,
year=		1993
}

@inproceedings{BshoutyGoHaMa93
,author=	{Nader H. Bshouty and Sally A. Goldman and Thomas R.
		 Hancock and Sleiman Matar}
,title=		{Asking questions to minimize errors}
,booktitle=	colt93
,month=		jul
,year=		1993
,pages=		{41--50}
}

@inproceedings{BshoutyHaHe92,
author=		{Nader H. Bshouty and Thomas R. Hancock and Lisa
		 Hellerstein},
title=		{Learning Arithmetic Read-Once Formulas},
booktitle=	stoc92,
year=		1992,
month=		may,
pages=		{370--381}
}



@BOOK{Cover,
AUTHOR = "T.M. Cover and Thomas, J.A.",
TITLE = "Elements of Information Theory",
PUBLISHER = "John Wiley and Sons",
ADDRESS = "New York",
YEAR = "1991"
}

@inproceedings{BshoutyHaHe92b,
author=		{Nader H. Bshouty and Thomas R. Hancock and Lisa
		 Hellerstein},
title=		{Learning Boolean Read-Once Formulas with Arbitrary
		 Symmetric and Constant Fan-in Gates},
booktitle=	colt92,
pages=		{1--15},
month=		jul,
year=		1992
}

@unpublished{BshoutyHaHeKa91,
author=   	{Nader H. Bshouty and Thomas R. Hancock and Lisa
		 Hellerstein and Marek Karpinski},
title=    	{Read-Once Threshold Formulas, Justifying Assignments,
		 and Generic Transformations},
year=     	1991,
note =          {Unpublished manuscript}
}

@article{BubeckMuStSz12,
author = {S\'ebastien Bubeck and R\'emi Munos and Gilles Stoltz and
  Csaba Szepesv\'ari},
title = {{$X$}-armed bandits},
year = 2011,
journal = jmlr,
volume = 12,
pages = {1655--1695},
}

@article{BubeckCe12,
author = {S\'ebastien Bubeck and Nicol\'o Cesa-Bianchi},
title = {Regret analysis of stochastic and nonstochastic multi-armed bandit
problems},
journal = {Foundations and Trends in Machine Learning},
volume = 5,
number = 1,
pages = {1--122},
year = 2012,
}

@inproceedings{BuckleySaAl94
,author=	{Chris Buckley and Gerard Salton and James Allan}
,title=		{The effect of adding relevance information in the
		relevance feedback environment}
}

@inproceedings{BuckleySa95,
        author = {Chris Buckley and Gerard Salton},
        booktitle = sigir95,
        month = jul,
        pages = {351--357},
        title = {Optimization of Relevance Feedback Weights},
        year = {1995},
        editor = {Edward Fox and Peter Ingwersen and Raya Fidel},
        publisher = {Association for Computing Machinery, New York},
}

@incollection{Buehler70,
author=   	{Buehler, Robert J.},
title=    	{Measuring Information and Uncertainty},
booktitle=  	{Foundations of Statistical Inference},
editor=   	{V. P. Godambe and D. A. Sprott},
year=     	1970,
publisher=  	{Holt, Rinehard, and Winston},
comment=  	{General study of payoff functions that encourage honesty for
           	someone making probabilistic predictions (e.g. a weatherman).}
}

@inproceedings{BuffoniCaGaUs11,
author = {D. Buffoni and C. Calauzenes and P. Gallinari and N. Usunier},
title = {Learning scoring functions with order-preserving losses and standardized supervision},
booktitle = icml11,
year = 2011,
}

@book{BuhlmannGe11,
author = {Peter B\"uhlmann and Sara van de Geer},
title = {Statistics for High-Dimensional Data: Methods,
 Theory and Applications},
year = 2011,
publisher = {Springer},
}

@article{BuhlmannWy99,
	author = "P. Buhlmann and A.J. Wyner",
	title = "Variable Length Markov Chains",
	journal = "The Annals of Statistics",
	volume = 27,
	number = 2,
	pages = "480--513",
	year = 1999
}

@book{BuldyginKo00,
author = {V. Buldygin and Yu. Kozachenko},
title = {Metric Characterization of Random Variables and Random Processes},
year = 2000,
publisher = {American Mathematical Society},
series = {Translations of Mathematical Monographs},
volume = 188,
}

@inproceedings{BunSt16,
author = {Mark Bun and Thomas Steinke},
year = 2016,
title = {Concentrated Differential Privacy: Simplifications, Extensions,
   and Lower Bounds},
booktitle = {Theory of Cryptography Conference (TCC)},
pages = {635--658},
}

@phdthesis{Buntine90
,author=	{Wray Lindsay Buntine}
,title=		{A Theory of Learning Classification Rules}
,school=	{University of Technology, Sydney}
,year=		1990
}

@article{Buntine92
,author=	{Wray Buntine}
,title=		{Learning Classification Trees}
,journal=	{Statistics and Computing}
,volume=	2
,year=		1992
,pages=		{63--73}
}

@article{BuntineNi92
,author=	{Wray Buntine and Tim Niblett}
,title=		{A further comparison of splitting rules for
		 decision-tree induction}
,journal=	ml
,year=		1992
}

@article{BurerMo03,
  title={A nonlinear programming algorithm for solving semidefinite
                  programs via low-rank factorization},
  author={Burer, Samuel and Monteiro, Renato DC},
  journal={Mathematical Programming},
  volume={95},
  number={2},
  pages={329--357},
  year={2003},
  publisher={Springer}
}

@inproceedings{Burges96,
	author = "C.J.C. Burges",
        title = "Simplified Support Vector Decision Rules",
        booktitle = icml96,
        year = 1996,
        pages = {71--77}
}

@article{Burges98,
	author = "C.J.C. Burges",
	title = "A tutorial on support vector machines for pattern recognition",
	journal = "Data Mining and Knowledge Discovery",
	volume = 2,
	number = 2,
	pages = "1--47",
	year = 1998
}


@inproceedings{BurgesShReLaDeHaHu05,
  author = "C.J.C. Burges and T. Shaked and E. Renshaw and A. Lazier and M. Deeds and N. Hamilton and G. Hullender",
  booktitle = icml05,
  title = "Learning to rank using gradient descent",
  year = 2005,
 pages = {89--96},
}

@article{Burke85,
author = {James Burke},
title = {Descent methods for composite nondifferentiable optimization
  problems},
year = 1985,
journal = mathprog,
volume = 33,
pages = {260--279},
}

@article{BurkeFe95,
author = {James Burke and Michael Ferris},
title = {A {G}auss-{N}ewton method for convex composite optimization},
year = 1995,
journal = mathprog,
volume = 71,
pages = {179--194},
}

@article{BurkeLeOv05,
author = {James Burke and Adrian Lewis and Michael Overton},
title = {A robust gradient sampling algorithm for nonsmooth,
   nonconvex optimization},
year = 2005,
journal = siopt,
volume = 15,
number = 3,
pages = {751--779},
}

@article{BurkeLeOv02,
author = {James Burke and Adrian Lewis and Michael Overton},
year = 2002,
title = {Approximating subdifferentials by random sampling of gradients},
journal = {Mathematics of Operations Research},
volume = 27,
number = 3,
pages = {567--584},
comment = {Studies convergence of random sampling procedures for evaluation
  of a gradient--for an a.s. differentiable function--to the true
  Clarke subgradient, or modifications thereof. Some nice analytical results.},
}

@article{BurkeMo94,
author = {James Burke and Jorge Mor\'e},
title = {Exposing Constraints},
year = 1994,
journal = siopt,
volume = 4,
number = 3,
pages = {573--595},
}

@book{ButnariuIu00,
    author = "D. Butnariu and A.N. Iusem",
    title = "Totally Convex Functions for Fixed Points Computation
        and Infinite Dimensional Optimization",
    publisher = "Kluwer Academic Publishers, Dordrecht, the Netherlands",
    year = 2000
}

@article{CaiLo15,
author = {Tony Cai and Mark Low},
title = {A framework for estimating convex functions},
year = 2015,
journal = {Statistica Sinica},
volume = 25,
pages = {423--456},
comment = {
  Builds off of the results of Donoho to give a more local analysis of
  minimax estimation of a functional at a point. Defines the quantity
  $R_n(f) = \sup_{g \in \mc{F}} \inf_{\hat{T}} \max\{\E[(\hat{T} - f(0))^2],
  \E[(\hat{T} - g(0))^2]\}$, which is a type of local minimax quantity.
  Shows how estimation of convex functions (among other shape
  constrained functions) is governed by this rate, and gives an adaptive
  estimator that attains the rate $R_n(f)$ uniformly among (most) convex
  functions. (This is possible because the shape constraint
  allows accurate bias estimation.) The quantity is essentially identical
  to a local modulus of continuity. Also shows that though convexity
  allows adaptivity, smoothness rates are same as in the non-convex case.
},
}

@article{CalafioreCa05,
author = {Giuseppe Calafiore and M.C. Campi},
title = {Uncertain convex programs: randomized solutions and
confidence levels},
year = 2005,
journal = {Mathematical Programming Series A},
volume = 102,
pages = {25--46},
comment = {Considers sampling based approaches to a robust convex problem
  of $\min. c^Tx$ s.t.\ $f(x, \delta) \le 0$, all $\delta \in \Delta$, by
  sampling from a distribution $P$ on $\Delta$. Via a clever counting
  argument, shows that given $N$ samples $\delta^i$, the expected probability
  of $\delta$s such that a solution $\what{x}_N$ fails
  to satisfy $f(\what{x}_N, \delta) \le 0$ is bounded by $n / (N + 1)$.
  The proof of the result is by showing--roughly via a hyperplane argument
  (or Helly selection/intersection theorem for convex sets, see
  also CalafioreCa04)--that only $n$ of the constraints can be active
  at once, so on average dropping most of them does not matter.},
}

@incollection{CalafioreCa04,
author = {Giuseppe Calafiore and M.C. Campi},
title = {Decision making in an uncertain environment:
         the scenario-based optimization approach},
year = 2004,
booktitle = {Multiple Participant Decision Making},
publisher = {Advanced Knowledge International},
pages = {99--111},
comment = {A high-probability version of CalafioreCa05, which gives
  similar results but with high probability. Also builds on a Helly
  selection argument to show that we only need to get a certain number
  of constraints correct, then some simple combinatorics do the rest.
  Interestingly, no dependence on structure of robustifying set
  $\Delta$ or distribution or anything, and rates are fast ($1/\epsilon$
  rather than $1/\epsilon^2$ samples required).},
}

@article{CalderEsHe13,
author = {Jeff Calder and Selim Esedoglu and Alfred O. Hero},
year = 2013,
title = {A {H}amilton-{J}acobi equation for the continuum limit of
   non-dominated sorting},
journal = {arXiv:1302.5828 [math.AP]},
url = {http://arxiv.org/abs/1302.5828},
}

@unpublished{Camacho97,
author = {Rui Camacho},
title = {Ailerons Dataset},
year = 1997,
note = {Available at http://www.liaad.up.pt/\~{}ltorgo/Regression/DataSets.html},
url = {http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html},
}

@article{CamponovoOt14,
  title={On Bartlett correctability of empirical likelihood in generalized power divergence family},
  author={Camponovo, Lorenzo and Otsu, Taisuke},
  journal={Statistics \& Probability Letters},
  volume=86,
  pages={38--43},
  year=2014,
  publisher={Elsevier},
  comment={Shows that exponentially tilted EL (KL divergence minimizing probability plugged into the EL objective) is not Bartlett correctable.}
}

@InProceedings{Candes06,
  author = 	 {E. J. Candes},
  title = 	 {Compressive sampling},
  booktitle = {Proc. of the Int. Congress of Math., Madrid, Spain},
  year = 	 {2006}
}

@article{Candes08,
author = {Emmanuel Cand\`es},
year = 2008,
title = {The restricted isometry property and its implications for
         compressed sensing},
journal = {Compte Rendus de l'Academie des Sciences, Paris},
series = {Serie I},
volume = 346,
pages = {589--592},
}


@article{CandesDa13,
author = {Emmanuel J. Cand\`es and Mark A. Davenport},
title = {How well can we estimate a sparse vector},
year = 2013,
journal = {Applied and Computational Harmonic Analysis},
volume = 34,
number = 2,
pages = {317--323},
comment = {Gives sparse estimation lower bounds of roughly $s \log d / n$, but
  with good depednence on Frobenius norm of sensing matrix $X$. Uses a
  complicated packing construction---complete with matrix concentration,
  etc.---to show how covariance of packing gives sharper bounds.},
}

@article{CandesElStVo13,
author = {Emmanuel J. Cand\`{e}s and Yonina Eldar and Thomas Strohmer
and Vladimir Voroninski},
title = {Phase Retrieval via Matrix Completion},
year = 2013,
journal = {SIAM Journal on Imaging Sciences},
volume = 6,
number = 1,
pages = {199--225},
}

@article{CandesLi14,
author = {Emmanuel J. Cand\`{e}s and Xiaodong Li},
title = {Solving Quadratic Equations via {P}hase{L}ift
   When There Are About as Many Equations as Unknowns},
year = 2014,
journal = focm,
pages = {1017--1026},
volume = 14,
number = 5,
}

@article{CandesLiMaWr11,
author = {Emmanuel J. Cand\`es and Xiadong Li and Yi Ma and John Wright},
title = {Robust principal component analysis?},
year = 2011,
journal = jacm,
volume = 58,
number = 3,
articleno = 11,
pages = {11:1--11:37},
}

@article{CandesLiSo15,
author = {Emmanuel J. Cand\`{e}s and Xiaodong Li and Mahdi Soltanolkotabi},
title = {Phase Retrieval via {W}irtinger Flow: Theory and Algorithms},
journal = ieeeit,
year = 2015,
volume = 61,
number = 4,
pages = {1985--2007},
}

@article{CandesPl11,
  author = {Cand{\`e}s, Emmanuel J and Plan, Yaniv},
  title = {Tight oracle inequalities for low-rank matrix recovery from
    a minimal number of noisy random measurements},
  journal = ieeeit,
  volume = {57},
  number = {4},
  pages = {2342--2359},
  year = {2011},
  publisher={IEEE}
}

@article{CandesTa07,
author = {E. J. Candes and T. Tao},
title = {The {D}antzig selector: statistical estimation when $p$ is much larger
than $n$},
year = 2007,
journal = aos,
volume = 35,
pages = {2313--2351},
}

@article{CandesTa08,
author = {Emmanuel J. Cand\`{e}s and Terrence Tao},
title = {The power of convex relaxation: Near-optimal matrix completion},
journal = ieeeit,
year = 2008,
volume = 56,
number = 5,
pages = {2053--2080},
}

@article{CandesRe08,
author = {E. J. Candes and B. Recht},
title = {Exact matrix completion via convex optimization},
year = 2008,
journal = {Foundations of Computational Mathematics},
volume = 9,
pages = {717--772},
}

@article{CandesStVo13,
author = {Emmanuel Cand\`{e}s and Thomas Strohmer and Vladimir Voroninski},
title = {Phase{L}ift: exact and stable signal recovery from
   magnitude measurements via convex programming},
year = 2013,
journal = {Communications on Pure and Applied Mathematics},
volume = 66,
number = 8,
page = {1241--1274},
}

@inproceedings{CaoQiLiTsLi07,
  author    = {Zhe Cao and
               Tao Qin and
               Tie-Yan Liu and
               Ming-Feng Tsai and
               Hang Li},
  title     = {Learning to rank: from pairwise approach to listwise approach},
  booktitle = {icml07},
  year      = {2007},
  pages     = {129-136},
}

@article{CaponnettoDe07,
author = {Andrea Caponnetto and Ernesto De Vito},
title = {Optimal Rates for Regularized Least-Squares Algorithm},
year = 2007,
journal = {Foundations of Computational Mathematics},
volume = 7,
number = 3,
pages = {331--368},
comment = {Gives an argument that shows that the "effective dimensionality"
  (i.e. the quantity tr((S + \lambda I)^{-1}), where S is the population
  covariance operator) governs convergence of kernel regression estimators.
  Matching lower bound given by looking at spectral decomposition of S,
  then identifying signs of first M eigenvectors (M chosen carefully to
  match the nonparametric rate based on decay of eigenvalues of S) with corners
  of hypercube. For some reason fails to cite Stone82. Also makes assumptions
  that the minimizer of E[(f(x) - y)^2] over the Hilbert space H is attained,
  which seems a little strong...},
}

@inproceedings{CarbonellG87,
author=   	{Carbonell, Jaime G. and Yolanda Gil},
title=    	{Learning by Experimentation},
booktitle=	{Proceedings of the Fourth International Workshop on Machine
		Learning},
month=    	Jun,
year=     	1987,
editor=   	{Pat Langley},
pages=    	{256--266},
publisher=	{Morgan Kaufmann}
}

@article{CarmonDu16,
title = {Gradient Descent Efficiently Finds the Cubic-Regularized
 Non-Convex {N}ewton Step},
author = {Yair Carmon and John C. Duchi},
year = 2016,
journal = {arXiv:1612.00547 [math.OC]},
}

@inproceedings{CarmonDu16_workshop,
title = {Gradient Descent Efficiently Finds the Cubic-Regularized
 Non-Convex {N}ewton Step},
author = {Yair Carmon and John C. Duchi},
year = 2016,
booktitle = {NIPS Workshop on Non-Convex Optimization}
}

@article{CarmonDuHiSi16,
  title={Accelerated Methods for Non-Convex Optimization},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, 
	Aaron},
  journal={arXiv:1611.00756 [math.OC]},
  year={2016}
}

@inproceedings{CarmonDuHiSi17,
title = {Convex until proven guilty: dimension-free acceleration
  of gradient descent on non-convex functions},
author = {Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, 
	Aaron},
booktitle = icml17,
year={2017},
}

@article{CarmonDuHiSi17li,
title = {Lower bounds for finding stationary points
 {I}},
author = {Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, 
	Aaron},
year = 2017,
journal = {arXiv:1710.11606 [math.OC]},
}

@article{CarmonDuHiSi17lii,
title = {Lower bounds for finding stationary points
 {II}: First order methods},
author = {Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, 
	Aaron},
year = 2017,
journal = {arXiv:1711.00841 [math.OC]},
}

@TechReport{CarrLa00,
author = {R.~D.~Carr and G.~Lancia},
title = {Compact vs. Exponential-Size {LP} Relaxations},
Institution = {SANDIA Report},
Number = {SAND2000-2170},
Year = {2000},
Month = {September}
}

@article{CarrollHa88,
author = {Raymond Carroll and Peter Hall},
title = {Optimal rates of convergence for deconvolving a density},
year = 1988,
journal = jasa,
volume = 83,
number = 404,
pages = {1184--1186},
comment = {Shows that for density estimation problems, if samples are
perturbed by additive noise $W$ with characteristic function $\phi_W$
satisfying $|\phi_W(t)| = \order(|t|^{-a})$ for some $a > 0$, then no
estimator can deconvolve the perturbed samples to get a better (local)
convergence rate than $n^{-k / (2k + 2a + 1)}$, where $k$ is the number
of derivatives.},
}

@book{CarrollRuStCr06,
author = {Raymond Carroll and David Ruppert and Leonard Stefanski and Ciprian
   Crainiceanu},
title = {Measurement Error in Nonlinear Models: A Modern Perspective},
year = 2006,
edition = {Second},
publisher = {Chapman and Hall},
}

@article{CartisGoTo10,
 Abstract = {It is shown that the steepest-descent and Newton's
                  methods for unconstrained nonconvex optimization
                  under standard assumptions may both require a number
                  of iterations and function evaluations arbitrarily
                  close to $O(\epsilon^{-2})$ to drive the norm of the
                  gradient below $\epsilon$. This shows that the upper
                  bound of $O(\epsilon^{-2})$ evaluations known for
                  the steepest descent is tight and that Newton's
                  method may be as slow as the steepest-descent method
                  in the worst case. The improved evaluation
                  complexity bound of $O(\epsilon^{-3/2})$ evaluations
                  known for cubically regularized Newton's methods is
                  also shown to be tight.  Read More:
                  http://epubs.siam.org/doi/abs/10.1137/090774100},
Author = {Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
Journal = siopt,
Keywords = {nonconvex; cubic},
Number = {6},
Pages = {2833--2852},
Title = {On the complexity of steepest descent, {N}ewton's and regularized
   {N}ewton's methods for nonconvex unconstrained optimization problems},
Volume = {20},
Year = {2010},
}

@article{CartisGoTo11,
author = {Coralia Cartis and Nicholas I. M. Gould and Philippe L. Toint},
title = {Adaptive cubic regularisation methods for unconstrained optimization.
  {P}art {I}: motivation, convergence and numerical results},
year = 2011,
journal = mathproga,
volume = 127,
pages = {245--295},
comment = {Builds off of Nesterov and Polyak's cubic Newton approaches,
  providing an analysis of convergence without using Hessian information
  (but necessarily losing some factors there). Gives asymptotic guarantees
  of convergence, as well as showing that full solutions to cubic Newton
  step are unnecessary.},
}

@article{CartisGoTo12,
  title={Complexity bounds for second-order optimality in unconstrained
     optimization},
  author={Cartis, Coralia and Gould, Nicholas IM and Toint, Ph L},
  journal={Journal of Complexity},
  volume={28},
  number={1},
  pages={93--108},
  year={2012},
  publisher={Elsevier}
}

@article{CartisGoTo12b,
title = {How Much Patience Do You Have? {A} Worst-Case Perspective
  on Smooth Nonconvex Optimization},
author = {Coralia Cartis and Nicholas I. M. Gould and Philippe L. Toint},
year = 2012,
journal = {Optima},
volume = 88,
}

@article{CartisGoTo17,
	title={Worst-case evaluation complexity and optimality of second-order methods for nonconvex smooth optimization},
	author = {Coralia Cartis and Nicholas I. M. Gould and Philippe L. Toint},
	journal = {arXiv:1709.07180 [math.OC]},
	year={2017}
}

@article{Caruana97,
author = "R.~Caruana",
title = "Multitask Learning",
journal = "Machine Learning",
volume = 28,
number = 1,
pages = "41--75",
year = 1997
}

@inproceedings{CaruanaBaMi96,
	author = "Rich Caruana and Shumeet Baluja and Tom Mitchell",
	title = {Using the Future to ``Sort Out'' the Present:
		{R}ankprop and Multitask Learning for Medical Risk Evaluation},
	booktitle = nips8,
        pages = {959-965},
	year = 1996
}

@inproceedings{CatanzaroKaLeAsDeKeShYeFo09,
author = {Bryan Catanzaro and Shoaib Kamil
 and Yunsup Lee and Krste Asanovic and James Demmel and Kurt Keutzer
 and John Shalf and Kathy Yelick and Armando Fox},
title = {{SEJITS}: Getting Productivity And Performance With Selective,
 Just-In-Time Specialization},
year = 2009,
booktitle = {Proceedings of the 1st Workshop on Programming
 Models for Emerging Architectures},
}

@inproceedings{Catlett9?
,author=	{Jason Catlett}
,title=		{Overpruning large decision trees}
}

@article{CavallantiCeGe11,
author = {Giovanni Cavallanti and Nicol\`{o} Cesa-Bianchi and Claudio
                  Gentile},
title = {Learning noisy linear classifiers via adaptive and selective sampling},
year = 2011,
journal = ml,
volume = 83,
pages = {71--102},
}

@article{CensorEl94,
    author = "Y. Censor and T. Elfving",
    title = "A multiprojections algorithm using {B}regman projections
        in a product space",
    journal = "numerical algorithms",
    volume = "8",
    pages = "221--239",
    year = 1994
}

@article{CensorLe81,
    author = "Y. Censor and A. Lent",
    title = "An iterative row-action method for interval convex programming",
    journal = "Journal of Optimization Theory and Applications",
    volume = 34,
    pages = "321--353",
    year = 1981
}

@article{CensorRe96,
    author= "Y. Censor and S. Reich",
    title = "Iterations of paracontractions and firmly nonexpansive
        operators with applications to feasibility and optimization",
    journal = "Optimization",
    volume = "37",
    pages = "323--339",
    year = 1996
}

@book{CensorZe97,
    author = "Y. Censor and S.A. Zenios",
    title = "Parallel Optimization: Theory, Algorithms, and Applications",
    publisher = "Oxford University Press, New York, NY, USA",
    year = 1997
}

@article{Cesabianchi99,
        author = "Nicol\`o Cesa-Bianchi",
        title = "Analysis of Two Gradient-Based Algorithms for On-Line
                 Regression",
        journal = jcss,
        volume = 59,
        number = 3,
        pages = "392-411",
        year = "1999",
}

@inproceedings{CesabianchiFrHeHaScWa92,
author=		{N. Cesa-Bianchi and Y. Freund and D.P.
		 Helmbold and D. Haussler and R.E. Schapire
		 and Manfred K. Warmuth},
title=		{How to use expert advice},
booktitle=	stoc93,
year=		1993,
pages=		{382--391},
}

@Article{CesabianchiFrHeHaScWa97,
title={How to Use Expert Advice},
author={Nicol{\`o} Cesa-Bianchi and Yoav Freund and David Haussler and
David P. Helmbold and Robert E. Schapire and Manfred K. Warmuth},
journal=jacm,
pages={427--485},
month=may,
year=1997,
volume=44,
number=3
}


@Article{CesabianchiFrHeWa96,
  author = 	 {Nicol{\`o} Cesa-Bianchi and Yoav Freund and David
                  P. Helmbold and Manfred K. Warmuth},
  title = 	 {On-line Prediction and Conversion Strategies},
  journal = 	 ml,
  year = 	 1996,
  volume =	 25,
  pages =	 {71-110}
}

@inproceedings{CesabianchiLoWa93,
author=		{Nicol\`o Cesa-Bianchi and Philip M. Long and Manfred
		 K. Warmuth},
title=		{Worst-case Quadratic Loss Bounds for a Generalization
		 of the {W}idrow-{H}off Rule},
booktitle=	colt93,
month=		jul,
year=		1993,
pages=		{429--438}
}

@article{CesabianchiDiFiShSi97,
	author = "N. Cesa-Bianchi and E. Dictherman and P. Fischer and
		E. Shamir and H.U. Simon",
	title = "Sample-efficient strategies for learning in the presence
		of noise",
	journal  = "Journal of the Association for Computing Machinery",
	year = "(to appear)"
}

@inproceedings{CesaBianchiCoGe02,
	author= {N.~Cesa-Bianchi and A.~Conconi and C.~Gentile},
	title=  {On the Generalization Ability of On-line Learning Algorithms},
	booktitle= nips14,
        pages={359--366},
	year= 2002,
}

@article{CesaBianchiCoGe04,
	author= {N.~Cesa-Bianchi and A.~Conconi and C.~Gentile},
	title=  {On the Generalization Ability of On-line Learning Algorithms},
	journal= ieeeit,
        volume = 50,
        number = 9,
        month = "September",
	year = "2004",
        pages = {2050--2057}
}

@article{CesaBianchiCoGe05,
author = {N. Cesa-Bianchi and A. Conconi and and C. Gentile},
title = {A Second-Order Perceptron Algorithm},
journal = {SIAM Journal on Computing},
volume = {34},
number = {3},
pages = {640--668},
year = {2005}
}

@inproceedings{CesaBianchiDeSh13,
author = {Nicolo Cesa-Bianchi and Ofer Dekel and Ohad Shamir},
title = {Online learning with switching costs and other adaptive adversaries},
year = 2013,
booktitle = nips26,
}

@inproceedings{CesaBianchiGe06,
	author= {N.~Cesa-Bianchi and C.~Gentile},
	title=  "Tracking the Best Hyperplane with a Simple Budget Perceptron",
	booktitle= colt06,
	year= 2006,
        pages={483--498}
}

@inproceedings{CesaBianchiGe06b,
	author= {N.~Cesa-Bianchi and C.~Gentile},
	title=  {Improved Risk Tail Bounds for On-Line Algorithms},
	booktitle= nips19,
	year= 2006
}

@inproceedings{CesaBianchiGeMa13,
author = {Nicolo Cesa-Bianchi and Claudio Gentile and Yishay Mansour},
title = {Regret minimization for reserve prices in second-price auctions},
year = 2013,
booktitle = soda13,
pages = {1190--1204},
}

@article{CesaBianchiGeZa06,
author =        {N. Cesa-Bianchi and C. Gentile and L. Zaniboni},
title =         {Incremental Algorithms for Hierarchical Classification},
journal =       {Journal of Machine Learning Research},
volume  =       {7},
pages =         {31--54},
year =          {2007}
}

@article{CesaBianchiLu99,
author = {Nicol\'o Cesa-Bianchi and G\'abor Lugosi},
title = {On prediction of individual sequences},
year = 1999,
journal = aos,
volume = 27,
number = 6,
pages = {1865--1895},
comment = {Shows that in sequential prediction games with absolute loss,
  the Rademacher complexity provides an upper bound on value of the game.},
}

@article{CesaBianchiLu03,
author = {N. Cesa-Bianchi and G. Lugosi},
title  = {Potential-based algorithms in on-line prediction and game theory},
journal = {Machine Learning Journal},
volume  =       {3},
number = {51},
pages =         {239--261},
year =          {2003}
}

@article{CesabianchiLuSt06,
  title={Regret minimization under partial monitoring},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor and Stoltz, Gilles},
  journal={Mathematics of Operations Research},
  volume={31},
  number={3},
  pages={562--580},
  year={2006},
  publisher={INFORMS}
}

@book{CesaBianchiLu06,
author = {N. Cesa-Bianchi and G. Lugosi},
title  = {Prediction, learning, and games},
publisher = {Cambridge University Press},
year = {2006}
}

@article{CesaBianchiMaSt07,
author = {Nicol\'o Cesa-Bianchi and Yishay Mansour and Gilles Stoltz},
title = {Improved second-order bounds for prediction with expert advice},
year = 2007,
journal = ml,
volume = 66,
number = {2--3},
pages = {321--352},
}

@inproceedings{CestnikKoBr87,
author=	   	{Cestnik, B, I. Kononenkko, and I. Bratko},
title=	   	{Assistant 86: A Knowledge-Elicitation Tool for Sophisticated
	   	Users},
booktitle= 	{Progress in Machine Learning--Proceedings of EWSL 87:
	   	2nd European Working Session on Learning},
address=   	{Bled, Yogoslavia},
year=	   	1987,
editor=	   	{Bratko, I. and N. Lavrac},
month=	   	may,
pages=	   	{31--45}
}

@article{ChaiMoPa11,
  author={Anwei Chai and Miguel Moscoso and George Papanicolaou},
  title={Array imaging using intensity-only measurements},
  journal={Inverse Problems},
  volume={27},
  number={1},
  pages={015005},
  year={2011},
}

@inproceedings{ChagantyLi14,
author = {Arun Chaganty and Percy Liang},
title = {Estimating latent-variable graphical models using moments
   and likelihoods},
year = 2014,
booktitle = icml14,
}

@inproceedings{ChakrabartiShWiYa01,
author = {Amit Chakrabarti and Yaoyun Shi and Anthony Wirth and Andrew Yao},
title = {Informational complexity and the direct sum problem for simultaneous
   message complexity},
year = 2001,
booktitle = focs01,
pages = {270--278},
comment = {Introduces information complexity to show that direct sum problems
  (i.e. problems of the form compute f^m, meaning
   [f(x_1, y_1), f(x_2, y_2), ..., f(x_m, y_m)] where x_i and y_i are bit
  strings on separate computers Alice and Bob) must take at least m * the
  initial communication complexity in the *simultaneous message* (SM) model,
  meaning that messages are sent to a centralized fusion center with no
  backwards message passing. Also shows that communication complexity
  and information complexity are roughly the same in the SM model.}
}

@book{ChambersHa92
,author=	{John M. Chambers and Trevor J. Hastie}
,title=		{Statistical Models in {S}}
,year=		1992
,publisher=	{Wadsworth \& Brooks/Cole}
}

@inproceedings{ChanDiVaVa14,
  title = "Optimal algorithms for testing closeness of discrete distributions",
  author = "Siu-On Chan and Ilias Diakonikolas and Gregory Valiant and Paul Valiant ",
  booktitle= soda14,
  year = "2014",
}

@article{ChandrasekaranJo13,
author = {Venkat Chandrasekaran and Michael I. Jordan},
year = 2013,
journal = pnas,
title = {Computational and statistical tradeoffs via convex relaxation},
volume = 110,
number = 13,
pages = {1181--1190},
}

@article{ChandrasekaranPaWi12,
author = {Venkat Chandrasekaran and Pablo Parrilo and
Alan S. Willsky},
title = {Latent variable graphical model selection via
convex optimization},
year = 2012,
journal = aos,
volume = 40,
number = 4,
pages = {1935–-1967},
}

@article{ChandrasekaranRePaWi12,
author = {Venkat Chandrasekaran and Benjamin Recht and Pablo Parrilo and
Alan S. Willsky},
year = 2012,
title = {The convex geometry of linear inverse problems},
journal = focm,
volume = 12,
number = 6,
pages = {805--849},
}

@article{ChangLi11,
  title={LIBSVM: a library for support vector machines},
  author={Chang, Chih-Chung and Lin, Chih-Jen},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={2},
  number={3},
  pages={27},
  year={2011},
}

@inproceedings{ChanShSo12,
author = {T-H. Hubert Chan and Elaine Shi and Dawn Song},
year = 2012,
title = {Optimal Lower Bound for Differentially
  Private Multi-Party Aggregation},
booktitle = {European Symposium on Algorithms (ESA)},
url = {http://eprint.iacr.org/2012/373.pdf},
}

@inproceedings{ChapelleHa05,
  author = {Chapelle, O. and Z. Harchaoui},
  title = {A Machine Learning Approach to Conjoint Analysis.},
  year = {2005},
  volume = 17,
  booktitle = {Advances in Neural Information Processing Systems}
}

@inproceedings{ChapelleMeZhGr09,
author = {O. Chapelle and D. Metzler and Y. Zhang and P. Grinspan},
title = {Expected reciprocal rank for graded relevance},
year = 2009,
booktitle = {Conference on Information and Knowledge Management},
}

@inproceedings{ChapelleZh09,
  author    = {Olivier Chapelle and
               Ya Zhang},
  title     = {A dynamic bayesian network click model for web search ranking},
  booktitle = {WWW},
  year      = {2009},
  pages     = {1-10},
}

@inproceedings{ChapelleWeSc03,
   author = {Chapelle, O. and J. Weston and B. Sch\"olkopf},
   title = {Cluster Kernels for Semi-Supervised Learning.},
   year = {2003},
   volume = {15},
   booktitle = {Advances in Neural Information Processing Systems}
}

@inproceedings{Charikar02,
author = {Moses Charikar},
title = {Similarity estimation techniques from rounding algorithms},
year = 2002,
booktitle = stoc02,
}

@unpublished{Charniak??,
author=   	{Charniak, Eugene},
title=    	{The Bayesian Basis of Common Sense Medical Diagnosis},
year=     	{??},
comment=  	{Where was this published??.
	   	Argues in favor of Bayesian approach for medical diagnosis.}
}

@article{Chatterjee07,
author = {S. Chatterjee},
title = {Stein's method for concentration inequalities},
journal = {Probability Theory and Related Fields},
year = 2007,
volume = 138,
pages = {305--321},
}

@article{Chatterjee05,
author = {Sourav Chatterjee},
title = {An error bound in the {S}udakov-{F}ernique inequality},
journal = {arXiv:0510424 [math.PR]},
year = 2005,
}

@techreport{ChatterjeeDi15,
author = {Sourav Chatterjee and Persi Diaconis},
title = {The sample size required in importance sampling},
year = 2015,
institution = {Stanford University Department of Statistics},
}

@inproceedings{ChatterjeeDuLaZh16,
title = {Local Minimax Complexity of Stochastic Convex Optimization},
author = {Sabyasachi Chatterjee and John Duchi
   and John Lafferty and Yuancheng Zhu},
year = 2016,
booktitle = nips29,
}

@article{ChatterjeeDuLaZh16a,
title = {Local Minimax Complexity of Stochastic Convex Optimization},
author = {Sabyasachi Chatterjee and John Duchi
   and John Lafferty and Yuancheng Zhu},
year = 2016,
journal = {arXiv:1605.07596 [stat.ML]},
}

@inproceedings{ChaturapruekDuRe15,
author = {Sorathan Chaturapruek and John C. Duchi and Christopher R\'e},
title = {Asynchronous stochastic convex optimization:
the noise is in the noise and {SGD} don't care},
year = 2015,
booktitle = nips28,
}

@inproceedings{ChaudhuriHs11,
author = {Kamalika Chaudhuri and Daniel Hsu},
title = {Sample complexity bounds for differentially private learning},
year = 2011,
booktitle = colt11,
comment = {Considers differentially private classification algorithms where
  one learns using ERM directly on 0-1 loss. Two main results: (1) algorithms
  that are differentially private and have data coming from [0, 1] won't
  work and (2) with some side information/constraints on the distribution,
  learning is possible. For (1), they construct a lower bound using thresholds
  on [0, 1], but put most of the probability mass in a very tight window
  around the correct threshold. Then differential privacy of the released
  classifier causes more deviation than this tight window, which makes the
  problem hard. For (2), they show that given a secondary distribution that
  is smooth (something like strongly absolutely continuous, almost in a
  Lipschitzian sense) w.r.t. the data generating distribution, then covering
  the secondary distribution with hypotheses from the hypothesis space,
  and selecting (differentially privately) the best one from that space
  gives sample complexity scaling as 1 / (\alpha \epsilon) + 1 / \epsilon^2,
  where \alpha is differential privacy parameter.},
}

@inproceedings{ChaudhuriHs12,
author = {Kamalika Chaudhuri and Daniel Hsu},
title = {Convergence rates for differentially private statistical
estimation},
year = 2012,
booktitle = icml12,
comment = {Gives lower bounds on sample complexity (for 1 dimensional problems)
  scaling (roughly) as 1 / (\epsilon \alpha) for \alpha-differentially private
  algorithms in expected convergence rate. Shows how these convergence
  rates are related to sensitivity in the sense of robust statistics--both
  upper and lower bounds depend on them. Lower bound uses fact that
  a given private algorithm, given similar datasets, cannot output two
  very different things. Upper bounds via Laplace perturbation of 1-dimensional
  quantities match lower bounds. (Interesting that amount of perturbation
  seems very low. Also algorithms may be computationally inefficient in
  some cases, though special case of M-estimation works.)},
}

@inproceedings{ChaudhuriKaNeSa15,
  title={Convergence rates of active learning for maximum likelihood estimation},
  author={Kamalika Chaudhuri and Sham M. Kakade and Praneeth Netrapalli and Sujay Sanghavi},
  booktitle=nips28,
  pages={1090--1098},
  year={2015}
}

@article{ChaudhuriMoSa11,
author = {Kamalika Chaudhuri and Claire Monteleoni and Anand D. Sarwate},
title = {Differentially private empirical risk minimization},
year = 2011,
journal = jmlr,
volume = 12,
pages = {1069--1109},
comment = {
Uses differential privacy as measure of privacy for SVM (and similar ERM
problems). Studies both output perturbation--adding noise to learned weight
vector--and objective perturbation, which involves adding a random linear
term to ERM objective. Theory and practical results in paper suggest
objective perturbation is better. Analysis follows from usual stability
of ERM, then additional noise to make sure things are appropriately
smooth (and densities exist). The objective perturbation technique requires
showing that (under suitable differentiability conditions) there is a bijection
between the output weight vector and perturbing linear term. Then
one can compute a change of variables and use that to talk about the
density of the final weight vector based on the distribution of the
perturbing linear term. Convergence rates are a bit odd, and
algorithm to do model selection while maintaining privacy destroys rates
of convergence.
},
}

@inproceedings{ChaudhuriSaSi12,
author = {Kamalika Chaudhuri and Anand Sarwate and Kaushik Sinha},
title = {Near-optimal algorithms for differentially-private principal
  components},
year = 2012,
booktitle = nips25,
url = {http://arxiv.org/abs/1207.2812},
comment = {Shows exponential mechanism for releasing orthogonal vectors
  (matrices), uses matrix Bingham distribution, which is hard to compute but
  may be sampleable. Lower bound provides bounds on error for *sample*
  not population PCA vectors, uses standard packing with slightly different
  datasets (by changing small numbers of entries).},
}

@inproceedings{ChaudhuriTe15,
author = {Sougata Chaudhuri and Ambuj Tewari},
title = {Online Ranking with Top-1 Feedback},
booktitle = aistat15,
year = 2015,
}

@inproceedings{Cheeseman83,
author=   	{Cheeseman, Peter C.},
title=    	{A Method of Computing Generalized Bayesian Probability Values
	   	for Expert Systems},
booktitle= 	{Proceedings Eighth International Conference on Artificial
	   	Intelligence (Karlruhe, West Germany)},
year=      	1983,
month=     	Aug,
pages=     	{198--202},
comment=   	{Describes iterative graph-oriented method for computing
	   	a maximum-entropy distribution subject to constraints.}
}

@inproceedings{Cheeseman84,
author=   	{Cheeseman, Peter C.},
title=    	{Learning of Expert Systems from Data},
booktitle= 	{Proceedings of the Workshop on Principles of Knowledge-Based
	   	Systems},
year=      	1984,
month=     	Dec,
pages=     	{115--122},
comment=   	{Describes a `message-length' approach to inferring significant
	   	contingencies in a contingency table.}
}

@inproceedings{Cheeseman85,
author=   	{Cheeseman, Peter C.},
title=    	{In Defense of Probability},
booktitle= 	{Proceedings of the Ninth International Joint Conference on
	   	Artificial Intelligence},
year=     	1985,
pages=    	{1002--1009},
comment=  	{Argues in favor of subjective Bayesianism by refuting some
	  	common misconceptions.}
}

@article{Cheeseman88,
author = 	{Cheeseman, Peter C.},
title = 	{An inquiry into computer understanding},
journal = 	{Computational Intelligence},
year = 		1988,
month = 	Feb,
volume = 	4,
number = 	1,
pages = 	{58--66},
comment = 	{More defense of Bayesian inference}
}

@inproceedings{Cheeseman88b,
author = 	{Cheeseman, Peter C. and Matthew Self and
		Jim Kelly and Will Taylor and Don Freeman and
		John Stutz},
title = 	{Bayesian Classification},
booktitle = 	{AAAI 88 Proceedings},
year = 		1988,
pages = 	{607--611}
}

@phdthesis{Chen97
,author=        {Lei Chen}
,title=         {Applications of play against past strategies in
                  repetitions of a game}
}

@article{ChenCa15,
author = {Yuxin Chen and Emmanuel Cand\`{e}s},
title = {Solving random quadratic systems of equations is nearly as
  easy as solving linear systems},
year = 2015,
journal = {Communications on Pure and Applied Mathematics},
volume = {To appear},
}

@article{ChenCh04,
author = "J-H.~Chen and C-S.~Chen",
title = {Reducing {SVM} classification time using multiple mirror classifiers},
month = "April",
year = 2004,
journal = "IEEE transactions on systems, man and cybernetics -- part {B}: {C}ybernetics",
part = "B",
volume = 34,
number = 2,
pages = {1173--1183}
}

@article{ChengSaBa06,
title = {Large-scale prediction of disulphide bridges using kernel methods,
two-dimensional recursive neural networks, and weighted graph matching},
author = {J. Cheng and H. Saigo and P. Baldi},
year = 2006,
journal = {Proteins: Structure, Function, and Bionformatics},
volume = 62,
pages = {617--629},
number = 3,
}

@article{ChengSh13,
author = {Guang Cheng and Zuofeng Shang},
title = {Joint Asymptotics for Semi-Nonparametric Regression Models with Partially
  Linear Structure},
year = 2013,
journal = {arXiv:1311.2628 [math.ST]},
}

@article{ChengalvarayanDe98,
author = 	{R. Chengalvarayan and L. Deng},
title = 	{Speech Trajectory Discrimination Using the  Minimum Classification Error Learning},
journal = 	{IEEE Trans. Speech and Audio Proc.},
year =      1998,
volume = 	6,
number = 	6,
pages = 	{505--515},
}

@article{ChenGiTr12,
author = {Richard Chen and Alex Gittens and Joel A. Tropp},
title = {The masked sample covariance estimator: an analysis using matrix
concentration inequalities},
year = 2012,
journal = {Information and Inference},
volume = {to appear},
}


@article{ChenMe95,
author = {C. Chen and O. L. Mengasarian},
year = 1995,
title = {Smoothing methods for convex inequalities and linear complementarity problems},
journal = {Mathematical Programming},
volume = 71,
pages = {51--69},
comment = {Studies the effect of replacing $\max\{0, x\}$ with
                  logistic functions that more and more closely
                  approximate the max; specifically focuses on
                  complimentarity problems},
}

@article{ChenMa96,
author = {C. Chen and O. L. Mangasarian},
title = {A class of smoothing functions for nonlinear and mixed complementarity problems},
journal = {Computational Optimization and Applications},
year = 1996,
volume = 5,
pages = {97--138},
comment = {A fairly systematic study of general approximations to the
                  max(0, x) function, which has applications in
                  complementarity and in exact penalty methods},
}

@article{ChenRo97,
author = {G. Chen and R. T. Rockafellar},
title = {Convergence rates in forward-backward splitting},
year = 1997,
journal = siopt,
volume = 7,
number = 2,
pages = {421--444},
}

@article{ChenPeQi09,
  title={Effects of data dimension on empirical likelihood},
  author={S. X. Chen and L. Peng and Y. L. Qin},
  journal={Biometrika},
  volume=96,
  number=3,
  pages={711--722},
  year=2009,
  publisher={Biometrika Trust}
}

@article{ChenVaSiKo15,
  title={Signal representations on graphs: Tools and applications},
  author={Siheng Chen and Roham Varma and Aarti Singh and Jelena Kova{\v{c}}evi{\'c}},
  journal={arXiv:1512.05406 [cs.AI]},
  year={2015}
}

@article{CheriditoDeKu04,
author = {Patrick Cheridito and Freddy Delbaen and Michael Kupper},
title = {Coherent and convex monetary risk measures for bounded c\`{a}dl\`{a}g processes},
year = 2004,
journal = {Stochastic Processes and their Applications},
volume = 112,
number = 1,
pages = {1--22},
}

@article{ChoOhNiStEiChMaWaThSo13,
author = {Minseon Cho and Seung Soo Oh and Jeff Nie
and Ron Stewart and Michael Eisenstein
and James Chambers and Jamey D. Marth and Faye Walker
and James A. Thomson and H. Tom Soh},
year = 2013,
title = {Quantitative selection and parallel characterization of aptamers},
journal = pnas,
volume = 110,
number = 46,
}

@inproceedings{ChoiHiHiMaNaPeSiWh98,
	author = "J. Choi and D. Hindle and J. Hirschberg and
		I. Magrin-Chagnolleau and C. Nakatani and F. Pereira
		and A. Singhal and S. Whittaker",
	title = "{SCAN} - speech content based audio navigator:
		A systems overview",
	booktitle = "Proceedings of the Fifth International Conference on
		Spoken Language Processing",
	year = 1998
}

@book{Chomsky65,
	author = "Noam Chomsky",
	title = "Aspects of the theory of syntax",
	publisher = "{MIT Press}",
	year = 1965
}


@article{ChorGo88,
author=		{B. Chor and O. Goldreich},
title=		{Unbiased bits from sources of weak randomness and
		 probabilistic communication complexity},
journal=	sicomp,
volume=		17,
year=		1988,
pages=		{230--261}
}

@article{ChowlaHeMo51,
author = {S. Chowla and I. N. Herstein and W. K. Moore},
title = {On recursions connected with symmetric groups {I}},
year = 1951,
journal = {Canadian Journal of Mathematics},
volume = 3,
pages = {328--334},
comment = {Shows that the "telephone numbers", or the
  Hosoya index of the complete graphs (that is,
  number of matchings in the graph), grow
  at most as $\exp(\half n \log n)$, with lower
  order terms.},
}

@book{ChowTe12,
  title={Probability theory: independence, interchangeability, martingales},
  author={Chow, Yuan Shih and Teicher, Henry},
  year=2012,
  publisher={Springer Science \& Business Media}
}

@article{Christie82,
  title={The stochastic behavior of common stock variances: Value, leverage and interest rate effects},
  author={Christie, Andrew A},
  journal={Journal of financial Economics},
  volume=10,
  number=4,
  pages={407--432},
  year=1982,
  publisher={Elsevier}
}

@inproceedings{ChuKe05,
title = {New approaches to support vector ordinal regression},
author = {W. Chu and S. Keerthi},
year = 2005,
booktitle = icml05,
pages = {321--328}
}

@inproceedings{Chung94
, author =      "Thomas H. Chung"
, title =       "Approximate methods for sequential decision making using expert advice"
, booktitle =   colt94
, year =        1994
, pages =       {183--189}
}

@phdthesis{Chung94b
,author=	{Thomas H. Chung}
,title=		{Minimax learning in iterated games via distributional
		 majorization}
}

@Book{Chung98,
  author =	 {F.~R.~K. Chung},
  title = 	 {Spectral Graph Theory},
  publisher = 	 {AMS},
  year = 	 1998
}

@unpublished{ChurchGa??
,author=	{Kenneth W. Church and William A. Gale}
,title=		{Poisson mixtures}
}

@article{Chvatal79,
author=		{V. Chvatal},
title=		{A greedy heuristic for the set covering problem},
journal=	{Mathematics of Operations Research},
volume=		4,
number=		3,
year=		1979,
pages=		{233--235}
}


@Book{Chvatal80,
  author = 	 {V. Chvatal},
  title = 	 {Linear Programming},
  publisher = 	 {Freeman},
  year = 	 {1980}
}

@article{CiollaroCiFrGeLeOCWa14,
author = {Mattia Ciollaro and Jessi Cisewski and Peter E. Freeman and
Christopher R. Genovese and Jing Lei and Ross O’Connell and Larry Wasserman},
title = {Functional regression for quasar spectra},
year = 2014,
journal = {arXiv:1404.3168 [stat.ME]},
url = {http://arxiv.org/abs/1404.3168},
}

@article{ClarkeBa90,
author = {Bertrand S. Clarke and Andrew R. Barron},
title = {Information-theoretic asymptotics of Bayes Methods},
year = 1990,
journal = ieeeit,
volume = 36,
number = 3,
pages = {453--471},
}

@unpublished{ClarkNi87,
author=   	{Peter Clark and Tim Niblett},
title=    	{The CN2 Induction Algorithm},
year=     	1987,
institution= 	{The Turing Institute},
comment=  	{Experimental study of rule induction, with accomodation for
		noise.}
}

@inproceedings{ClemenconLuVa05,
  author = "S. Cl\'emen\c{c}on and G. Lugosi and N. Vayatis",
  title = "Ranking and Scoring Using Empirical Risk Minimization",
  booktitle = colt05,
  page = "1--15",
  year = 2005
}

@article{ClemenconLuVa08,
author = {S.\ Cl\'emen\c{c}on and G.\ Lugosi and N.\ Vayatis},
title = {Ranking and empirical minimization of {$U$}-statistics},
year = 2008,
journal = aos,
volume = 36,
number = 2,
pages = {844--874},
}

@article{ClarkeAnPeCaMoZo11,
author = {Geraldine M. Clarke and Carl A. Anderson and Fredrik H. Pettersson
and Lon R. Cardon and Andrew P. Morris and Krina T. Zondervan},
title = {Basic statistical analysis in genetic case-control studies},
year = 2011,
journal = {Nature Protocols},
volume = 6,
number = 2,
pages = {121--133},
}

@inproceedings{ClarkNi87b,
author=	   	{Clark, P. and T. Niblett},
title=	   	{Induction in Noisy Domains},
booktitle= 	{Progress in Machine Learning--Proceedings of EWSL 87:
	   	2nd European Working Session on Learning},
address=   	{Bled, Yogoslavia},
year=	   	1987,
editor=	   	{Bratko, I. and N. Lavrac},
month=	   	may,
pages=	   	{11--30}
}

@article{Clarkson36,
author = {J.A. Clarkson},
title = {Uniformly convex spaces},
year = 1936,
journal = {Transactions of the American Mathematical Society},
volume = 40,
pages = {396--414},
}

@article{ClarksonHaWo12,
author = {Kenneth Clarkson and Elad Hazan and David Woodruff},
title = {Sublinear optimization for machine learning},
journal = jacm,
year = 2012,
volume = 59,
number = 5,
}

@inproceedings{ClarksonMo99,
author=	   	{P. Clarkson and P. Moreno},
title=	   	{On The Use Of Support Vector Machines For Phonetic Classification},
booktitle= 	{Proceedings of the International Conference on Acoustics, Speech and Signal Processing 1999},
address=   	{Phoenix, Arizona},
year=	   	1999,
}

@article{ClausenDrGrKa91,
author=		{Michael Clausen and Andreas Dress and Johannes
		 Grabmeier and Marek Karpinski},
title=		{On zero-testing and interpolation of {$k$}-sparse
		 multivariate polynomials over finite fields},
journal=	tcs,
volume=		84,
year=		1991,
pages=		{151--164}
}

@article{ClausetShNe09,
author = {Aaron Clauset and Cosma Shalizi and M. E. J. Newman},
year = 2009,
title = {Power-law distributions in empirical data},
journal = {SIAM Review},
pages = {661--703},
volume = 51,
number = 4,
}

@incollection{CoatesNg12,
author = {Adam Coates and Andrew Y. Ng},
title = {Learning feature representations with $k$-means},
year = 2012,
booktitle = {Neural Networks: Tricks of the Trade, Reloaded},
publisher = {Springer},
}

@inproceedings{Cohen95
,author=	{William Cohen}
,title=		{Fast Effective Rule Induction}
,booktitle=	{Proceedings of the Twelfth International Conference
		on Machine Learning}
,pages=		{115-123}
,year=		1995
}

@inbook{CohenFe68,
editor=   	{Cohen, Paul R. and Edward A. Feigenbaum},
title=    	{The Handbook of Artificial Intelligence},
volume=   	3,
year=     	1968,
chapter=  	{XIV: {\em Learning and Inductive Inference}},
publisher= 	{William Kaufman, Inc.},
address=   	{Los Altos, California},
pages=     	{324--511}
}

@InProceedings{CohenScSi97,
  author = 	 {W.~W.~Cohen and Robert E. Schapire and Yoram Singer},
  title = 	 {Learning to order things},
  booktitle = nips10,
  year =	 1998
}

@Article{CohenScSi99,
  author = 	 {W.~W.~Cohen and R.~E.~Schapire and Y.~Singer},
  title = 	 {Learning to order things},
  journal = 	 jair,
  year = 	 1999,
  volume =	 10,
  pages =	 {243-270},
}

@InProceedings{CohenSi96,
  author = 	 {William W. Cohen and Yoram Singer},
  title = 	 {Context-sensitive learning methods for text categorization},
  booktitle = 	 sigir96,
  year =	 1996,
  pages =	 {307-315}
}

@Article{CohenSi99b,
  author =   {William W. Cohen and Yoram Singer},
  title =    {Context-sensitive learning methods for text categorization},
  journal =  {ACM Transactions on Information Systems},
  volume =   17,
  number =   2,
  pages =    {1-33},
  year = 1999
}

@article{CohnAtLa94,
	author = "D. Cohn and L. Atlas and R. Ladner",
	title = "Improving generalization with active learning",
	journal = "Machine Learning",
	volume = 15,
	pages = "201--221",
	year = 1994
}

@article{CoifmanWi92,
	author = "R. Coifman and M. Wickerhauser",
	title = "Entropy-Based Algorithms for Best Basis Selection",
	journal = "IEEE Transactions on Information Theory",
	volume = 39,
	pages = "713--718",
	year = 1992
}

@article{CollobertBe01,
author=   	{Ronan Collobert and Samy Bengio},
title=    	{{SVM}torch: Support Vector Machines
                 for Large-Scale Regression Problems},
journal=  	"Journal of Machine Learning Research",
year=     	2001,
volume=   	1,
pages=    	{143--160},
}

@techreport{CollobertBeMa02,
        Author = {R. Collobert and S. Bengio and J. Mari\'ethoz},
        Date-Added = {2006-03-03 13:37:47 +0100},
        Date-Modified = {2006-03-03 13:39:45 +0100},
        Institution = {IDIAP},
        Number = {46},
        Read = {No},
        Title = {Torch: a modular machine learning software library},
        Type = {IDIAP-RR},
        Year = {2002}}

@misc{ Collins97,
  author = "Michael Collins",
  title = "The {E}{M} Algorithm",
  url = "citeseer.nj.nec.com/collins97em.html" }

@inproceedings{CollinsDaSc01,
  author = "M. Collins and S. Dasgupta and R. Schapire",
  title = "A generalization of principal component analysis to the exponential family",
  booktitle = nips13,
  year = 2001
}

@InProceedings{CollinsDu02,
    author = "M.~Collins and N.~Duffy",
	title = "New Ranking Algorithms for Parsing and Tagging:
		Kernels over Discrete Structures, and the Voted Perceptron",
	booktitle = "30th Annual Meeting of the Association for Computational
		Linguistics",
	year = 2002,
}

@InProceedings{CollinsSi99,
    author = "M. Collins and Y. Singer",
    title = "Unsupervised Models for Named Entity Classification",
    booktitle = "Proceedings of the Joint SIGDAT Conference on
        Empirical Methods in Natural Language Processing and
        Very Large Corpora",
    year = 1999
}

@InProceedings{Collins02,
    author = "M. Collins",
    title = "Discriminative Training Methods for Hidden Markov Models:
      Theory and Experiments with Perceptron Algorithms",
    booktitle = "Conference on Empirical Methods in Natural Language
      Processing",
    year = 2002
}

@inproceedings{Collins02a,
  author = "M. Collins",
  title = "Ranking Algorithms for Named-Entity Extraction: Boosting and the Voted Perceptron",
  booktitle = "40th Annual Meeting of the Association for Computational	Linguistics",
  year = 2002
}



@InProceedings{Collins00,
    author = "M. Collins",
    title = " Discriminative Reranking for Natural Language Parsing",
	booktitle = ml00,
	year = 2000
}

@InProceedings{Collins02short,
    author = "M. Collins",
    title = "Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms",
	booktitle = "EMNLP",
	year = "2002"
}


@article{CollinsScSi02,
	title = "Logistic Regression, {A}da{B}oost and {B}regman Distances",
	author = "M.~Collins and R.E. Schapire and Y.~Singer",
	journal = "Machine Learning",
	volume = 47,
	number = "2/3",
	pages = "253--285",
	year = 2002
}

@InProceedings{CohenSi99,
  author = 	 {William W. Cohen and Yoram Singer},
  title = 	 {A Simple, Fast, and Effective Rule Learner},
  booktitle = 	 aaai99,
  year =	 1999
}

@article{CombettesWa05,
author = {P. Combettes and V. Wajs},
title = {Signal Recovery by Proximal Forward-Backward Splitting},
journal = {Multiscale Modeling and Simulation},
volume = 4,
number = 4,
pages = {1168--1200},
year = 2005,
comment = {Theoretical look at "proximal methods," aka FOLOS, and convergence
  analysis in Hilbert spaces. No good rates of convergence, though}
}

@BOOK{Condorcet1785,
  AUTHOR = {N.~Condorcet},
  TITLE = {Essai sur l'Application de l'Analyse \`a la Probabilit\'e
 des D\'ecisions Rendues \`a la Pluralit\'e des Voix},
  ADDRESS = {Paris},
  YEAR = {1785}
}

@article{Conlisk93
,author=	{John Conlisk}
,title=		{Adaptation in games: Two solutions to the {Crawford} puzzle}
,year=		1993
}

@article{Conlisk93b
,author=	{John Conlisk}
,title=		{Adaptive tactics in games: Further solutions to the
		 {Crawford} puzzle}
,year=		1993
}

@book{ConnGoTo00,
author = {Andrew R. Conn and Nicholas I. M. Gould and Philippe L. Toint},
title = {Trust Region Methods},
year = 2000,
publisher = {SIAM},
series = {MPS-SIAM Series on Optimization},
}

@book{ConnScVi09,
author = {A. Conn and Katja Scheinberg and L. Vicente},
title = {Introduction to Derivative-Free Optimization},
year = 2009,
publisher = {SIAM},
series = {MPS-SIAM Series on Optimization},
volume = 8,
}

@InProceedings{Cont06,
	author = 	 {A. Cont},
	title = 	 {Realtime Audio to Score Alignment for Polyphonic Music Instruments Using Sparse 	Non-negative constraints and Hierarchical {HMM}s},
	booktitle = 	 {IEEE International Conference in Acoustics and Speech Signal Processing},
	year =	 2006
}


@article{Cooper62,
author = 	{P. Cooper},
title = 	{The hypersphere in pattern recognition},
journal = 	infctrl,
year = 		1962,
volume = 	5,
pages = 	{324--346}
}

@article{Corcoran98,
  title={Bartlett adjustment of empirical discrepancy statistics},
  author={Corcoran, Stephen A},
  journal={Biometrika},
  pages={967--972},
  year=1998,
  publisher={JSTOR}
}

@book{CormenLeRi90,
author=		{Thomas H. Cormen and Charles E. Leiserson and
		 Ronald L. Rivest},
title=		{Introduction to Algorithms},
publisher=	{MIT Press},
year=		{1990}
}

@book{CormenLeRiSt01,
author =        {Thomas H. Cormen and Charles E. Leiserson and
		 Ronald L. Rivest and Clifford Stein},
title =         {Introduction to Algorithms},
publisher =     {MIT Press},
year =          2001
}

@Article{CortesVa95,
  author = 	 {C.~Cortes and V.~Vapnik},
  title = 	 {Support-Vector Networks},
  journal = 	 ml,
  year = 	 1995,
  volume =	 20,
  number =	 3,
  month =	 {September},
  pages =	 {273--297}
}

@InProceedings{CortesMo04,
  author =       {C. Cortes and M. Mohri},
  title =        {Confidence Intervals for the Area Under the ROC Curve},
  booktitle =  nips17,
  year =         {2004},
}

@article{CossockZh08,
author = {D. Cossock and T. Zhang},
title = {Statistical Analysis of {B}ayes Optimal Subset Ranking},
journal = ieeeit,
volume = 16,
year = 2008,
pages = {1274--1286},
}

@article{Cover65,
author = 	{Cover, Thomas M.},
title = 	{Geometrical and Statistical Properties of Systems of
		 Linear inequalities with applications to pattern
		 recognition},
journal = 	{IEEE Transactions on Electronic Computers},
volume = 	{EC-14},
year = 		1965,
number = 	3,
pages = 	{326--334}
}

@article{Cover65b,
author=	{Thomas M. Cover},
title=		{Behavior of sequential predictors of binary
		sequences},
journal = {Trans. 4th Prague Conf. Information Theory Statistical Decision Functions,
Random Processes},
year= {1965}
}

@article{Cover67,
author=	  	{Cover, T.M. and P.E. Hart},
title=	  	{Nearest Neighbor Pattern Classification},
journal=  	{IEEE Transactions in Information Theory},
year=     	1967,
month=    	jan,
volume=   	{IT-13},
number=   	1,
pages=    	{21--27}
}

@incollection{Cover69,
author=   	{Cover, Thomas M.},
title=    	{Learning in Pattern Recognition},
booktitle=  	{Methodologies of Pattern Recognition},
publisher=  	{Academic Press},
year=     	1969,
pages=    	{111--132},
comment=  	{Bayesian classification procedures. Learning with finite
		memory.}
}

@article{Cover84
,author=	{Thomas M. Cover}
,title=		{An algorithm for maximizing expected log investment
		return}
}

@article{Cover91
,author=	{Thomas M. Cover}
,title=		{Universal Portfolios}
,journal=	{Mathematical Finance}
,volume=	1
,number=	1
,month=		jan
,year=		1991
,pages=		{1--29}
}

@Article{CoverOr96,
  author = 	 {T. M. Cover and E. Ordentlich},
  title = 	 {Universal Portfolios With Side Information},
  journal = 	 ieeeit,
  year = 	 1996,
  month =	 {March}
}

@article{CoverSh77
,author=	{Thomas M. Cover and Aaron Shenhar}
,title=		{Compound {B}ayes predictors for sequences with
		 apparent {M}arkov structure}
,journal=	{IEEE Transactions on Systems, Man, and Cybernetics}
,volume=	{SMC-7}
,number=	6
,month=		jun
,year=		1977
,pages=		{421--424}
}

@book{CoverTh91,
author=		{T.~M.~Cover and J.~A.~Thomas},
title=		{Elements of Information Theory},
publisher=	{Wiley},
year=		1991
}

@book{CoverTh06,
author = {Thomas M. Cover and Joy A. Thomas},
title = {Elements of Information Theory, Second Edition},
publisher = {Wiley},
year = 2006,
}

@incollection{CoverWa76,
author=   	{Cover, T. M. and T. J. Wagner},
title=    	{Topics in Statistical Pattern Recognition},
booktitle=  	{Communication and Cybernetics: Digital Pattern Recognition},
chapter=  	2,
editor=   	{K. S. Fu},
year=    	1976,
volume=   	10,
publisher=  	{Springer-Verlag},
comment=  	{Learning classifiers. Distribution-free techniques. Modelling
		by gambling games.  Finite memory learning.}
}

@article{Cox46
,author=	{R. T. Cox}
,title=		{Probaility, Frequency and Reasonable Expectation}
,year=		1946
}

@book{CoxCo94,
author = {T. Cox and M. Cox},
title = {Multidimensional Scaling},
publisher= {Chapman and Hall, London},
year = {1994},
}




@book{CoxeterMo72,
author= 	{H. S. M. Coxeter and W. O. J. Moser},
title= 		{Generators and Relations for Discrete Groups},
publisher= 	{Springer-Verlag},
year= 		{1972},
address= 	{New York},
edition= 	{third},
comment= 	{high-powered book on groups with, among other things,
		good discussion of Cayley graphs.}
}

@article{CoxKaKi11,
author = {Lawrence H. Cox and Alan F. Karr and Satkartar K. Kinney},
title = {Risk-utility paradigms for statistical disclosure limitation:
 {H}ow to think, but not how to act},
year = 2011,
journal = {International Statistical Review},
volume = 79,
number = 2,
pages = {160--199},
}

@InProceedings{CrammerGiNaTi02,
  author = 	 {K. Crammer and R. Gilad-Bachrach and A. Navot and N. Tishby},
  title = 	 {Margin analysis of the LVQ algorithm},
  booktitle =  nips15,
  year = 	 {2002},
}

@inproceedings{CrammerSi00,
	author = "K.~Crammer and Y.~Singer",
	title = "On the Learnability and Design of Output Codes for
		Multiclass Problems",
	booktitle = colt00,
	year = 2000
}

@inproceedings{CrammerSi00a,
	author = "K.~Crammer and Y.~Singer",
	title = "Improved Output Coding for Classification Using Continuous Relaxation",
        booktitle = nips13,
	year = 2000
}



@inproceedings{CrammerSi01,
	author = "K.~Crammer and Y.~Singer",
	title = "Ultraconservative Online Algorithms for Multiclass Problems",
	booktitle = colt01,
	year = 2001
}


@article{CrammerSi01a,
	author = "K.~Crammer and Y.~Singer",
	title = "On the algorithmic Implementation of
		Multiclass Kernel-based Vector Machines",
	journal = "Journal of Machine Learning Research",
	volume = 2,
	pages = "265--292",
	year = "2001"
}


@inproceedings{CrammerSi01b,
	author = "K.~Crammer and Y.~Singer",
	title = "Pranking with Ranking",
	booktitle = nips14,
	year = "2001"
}


@inproceedings{CrammerSi02,
	author = "K.~Crammer and Y.~Singer",
	title = "A New Family of Online Algorithms for Category Ranking",
	booktitle = sigir02,
	year = "2002"
}



@article{CrammerSi02a,
	author = "K.~Crammer and Y.~Singer",
	title = "On the Learnability and Design of Output Codes for Multiclass Problems",
	journal = "Machine Learning",
	volume = 47,
	year = "2002"
}



@article{CrammerSi03,
	author = "K.~Crammer and Y.~Singer",
	title = "A New Family of Online Algorithms for Category Ranking",
	journal = "Journal of Machine Learning Research",
	volume = 3,
	pages = "1025--1058",
	year = "2003"
}


@article{CrammerSi03a,
	author = "K.~Crammer and Y.~Singer",
	title = "Ultraconservative Online Algorithms for Multiclass Problems",
	journal = "Journal of Machine Learning Research",
	volume = 3,
	pages = "951-991",
	year = "2003"
}


@inproceedings{CrammerSi03b,
	author = "K.~Crammer and Y.~Singer",
	title = "Learning Algorithms for Enclosing Points in Bregmanian Spheres",
	booktitle = colt03,
	year = "2003"
}


@inproceedings{CrammerKaSi03,
	author = "K.~Crammer and J.~Kandola and Y.~Singer",
	title = "Online Classification on a Budget",
	booktitle = nips16,
	year = "2003"
}

@inproceedings{CrammerDeShSi03,
	author = "K.~Crammer and O. Dekel and S. Shalev-Shwartz and Y.~Singer",
	title = "Online Passive Aggressive Algorithms",
	booktitle = nips16,
	year = "2003"
}


@article{CrammerSi05,
	author = "K.~Crammer and Y.~Singer",
	title = "Online Ranking by Projecting",
	journal = "Neural Computation",
        year = "2005",
        volume = "17",
        number = "1",
        page = "145--175"
}

@inproceedings{CrammerSi05a,
	author = "K.~Crammer and Y.~Singer",
	title = "Loss Bounds for Online Category Ranking",
	booktitle = colt05,
	year = 2005
}


@TechReport{CrammerDeKeShSi05,
  author = 	 {K.~Crammer and O. Dekel and J. Keshet and S. Shalev-Shwartz and Y.~Singer},
  title = 	 {Online Passive Aggressive Algorithms},
  institution =  {The Hebrew University},
  year = 	 {2005}
}

@article{CrammerDeKeShSi06,
  author = 	 {K.~Crammer and O. Dekel and J. Keshet and S. Shalev-Shwartz and Y.~Singer},
  title = 	 {Online Passive Aggressive Algorithms},
  journal =  {Journal of Machine Learning Research},
  year = 	 {2006},
  volume=  {7},
  month=    {Mar},
  pages =     {551--585}
}


@inproceedings{CrammerCh04,
	author = "K.~Crammer and G.~Chechik",
	title = "A Needle in a Haystack: Local One-Class Optimization",
	booktitle = icml04,
	year = "2004"
}


@inproceedings{CrammerCh04,
	author = "K.~Crammer and G.~Chechik",
	title = "A Needle in a Haystack: Local One-Class Optimization",
	booktitle = icml04,
	year = "2004"
}

@phdthesis{Crammer05,
author = 	{K.~Crammer},
title  = 	{Online Learning for Complex Categorial Problems},
school = 	{Hebrew University of Jerusalem},
year = 		{2005},
note =          {to appear}
}

@inproceedings{CraswellZoTaRa08,
  author    = {Nick Craswell and
               Onno Zoeter and
               Michael J. Taylor and
               Bill Ramsey},
  title     = {An experimental comparison of click position-bias models},
  booktitle = {Web Search and Data Mining (WSDM)},
  year      = {2008},
  pages     = {87-94},
}

@PhdThesis{Craven96,
  author = 	 {Mark W. Craven},
  title = 	 {Extracting Comprehensible Models from Trained Neural Networks},
  school = 	 {University of Wisconsin-Madison},
  year = 	 1996,
  note =	 {Also appears as UW Technical Report CS-TR-96-1326}
}

@article{CressieRe84,
  title={Multinomial goodness-of-fit tests},
  author={Cressie, Noel and Read, Timothy RC},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={440--464},
  year=1984,
  publisher={JSTOR}
}

@book{CristianiniSh00,
	author = "N.~Cristianini and J.~Shawe-Taylor",
	title = "An Introduction to Support Vector Machines",
	publisher =	"Cambridge University Press",
	year = 2000
}

@book{CristianiniSh04,
	author = "Nello Cristianini and John Shawe-Taylor",
	title = "Kernel Methods for Pattern Analysis",
	publisher =	"Cambridge University Press",
	year = 2004,
}


@inproceedings{CristianiniElSTKa01,
	author = "Nello Cristianini and Andre Elisseeff and John Shawe-Taylor and Jaz Kandla",
	title = "On Kernel Target Alignment",
	booktitle = nips14,
	year = "2001"
}

@article{CsibaQuRi15,
  title={Stochastic dual coordinate ascent with adaptive probabilities},
  author={Csiba, Dominik and Qu, Zheng and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1502.08053},
  year=2015
}

@article{CsibaRi16,
  title={Importance Sampling for Minibatches},
  author={Csiba, Dominik and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1602.02283},
  year=2016
}

@article{Csiszar67,
author = {Imre Csisz\'ar},
title = {Information-type measures of difference of probability distributions
and indirect observation},
year = 1967,
journal = {Studia Scientifica Mathematica Hungary},
volume = 2,
pages = {299--318},
}

@article{Csiszar75,
author=   	{Csisz\`ar, I.},
title=    	{I-Divergence Geometry of Probability Distributions and
	   	Minimization Problems},
journal=  	{The Annals of Probability},
year=     	1975,
volume=   	3,
number=   	1,
pages=    	{146--158},
comment=  	{Generalized proof of iterative techniques for computing
	   	maximum-entropy distributions.}
}

@article{Csiszar89
,author=	{Imre Csisz\'ar}
,title=		{A geometric interpretation of {D}arroch and
		 {R}atcliff's generatlized iterative scaling}
}

@article{Csiszar89b
,author=	{Imre Csisz\'ar}
,title=         {Why least squares and maximum entropy?  An axiomatic
                  approach to inference for linear invers problems}
,year=          1991
}

@book{CsiszarKo81,
author = {Imre Csisz\'ar and J\'anos K\"orner},
title = {Information Theory: Coding Theorems for Discrete Memoryless Systems},
year = 1981,
publisher = {Academic Press},
}

@article{CsiszarSh04,
author = {Imre Csisz\'ar and Paul Shields},
title = {Information theory and statistics: a tutorial},
year = 2004,
journal = {Foundations and Trends in Communications and Information
   Theory},
volume = 1,
number = 4,
pages = {417--528},
}

@article{CsiszarTu84
,author=	{I. Csisz\'ar and G. Tusn\'ady}
,title=         {Information geometry and alternaning minimization procedures}
,journal=	{Statistics and Decisions, Supplement Issue}
,volume=	{1}
,pages=		{205--237}
,year=          1984
}

@article{CsorgoHoMa86,
  title={What portion of the sample makes a partial sum asymptotically stable or normal?},
  author={Csorgo, S{\'a}ndor and Horv{\'a}th, Lajos and Mason, David M},
  journal={Probability Theory and Related Fields},
  volume=72,
  number=1,
  pages={1--16},
  year=1986,
  publisher={Springer}
}

@article{CsorgoCsHoMa86a,
  title={Weighted empirical and quantile processes},
  author={Csorgo, Miklos and Csorgo, Sandor and Horv{\'a}th, Lajos and Mason, David M},
  journal={The Annals of Probability},
  pages={31--85},
  year=1986,
  publisher={JSTOR}
}

@article{CsorgoCsHoMa86b,
  title={Normal and stable convergence of integral functions of the empirical distribution function},
  author={Csorgo, Miklos and Csorgo, Sandor and Horv{\'a}th, Lajos and Mason, David M},
  journal={The Annals of Probability},
  pages={86--118},
  year=1986,
  publisher={JSTOR}
}

@article{CsorgoHaMa88a,
  title={The asymptotic distribution of trimmed sums},
  author={Csorgo, Sandor and Haeusler, Erich and Mason, David M},
  journal={The Annals of Probability},
  pages={672--699},
  year=1988,
  publisher={JSTOR}
}

@article{CsorgoHaMa88b,
  title={A probabilistic approach to the asymptotic distribution of sums of independent, identically distributed random variables},
  author={Csorgo, S{\'a}ndor and Haeusler, Erich and Mason, David M},
  journal={Advances in Applied Mathematics},
  volume=9,
  number=3,
  pages={259--333},
  year=1988,
  publisher={Elsevier}
}

@article{CsorgoHo87,
  title={Approximation of intermediate quantile processes},
  author={Csorgo, Mikl{\'o}s and Horv{\'a}th, Lajos},
  journal={Journal of Multivariate Analysis},
  volume=21,
  number=2,
  pages={250--262},
  year=1987,
  publisher={Elsevier}
}

@inproceedings{CsorgoMa85,
  title={Central limit theorems for sums of extreme values},
  author={Csorgo, Sandor and Mason, David M},
  booktitle={Mathematical Proceedings of the Cambridge Philosophical Society},
  volume=98,
  pages={547--558},
  year=1985,
  organization={Cambridge Univ Press}
}

@article{CsorgoTe90,
  title={Empirical Laplace transform and approximation of compound distributions},
  author={Csorgo, S{\'a}ndor and Teugels, Jef L},
  journal={Journal of Applied Probability},
  volume=27,
  number=1,
  pages={88--101},
  year=1990,
  publisher={Cambridge University Press}
}

@article{CurramMi94
,author=	{Stephen P. Curram and John Mingers}
,title=		{Neural networks, decision tree induction and
		discriminant analysis: an empirical comparison}
}

@inproceedings{CuttingKuPeSi92
,author=	{Doug Cutting and Julian Kupiec and Jan Pedersen and
		 Penelope Sibun}
,title=		{A practical part-of-speech tagger}
}

@unpublished{Cybenko88,
author = 	{G. Cybenko},
title = 	{Approximation by Superpositions of a Sigmoidal Function},
year = 		1989,
note = 		{To appear.}
}

@unpublished{Cybenko88b,
author = 	{G. Cybenko},
title = 	{Continuous-Valued Neural Networks with Two Hidden
		 Layers are Sufficient},
year = 		1989,
note = 		{To appear.}
}
@article{DabbeneShPo10,
author = {F. Dabbene and P. S. Shcherbakov and B. T. Polyak},
title = {A Randomized Cutting Plane Method with Probabilistic Geometric Convergence},
journal = siopt,
volume = {20},
number = {6},
pages = {3185--3207},
year = {2010},
doi = {10.1137/080742506},
URL = {http://dx.doi.org/10.1137/080742506},
}

@unpublished{DajaniLaSiKiReMaGaDaGrKaKiLeScSeViAb17,
author = {Aref N. Dajani and Amy D. Lauger and Phyllis E. Singer
 and Daniel Kifer and Jerome P. Reiter
 and Ashwin Machanavajjhala and Simson L. Garfinkel1 and Scot A. Dahl
 and Matthew Graham
 and Vishesh Karwa and Hang Kim and Philip Leclerc and Ian M. Schmutte and
 William N. Sexton and Lars Vilhuber and John M. Abowd},
title = {The modernization of statistical disclosure limitation at the
{U.S.} {C}ensus Bureau},
year = 2017,
note = {Available online at
 \url{https://www2.census.gov/cac/sac/meetings/2017-09/statistical-disclosure-limitation.pdf}},
}

@unpublished{DaganEn95
,author=	{Ido Dagan and Sean P. Engelson}
,title=		{Committee-based sampling for training probabilistic
		 classifiers}
}

@unpublished{DajaniLaSiKiReMaGaDaGrKaKiLeScSeViAb17,
author = {Aref N. Dajani Amy D. Lauger and Phyllis E. Singer and
 Daniel Kifer and  Jerome P. Reiter and 
 Ashwin Machanavajjhala and  Simson L. Garfinkel and  Scot A. Dahl and
 Matthew Graham and Vishesh Karwa and  Hang Kim and Philip Leclerc and
 Ian M. Schmutte and  William N. Sexton and Lars Vilhuber and John M. Abowd},
title = {The modernization of statistical disclosure limitation at the
{U.S.} {C}ensus {B}ureau},
year =  2017,
note = {Available online at \url{https://www2.census.gov/cac/sac/meetings/2017-09/statistical-disclosure-limitation.pdf}},
}

@article{DalalyanTs08,
author = {Arnak Dalalyan and Alexandre B. Tsybakov},
title = {Aggregation by Exponential Weighting, Sharp Oracle Inequalities and Sparsity},
year = 2008,
journal = ml,
volume = 72,
pages = {39--61},
comment = {Shows that for least-squares problems (with a fixed design),
it is possible to obtain something like optimal convergence rates for
exponentially-weighted parameters. That is, O(KL(p, pi)/n) rates, where
pi is the prior distribution and p is the posterior distribution chosen, and
the empirical function used is exponentially weighted based on
exp(-n ||y - f_i||_n^2). Did not carefully read proof techniques, but a nice
PAC-Bayesian bound.},
}

@techreport{Dalkey85,
author=   	{Dalkey, Norman C.},
title=    	{Prior Probabilities Revisited},
institution=  	{UCLA Computer Science Department},
number=   	{CSD-850007},
year=     	1985,
comment=  	{Justification of maximum-entropy via proper scoring rules for
		probability distributions.  Some consequences.}
}

@article{DangLa15,
  title={Stochastic block mirror descent methods for nonsmooth and stochastic optimization},
  author={Dang, Cong D and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume=25,
  number=2,
  pages={856--881},
  year=2015,
  publisher={SIAM}
}

@inproceedings{DaniHaKa07,
author = {Varsha Dani and Thomas Hayes and Sham Kakade},
title = {The price of bandit information in online optimization},
year = 2007,
booktitle = nips20,
comment = {Presents a bandit algorithm for linear bandits with bounded
  losses, using a simple information-theoretic argument to give a lower
  bound of d \sqrt{n} (for d dimensions, n observations) on regret.
  The optimization problem roughly appears to be losses of the form
  $l(x) = v^T x$ for $||v||_1 \le 1$ and $||x||_\infty \le 1$.
  The upper bound is not achieved, but using Barycentric spanners
  with exploration gives $d^{3/2} \sqrt{n}$ regret.},
}

@inproceedings{DaniHaKa08,
author = {Varsha Dani and Thomas Hayes and Sham Kakade},
title = {Stochastic linear optimization under bandit feedback},
year = 2008,
booktitle = colt08,
}

@article{Daniels87,
  title={Tail probability approximations},
  author={Daniels, Henry E},
  journal={International Statistical Review/Revue Internationale de Statistique},
  pages={37--48},
  year=1987,
  publisher={JSTOR}
}

@article{DanielssonDePeDe01,
  title={Using a bootstrap method to choose the sample fraction in tail index estimation},
  author={Danielsson, Jon and de Haan, Laurens and Peng, Liang and de Vries, Capser G},
  journal={Journal of Multivariate Analysis},
  volume=76,
  number=2,
  pages={226--248},
  year=2001,
  publisher={Elsevier}
}

@inproceedings{DanielyLiSh13,
author = {Amit Daniely and Nati Linial and Shai Shalev-Shwartz},
title = {More data speeds up training time in learning halfspaces over
  sparse vectors},
year = 2013,
booktitle = colt13,
}

@inproceedings{DanielyLiSh14,
author = {Amit Daniely and Nati Linial and Shai Shalev-Shwartz},
title = {From average case complexity to improper learning complexity},
year = 2014,
booktitle = stoc14,
}

@book{Danskin67,
author={Danskin, John M},
title={The theory of max-min and its application to weapons allocation problems},
year=1967,
volume=5,
publisher={Springer Science \& Business Media}
}

@article{DarrochRa72
,author=       {J.~N.~Darroch and D.~Ratcliff}
,title=        {Generalized iterative scaling for log-linear models}
,year=         1972
,journal=      {The Annals of Mathematical Statistics}
,volume=       43
,number=       5
,pages=        {1470-1480}
}


@Unpublished{Dasgupta99,
  author = 	 {Sanjoy Dasgupta},
  title = 	 {Learning Mixtures of Gaussians},
  note = 	 {(In preparation)}
}

@article{DasguptaGu02,
author = {Sanjoy Dasgupta and Anupam Gupta},
title = {An Elementray Proof of a Theorem of {J}ohnson and {L}indenstrauss},
year = 2002,
journal = {Random Structures and Algorithms},
volume = 22,
number = 1,
pages = {60--65},
}

@book{DasguptapaVa07,
  author = "S. Dasgupta and C.H. Papadimitriou and U.V. Vazirani",
  title = "Algorithms",
  publisher = "Mcgraw-Hill Higher Education",
  year = 2007
}

@inproceedings{DatarInImMi04,
	author = {M. Datar and P. Indyk and N. Immorlica and V. Mirrokni},
	title = {Locality-Sensitive Hashing Scheme Based on p-Stable Distributions},
	booktitle = {Proceedings of the Symposium on Computational Geometry},
	year = 2004,
}

@article{DaubechiesDeDe04,
	author = {I. Daubechies and M. Defrise and C. De Mol},
	title = {An iterative thresholding algorithm for linear inverse problems
		with a sparsity constraint},
	journal = {Communication on Pure and Applied Mathematics},
	volume = 57,
	number = 11,
	pages = {1413--1457},
	year = 2004
}


@article{DaubechiesFoLo08,
author = {I. Daubechies and M. Fornasier and I. Loris},
title = {Accelerated Projected Gradient Method for Linear Inverse Problems with Sparsity Constraints},
journal = {Fourier Analysis and Applications},
year = 2008,
volume = 14,
number = 5,
publisher = {Springer},
pages = {764--792},
}

@article{DavenportPlVaWo15,
author = {Mark A. Davenport and Yaniv Plan and Ewout van den Berg and Mary Wootters},
title = {One-bit matrix completion},
year = 2015,
journal = {Information and Inference},
pages = {to appear},
}


@book{David69,
author = {H. A. David},
title = {The Method of Paired Comparisons},
publisher = {Charles Griffin \& Company},
year = 1969,
}

@book{David81,
author=		{H. A. David},
title=		{Order Statistics},
publisher=	{John Wiley \& Sons},
year=		1981,
edition=	{second}
}

@article{Dawid84
,author=	{A. P. Dawid}
,title=		{Statistical theory: The prequential approach}
,journal=       {Journal of the Royal Statistical Society, Series A}
,year=          1984
,volume=        147
,pages=         {278-292}
}

@article{Dawid92
,author=	{A. P. Dawid}
,title=		{Prequential analysis, stochastic complexity and
		 {B}ayesian inference}
}

@article{DawidSk79,
author = {A.P. Dawid and A.M. Skene},
title = {Maximum likelihood estimation of observer error-rates using the {EM}
algorithm},
year = 1979,
journal = jrss,
volume = 28,
pages = {20--28},
}


@article{DawidVo97,
author = {A.P. Dawid and V. Vovk},
title = {Prequential probability: principles and properties},
journal = {Bernoulli},
volume = 3,
pages = {1--38},
year = {1997}
}

@article{Dayan92,
author=		{Peter Dayan},
title=		{The Convergence of {$TD(\lambda)$} for General~{$\lambda$}},
journal=	ml,
volume=		8,
number=		{3/4},
month=		may,
year=		1992,
pages=		{341--362}
}

@article{DayanHiNeZe95
,author=	{Peter Dayan and Geoffrey E. Hinton and Radford
		 M. Neal and Richard S. Zemel}
,title=		{The {Helmholtz} Machine}
}

@techreport{DayanSe93,
author=		{Peter Dayan and Terrence J. Sejnowski},
title=		{{$TD(\lambda)$} Converges with Probability~1},
institution=	{CNL, The Salk Institute},
year=		1993
}

@article{DayanSe94
,author=	{Peter Dayan and Terrence J. Sejnowski}
,title=		{{$TD(\lambda)$} Converges with Probability~1}
,journal=	ml
,volume=	14
,number=	3
,year=		1994
,pages=		{295--301}
}

@article{Dannenberg84,
author=   	{Dannenberg, R.},
title=    	{An On-Line Algorithm for Real-Time Accompaniment},
journal=  	{Proc. Int'l Computer Music Conference},
year=     	{1984},
}

@article{Dantzig40,
author = {George Dantzig},
title = {On the non-existence of tests of {S}tudent's hypothesis having power
 functions independent of $\sigma$},
year = 1940,
journal = {The Annals of Mathematical Statistics},
volume = 11,
pages = {186--192},
number = 2,
}

@article{DantzigFoSh67,
author = {George Dantzig and Jon Folkman and Norman Shapiro},
title = {On the continuity of the minimum set of a continuous function},
year = 1967,
journal = {Journal of Mathematical Analysis and Applications},
volume = 17,
pages = {519--548},
}

@article{DantzigWo60,
author = {G. B. Dantzig and P. Wolfe},
title = {Decomposition principle for linear programs},
journal = {Operations Research},
year = 1960,
volume = 8,
pages = {101--111},
}

@article{DavisDrPa17,
author = {Damek Davis and Dmitriy Drusvyatskiy and Courtney Paquette},
title = {The nonsmooth landscape of phase retrieval},
year = 2017,
journal = {arXiv:1711.03247 [math.OC]},
}

@article{Davisson65,
author = {Lee D. Davisson},
title = {The prediction error of stationary Gaussian time series of unknown
   covariance},
year = 1965,
journal = ieeeit,
volume = 11,
pages = {527--532},
}

@inproceedings{De12,
author = {Anindya De},
title = {Lower bounds in differential privacy},
year = 2012,
booktitle = {Proceedings of the Ninth Theory of Cryptography Conference},
url = {http://arxiv.org/abs/1107.2183},
}

@book{DeHaanFe07,
  title={Extreme Value Theory: An Introduction},
  author={De Haan, Laurens and Ferreira, Ana},
  year=2007,
  publisher={Springer Science \& Business Media}
}

@inproceedings{DeanAnBaEnKaKoMa92,
author=		{Thomas Dean and Dana Angluin and Kenneth Basye and
		 Sean Engelson and Leslie Kaelbling and Evangelos
		 Kokkevis and Oded Maron},
title=		{Inferring Finite Automata with Stochastic Output
		 Functions and an Application to Map Learning},
booktitle=	{Proceedings Tenth National Conference on
		 Artificial Intelligence},
pages=		{208--214},
month=		jul,
year=		1992
}

@inproceedings{DeanCoMoChDeMaRaSeTuYaNg12,
author = {Jeffrey Dean and Greg S. Corrado and Rajat Monga and Kai Chen and
Matthieu Devin and Quoc V. Le and Mark Z. Mao and Marc’Aurelio Ranzato and
Andrew Senior and Paul Tucker and Ke Yang and Andrew Y. Ng},
title = {Large Scale Distributed Deep Networks},
year = 2012,
booktitle = nips25,
}

@article{DeanKa89,
        author = "T. Dean and K. Kanazawa",
        title = "A model for reasoning about persistence and causation",
        journal = "Computational Intelligence",
        volume = 5,
        number = 3,
        pages = "142--150",
        year = 1989
}

@inproceedings{DeanGe04,
title = {Map{R}educe: Simplified Data Processing on Large Clusters},
author = {Jeffrey Dean and Sanjay Ghemawat},
year = 2004,
booktitle = {Sixth Symposium on Operating System Design and Implementation
(OSDI)},
}

@article{DeAcosta81,
author = {Alejandro de Acosta},
title = {Inequalities for {$B$}-valued random vectors with applications
to the strong law of large numbers},
year = 1981,
journal = {The Annals of Probability},
volume = 9,
pages = {157--161},
comment = {Proves a Rosenthal-type inequality for vectors in a Banach
  space, bounding E[(||S_n|| - E[||S_n||])^p] with a Sub-Gaussian term and
  a (essentially) sub-exponential-type term.}
}

@book{delaPenaGi99,
author = {Victor H. de la Pe\~na and Evarist Gin\'e},
title = {Decoupling: From Dependence to Independence},
year = 1999,
publisher = {Springer},
}

@inproceedings{DefazioBaLa14,
author = {Aaron Defazio and Francis Bach and Simon Lacoste-Julien},
title = {{SAGA}: A Fast Incremental Gradient Method With
  Support for Non-Strongly Convex Composite
  Objectives},
year = 2014,
booktitle = nips27,
}

@article{DeGroot62,
author = {Morris H. De{G}root},
title = {Uncertainty, Information, and Sequential Experiments},
journal = aoms,
year = 1962,
volume = 33,
number = 2,
pages = {404--419},
comment = {Classic paper on statistical information in simple
  multi-way experiments. That is, for some prior probabilities
  $\xi \in \R^k$ on $k$ different possibilities and a concave function
  $U$ defined on the simplex, defines the information between $\xi$ and
  an experiment $X$ (defined as a random variable distributed according
  to one of the hypotheses $i = 1, \ldots, k$) via
  $I(X, \xi; U) = U(\xi) - E[U(\xi(X)) \mid \xi]$, where
  $\xi(X)$ denotes the posterior probability of the hypotheses given the
  observation $X$. This quantity is nonegative for all experiments (random
  variables $X$) if and only if $U$ is concave. Also looks at sequential
  testing and how to optimize that, but optimization ``procedures'' are
  impractical.}
}

@book{DeGroot70,
author = {Morris H. De{G}root},
title = {Optimal Statistical Decisions},
publisher = {Mcgraw-Hill College},
year = 1970
}

@article{DekelGiShXi12,
author = {Ofer Dekel and Ran Gilad-Bachrach and Ohad Shamir and Lin Xiao},
title = {Optimal distributed online prediction using mini-batches},
year = 2012,
journal = jmlr,
volume = 13,
pages = {165--202},
}

@inproceedings{DekelGiShXi11,
author = {O. Dekel and R. Gilad-Bachrach and O. Shamir and L. Xiao},
title = {Optimal distributed online prediction},
booktitle = icml11,
year = 2011,
}

@unpublished{DekelGiShXi10,
author = {O. Dekel and R. Gilad-Bachrach and O. Shamir and L. Xiao},
title = {Optimal distributed online prediction using mini-batches},
year = 2010,
url = {http://arxiv.org/abs/1012.1367},
note = {URL \url{http://arxiv.org/abs/1012.1367}},
comment = {Shows the asymptotic improvement of distributing computation for
stochastic optimization through a series of reductions to centralized
problems},
}

@unpublished{DekelGiShXi10b,
author = {O. Dekel and R. Gilad-Bachrach and O. Shamir and L. Xiao},
title = {Robust distributed online prediction},
year = 2010,
note = {URL http://arxiv.org/abs/1012.1370},
url = {http://arxiv.org/abs/1012.1370},
comment = {Robust version of the distributed online prediction paper by
Dekel et al.},
}

@inproceedings{DekelKeSi04,
	author = "O. Dekel and J. Keshet and Y. Singer ",
	title = "Large Margin Hierarchical Classification",
	booktitle = icml04,
	year = 2004
}

@inproceedings{DekelKeSi04a,
	author = "O. Dekel and J. Keshet and Y. Singer ",
	title = "Online Algorithm for Hierarchical Phoneme Classification",
	booktitle = {Workshop on Multimodal Interaction and Related Machine Learning Algorithms; Lecture Notes in Computer Science},
	year = 2004,
	vol = {3361/2005},
	pages = {146-159},
	publisher={Springer-Verlag}
}

@inproceedings{DekelLoSi06,
	author = "O.~Dekel and P.~Long and Y.~Singer",
	title = "Online Multitask Learning",
	booktitle = colt06,
	year = 2006
}


@inproceedings{DekelMaSi03,
	author = "O. Dekel and C. Manning and Y. Singer",
	title = "Log-Linear Models for Label Ranking",
	booktitle = nips16,
	year = 2004
}

@inproceedings{DekelShSi03,
	author = "O. Dekel and S. Shalev-Shwartz and Y. Singer ",
	title = "Smooth Epsilon-Insensitive Regression by Loss Symmetrization",
	booktitle = colt03,
	year = 2003
}

@inproceedings{DekelShSi04,
	author = "O. Dekel and S. Shalev-Shwartz and Y. Singer ",
	title = "The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees",
	booktitle = nips17,
	year = 2005
}

@inproceedings{DekelShSi05a,
	author = "O.~Dekel and S.~Shalev-Shwartz and Y.~Singer ",
	title = "The {F}orgetron: {A} Kernel-Based Perceptron on a Fixed Budget",
	booktitle = nips18,
	year = 2005,
}

@article{DekelShSi08,
	author = "O.~Dekel and S.~Shalev-Shwartz and Y.~Singer ",
	title = "The {F}orgetron: {A} Kernel-Based Perceptron on a Budget",
        journal = sicomp,
        year = 2008,
        volume = 37,
        issue = 5,
        pages = {1342--1372}
}

@inproceedings{DekelSi05,
	author = "O.~Dekel and Y.~Singer ",
	title = "Data-Driven Online to Batch Conversions",
	booktitle = nips18,
	year = 2005
}

@inproceedings{DekelSi06,
	author = "O.~Dekel and Y.~Singer ",
	title = "Support Vector Machines on a Budget",
	booktitle = nips19,
	year = 2006
}


@article{DekelShSi05,
  author = 	 {O. Dekel and S. Shalev-Shwartz and Y. Singer},
  title = 	 {Smooth Epsilon-Insensitive Regression by Loss Symmetrization},
  journal = 	 {Journal of Machine Learning Research},
  year = 	 {2005},
  volume = 	 {6},
  pages = 	 {711--741},
  month = 	 {May},
}

@inproceedings{DekelSi02,
	author = "O. Dekel and Y. Singer",
	title = "Multiclass Learning by Probabilistic Embeddings",
	booktitle = nips15,
	year = 2002
}

@article{DempsterLaRu77,
	author = "A.P. Dempster and N.M. Laird and D.B. Rubin",
	title = "Maximum Likelihood from Incomplete Data Via the {EM} Algorithm",
	journal = "Journal of the Royal Statistical Society, Ser. B",
	volume = 39,
	pages = "1--38",
	year = 1977
}

@article{DePierroIu86,
    author = "A.R. De Pierro and A.N. Iusem",
    title = "A relaxed version of Bregman's method for convex programming",
    journal = "Journal of Optimization Theory and Applications",
    volume = "51",
    pages = "421--440",
    year = 1986
}

@book{DeSaintExupery43,
author=   	{Saint-Exup\`ery, Antoine de},
title=    	{The Little Prince},
publisher=	{Harcourt, Brace, \& World},
year=     	1943
}

@book{Deutsch01,
author=   	{F.R.~Deutsch},
title=    	{Best Approximation in Inner Product Spaces Series: CMS Books in Mathematics},
publisher=	{Sptringer},
year=     	{2001}
}


@article{DeCosteSc01,
	author = "Dennis DeCoste and Bernhard Schoelkopf",
	title = "Training Invariant Support Vector Machines",
	journal = "Machine Learning",
	volume = 46,
	pages = "133--168",
        number = "1--3",
	year = 2001
}


@article{DeHaanSt96,
  title={Generalized regular variation of second order},
  author={de Haan, Laurens and Stadtm{\"u}ller, Ulrich},
  journal={Journal of the Australian Mathematical Society (Series A)},
  volume=61,
  number=03,
  pages={381--395},
  year=1996,
  publisher={Cambridge Univ Press}
}

@article{DeMeyerTe85,
  title={Limit theorems for Pareto-type distributions},
  author={De-Meyer, A and Teugels, JL},
  journal={Banach Center Publications},
  volume=16,
  number=1,
  pages={393--400},
  year=1985,
  publisher={Institute of Mathematics Polish Academy of Sciences}
}

@article{DekkersDe89,
  title={On the estimation of the extreme-value index and large quantile estimation},
  author={Dekkers, Arnold LM and De Haan, Laurens},
  journal={The Annals of Statistics},
  pages={1795--1832},
  year=1989,
  publisher={JSTOR}
}

@article{DellaDeLa97,
	author = "S. Della Pietra and V. Della Pietra and J. Lafferty",
	title = "Inducing features of random fields",
	journal = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
	volume = 5,
	pages = "179--190",
	year = 1997
}

@article{DelaDeLa97,
	author = "S. Della Pietra and V. Della Pietra and J. Lafferty",
	title = "Inducing features of random fields",
	journal = "IEEE Transactions on Pattern Analysis and Machine Intelligence",
	volume = 5,
	pages = "179--190",
	year = 1997
}

@article{DelageYe10,
  title={Distributionally robust optimization under moment
     uncertainty with application to data-driven problems},
  author={Delage, Erick and Ye, Yinyu},
  journal={Operations Research},
  volume=58,
  number=3,
  pages={595--612},
  year=2010,
  publisher={INFORMS}
}

@incollection{Delbaen02,
  title={Coherent risk measures on general probability spaces},
  author={Delbaen, Freddy},
  booktitle={Advances in finance and stochastics},
  pages={1--37},
  year=2002,
  publisher={Springer}
}

@techreport{DellaDeLa02,
	author = "S. Della Pietra and V. Della Pietra and J. Lafferty",
	title = "Duality and auxilary functions for {B}regman distances",
	institution = "{CMU}",
	number = "CS-01-10",
	year = 2002
}

@book{DellerPrHa93,
author=   	{J.R Deller and J.G. Proakis and J.H.L. Hansen},
title=    	{Discrete-Time Processing of Speech Signals},
publisher=	{Prentice-Hall},
year=     	1987
}

@article{DelMoralLeMi03,
author = {Pierre {Del Moral} and Michel Ledoux and Laurent Miclo},
title = {On contraction properties of {M}arkov kernels},
year = 2003,
journal = {Probability Theory and Related Fields},
pages = {395--420},
volume = 126,
comment = {Builds off the classical result of Dobrushin that
  if $K$ is a Markov kernel such that, for any two probability
  measures $P, Q$ we have
  $\tvnorm{P K - Q K} \le \alpha \tvnorm{\mu - \nu}$,
  then $D_f(PK || QK) \le \alpha D_f(P, Q)$ for all $P, Q$. The proof is
  by showing that any $f$ divergence---as $f$ is a convex function---can
  be approximated by piecewise linear functions (clearly), and then
  using the variation-norm contraction to build the piecewise linear
  approximations.},
}

@book{DemboZe98,
author = {Amir Dembo and Ofer Zeitouni},
title = {Large Deviations Techniques and Applications},
year = 1998,
publisher = {Springer-Verlag},
}

@unpublished{Dembo16,
author = {Amir Dembo},
title = {Lecture Notes on Probability Theory: Stanford Statistics 310},
year = 2016,
url = {http://statweb.stanford.edu/~adembo/stat-310b/lnotes.pdf},
note = {Accessed October 1, 2016},
}

@article{DemingSt40,
author=   	{Deming, W. Edwards and Frederick F. Stephan},
title=    	{On a Least Squares Adjustment of a Sampled Frequency Table
		when the Expected Marginal Totals are Known},
journal=  	{Annals Mathematical Statistics},
year=     	1940,
volume=   	11,
pages=    	{427--444},
comment=  	{Introduces iterative updating procedure; useful for
	   	computing maximum-entropy solution.}
}

@inproceedings{DengDoSoLiLiFe09,
author = {J. Deng and W. Dong and R. Socher and L. Li and K. Li and
          L. Fei-Fei},
title = {Image{N}et: a large-scale hierarchical image database},
year = 2009,
booktitle = cvpr,
}

@article{Dennis84,
author=   	{Dennis, J.E., Jr.},
title=    	{A User's Guide to Nonlinear Optimization Algorithms},
journal=  	{Proceedings of the IEEE},
year=     	1984,
month=    	Dec,
volume=   	72,
number=   	12,
pages=    	{1765--1776},
comment=  	{Brief survey with bibliography.}
}

@article{DentchevaPeRu10,
  title = {Kusuoka representation of higher order dual risk measures},
  author = {Dentcheva, Darinka and Penev, Spiridon and Ruszczy{\'n}ski, Andrzej},
  journal = {Annals of Operations Research},
  volume = 181,
  number = 1,
  pages = {325--335},
  year = 2010,
  publisher = {Springer}
}

@inproceedings{DesantisMaWe88
,author=	{A. DeSantis and G. Markowsky and M.N. Wegman}
,title=		{Learning probabilistic prediction functions}
,booktitle=	{COLT}
,pages=		{312--328}
,year=		1988
}

@article{DeslauriersScWi11,
author = {Louis Deslauriers and Ellen Schelew and Carl Wieman},
title = {Improved Learning in a Large-Enrollment Physics Class},
year = 2011,
journal = {Science},
volume = 332,
pages = {862--864},
month = {May},
}

@book{DeuschelSt89,
  title={Large deviations},
  author={Deuschel, Jean-Dominique and Stroock, Daniel W},
  volume=137,
  year=1989,
  publisher={Academic press Boston}
}

@Article{Devroye82,
  author = 	 {Luc Devroye},
  title = 	 {Bounds for the uniform deviation of empirical measures},
  journal = 	 {Journal of Multivariate Analysis},
  year = 	 1982,
  volume =	 12,
  pages =	 {72-79}
}

@article{Devroye88,
author = 	{Luc Devroye},
title = 	{Automatic Pattern Recognition: A Study of the Probability
	 	 of Error},
journal = 	{IEEE Trans.\ Pattern Analysis and Machine Intelligence},
volume = 	10,
number = 	4,
year = 		1988,
month = 	Jul,
pages = 	{530--543}
}

@book{DevroyeGy85,
author = {Luc Devroye and L\'aszl\'o Gy\"{o}rfi},
title = {Nonparametric Density Estimation: The $L_1$ View},
year = 1985,
publisher = {John Wiley and Sons},
}

@Book{DevroyeGyLu96,
  author = 	 {L. Devroye and L. Gy\"{o}rfi and G. Lugosi},
  title = 	 {A Probabilistic Theory of Pattern Recognition},
  publisher = 	 {Springer},
  year = 	 1996,
}

@article{DezeureBuMeME15,
author = {Ruben Dezeure and Peter B\"uhlmann and Lukas Meier and
Nicolai Meinshausen},
title = {High-dimensional inference: confidence intervals,
  $p$-values, and {R}-software {\tt hdi}},
year = 2015,
journal = statsci,
volume = 30,
number = 4,
pages = {533--558},
}

@inproceedings{DhillonLuFoUn13,
  title={New subsampling algorithms for fast least squares regression},
  author={Paramveer Dhillon and Yichao Lu and Dean P. Foster and Lyle Ungar},
  booktitle={Advances in Neural Information Processing Systems},
  pages={360--368},
  year={2013}
}

@book{DiCiccioHaRo88,
  title={Bartlett adjustment for empirical likelihood},
  author={DiCiccio, Thomas and Hall, Peter and Romano, Joseph},
  publisher={Technical Report No. 298. Department of Statistics,
                  Stanford University},
  year=1988
}

@article{DiCiccioHaRo91,
  title={Empirical likelihood is Bartlett-correctable},
  author={DiCiccio, Thomas and Hall, Peter and Romano, Joseph},
  journal={The Annals of Statistics},
  pages={1053--1061},
  year=1991,
  publisher={JSTOR}
}

@article{Diaconis87
,author=        {Persi Diaconis}
,title=         {A generalization of spectral analysis with
                  application to ranked data}
}

@article{DiaconisSt91
,author=	{Persi Diaconis and Daniel Stroock}
,title=		{Geometric bounds for eigenvalues of Markov chains}
,journal=	{The Annals of Probability}
,volume=	1
,number=	1
,year=		1991
,pages=		{36--61}
}

@phdthesis{Diep95
,author=	{Thanh Am Diep}
,title=		{Capacity of multi-level threshold devices}
}

@inproceedings{Dietterich84,
author=   	{Dietterich, Thomas G.},
title=    	{Learning About Systems That Contain State Variables},
booktitle= 	{Proceedings of the National Conference on Artificial
           	Intelligence},
year=     	1984,
month=   	Aug,
pages=    	{96--100}
}

@incollection{Dietterich90,
author=		{Thomas G. Dietterich},
title=		{Machine Learning},
booktitle=	{Annual Review of Computer Science},
volume=		4,
year=		{1990},
editor=		{Joseph F. Traub and Barbara J. Grosz and Butler W.
		 Lampson and Nils J. Nilsson},
publisher=	{Annual Reviews},
pages=		{255--306},
comment=	{address= Palo Alto}
}

@article{Dietterich99,
  author = 	 {T. G. Dietterich},
  title = 	 {An experimental comparison of three methods for
                  constructing ensembles of decision trees: Bagging,
                  boosting, and randomization},
  journal=         ml,
  volume = 40,
  number = 2,
  pages = {139--158},
  year =	 1999
}

@article{Dietterich00,
  author = 	 {Thomas G. Dietterich},
  title = 	 {An experimental comparison of three methods for
                  constructing ensembles of decision trees: Bagging,
                  boosting, and randomization},
journal=         ml,
volume = 40,
number = 2,
pages = "139--158",
  year =	 2000
}

@inproceedings{DietterichBa91
,author=	{Thomas G. Dietterich and Ghulum Bakiri}
,title=		{Error-correcting output codes: a general method for
		 improving multiclass inductive learning programs}
,year={1991}
}

@article{DietterichBa95
,author=	{T.~G.~Dietterich and G.~Bakiri}
,title=		{Solving Multiclass Learning Problems via
		 Error-Correcting Output Codes}
,journal=	jair
,year=		1995
,month=		jan
,pages=		{263--286}
,volume=	2
}

@inproceedings{DietterichKeMa96
,author=	{Tom Dietterich and Michael Kearns and Yishay Mansour}
,title=		{Applying the Weak Learning Framework to Understand
		 and Improve {C4.5}}
,booktitle=	ml96
,year=		1996
}

@techreport{DietterichKo95
,title=         "Machine Learning Bias, Statistical Bias, and
		 Statistical Variance of Decision Tree Algorithms"
,author=        {Tom Dietterich and Eun Bae Kong}
,institution=   {Oregon State University}
,year=          1995
,note=          {Available via the WWW at
		  http://www.cs.orst.edu:80/$\sim$tgd/cv/tr.html}
}

@article{DigalakisOsRo92,
author=	{V.V. Digalakis and M. Ostendorf and J.R. Rohlicek},
title=		{Fast algorithms for phone classification and recognition using segment-based models},
journal=	{IEEE Trans. on Signal Processing},
year=	1992,
pages=	{2885--2896},
volume=	40
}

@ARTICLE{DimakisSaWa08,
   AUTHOR = "A. G. Dimakis and A. Sarwate and M. J. Wainwright",
   TITLE = "Geographic gossip: {E}fficient averaging for sensor networks",
   JOURNAL = "IEEE Transactions on Signal Processing",
   YEAR = 	2008,
   VOLUME = 53,
   MONTH = "March",
   PAGES = "1205--1216"
}

@inproceedings{DinurNi03,
author = {Irit Dinur and Kobbi Nissim},
title = {Revealing information while preserving privacy},
year = 2003,
booktitle = {Proceedings of the Twenty-Second Symposium on Principles of
Database Systems},
pages = {202--210},
comment = {
  Shows that several natural methods of attempting to attain privacy are quite
  broken. In particular, with n items, noise of order \sqrt{n} must be
  added to avoid some seriously broken privacy (in some ways).
  The specific techniques are as follows: a database d is viewed as an n bit
  vector in {0, 1}^n. A query is a vector q \in {0, 1}^n (select a subset
  of indices) and the answer a_q to the query is a_q = d' * q. If an adversary
  is allowed time exponential in n (and queries exponential in n), and
  the amount of perturbation is o(n), then the database can be reconstructed.
  If the adversary is allowed poly(n) time (and queries), then the amount
  of perturbation to a_q must be \Omega(\sqrt{n}), because otherwise
  one can ask a set of n \log^2 n random queries q, solve
  a simple LP to estimate the on and off answers (that is, find c \in [0,1]^n
  a_q - err <= q' * c <= a_q + err
  for each random query q, which is polynomial time, then round the c vectors),
  and a coupon collector argument shows that the right database can be
  reconstructed if the noise--i.e. err--is o(\sqrt{n}).
  This motivated later work on differential privacy.
},
}

@book{Dobson90,
author=		{A.J.~Dobson},
title=		{An Introduction to Generalized Linear Models},
publisher=	{Chapman and Hall},
year=		1990
}

@phdthesis{Dolan89,
author = 	{Charles Patrick Dolan},
title = 	{Tensor Manipulation Networks: Connectionist and Symbolic
		 Approaches to Comprehension, Learning, and Planning},
school = 	{UCLA Computer Science Department},
month = 	Jun,
year = 		1989
}

@InProceedings{Domingos97,
  author = 	 {Pedro Domingos},
  title = 	 {Knowledge Acquisition from Examples Via Multiple Models},
  booktitle = 	 {ml97},
  pages =	 {98--106},
  year =	 1997
}

@inproceedings{DomingoWa00,
    author = "Carlos Domingo and Osamu Watanabe",
    title = "Scaling Up a Boosting-Based Learner via Adaptive Sampling",
    booktitle = "Pacific-Asia Conference on Knowledge Discovery and Data Mining",
    pages = "317-328",
    year = "2000"
}

@inproceedings{DomingoWa00b,
  author = "C. Domingo and O. Watanabe",
  title = "MadaBoost: A Modification of AdaBoost",
  booktitle = colt00,
  year = 2000
}

@Article{DonahueGuDaSa97,
  author = 	 {M. J. Donahue and L. Gurvits and C. Darken and E. Sontag},
  title = 	 {Rates of convex approximation in non-{H}ilbert spaces},
  journal = 	 {Constructive Approximation},
  year = 	 1997,
  volume =	 13,
  pages =	 {187--220}
}

@article{Donoho94,
author = {David L. Donoho},
title = {Statistical Estimation and Optimal Recovery},
year = 1994,
journal = aos,
volume = 22,
number = 1,
pages = {238--270},
}

@InProceedings{Donoho06a,
  author = 	 {D.L. Donoho},
  title = 	 {Compressed Sensing},
  booktitle = {Technical Report, Stanford University},
  year = 	 {2006}
}

@InProceedings{Donoho06,
  author = 	 {D.L. Donoho},
  title = 	 {For most large underdetermined systems of linear equations,
                  the minimal $\ell_1$-norm solution is also the sparsest
                  solution},
  booktitle = {Comm. Pure Appl. Math. 59},
  year = 	 {2006}
}

@article{DonohoJo94,
title = {Minimax risk over $\ell_p$-balls for $\ell_q$-error},
author = {David L. Donoho and Iain M. Johnstone},
journal = "Probability Theory and Related Fields",
year = "1994",
volume = 99,
pages = "277--303"
}

@article{DonohoLiMa90,
author = {David L. Donoho and Richard C. Liu and Brenda MacGibbon},
title = {Minimax risk over hyperrectangles, and implications},
year = 1990,
journal = aos,
volume = 18,
number = 3,
pages = {1416--1437},
comment = {Considers estimation of a vector $\theta \in \ell_2$ from
  observations $y_i = \theta_i + \epsilon_i$ for each $i$. Shows that
  if $\theta \in \Theta$, where $\Theta$ is quadratically convex
  (meaning that the points $\theta.^2$ for $\theta \in \Theta$ are
  convex), then rectangular sub-problems are just as hard for \emph{linear}
  estimators as the full problem. Then, since linear estimators and
  nonlinear estimators behave similarly for rectangular $\Theta$, the
  heuristic of "hardest rectangular sub-problem" is a good one.
  But for non-quadratically convex sets, the risks can be arbitrarily
  different (and a non-linear soft-thresholding estimator, for example,
  achieves logarithmic factors of the minimax risk).
},
}

@techreport{DonohoLi87,
author = {David L. Donoho and Richard C. Liu},
title = {Geometrizing Rates of Convergence {I}},
year = 1987,
institution = {University of California, Berkeley, Department of Statistics},
number = 137,
comment = {Never published, but shows how modulus of continuity of a
  functional w.r.t. Hellinger distance governs minimax rates of estimation.},
}

@article{DonohoLi91a,
author = {David L. Donoho and Richard C. Liu},
title = {Geometrizing Rates of Convergence {II}},
year = 1991,
journal = aos,
volume = 19,
number = 2,
pages = {633--667},
}

@article{DonohoLi91b,
author = {David L. Donoho and Richard C. Liu},
title = {Geometrizing Rates of Convergence {III}},
year = 1991,
journal = aos,
volume = 19,
number = 2,
pages = {688--701},
}

@misc{Donoho82,
author = {David Donoho},
title = {Breakdown properties of multivariate location estimators},
howpublished = {Harvard University, qualifying paper, Department of
  Statistics},
year = 1982,
}

@article{DonohoGa92,
author = {David Donoho and Miriam Gasko},
title = {Breakdown properties of location estimates based on halfspace
  depth and projected outlyingness},
journal = aos,
year = 1992,
volume = 20,
number = 4,
pages = {1803--1827},
}

@article{DonohoJi04,
author = {David L. Donoho and Jiashun Jin},
title = {Higher criticism for detecting sparse heterogeneous mixtures},
year = 2004,
journal = aos,
volume = 32,
number = 3,
}

@Article{DonohoJo95,
  author = 	 {David L. Donoho and Iain M. Johnstone},
  title = 	 {Adapting to Unknown Smoothness via Wavelet Shrinkage},
}

@article{DonohoNu90,
author = {David L. Donoho and Michael Nussbaum},
title = {Minimax quadratic estimation of a quadratic functional},
journal = {Journal of Complexity},
volume = 6,
number = 3,
pages = {290--323},
year = 1990,
}

@TechReport{Donoho04,
       author = {D.L. Donoho},
       title = {For Most Large Underdetermined Systems of Equations,
the Minimal L1-norm Near-Solution
Approximates the Sparsest Near-Solution},
  institution =  {Stanford University},
  year = 	 {2004}
}

@book{DontchevRo14,
author = {Asen L. Dontchev and R. Tyrrell Rockafellar},
title = {Implicit Functions and Solution Mappings: A View from Variational
 Analysis},
year = 2014,
edition = {Second},
publisher = {Springer},
}

@Book{Doukhan94,
  author =	 {Paul Doukhan},
  title = 	 {Mixing, Properties and Examples},
  publisher = 	 {Springer},
  year = 	 1994,
  number =	 85,
  series =	 {Lecture Notes in Statistics},
  comment =	 {This book was recommended by Avi Wyner, he sais it has a good summary of "exponential bounds" which are a generalization of Hoeffding/Chernoff bounds to non-IID processes. Currently (3/99) the book is out of print.}
}

@inproceedings{DoukhanMaRi95,
  title={Invariance principles for absolutely regular empirical processes},
  author={Doukhan, Paul and Massart, Pascal and Rio, Emmanuel},
  booktitle={Annales de l'IHP Probabilit{\'e}s et statistiques},
  volume=31,
  pages={393--427},
  year=1995,
  organization={Elsevier},
  comment={Donsker theorem for beta-mixing (absolutely regular)
                  sequences under bracketing conditions. Uses
                  Barbee79's coupling argument to construct
                  independent blocks which yields a maximal
                  inequality.}
}

@article{Drees01,
  title={Minimax risk bounds in extreme value theory},
  author={Drees, Holger and others},
  journal={The Annals of Statistics},
  volume=29,
  number=1,
  pages={266--294},
  year=2001,
  publisher={Institute of Mathematical Statistics}
}

@article{DreesKa98,
  title={Selecting the optimal sample fraction in univariate extreme value estimation},
  author={Drees, Holger and Kaufmann, Edgar},
  journal={Stochastic Processes and Their Applications},
  volume=75,
  number=2,
  pages={149--172},
  year=1998,
  publisher={Elsevier}
}

@techreport{Drescher80,
author=   	{Drescher, Gary L.},
title=    	{Suggestions for Genetic A.I.},
institution= 	{MIT Artificial Intelligence Laboratory},
year=     	1980,
number=   	198,
month=    	Feb
}

@mastersthesis{Drescher85,
author=   	{Drescher, Gary L.},
title=    	{The Schema Mechanism: A Conception of Constructivist
		Intelligence},
school=   	{MIT Department of Electrical Engineering and Computer
		Science},
year=     	1985,
month=    	Feb,
comment=  	{Constructivist version of Piagetian theory.}
}

@techreport{Drescher86,
author=   	{Drescher, Gary L.},
title=    	{Genetic {AI} --- Translating {P}iaget into {L}isp},
institution= 	{MIT Artificial Intelligence Laboratory},
year=     	1986,
number=   	890,
month=    	Feb
}

@inproceedings{Drescher87,
author = 	{Gary L. Drescher},
title = 	{A Mechanism for Early {Piagetian} Learning},
booktitle = 	{Proceedings of AAAI-87: Sixth National Conference on
		 Artificial Intelligence},
address = 	{Seattle, Washington},
month = 	Jul,
year = 		1987,
pages = 	{290--294}
}

@book{Drescher91,
author=		{Gary L. Drescher},
title=		{Made-up Minds: A Constructivist Approach to
		 Artificial Intelligence},
publisher=	{MIT Press},
year=		1991
}

@article{DressGr91,
author=		{Andreas Dress and Johannes Grabmeier},
title=		{The Interpolation Problem for $k$-sparse Polynomials
		 and Character Sums},
journal=	{Advances in Applied Mathematics},
volume=		12,
year=		1991,
pages=		{57--75}
}

@unpublished{Drucker95
,author=	{Harris Drucker}
,title=		{Fast decision tree ensembles for optical character
		 recognition}
}

@inproceedings{Drucker97
,author=	{Harris Drucker}
,title=		{Improving regressors using boosting techniques}
,year=		1997
,booktitle=	ml97
,pages=		{107-115}
}

@inproceedings{DruckerBuKaSmVa97
,author=	{Harris Drucker and Chris J. C. Burges and Linda
		 Kaufman and Alex Smola and Vladimir Vapnik}
,title=		{Support Vector Regression Machines}
}

@unpublished{DruckerCo95b
,author=	{Harris Drucker and Corinna Cortes}
,title=		{Improving Pattern Classification Performance Using
		 Boosting Techniques}
,year=		1995
}

@inproceedings{DruckerCo96
,author=	{Harris Drucker and Corinna Cortes}
,title=		{Boosting Decision Trees}
,year=		1996
,booktitle=	nips8
,pages=		{479-485}
}

@article{DruckerCoJaLeVa94
,author=	{Harris Drucker and Corinna Cortes and L. D. Jackel
		 and Yann LeCun and Vladimir Vapnik}
,title=		{Boosting and other ensemble methods}
,journal=	{Neural Computation}
,volume=	6
,number=	6
,year=		1994
,pages=		{1289--1301}
}

@inproceedings{DruckerScSi93
,author=	{Harris Drucker and Robert Schapire and Patrice
		 Simard}
,title=		{Improving performance in neural networks using a
		 boosting algorithm}
,booktitle=	nips5
,year=		1993
,comment=	{,publisher=	{Morgan Kaufmann},editor=	nips5eds}
,pages=		{42--49}
}

@article{DruckerScSi93b
,author=	{Harris Drucker and Robert Schapire and Patrice
		 Simard}
,title=		{Boosting Performance in Neural Networks}
,journal=	{International Journal of Pattern Recognition and
		 Artificial Intelligence}
,year=		{1993}
,pages=		{705--719}
,volume=	7
,number=	4
}

@article{DrukhMa05,
author = {E.~Drukh and Y.~Mansour},
title = {Concentration bounds for unigrams language model},
journal = {Journal of Machine Learning Research},
year = {2005}
}

@article{DrusvyatskiyIoLe16,
author = {Dmitry Drusvyatskiy and Alexander Ioffe and Adrian Lewis},
title = {Nonsmooth optimization using {T}aylor-like models: error bounds,
  convergence, and termination criteria},
year = 2016,
journal = {arXiv:1610.03446 [math.OC]},
url = {https://arxiv.org/abs/1610.03446},
}

@article{DrusvyatskiyLe11,
author = {Dmitry Drusvyatskiy and Adrian Lewis},
title = {Generic nondegeneracy in convex optimization},
year = 2011,
journal = {Proceedings of the American Mathematical Society},
volume = 139,
number = 7,
pages = {2519–-2527},
}

@article{DrusvyatskiyLe13,
author = {Dmitry Drusvyatskiy and Adrian Lewis},
title = {Tilt Stability, Uniform Quadratic Growth, and Strong Metric 
  Regularity of the Subdifferential},
year = 2013,
journal = siopt,
volume = 23,
number = 1,
pages = {256--267},
}

@article{DrusvyatskiyLe16,
  title={Error bounds, quadratic growth, and linear convergence of
   proximal methods},
  author={Dmitry Drusvyatskiy and Adrian Lewis},
  journal={arXiv:1602.06661 [math.OC]},
  year={2016}
}

@article{DrusvyatskiyPa16,
author = {Dmitry Drusvyatskiy and Caroline Paquette},
title = {Efficiency of minimizing compositions of convex functions and smooth maps},
journal = {arXiv:1605.00125 [math.OC]},
year = 2016,
comment = {Old title = {An accelerated algorithm for minimizing convex compositions}},
}

@misc{Duchi15i,
author = {John C. Duchi},
title = {Information Theory and Statistics},
year = 2015,
howpublished = {Lecture Notes for Statistics 311/{EE} 377},
}

@misc{Duchi15,
author = {John C. Duchi},
title = {Stats311/{EE}377: Information theory and statistics},
year = 2015,
month = {Fall},
howpublished = {Course at Stanford University},
url = {http://web.stanford.edu/class/stats311},
}

@misc{Duchi16_convex_slides_w,
author = {John C. Duchi},
title = {Lecture 1: Background on Convex Analysis (written)},
note = {Park City Mathematics Institute Graduate Summer School,
 Institute for Advanced Study},
year = 2016,
url = {https://stanford.box.com/s/94i81xs4wfsgkvntlxg35yf5548k8gaz},
}

@misc{Duchi16_convex_slides,
author = {John C. Duchi},
title = {Lecture 1: Background on Convex Analysis},
note = {Park City Mathematics Institute Graduate Summer School,
Institute for Advanced Study},
year = 2016,
url = {https://stanford.box.com/s/a0wu1uqd9t2w2c255rzbsjo6s2us79th},
}

@incollection{Duchi17,
author = {John C. Duchi},
title = {Introductory Lectures on Stochastic Convex Optimization},
booktitle = {Park City Mathematics Institute Graduate Summer School:
  Collected Lectures},
publisher = {American Mathematical Society (forthcoming)},
year = 2017,
}

@misc{DuchiChRe15code,
author = {John C. Duchi and Sorathan Chaturapruek and Christopher R\'e},
title = {Asynchronous stochastic convex optimization},
year = 2015,
url = {https://www.codalab.org/worksheets/0x610bcdb722bf48d3b537a65edf0fe72d/},
note = {Code for reproducing experiments},
}

@article{DuchiChRe15,
author = {John C. Duchi and Sorathan Chaturapruek and Christopher R\'e},
title = {Asynchronous stochastic convex optimization},
year = 2015,
journal = {arXiv:1508.00882 [math.OC]},
}

@inproceedings{Duchi12,
author = {John C. Duchi},
title = {Commentary on ``{T}oward a Noncommutative Arithmetic-geometric Mean Inequality:
 Conjectures, Case-studies, and Consequences''},
booktitle = colt12,
pages = {11.25--11.27},
year = 2012,
}

@phdthesis{Duchi14,
author = {John C. Duchi},
title = {Multiple Optimality Guarantees in Statistical Learning},
school = {University of California, Berkeley},
year = 2014,
}

@article{DuchiAgJoJo12,
author = {John C. Duchi and Alekh Agarwal and Mikael Johansson and Michael I. Jordan},
title = {Ergodic Mirror Descent},
year = 2012,
journal = siopt,
volume = 22,
number = 4,
pages = {1549--1578},
}

@inproceedings{DuchiAgJoJo11_allerton,
author = {John C. Duchi and Alekh Agarwal and Mikael Johansson and
   Michael I. Jordan},
title = {Ergodic Mirror Descent},
year = 2011,
booktitle = allerton11,
pages = {701--706},
}


@unpublished{DuchiAgJoJo11,
author = {J. C. Duchi and A. Agarwal and M. Johansson and M. Jordan},
title = {Ergodic Mirror Descent},
year = 2011,
note = {URL \url{http://arxiv.org/abs/1105.4681}},
}

@inproceedings{DuchiAgWa10,
author = {John C. Duchi and A. Agarwal and M. J. Wainwright},
title = {Distributed dual averaging in networks},
year = 2010,
booktitle = nips23,
}

@article{DuchiAgWa12,
author = {John C.\ Duchi and Alekh Agarwal and Martin J.\ Wainwright},
title = {Dual averaging for distributed optimization: convergence analysis
and network scaling},
year = 2012,
journal = ieeetac,
volume = 57,
number = 3,
pages = {592--606},
}

@inproceedings{DuchiAgWa12_allerton,
author = {John C.\ Duchi and Alekh Agarwal and Martin J.\ Wainwright},
title = {Dual averaging for distributed optimization},
year = 2012,
booktitle = allerton12,
}

@unpublished{DuchiAgWa11b,
author = {John C. Duchi and A. Agarwal and M. J. Wainwright},
title = {Dual averaging for distributed optimization: convergence analysis
         and network scaling},
url = {http://arxiv.org/abs/1005.2012},
year = 2011,
}

@unpublished{DuchiBaWa11,
author = {J. C. Duchi and P. L. Bartlett and M. J. Wainwright},
title = {Randomized Smoothing for Stochastic Optimization},
year = 2011,
url = {http://arxiv.org/abs/1103.4296},
note = {URL \url{http://arxiv.org/abs/1103.4296}},
}

@inproceedings{DuchiBaWa12_icml,
author = {John C. Duchi and Peter L. Bartlett and Martin J. Wainwright},
title = {Randomized Smoothing for (Parallel) Stochastic Optimization},
year = 2012,
booktitle = icml12,
}

@inproceedings{DuchiBaWa12_cdc,
author = {John C. Duchi and Peter L. Bartlett and Martin J. Wainwright},
title = {Randomized Smoothing for Stochastic Optimization},
year = 2012,
booktitle = cdc2012,
}

@article{DuchiBaWa12,
author = {John C. Duchi and Peter L. Bartlett and Martin J. Wainwright},
title = {Randomized Smoothing for Stochastic Optimization},
year = 2012,
journal = siopt,
volume = 22,
number = 2,
pages = {674--701},
}

@unpublished{DuchiElJo11,
author = {J. C. Duchi and L. El Ghaoui and M. Johansson},
title = {Useful bits of convex analysis},
year = 2011,
note = {Lecture notes for EE290o, University of California, Berkeley},
}

@unpublished{DuchiElJo11_prox,
author = {J. C. Duchi and L. El Ghaoui and M. Johansson},
title = {Proximal and First-Order Methods for Convex Optimization},
year = 2011,
note = {Lecture notes for EE290o, University of California, Berkeley},
}

@article{DuchiGlNa16,
  title={Statistics of Robust Optimization: A Generalized Empirical
    Likelihood Approach},
  author={John C. Duchi and Peter W. Glynn and Hongseok Namkoong},
  year=2016,
  journal={arXiv:1610.03425 [stat.ML]},
  url = {https://arxiv.org/abs/1610.03425},
}


@inproceedings{DuchiGoKo08,
author = {John C. Duchi and Stephen Gould and Daphne Koller},
title = {Projected Subgradient Methods for Learning Sparse Gaussians},
booktitle = {Proceedings of the 24th Conference on Uncertainty in Artificial
  Intelligence (UAI)},
year = 2008,
}

@article{DuchiHaSi11,
author = {John C. Duchi and Elad Hazan and Yoram Singer},
title = {Adaptive subgradient methods for online learning and stochastic
         optimization},
year = 2011,
journal = jmlr,
volume = {12},
pages = {2121--2159},
}

@inproceedings{DuchiHaSi10,
author = {John C.\ Duchi and Elad Hazan and Yoram Singer},
title = {Adaptive subgradient methods for online learning and stochastic
         optimization},
year = 2010,
booktitle = colt10,
}

@inproceedings{DuchiJoMc13_nips,
author = {John C. Duchi and Michael I. Jordan and H. Brendan McMahan},
title = {Estimation, Optimization, and Parallelism when Data is Sparse},
year = 2013,
booktitle = nips26,
}

@inproceedings{DuchiJoWaWi12,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright and
Andre Wibisono},
title = {Finite Sample Convergence Rates of Zero-Order Stochastic Optimization
Methods},
year = 2012,
booktitle = nips25,
}

@article{DuchiJoWaWi13,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright and
Andre Wibisono},
title = {Optimal rates for zero-order optimization: the power of
two function evaluations},
year = 2013,
journal = {arXiv:1312.2139 [math.OC]},
}

@article{DuchiJoWaWi15,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright and
Andre Wibisono},
title = {Optimal rates for zero-order optimization: the power of
two function evaluations},
year = 2015,
journal = ieeeit,
volume = 61,
number = 5,
pages = {2788--2806},
}

@inproceedings{DuchiJoWa12_nips,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright},
title = {Privacy Aware Learning},
year = 2012,
booktitle = nips25,
}

@article{DuchiJoWa12,
author = {John C.\ Duchi and Michael I.\ Jordan and Martin J.\ Wainwright},
title = {Privacy Aware Learning},
year = 2012,
journal = {arXiv:1210.2085 [stat.ML]},
url = {http://arxiv.org/abs/1210.2085},
}

@article{DuchiJoWa14,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright},
title = {Privacy Aware Learning},
year = 2014,
journal = jacm,
volume = 61,
number = 6,
pages = {38:1--38:57},
}


@inproceedings{DuchiJoWa13_focs,
author = {John C.\ Duchi and Michael I.\ Jordan and Martin J.\ Wainwright},
title = {Local privacy and statistical minimax rates},
booktitle = focs13,
year = 2013,
}

@inproceedings{DuchiJoWa13_itw,
author = {John C.\ Duchi and Michael I.\ Jordan and Martin J.\ Wainwright},
title = {Local Privacy, Quantitative Data Processing Inequalities,
  and Statistical Minimax Rates},
year = 2013,
booktitle = {IEEE Information Theory Workshop},
}

@inproceedings{DuchiJoWa13_nips,
author = {John C.\ Duchi and Michael I.\ Jordan and Martin J.\ Wainwright},
title = {Local Privacy and Minimax Bounds:
   Sharp Rates for Probability Estimation},
booktitle = nips26,
year = 2013,
}

@article{DuchiJoWa13,
author = {John C.\ Duchi and Michael I.\ Jordan and Martin J.\ Wainwright},
title = {Local privacy, data processing inequalities, and minimax rates},
year = 2013,
journal = {arXiv:1302.3203 [math.ST]},
url = {http://arxiv.org/abs/1302.3203},
comment = {note = {In submission to \emph{Annals of Statistics}}},
}

@article{DuchiJoWa13_parametric,
author = {John C.\ Duchi and Michael I.\ Jordan and Martin J.\ Wainwright},
title = {Local privacy, data processing inequalities,
 and statistical minimax rates},
year = 2013,
journal = {arXiv:1302.3203 [math.ST]},
comment = {url = {http://arxiv.org/abs/1302.3203},
           note = {In submission to \emph{Annals of Statistics}}},
}

@article{DuchiJoWa13_probability,
author = {John C.\ Duchi and Michael I.\ Jordan and Martin J.\ Wainwright},
title = {Local privacy and minimax bounds: sharp rates for probability
estimation},
year = 2012,
journal = {arXiv:1305.6000 [math.ST]},
url = {http://arxiv.org/abs/1305.6000},
}

@article{DuchiJoWa16,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright},
title = {Minimax Optimal Procedures for Locally Private Estimation},
year = 2016,
journal = {arXiv:1604.02390 [math.ST]},
}

@article{DuchiJoWa18,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright},
title = {Minimax Optimal Procedures for Locally Private Estimation},
year = 2016,
journal = jasa,
volume = {To appear},
}

@article{DuchiJoWaZh14,
author = {John C.\ Duchi and Michael I.\ Jordan and
Martin J.\ Wainwright and Yuchen Zhang},
title = {Information-theoretic lower bounds for distributed statistical
  estimation with communication constraints},
journal = {arXiv:1405.0782 [cs.IT]},
year = {2014},
comment = {url = {http://arxiv.org/abs/1405.0782}},
}

@article{DuchiKhRu16,
author = {John C.\ Duchi and Khashayar Khosravi and Feng Ruan},
title = {Information Measures, Experiments,
    Multi-category Hypothesis Tests, and Surrogate Losses},
year = 2016,
journal = {arXiv:1603.00126 [math.ST]},
}

@unpublished{DuchiKhRu17s,
author = {John C.\ Duchi and Khashayar Khosravi and Feng Ruan},
title = {Supplement to ``{I}nformation Measures, Experiments,
    Multi-category Hypothesis Tests, and Surrogate Losses''},
year = 2017,
note = {DOI: COMPLETED BY TYPESETTER},
}

@inproceedings{DuchiMaJo10,
author = {John C. Duchi and Lester Mackey and Michael I. Jordan},
title = {On the Consistency of Ranking Algorithms},
booktitle = icml10,
year = 2010,
}

@techreport{DuchiMaJo10a,
   Author = {John C. Duchi and Lester W. Mackey and Michael I. Jordan},
   Title = {On the Consistency of Ranking Algorithms},
   Institution = {UC Berkeley},
   Year = {2010},
   Number = {EECS-2010-56},
   URL = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-56.html},
}

@article{DuchiMaJo12,
author = {John C. Duchi and Lester Mackey and Michael I. Jordan},
year = 2012,
title = {The Asymptotics of Ranking Algorithms},
journal = {arXiv:1204.1688 [math.ST]},
comment = {http://arxiv.org/abs/1204.1688},
}

@article{DuchiMaJo13,
author = {John C. Duchi and Lester Mackey and Michael I. Jordan},
title = {The Asymptotics of Ranking Algorithms},
journal = aos,
volume = 41,
year = 2013,
number = 5,
pages = {2292--2323},
comment = {url = {http://arxiv.org/abs/1204.1688}},
}

@unpublished{DuchiMaJo13_supp,
author = {John C. Duchi and Lester Mackey and Michael I. Jordan},
year = 2013,
title = {Supplement to ``{T}he Asymptotics of Ranking Algorithms''},
note = {DOI: COMPLETED BY TYPESETTER},
}

@article{DuchiNa16,
title = {Variance-based regularization with convex objectives},
author = {John C. Duchi and Hongseok Namkoong},
year = 2016,
journal = {arXiv:1610.02581 [stat.ML]},
}

@inproceedings{DuchiNa16_workshop,
author = {John C. Duchi and Hongseok Namkoong},
title = {Robust Stochastic Optimization: Learning the Tails},
year = 2016,
booktitle = {Reliable Machine Learning in the Wild Workshop,
International Conference on Machine Learning},
}

@article{DuchiRu16,
author = {John C. Duchi and Feng Ruan},
title = {Local asymptotics for some stochastic optimization problems:
optimality, constraint identification, and dual averaging},
year = 2016,
journal = {arXiv:1612.05612 [math.ST]},
}

@article{DuchiRu17b,
author = {John C. Duchi and Feng Ruan},
title = {Solving (most) of a set of quadratic equalities:
  Composite optimization for robust phase retrieval},
year = 2017,
journal = {arXiv:1705.02356 [math.ST]},
}

@article{DuchiRu17,
author = {John C. Duchi and Feng Ruan},
title = {Stochastic Methods for Composite Optimization Problems},
year = 2017,
journal = {arXiv:1703.08570 [math.OC]},
}

@inproceedings{DuchiShSiCh08,
author =    {John C. Duchi and Shai Shalev-Shwartz and Yoram Singer and
  Tushar Chandra},
title =     {Efficient Projections onto the $\ell_1$-Ball for Learning
             in High Dimensions},
booktitle = icml08,
year =      {2008},
}

@techreport{DuchiShSi08b,
author =    {J.~Duchi and T.~Shaked and Y.~Singer},
title =     {Infusing Boosting with $\ell_1$ and $\ell_\infty$ regularization},
institution= {Department of Computer Science, University of California,
		Berkeley},
year=     	2008,
month=    	Oct,
number=     {7777}
}

@inproceedings{DuchiSi09a,
author = {J. C. Duchi and Y. Singer},
title = {Boosting with structural sparsity},
year = 2009,
booktitle = icml09,
}

@inproceedings{DuchiSi09b,
author = {J. C. Duchi and Y. Singer},
title = {Efficient learning using forward-backward splitting},
year = 2009,
booktitle = nips22,
}

@article{DuchiSi09c,
author = {J. C. Duchi and Y. Singer},
title = {Efficient Online and Batch Learning using Forward-Backward Splitting},
year = 2009,
journal = jmlr,
volume = 10,
pages = {2873--2898},
}

@inproceedings{DuchiShSiTe10,
author = {J. C. Duchi and S. Shalev-Shwartz and Y. Singer and A. Tewari},
title = {Composite Objective Mirror Descent},
year = 2010,
booktitle = colt10,
}

@inproceedings{DuchiTaElKo06,
author = {John Duchi and Daniel Tarlow and Gal Elidan and Daphne Koller},
title = {Using Combinatorial Optimization within Max-Product
  Belief Propagation},
year = 2006,
booktitle = nips19,
}

@article{DuchiWa13,
author = {John C. Duchi and Martin J. Wainwright},
title = {Distance-based and continuum {F}ano inequalities with
        applications to statistical estimation},
year = 2013,
journal = {arXiv:1311.2669 [cs.IT]},
comment = {url = {http://arxiv.org/abs/1311.2669}},
}

@book{DudaHa73,
author = 	{R.~O.~Duda and P.~E.~Hart},
title = 	{Pattern Classification and Scene Analysis},
publisher = 	{Wiley},
year = 		{1973}
}

@book{DudaHa01,
author = 	{R.~O.~Duda and P.~E.~Hart and D.~G.~Stork},
title = 	{Pattern Classification},
publisher = 	{Wiley},
year = 		{2001},
edition =       {2}
}

@article{DudikPhSc07,
  author = "M.~Dud\'ik and S.~J.~Phillips and R.~E.~Schapire",
  title = "Maximum entropy density estimation with generalized
    regularization and an application to species distribution modeling",
  journal = jmlr,
  volume = 8,
  month = "June",
  pages = "1217--1260",
  year = 2007
}

@article{Dudley78,
author=   	{Dudley, R. M.},
title=    	{Central Limit Theorems for Empirical Measures},
journal=  	{The Annals of Probability},
year=     	1978,
volume=   	6,
number=   	6,
pages=    	{899--929},
comment=  	{Generalization and proofs of Vapnik-Chervonenkis results.}
}

@article{Dudley79,
author=        {Richard M. Dudley},
title=         {Balls in {$R^k$} do not cut all subsets of {$k+2$}
                  points},
year = 1979,
journal = {Advances in Mathematics},
volume = 31,
number = 3,
pages = {306--308},
}

@article{Dudley87,
author=		{R. M. Dudley},
title=		{Universal {D}onsker classes and metric entropy},
journal=	{Annals of Probability},
volume=		15,
number=		4,
pages=		{1306--1326},
year=		1987
}

@book{Dudley99,
author = {Richard M. Dudley},
title = {Uniform Central Limit Theorems},
publisher = {Cambridge University Press},
year = 1999,
}

@book{Dudley02,
author = {Richard M. Dudley},
title = {Real Analysis and Probability},
publisher = {Cambridge University Press},
edition = {Second},
year = 2002,
}


@article{DuffyWi15,
  title={Estimating large deviation rate functions},
  author={Duffy, Ken R and Williamson, Brendan D},
  journal={arXiv preprint arXiv:1511.02295},
  year=2015,
  comment={Gives large deviation rates for Sanov's theorem for plug-in
           estimators for the large deviation rate functional}
}

@article{DuffieldLeOCRuTo95,
  title={Entropy of ATM traffic streams: a tool for estimating QoS parameters},
  author={Duffield, Nick G. and Lewis, John T and O'Connell, Neil and Russell, Raymond and Toomey, Fergal},
  journal={IEEE Journal on Selected Areas in Communications},
  volume=13,
  number=6,
  pages={981--990},
  year=1995,
  publisher={IEEE}
}

@inproceedings{DuffyHe99,
	author = "N. Duffy and D. Helmbold",
	title = "A Geometric Approach to Leveraging Weak Learners",
	booktitle = eurocolt99,
	publisher =	"Springer-Verlag",
	year = 1999
}

@inproceedings{DuffyHe99b,
	author = "N. Duffy and D. Helmbold",
	title = "Potential Boosters ?",
	booktitle = nips12,
        pages = {258--264},
        publisher = "MIT press",
	year = 1999
}

@inproceedings{DuffyHe00,
	author = "N. Duffy and D. Helmbold",
	title = "Leveraging for Regression",
	booktitle = colt00,
	publisher =	"ACM",
	year = 2000
}

@article{DuffyMe05,
  title={The large deviations of estimating rate functions},
  author={Duffy, Ken and Metcalfe, Anthony P},
  journal={Journal of Applied Probability},
  volume=42,
  number=1,
  pages={267--274},
  year=2005,
  publisher={Cambridge University Press}
}

@inproceedings{ DumaisCh00,
    author = "S. T. Dumais and H. Chen",
    title = "Hierarchical classification of {W}eb content",
    booktitle = "Proceedings of {SIGIR}-00",
    pages = "256--263",
    year = 2000
}

@article{DumbgenFrJo04,
author = {Lutz D\"umbgen and Sandra Freitag and Geurt Jongbloed},
title = {Consistency of Concave Regression with an Application to
   Current-Status Data},
year = 2004,
journal = {Mathematical Methods of Statistics},
volume = 13,
pages = {69--81},
}

@article{DumbgenSaSc11,
author = {Lutz D\"umbgen and Richard Samworth and },
title = {Approximation by log-concave distributions with applications
   to regression},
year = 2011,
journal = aos,
volume = 39,
pages = {702–-730},
}

@article{DumbgenGeVeWe10,
author = {Lutz D\"umbgen and Sara {van de Geer} and Mark Veraar and
  Jon Wellner},
title = {Nemirovski's inequalities revisited},
year = 2010,
journal = {American Mathematical Monthly},
pages = {138--160},
volume = 117,
}

@slides{Dumouchel97
,author=        {William duMouchel}
,title=         {Statistical analysis of categorical data}
}

@article{DuncanLa86,
author = {George T. Duncan and Diane Lambert},
title = {Disclosure-limited data dissemination},
year = 1986,
journal = jasa,
volume = 81,
number = 393,
pages = {10--18},
comment = {
This paper, along with Duncan and Lambert 1989, seems to be the proposer
of a way to measure privacy in statistical databases (like releases of census
data) by way of disclosure identification/limitation. They propose a
decision-theoretic way to measure disclosure (in this paper, it is for
tabular data) by measuring identification risk/a user's predictive
distribution over data, and how it changes before and after data release.
(A bit vague for me.)
},
}

@article{DuncanLa89,
author = {George T. Duncan and Diane Lambert},
title = {The risk of disclosure for microdata},
year = 1989,
journal = {Journal of Business and Economic Statistics},
volume = 7,
number = 2,
pages = {207--217},
comment = {
  Discusses the disclosure limitation framework for microdata, that is, when
  a set of records is released in full (non-tabularized data). This extends
  their earlier work in JASA 86, and measures risk by a decision-theoretic
  loss for when a datum is actually "linked," that is, the intruder (bad
  guy) figures out that some released data item is actually something that
  he owns already. The risk is then measured by a loss weighted by the
  conditional probabilities of such linkage events. Evaluating these
  conditional probabilities is somewhat challening, as it is unclear what
  data an adversary may have, so to be maximally private, one must assume
  that an adversary/intruder has access to lots of data (for example, the
  intruder may know the non-private data of each record being released, and
  may be simply trying to identify which are which).
},
}

@article{DupacovaWe88,
  title={Asymptotic behavior of statistical estimators and of optimal solutions of stochastic optimization problems},
  author={Dupacov{\'a}, Jitka and Wets, Roger},
  journal=aos,
  pages={1517--1549},
  year=1988,
  comment={Conditions under which consistency and asymptotic normality
                  of empirical optimum hold are given. Feasible set is
                  assumed to be fixed and the objective smooth. Cleans
                  up measurability issues using measurable
                  selections.}
}

@inproceedings{DureyCl01,
        author = "Durey, A. S. and Clements, M. A. ",
        title = "Melody Spotting Using Hidden Markov Models",
        booktitle = "Proceedings of the International Symposium on Music
          Information Retrieval",
        address = "Bloomington, IN",
        month = "October",
        year = "2001",
        pages = "109--117"
}


@article{DurGr93,
author=		{A. D\"ur and J. Grabmeier},
title=		{Applying Coding Theory to Sparse Interpolation},
journal=	sicomp,
volume=		22,
number=		4,
pages=		{695--704},
month=		aug,
year=		1993
}

@article{Duttweiler78
,author=	{Donald L. Duttweiler}
,title=		{A twelve-channel digital echo canceler}
,year=		1978
}

@incollection{Dwork08,
author = {Cynthia Dwork},
title = {Differential privacy: a survey of results},
year = 2008,
booktitle = {Theory and Applications of Models of Computation},
series = {Lecture Notes in Computer Science},
volume = 4978,
pages = {1--19},
publisher = {Springer},
comment = {
  Nice survey of differential privacy ideas. Discusses the addition of Laplace
  noise and shows that for queries--i.e. functions computed on a dataset--that
  satisfy a Lipschitz condition with respect to Hamming metric Laplace noise
  is sufficient to guarantee privacy. Points out that the
  statistician (curator of the dataset) \emph{must} be trusted. Goes through
  several examples of differential privacy applications: frequency analysis,
  contingency tables (i.e. marginals), halfspace learning, statistical
  query modeling, and PAC learning. Not clear from survey that Laplace
  noise is necessary or essential to differential privacy, but clear that
  most work has used this.
},
}

@article{DworkFeHaPiReRo15sci,
author = {Cynthia Dwork and Vitaly Feldman and Moritz Hardt and Toni
 Pitassi and Omer Reingold and Aaron Roth},
title = {The reusable holdout: Preserving Statistical Validity
  in Adaptive Data Analysis},
year = 2015,
journal = {Science},
volume = 349,
number = 6248,
pages = {636--638},
}

@article{DworkFeHaPiReRo14,
author = {Cynthia Dwork and Vitaly Feldman and Moritz Hardt and Toni
 Pitassi and Omer Reingold and Aaron Roth},
title = {Preserving Statistical Validity in Adaptive Data Analysis},
journal = {arXiv:1411.2664v2 [cs.LG]},
year = 2014,
}

@inproceedings{DworkFeHaPiReRo15,
author = {Cynthia Dwork and Vitaly Feldman and Moritz Hardt and Toni
 Pitassi and Omer Reingold and Aaron Roth},
title = {Preserving Statistical Validity in Adaptive Data Analysis},
year = 2015,
booktitle = stoc15,
}

@article{DworkFeHaPiReRo15b,
author = {Cynthia Dwork and Vitaly Feldman and Moritz Hardt and Toni
 Pitassi and Omer Reingold and Aaron Roth},
title = {Generalization in Adaptive Data Analysis and Holdout Reuse},
year = 2015,
journal = {arXiv:1506.02629 [cs.LG]},
}

@inproceedings{DworkKeMcMiNa06,
author = {Cynthia Dwork and Krishnaram Kenthapadi and Frank McSherry
  and Ilya Mironov and Moni Naor},
title = {Our Data, Ourselves: Privacy Via Distributed Noise Generation},
booktitle = {Advances in Cryptology (EUROCRYPT 2006)},
year = 2006,
comment = { Defines (\epsilon, \delta)-differential privacy by allowing
  an additive probability of error if the communicated statistics are
  extremely unlikely, i.e. P(Z \in S \mid x) \le e^\epsilon P(Z \in S \mid x')
  + \delta, where Z is the released statistic and x and x' are different
  in the way that we want to make private.
  Also shows how to generate noise in a distributed way.},
}

@inproceedings{DworkKuNaSi01,
author = {C.~Dwork and R.~Kumar and M.~Naor and D.~Sivakumar},
title = {Rank aggregation methods for the web},
year = 2001,
booktitle = {Proceedings of the Tenth International World Wide Web Conference
(WWW10)},
}

@inproceedings{DworkLe09,
author = {Cynthia Dwork and Jing Lei},
title = {Differential privacy and robust statistics},
year = 2009,
booktitle = stoc09,
abstract = { We show by means of several examples that robust
             statistical estimators present an excellent starting
             point for differentially private estimators. Our
             algorithms use a new paradigm for differentially
             private mechanisms, which we call
             Propose-Test-Release (PTR), and for which we give a
             formal definition and general composition theorems.
             },
comment = {
  Uses robust statistics, which are stable to data perturbation, to guarantee
  differential privacy (after a perturbation). Add an additional wrinkle in
  that a database will not release information if it is judged to be
  unstable (i.e. a non-robust estimator). Not clear what rates they can
  attain, as results appear to be asymptotic. They do get something like
  ''with probability at least $1 - n^{-\alpha \epsilon}$, the released
  statistic is within $[n^{-\alpha}, n^\alpha] q$, where $q$ is the
  inter-quartile range of the statistic being evaluated.
  They discretize the space to localize, then apply noise addition, which
  has some similarity to NissimRaSm07. They have issues of discretization
  though, because statistics may hit weird locations and require
  re-discretization. Generalization to higher-d is a bit unclear.
},
}

@inproceedings{DworkMcNiSm06,
author = {Cynthia Dwork and Frank McSherry and Kobbi Nissim and Adam Smith},
title = {Calibrating noise to sensitivity in private data analysis},
year = 2006,
booktitle = {Proceedings of the Third Theory of Cryptography Conference},
pages = {265--284},
comment = {
The initial paper that defines differential privacy as a ratio of probabilities
of outputs of statistical procedures on datasets differing in at most
one entry. They show that adding Laplace-distributed noise guarantees
privacy. They also give a few lower bounds (which seem quite loose and
also a bit hard to evaluate) that show that an \epsilon-private mechanism
cannot answer a large number of queries/statistical questions unless
the number of data points is large. The notion of answering queries is
a little cryptographic though. Appendices show the
equivalence of some semantic notions of differential privacy; it seems
that differential privacy means that an adversary knowing most of a dataset
cannot recover information about a single entry in a dataset with a few
queries of the dataset.
},
}

@article{DworkSm09,
author = {Cynthia Dwork and Adam Smith},
year = 2009,
title = {Differential privacy for statistics: what we know and what we want
to learn},
journal = {Journal of Privacy and Confidentiality},
volume = 1,
number = 2,
pages = {135--154},
comment = {
  Surveys work at intersection of differential privacy and statistical
  inference. Mostly recaps papers by Dwork and Lei (09) and Smith (11) on
  robust statistics and convergence rates for point estimators. Gives
  simple arguments/explanations for both of them; easy to read.
},
}

@article{DworkRo16,
author = {Cynthia Dwork and Guy Rothblum},
title = {Concentrated Differential Privacy},
year = 2016,
journal = {arXiv:1603.01887 [cs.DS]},
}

@inproceedings{DworkRoVa10,
author = {Cynthia Dwork and Guy N. Rothblum and Salil P. Vadhan},
title = {Boosting and Differential Privacy},
year = 2010,
booktitle = focs10,
pages = {51--60},
comment = {
  Combines boosting with tools that generate synopses of a dataset to
  release private and (for some set of queries) useful dataset synopses.
  More specifically, starts with a set $Q$ of queries, then proceeds in rounds
  of boosting, where in each round $t$ a synopsis $A_t$ is computed. This
  synopsis should have $A_t(q) \approx q(X)$, where $X$ is the database
  and $A_t(q)$ is synopsis $t$'s approximation to $q(X)$ for the query $q$,
  for sufficiently many queries $q$. Performs boosting on the weights
  where each query $q$ is treated as a training example and the goal is
  to approximate $q(X)$ correctly.
  %
  A few issues: run time is (obviously) large in $|Q|$, but may also be
  large in $|X|$ (or the possible size thereof). It would be reasonable
  to try to understand whether such algorithms were possible for sets of
  infinite size, but with finite metric entropies (or something along those
  lines). What if the queries consist of all queries of the form
  $\sum_{i=1}^n l'(x_i^T \theta) x_i$, where $l$ is some loss. That is, all
  linear models/GLMs?
},
}

@article{DyerFrKa91,
author=		{Martin Dyer and Alan Frieze and Ravi Kannan},
title=		{A Random Polynomial-Time Algorithm for Approximating
		 the Volume of Convex Bodies},
journal=	jacm,
volume=		38,
number=		1,
pages=		{1--17},
month=		jan,
year=		1991
}

@manual{Economist14,
organization = {The Economist Intelligence Unit},
title = {Who's big on {B}ig {D}ata?},
year = 2014,
url = {http://www.economistinsights.com/analysis/who-s-big-big-data},
}

@book{Edwards73,
author = {C. Henry Edwards},
title = {Advanced Calculus of Several Variables},
year = 1973,
publisher = {Academic Press},
address = {New York},
}

@misc{EE364b,
author = {Stephen P. Boyd and John C. Duchi},
title = {{EE}364b: Convex {O}ptimization {II}},
year = 2015,
month = {Spring},
howpublished = {Course at Stanford University},
url = {http://ee364b.stanford.edu},
}

@book{Efromovich99,
author = {Sam Efromovich},
year = 1999,
title = {Nonparametric Curve Estimation: Methods, Theory, and Applications},
publisher = {Springer-Verlag},
}

@article{EfronHaJoTi04,
author = {Bradley Efron and Trevor Hastie and Iain Johnstone and Robert
  Tibshirani},
title = {Least angle regression},
year = 2004,
journal = aos,
volume = 32,
number = 2,
pages = {407--451},
}

@book{EfronTi93
,author=	{Bradley Efron and Robert J. Tibshirani}
,title=		{An Introduction to the Bootstrap}
,year=		1993
,publisher=	{Chapman \& Hall}
}

@book{Efron12,
author = {Bradley Efron},
title = {Large-Scale Inference: Empirical Bayes Methods for Estimation,
  Testing, and Prediction},
year = 2012,
publisher = {Cambridge University Press},
series = {Insitute of Mathematical Statistics Monographs},
}

@inproceedings{EhrenfeuchtHa88,
author=   	{Ehrenfeucht, Andrzej and David Haussler},
title=    	{Learning Decision Trees from Random Examples},
booktitle=	colt88,
publisher=	{Morgan Kaufman},
address=	{San Mateo, CA},
month=    	Aug,
year=     	1988,
pages = 	{182--194}
}

@techreport{EhrenfeuchtHaKeVa87,
author = 	{A. Ehrenfeucht and D. Haussler and M. Kearns and L. Valiant},
title = 	{A General Lower Bound on the Number of Examples Needed
		 for Learning},
institution = 	ucsccrl,
year = 		1987,
number = 	{UCSC-CRL-87-26}
}

@inproceedings{EhrenfeuchtHaKeVa88,
author = 	{Andrzej Ehrenfeucht and David Haussler and Michael
		 Kearns and Leslie Valiant},
title = 	{A General Lower Bound on the Number of Examples Needed
		 for Learning},
booktitle = 	colt88,
year = 		{1988},
month = 	aug,
pages = 	{139--154}
}

@article{EichbergerHaMi93
,author=	{J. Eichberger and H. Haller and F. Milne}
,title=		{Naive {B}ayesian learning in $2\times 2$ matrix games}
,year=		1993
}

@inproceedings{EichhornToZiKuRaWeLoSc03,
	author = {J. Eichhorn and A. Tolias and A. Zien and M. Kuss and
		C. Rasmussen and J. Weston and N. Logothetis and B. Sch\"olkopf},
	title = "Prediction on Spike Data using Kernel Algorithms",
	booktitle = nips16,
	year = 2003,
	note = "(to appear)"
}

@book{ElGamalKi11,
author = {Abbas {El Gamal} and Young-Han Kim},
title = {Network Information Theory},
publisher = {Cambridge University Press},
year = 2011,
}

@article{EldarMe14,
author = {Yonina Eldar and Shahar Mendelson},
title = {Phase retrieval: Stability and recovery guarantees},
journal = {Applied and Computational Harmonic Analysis},
year = 2014,
volume = 36,
number = 3,
pages = {473–-494},
}

@inproceedings{ElidanMcKo06,
author = {Gal Elidan and Ian McGraw and Daphne Koller},
title = {Residual Belief Propagation:
   Informed Scheduling for Asynchronous Message Passing},
year = 2006,
booktitle = {Proceedings of the 22nd Conference on Uncertainty in Artificial
Intelligence (UAI)},
}

@inproceedings{ElisseeffWe01,
	author = "A. Elisseeff and J. Weston",
	title = "A Kernel Method for Multi-Labeled Classification",
	booktitle = nips14,
	year = 2001
}

@book{Ellis07,
  title={Entropy, large deviations, and statistical mechanics},
  author={Ellis, Richard},
  year=2007,
  publisher={Springer}
}

@phdthesis{Emerson09,
  title={Small sample performance and calibration of the Empirical Likelihood method},
  author={Emerson, Sarah},
  year=2009,
  school={Stanford University},
  comment={Ph.D. dissertation with Art Owen}
}

@article{ErlichChPeLe97,
	author={Y. Erlich and D. Chazan and S. Petrack and A. Levy},
	title={Lower bound on {VC}-dimension by local shattering},
	journal=	{Neural Computation},
	volume=		9,
	number=		4,
	pages=		{771--776},
	month=	 May,
	year=		1997
}

@inproceedings{ErlingsonPiKo14,
author = {Ulfar Erlingsson and Vasyl Pihur and Aleksandra Korolova},
title = {{RAPPOR}: Randomized Aggregatable Privacy-Preserving Ordinal Response},
year = 2014,
booktitle = {Proceedings of the 21st ACM Conference on Computer
  and Communications Security (CCS)},
}

@article{Ermoliev69,
author = {Y. M. Ermoliev},
title = {On the stochastic quasi-gradient method and stochastic quasi-{F}eyer
sequences},
year = 1969,
journal = {Kibernetika},
volume = 2,
pages = {72--83},
}

@article{ErwayGi09,
  title={A subspace minimization method for the trust-region step},
  author={Erway, Jennifer B and Gill, Philip E},
  journal = siopt,
  volume={20},
  number={3},
  pages={1439--1461},
  year={2009},
}

@article{EsfahaniKu15,
  title={Data-driven distributionally robust optimization using the Wasserstein metric: Performance guarantees and tractable reformulations},
  author={Esfahani, Peyman Mohajerin and Kuhn, Daniel},
  journal={arXiv preprint arXiv:1505.05116},
  year=2015,
  comment={Gives convex reformulations of DRO problems based on
                  Wasserstein distances for certain loss functions
                  (concave in uncertainty parameter, certain two-stage
                  stochastic programs). Using a recent result by
                  Fournier and Guillin (2014), they use a
                  concentration inequality for the probability of P
                  being contained in the Wasserstein ball to choose
                  the size of the robust region.}
}

@PhdThesis{Eskin02,
  author = 	 {E. Eskin},
  title = 	 {Sparse Sequence Modeling with Applications to Computational Biology and Intrusion Detection},
  school = 	 {Columbia University},
  year = 	 {2002},
}

@book{EthierKu09,
  title={Markov processes: characterization and convergence},
  author={Ethier, Stewart N and Kurtz, Thomas G},
  volume=282,
  year=2009,
  publisher={John Wiley \& Sons}
}

@MISC{EtsiFrontEnd00,
  title = {{ETSI Standard}, {ETSI ES 201 108}},
  year =         {2000},
  key =          {ETSI},
}

@inproceedings{EtzioniHaJiKaMaWa96,
	Author = "O. Etzioni and S. Hanks and T. Jiang and R. M. Karp and
		O. Madani and O. Waarts",
	title = "Efficient information gathering on the internet",
	booktitle = focs96,
	year = 1996
}

@inproceedings{EvfimievskiGeSr03,
author = {Alexandre V. Evfimievski and Johannes Gehrke
 and Ramakrishnan Srikant},
title = {Limiting privacy breaches in privacy preserving data mining},
year = 2003,
booktitle = {Proceedings of the Twenty-Second Symposium on Principles of
Database Systems},
pages = {211--222},
comment = {
  Looks at more local measures of privacy and proposes a quantity called
  "amplification" that is essentially identical to the differential privacy
  criterion. Specifically, there are N clients, each with data x_i, which
  they don't want to reveal to a central server; instead each client
  releases R(x_i), a randomized version of x_i. The authors measure privacy
  risk in terms of the increase/decrease in P(X_i = x_i | R(x_i)) vs.
  P(X_i = x_i), showing that this can be controlled by bounding the
  "amplification," which is max_{x, x', y} P(R(x) = y) / P(R(x') = y).
  They also suggest measuring privacy-breaches with a worst-case
  KL divergence (i.e. max_y KL(P(X | y), P(X))), because the mutual information
  can lead to privacy breaches for unlikely data x (as it is weighted by x).
},
}

@article{EvgeniouMiPo05,
author = "T.~Evgeniou and C.Micchelli and M.~Pontil",
title = "Learning Multiple Tasks with Kernel Methods",
journal = jmlr,
volume = 6,
pages = "615--637",
year = "2005"
}

@article{FaberMy91
,author=        {V. Faber and J. Mycielsky}
,title=         {Applications of learning theorems}
}

@article{Fabian08,
  title={Handling CVaR objectives and constraints in two-stage stochastic models},
  author={F{\'a}bi{\'a}n, Csaba I},
  journal={European Journal of Operational Research},
  volume=191,
  number=3,
  pages={888--911},
  year=2008,
  publisher={Elsevier}
}

@article{Fan91,
author = {Fan, Jianqing},
title = {On the estimation of quadratic functionals},
year = 1991,
journal = aos,
volume = 19,
number = 3,
pages = {1273--1294},
}

@book{FangPu93,
author=		{Shu-Cherng Fang and Sarat Puthenpura},
title=		{Linear Optimization and Extensions: Theory and
		 Algorithms},
year=		1993,
publisher=	{Prentice Hall}
}

@unpublished{Fano52,
author = {Robert M. Fano},
title = {Notes for {T}ransmission of {I}nformation, {MIT} course 6.574},
publisher = {MIT},
address = {Cambridge, MA},
year = 1952,
}

@techreport{FarmerSi88,
author=	  	{Farmer, J. Doyne and John J. Sidorowich},
title=	  	{Exploiting Chaos to Predict the Future and Reduce Noise},
institution= 	{Los Alamos National Laboratory},
year=	  	1988,
month=	  	mar,
number=	  	{LA-UR-88-901}
}

@article{FederMeGu92,
author=		{M. Feder and N. Merhav and M. Gutman},
title=		"Universal Prediction of individual sequences",
journal=	"IEEE Transactions on Information Theory",
volume=		38,
pages=		"1258--1270",
year=		1992
}

@book{Fedorov72,
  title={Theory of optimal experiments},
  author={Fedorov, Valerii Vadimovich},
  year={1972},
  publisher={Academic Press},
}

@article{Fellegi72,
author = {Ivan P. Fellegi},
title = {On the question of statistical confidentiality},
year = 1972,
journal = jasa,
volume = 67,
number = 337,
pages = {7--18},
comment = {
  Essentially an essay on confidentiality. Focuses on tabular data released
  from things like censuses, talks about how privacy may be compromised even
  when anonimized if certain tables yields linear equations with unique
  inverses.
},
}

@book{Feller71,
  title={An introduction to probability theory and its applications},
  author={Feller, Willliam},
  volume=2,
  year=1971,
  publisher={John Wiley \& Sons}
}

@book{Feller68,
author=   	{Feller, William},
title=    	{An Introduction to Probability and its Applications},
publisher=	{John Wiley and Sons},
year=     	1968,
edition=  	{third},
volume=   	1
}

@article{FercoqRi13,
  title={Smooth minimization of nonsmooth functions with parallel coordinate descent methods},
  author={Fercoq, Olivier and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1309.5885},
  year=2013
}

@book{Ferguson67
,author=	{Thomas S. Ferguson}
,title=		{Mathematical Statistics: A Decision Theoretic
		 Approach}
,year=		1967
,publisher=	{Academic Press}
}

@book{Fernholz83,
author={Fernholz, Luisa Turrin},
title={Von Mises calculus for statistical functionals},
volume=19,
year=1983,
publisher={Springer Science \& Business Media}
}

@article{Feuerverger89,
  title={On the empirical saddlepoint approximation},
  author={Feuerverger, Andrey},
  journal={Biometrika},
  volume=76,
  number=3,
  pages={457--464},
  year=1989,
  publisher={Oxford University Press}
}

@article{FeuervergerMc81,
  title={On the efficiency of empirical characteristic function procedures},
  author={Feuerverger, Andrey and McDunnough, Philip},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={20--27},
  year=1981,
  publisher={JSTOR}
}

@article{FeuervergerMu77,
  title={The empirical characteristic function and its applications},
  author={Feuerverger, Andrey and Mureika, Roman A},
  journal={The annals of Statistics},
  pages={88--97},
  year=1977,
  publisher={JSTOR}
}

@book{Feyerabend81,
author=   	{Feyerabend, P. K.},
title=    	{Philosophical Papers: Realism, Rationalism, \&
           	Scientific Method},
publisher=	{Cambridge University Press},
year=     	1981,
volume=   	1
}

@article{FiatRaRa94,
author=	{A. Fiat and Y. Rabani and Y. Ravid},
title=		{Competitive {$k$}-Server Algorithms},
journal=	jcss,
volume=	48,
number=	3,
year=1994,
pages={410-428}
}

@article{Fiedler72,
author=   	{Fiedler, Miroslav},
title=    	{Bounds for Eigenvalues of Doubly Stochastic Matrices},
journal=   	{Linear Algebra and its Applications},
year=      	1972,
month=     	Jul,
volume=    	5,
number=    	3,
pages=     	{299--310}
}

@article{Field75,
author={B. J. Field},
title={Towards automatic indexing: automatic assignment of
                  controlled-language indexing and classification from
                  free indexing},
journal={Journal of Documentation},
volume=31,
number=4,
month=dec,
year=1975,
pages={246-265}
}

@article{Fienberg70,
author=   	{Fienberg, Stephen E.},
title=    	{An Iterative Procedure for Estimation in Contingency Tables},
journal=  	{Journal of Mathematical Statistics},
year=     	1970,
volume=   	41,
number=   	3,
pages=    	{907--917},
comment=  	{Proves convergence of Deming/Stephan iterative procedure for
	   	finding maximum entropy solution}
}

@article{FienbergMaSt98,
author = {Stephen E. Fienberg and Udi E. Makov and Russell J. Steele},
title = {Disclosure Limitation Using Perturbation and Related
Methods for Categorical Data},
year = 1998,
journal = {Journal of Official Statistics},
volume = 14,
number = 4,
pages = {485--502},
}

@inproceedings{FienbergRiYa10,
author = {Stephen E. Fienberg and Alessandro Rinaldo and Xiaolin Yang},
title = {Differential Privacy and the Risk-Utility Tradeoff for
         Multi-dimensional Contingency Tables},
year = 2010,
booktitle = {The International Conference on
                  Privacy in Statistical Databases},
comment = {
  Studies a Fourier-based version of attaining differential privacy for
  contingency (count) tables by adding Laplace noise, originally proposed
  by Barak, Chaudhuri, et al in PODS. They argue that it introduces too much
  noise to be really effective, and yields unbearably high counts in some
  cases when the count data is really not that high. Simulations on
  three data sets exhibit the problems with maintaining privacy, since
  differential privacy appears quite stringent in this case. Though not
  100\% clear that the studied mechanism is the best for attaining differential
  privacy.
},
}

@article{Fienup78,
author = {James R. Fienup},
journal = {Optics Letters},
number = {1},
pages = {27--29},
title = {Reconstruction of an object from the modulus of its {F}ourier
  transform},
volume = {3},
year = {1978},
abstract = {We present a digital method for solving the phase-retrieval
 problem of optical-coherence theory: the reconstruction of a general object
 from the modulus of its Fourier transform. This technique should be useful
 for obtaining high-resolution imagery from interferometer data.},
}

@article{Fienup82,
author = {James R. Fienup},
journal = {Applied Optics},
number = {15},
pages = {2758--2769},
title = {Phase retrieval algorithms: a comparison},
volume = {21},
year = {1982},
}

@article{FigueiredoNoWr07,
author =        {M. Figueiredo and R. Nowak and
                 S. Wright},
title =         {Gradient projection for sparse reconstruction: application to
                 compressed sensing and other inverse problems},
journal =       {IEEE Journal of Selected Topics in Signal Processing: Special
                 Issue on Convex Optimization Methods for Signal Processing},
volume =        1,
number =        4,
year =          2007,
pages =         {586-598},
}

@article{Fill91,
author=		{James Allen Fill},
title=		{Eigenvalue bounds on convergence to stationarity for
		 nonreversible {M}arkov chains, with an application to
		 the exclusion process},
journal=	{The Annals of Applied Probability},
volume=		1,
number=		1,
year=		1991,
pages=		{62--87}
}


@article{FineSc01,
author = {S. Fine and K. Scheinberg},
title = {Efficient {SVM} training using low-rank kernel representations},
journal = {J. of Mach. Learning Res.},
volume = {2},
pages = {242--264},
year = {2001}
}

@inproceedings{FinkShSiUl06,
author=		{Michael Fink and Shai Shalev-Shwartz and Yoram Singer and Shimon Ullman},
title=		{Online Multiclass Learning by Interclass Hypothesis Sharing},
booktitle=	icml06,
year=		2006
}


@inproceedings{FischerSi90,
author=		{Paul Fischer and Hans Ulrich Simon},
title=		{On learning ring-sum-expansions},
booktitle=	colt90,
year=		1990,
month=		aug,
pages=		{130--143}
}



@article{FischerSi92,
author=		{Paul Fischer and Hans Ulrich Simon},
title=		{On learning ring-sum-expansions},
journal=	sicomp,
volume=		21,
number=		1,
pages=		{181--192},
month=		feb,
year=		1992
}

@article{FischhoffBM83,
author=   	{Fischhoff, Baruch and Ruth Beyth-Marom},
title=    	{Hypothesis Evaluation from a Bayesian Perspective},
journal=  	{Psychological Review},
year=     	1983,
volume=   	90,
number=   	3,
pages=    	{239--260},
comment=  	{Taxonomy of ways people might deviate from Bayesianism.}
}

@article{FlajoletGaTh92,
  title={Birthday paradox, coupon collectors, caching algorithms and self-organizing search},
  author={Flajolet, Philippe and Gardy, Daniele and Thimonier, Lo{\"y}s},
  journal={Discrete Applied Mathematics},
  volume=39,
  number=3,
  pages={207--229},
  year=1992,
  publisher={Elsevier}
}

@article{FlannaganFrHo86,
author=  	{Flannagan, Michael J. and Lisbeth S. Fried and Keith J.
		Holyoak},
title=   	{Distributional Expectations and the Induction of Category
		Structure},
journal= 	{Journal of Experimental Psychology: Learning, Memory, and
		Cognition},
year=    	1986,
volume=  	12,
number=  	2,
pages=   	{241--256},
comment= 	{Experimental evidence in favor of idea that people expect
		exemplars of a category to follow the normal distribution}
}

@inproceedings{FlaxmanKaMc05,
author = {Abraham D. Flaxman and Adam Tauman Kalai and H. Brendan McMahan},
title = {Online convex optimization in the bandit setting:
gradient descent without a gradient},
year = 2005,
booktitle = {Proceedings of the
Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
comment = {Re-discovers Nemirovski and Yudin's 1 point gradient estimator
based on uniform sampling from an \ell_2 ball. (See Nemirovski and Yudin's
1983 book, where Chapter 9 lists the problem as an exercise.)},
}

@article{Fletcher82,
author = {Roger Fletcher},
title = {A model algorithm for composite nondifferentiable optimization
   problems},
year = 1982,
journal = {Mathematical Programming Study},
volume = 17,
pages = {67--76},
comment = {Proposes and analyzes local convergence of a trust-region like
  method for the composite problem $\min. f(x) = h(c(x))$, where $h$
  is a polyhedral function and $c$ is smooth, by iteratively constructing
  second order approximations to $f(x)$ by taking the dual representation of
  $h$ and doing a second order expansion of it there.},
}

@book{Fletcher87,
	author = "R. Fletcher",
	title = "Practical Methods of Optimization",
	edition = "Second",
	publisher = "John Wiley",
	year = 1987
}

@article{FletcherWa80,
author = {Roger Fletcher and G. Alistair Watson},
title = {First and second order conditions for a class of
nondifferentiable optimization problems},
journal = mathprog,
volume = 18,
year = 1980,
pages = {291--307},
comment = {Provides second order optimality conditions based on Lagrangian
  calculations for minimization of $f(x) = h(c(x))$ for $h$ a norm and
  $c$ smooth. A nice structure of composite optimization problems.},
}

@inproceedings{Floyd89,
author=   	{Floyd, Sally},
title=    	{Space-bounded learning and the {V}apnik-{C}hervonenkis
		 Dimension},
booktitle=	colt89,
month=    	Jul,
year=     	1989,
pages = 	{349--364}
}

@phdthesis{Floyd89b,
author=   	{Floyd, Sally},
title=    	{On Space-bounded learning and the {V}apnik-{C}hervonenkis
		 Dimension},
school=		{University of California at Santa Cruz},
month=		dec,
year=		1989,
note=		{Available as Technical Report TR-89-061,
		 International Computer Science Institute}
}

@Article{FloydWa95,
  author = 	 {S. Floyd and M. Warmuth},
  title = 	 {Sample compression, learnability, and the
		  {V}apnik-{C}hervonenkis dimension},
  journal = 	 ml,
  year = 	 1995,
  volume =	 21,
  number =	 3,
  pages =	 {269-304}
}

@unpublished{Flynn88,
author=	{Anita Flynn (ed.)},
title=		{Olympic robot building manual},
year=		1988
}

@article{FollmerSc02,
  title={Convex measures of risk and trading constraints},
  author={F\"{o}llmer, Hans and Schied, Alexander},
  journal={Finance and stochastics},
  volume=6,
  number=4,
  pages={429--447},
  year=2002,
  publisher={Springer}
}

@article{ForsgrenGiWr02,
author = {A. Forsgren and P. E. Gill and M. H. Wright},
title =  {Interior methods for nonlinear optimization},
journal = {SIAM Review},
volume = {44},
number = {4},
year = {2002}
}

@article{Forsyth81
,author=	{Richard Forsyth}
,title=		{{BEAGLE} --- {A} {Darwinian} approach to pattern
		 recognition}
,journal=	{Kybernetes}
,year=		1981
,volume=	10
,pages=		{159--166}
}

@inproceedings{FortnowWh94
,author=	{Lance Fortnow and Duke Whang}
,title=		{Optimality and domination in repeated games with
		 bounded players}
,booktitle=	stoc94
}

@article{Foster91
,author=	{Dean P. Foster}
,title=		{Prediction in the worst case}
,journal=       {The Annals of Statistics}
,volume=        19
,number=        2
,pages=         {1084--1090}
,year=          1991
}

@article{FosterVo93
,author=	{D.P. Foster and R.V. Vohra}
,title=		{A randomization rule for selecting forecasts}
,journal=	{Operations Research}
,volume=	41
,number=	4
,month=		{July--August}
,year=		1993
,pages=		{704--709}
}

@unpublished{FosterVo97
,author=	{D.P. Foster and R. Vohra}
,title=		{Regret in the On-line Decision Problem}
,note=		{unpublished manuscript}
,year=		1997
}

@article{FosterVo98
,author=	{D.P. Foster and R.V. Vohra}
,title=		{Asymptotic calibration}
,journal=       {Biometrika}
,volume=        85
,year=          1998
,number=        2
,pages=         {379--390}
}

@article{FournierGu15,
  title={On the rate of convergence in Wasserstein distance of the empirical measure},
  author={Fournier, Nicolas and Guillin, Arnaud},
  journal={Probability Theory and Related Fields},
  volume=162,
  number={3-4},
  pages={707--738},
  year=2015,
  publisher={Springer}
}

@inproceedings{FrankHa01,
author = {E. Frank and M. Hall},
title = {A simple approach to ordinal regression},
booktitle = {Proceedings of the European Conference on Machine Learning},
pages = {145--165},
year = 2001
}

@article{FranklWi81
,author=	{P. Frankl and R. M. Wilson}
,title=		{Intersection theorems with geometric consequences}
,journal=	{Combinatorica}
,volume=	1
,year=		1981
,pages=		{357--368}
}

@book{Franklin68
,author=	{Joel N. Franklin}
,title=		{Matrix Theory}
,publisher=	{Prentice-Hall}
,year=		{1968}
}

@unpublished{FranklinGaYu93
,author=	{Matthew Franklin and Zvi Galil and Moti Yung}
,title=		{An overview of secure distributed computing}
}

@article{FrankWo56,
author = {Marguerite Frank and Philip Wolfe},
title = {An algorithm for quadratic programming},
year = 1956,
journal = {Naval Research Logistics},
volume = 3,
number = {1--2},
pages = {95--110},
doi = {10.1002/nav.3800030109},
}

@techreport{FreanDo98
,author=    "Frean, Marcus and Downs, Tom"
,title=     "A simple cost function for boosting"
,institution= "Department of Computer Science and Electrical
               Engineering, University of Queensland"
,year=      1998
}

@article{Freedman75,
author = {D.~A. Freedman},
title = {On Tail Probabilities for Martingales},
year = 1975,
journal = {The Annals of Probability},
volume = 3,
number = 1,
pages = {100-118},
month = feb}

@article{Freedman83,
author = {David A. Freedman},
title = {A note on screening regression equations},
journal = {The American Statistician},
pages = {152--155},
volume = 37,
number = 2,
year = 1983,
}

@book{Freedman09,
author = {David A. Freedman},
title = {Statistical Models: Theory and Practice},
year = 2009,
edition = {Second},
publisher = {Cambridge University Press},
}

@article{Frees89,
title = {Infinite Order U-Statistics},
author = {Frees, Edward W.},
journal = {Scandinavian Journal of Statistics},
volume = {16},
number = {1},
jstor_formatteddate = {1989},
pages = {pp. 29-45},
year = {1989},
publisher = {Blackwell Publishing on behalf of Board of the Foundation of the Scandinavian Journal of Statistics},
}

@inproceedings{Freund90,
author=		{Y. Freund},
title=		{Boosting a weak learning algorithm by majority},
month=		aug,
year=		1990,
booktitle=	colt90,
pages=		{202--216},
note=		{To appear, {\it Information and Computation}}
}

@inproceedings{Freund92,
author=		{Freund, Yoav},
title=		{An improved boosting algorithm and its implications
		 on learning complexity},
month=		jul,
year=		1992,
pages=		{391--398},
booktitle=	colt92
}

@phdthesis{Freund93
,author=	"Yoav Freund"
,title=		"Data Filtering and Distribution Modeling Algorithms
                 for Machine Learning"
,school=	"University of California at Santa Cruz"
,year =		 1993
,note=		"Retrievable from: ftp.cse.ucsc.edu/pub/tr/ucsc-crl-93-37.ps.Z"

}

@article{Freund95
,author=	"Yoav Freund"
,title=		"Boosting a weak learning algorithm by majority"
,journal=	infcomp
,year=		1995
,volume=	121
,number=	2
,pages=		{256--285}
}

@inproceedings{Freund96
,author=	"Yoav Freund"
,title=		"Predicting a binary sequence almost as well as the
		 optimal biased coin"
,booktitle=	colt96
,year=		1996
}

@article{Freund??
,author=	"Yoav Freund"
,title=		"Boosting a weak learning algorithm by majority"
,journal=	"Information and Computation"
,year=		"To appear"
,note=		{An extended abstract appeared in {\it Proceedings of
		 the Third Annual Workshop on Computational Learning
		 Theory}, 1990.}
}

@article{Freund01,
  author = "Y. Freund",
  title = "An adaptive version of the boost by majority algorithm",
  journal = "Machine Learning",
  volume = 43,
  number = 3,
  pages = "293--318",
  year = 2001
}

@InProceedings{FreundIyScSi98,
  author = 	 {Y.~Freund and R.~Iyer and R.~E.Schapire and
                  Y.~Singer},
  title = 	 {An efficient boosting algorithm for combining preferences},
  booktitle = 	 ml98,
  year =	 1998
}

@article{FreundIyScSi03,
author = {Y. Freund and R. Iyer and R. E. Schapire and Y. Singer},
title = {Efficient boosting algorithms for combining preferences},
journal = jmlr,
year = 2003,
volume = 4,
pages = {933--969},
}

@inproceedings{FreundKeMaRoRuSc95
,author=	{Yoav Freund and Michael Kearns and Yishay Mansour and
		 Dana Ron and Ronitt Rubinfeld and Robert E. Schapire}
,title=		{Efficient Algorithms for Learning to Play Repeated
		 Games Against Computationally Bounded Adversaries}
,booktitle=	focs95
,pages=		{332-341}
,year=		1995
}

@inproceedings{FreundKeRoRuScSe93
,author=	{Yoav Freund and Michael Kearns and Dana Ron and
		 Ronitt Rubinfeld and Robert E. Schapire and Linda
		 Sellie}
,title=		{Efficient learning of typical finite automata from
		 random walks}
,booktitle=	stoc93
,month=		may
,year=		1993
,pages=		{315--324}
}

@inproceedings{FreundRo95
,author=        {Yoav Freund and Dana Ron}
,title=         {Learning to model sequences generated by switching distribution
s}
,booktitle=     colt95
,year=          1995
,pages=         {41--50}
}

@inproceedings{FreundSc95
,author=	{Y. Freund and R.E. Schapire}
,title=		{A decision-theoretic generalization of on-line
		 learning and an application to boosting}
,booktitle=	eurocolt95
,year=		1995
,pages=		{23--37}
,publisher=	{Springer-Verlag}
,comment=	{,note=		{A draft of the journal version is available
		 electronically (on our web pages, or by email request).}}
}

@unpublished{FreundSc95b
,author=	{Y. Freund and R.E. Schapire}
,title=		{A decision-theoretic generalization of on-line
		 learning and an application to boosting}
,note=		{Unpublished manuscript available electronically (on
		 our web pages, or by email request).  An extended
		 abstract appeared in {\it Computational Learning
		 Theory: Second European Conference, EuroCOLT~'95},
		 pages~23--37, Springer-Verlag, 1995}
}


@inproceedings{FreundSc96
,author=	{Yoav Freund and Robert E. Schapire}
,title=		{Experiments with a New Boosting Algorithm}
,booktitle=	ml96
,year=		1996
,pages=		{148-156}
}

@inproceedings{FreundSc96b
,author=	{Y. Freund and R.E. Schapire}
,title=		{Game Theory, On-line Prediction and Boosting}
,booktitle=	colt96
,year=		1996
,pages=		{325-332}
}

@article{FreundSc97
,author=	{Yoav Freund and Robert E. Schapire}
,title=		{A decision-theoretic generalization of on-line
		 learning and an application to boosting}
,journal=	jcss
,year=		1997
,volume=	55
,number=	1
,month=		aug
,pages=		{119-139}
}

@Article{FreundSc9?,
  author = 	 {Yoav Freund and Robert E. Schapire},
  title = 	 {Adaptive game playing using multiplicative weights},
  journal = 	 {Games and Economic Behavior},
  year = 	 {to appear},
}

@InProceedings{FreundSc98,
  author = 	 {Y.~Freund and R.~E.~Schapire},
  title = 	 {Large margin classification using the perceptron
                  algorithm},
  booktitle = 	 colt98,
  year =	 1998,
}


@article{FreundSc99,
  author = 	 {Y.~Freund and R.~E.~Schapire},
  title = 	 {Large margin classification using the perceptron
                  algorithm},
  journal=	ml,
  volume=		37,
  number=		{3},
  year=		1999,
  pages=		{277--296}
}


@Article{FreundSc99b,
  author = 	 {Y.~Freund and R.~E.~Schapire},
  title = 	 {A short introduction to boosting},
  journal = 	 {Journal of Japanese Society for Artificial Intelligence},
  year = 	 {1999},
  volume = 	 {14},
  number = 	 {5},
  pages = 	 {771-780},
}

@inproceedings{FreundScSiWa97,
author =	{Yoav Freund and Robert E. Schapire and
			Yoram Singer and Manfred K. Warmuth},
title =		{Using and Combining Predictors that Specialize},
booktitle =	stoc97,
pages =		{334--343},
year =		1997
}


@article{FreundSeShTi97,
	author = "Y. Freund and H.S. Seung and E. Shamir and N. Tishby",
	title = "Selective sampling using the {Query By Committee} algorirhm",
	journal = "Machine Learning",
	volume = 28,
	pages = "133--168",
	year = 1997
}

@InProceedings{Freund99,
  author = 	 {Yoav Freund},
  title = 	 {An adaptive version of the boost by majority algorithm},
  booktitle = 	 colt99,
  year =	 1999
}

@article{FreundOp02,
	author = "Y. Freund and M. Opper",
	title = "Drifting games and {B}rownian motion",
	journal = jcss,
	volume = 64,
	pages = "113--132",
	year = 2002
}

@InProceedings{FreundMa99,
  author = 	 {Yoav Freund and Llew Mason},
  title = 	 {The alternating decision tree learning algorithm},
  booktitle = 	 ml99,
  pages = {124--133},
  year =	 1999
}

@unpublished{Friedman95
,author=	{Jerome H. Friedman}
,title=		{Introduction to computational learning and
		 statistical prediction}
,comment=	{Slides from ml-95}
}

@unpublished{Friedman96
,author=	{Jerome H. Friedman}
,title=		{Another approach to polychotomous classification}
}

@unpublished{Friedman96b
,author=	{Jerome H. Friedman}
,title=		{On Bias, Variance, 0/1-loss, and the Curse-of-Dimensionality}
,note=          {Available electronically from http://stat.stanford.edu/$\sim$jhf}
}

@article{Friedman01,
author = {J.H.~Friedman},
title = {Greedy Function Approximation: A Gradient Boosting Machine},
journal = {Annals of Statistics},
volume = {29},
number = {5},
year=2001,
pages = {1189--1232}
}


@article{FriedmanBeFi77,
author = 	{Jerome J. Friedman and Jon Louis Bentley and Raphael Ari Finkel},
title = 	{An Algorithm for Finding Best Matches in Logarithmic
		 Expected Time},
journal = 	{ACM Transactions on Mathematical Software},
year = 		{1977},
month = 	Sep,
volume = 	3,
number = 	3,
pages = 	{209--226}
}

@Unpublished{FriedmanHaTi98,
  author = 	 {J. Friedman and T. Hastie and R. Tibshirani},
  title = 	 {Additive logistic regression: a statistical view of
                  boosting},
  note = 	 {Technical Report},
  year = 1998
}

@article{FriedmanHaTi00,
  author = 	 {J. Friedman and T. Hastie and R. Tibshirani},
  title = 	 {Additive logistic regression: a statistical view of boosting},
  journal= 	{Annals of Statistics},
  volume = 28,
  number = 2,
  year = 2000,
  month = Apr,
  pages = {337--374}
}

@article{FriedmanHaTi07,
author =           {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
title =            {Pathwise coordinate optimization},
journal =          {Annals of Applied Statistics},
volume =           1,
number =           2,
year =             2007,
pages =            {302--332}
}

@inproceedings{FriedmanKaSz89,
 author = {Friedman, J. and Kahn, J. and Szemer\'{e}di, E.},
 title = {On the second eigenvalue of random regular graphs},
 booktitle = stoc89,
 year = {1989},
 isbn = {0-89791-307-8},
 pages = {587--598},
 location = {Seattle, Washington, United States},
 publisher = {ACM},
 }

@inproceedings{FriessCrCa98
,author=         {T.~Friess and N.~Cristianini and C.~Campbell}
,title=          {The Kernel-Adatron: A Fast and Simple Learning
                  Procedure for Support Vector Machines}
,booktitle=      ml98
,year=           1998
}

@book{FrontiersMassiveDataAnalysis,
title = {Frontiers in Massive Data Analysis},
author = {{National Research Council}},
comment = {author = {{Committee on the Analysis of Massive Data} and
   {Committee on Applied and Theoretical Statistics} and
   {Board on Mathematical Sciences and their Applications}}},
year = 2013,
publisher = {National Academies Press},
organization = {National Research Council},
}

@inproceedings{FrostigGeKaSi15,
author = {Roy Frostig and Rong Ge and Sham M. Kakade and Aaron Sidford},
booktitle = colt15,
title = {Competing with the empirical risk minimizer in a single pass},
year = {2015},
}

@inproceedings{FrostigGeKaSi15b,
author = {Roy Frostig and Rong Ge and Sham M. Kakade and Aaron Sidford},
booktitle = icml15,
title = {Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization},
year = {2015},
}

@article{FuBo75a,
author=   	{Fu, King-Sun and Taylor L. Booth},
title=    	{Grammatical Inference: Introduction and Survey -- Part I},
journal= 	{IEEE Transactions on Systems, Man, and Cybernetics},
year=     	1975,
month=    	Jan,
volume=   	{SMC-5},
number=   	1,
pages=    	{95--111},
comment=  	{Inference of finite-state and context-free grammars reviewed.}
}

@article{FuBo75b,
author=   	{Fu, King-Sun and Taylor L. Booth},
title=    	{Grammatical Inference: Introduction and Survey -- Part II},
journal= 	{IEEE Transactions on Systems, Man, and Cybernetics},
year=     	1975,
month=    	Jul,
volume=   	{SMC-5},
number=   	4,
pages=    	{409--423},
comment=  	{Inference of stochastic finite-state and context-free
		grammars.}
}

@article{FuChCh13,
author = {King-Wa Fu and CH Chan and Michael Chau},
title = {Assessing Censorship on Microblogs in {C}hina: Discriminatory Keyword
    Analysis and Impact Evaluation of the ``Real Name Registration'' Policy},
year = 2013,
journal = {IEEE Internet Computing},
volume = 17,
number = 3,
pages = {42--50},
}

@article{FudenbergLe93
,author=	{Drew Fudenberg and David K. Levine}
,title=		{Steady State Learning and Nash Equilibrium}
,year=		1993
}

@article{FudenbergLe95
,author=	{Drew Fudenberg and David K. Levine}
,title=		{Consistency and cautious fictitious play}
,year=		1995
,volume=	19
,journal=	{Journal of Economic Dynamics and Control}
,pages=		{1065--1089}
}

@book{FudenbergTi91
,author=	{Drew Fudenberg and Jean Tirole}
,title=		{Game Theory}
,year=		1991
,publisher=	{MIT Press}
}

@article{FuhrPf94
,author=        {Norbert Fuhr and Ulrich Pfeifer}
,title=         {Probabilistic information retrieval as a combination
                  of abstraction, inductive learning, and
                  probabilistic assumptions}
,journal=       {ACM Transactions on Information Systems}
,volume=        12
,number=        1
,month=         jan
,year=          1994
,pages=         {92-115}
}

@book{Fukunaga90
,author=	{Keinosuke Fukunaga}
,title=		{Introduction to Statistical Pattern Recognition}
,edition=	{second}
,year=		1990
,publisher=	{Academic Press}
}

@book{FullerMi11,
title = {The Future of Computing Performance: Game Over or Next Level?},
author = {Samule Fuller and Lynette Millett},
year = 2011,
publisher = {National Academies Press},
organization = {National Research Council},
}

@inproceedings{FunkRoKr06,
title = {Learning Rankings via Convex Hull Separation},
author = {G. Fung and R. Rosales and B. Krishnapuram},
booktitle = {Advances in Neural Information Processing Systems 18},
year = {2006}
}


@inproceedings{FurnkranzWi94
,author=	{Johannes  F\"urnkranz and Gerhard Widmer}
,title=		{Incremental Reduced Error Pruning}
,booktitle=	{Machine Learning: Proceedings of the Eleventh
		International Conference}
,year=		1994
,pages=		{70-77}
}

@techreport{FurstJaSm90,
author=		{Merrick Furst and Jeffrey Jackson and Sean Smith},
title=		{Learning {$AC^0$} Functions Sampled Under Mutually
		 Independent Distributions},
institution=	{Carnegie Mellon University, School of Computer Science},
number=		{CMU-CS-90-183},
month=		oct,
year=		1990
}

@inproceedings{FurstJaSm91,
author=		{Merrick L. Furst and Jeffrey C. Jackson and Sean W. Smith},
title=		{Improved Learning of {$AC^0$} Functions},
booktitle=	colt91,
month=		aug,
year=		1991,
pages=		{317--325}
}

@article{GabrelViMu14,
  title={Recent advances in robust optimization: An overview},
  author={Gabrel, Virginie and Murat, C{\'e}cile and Thiele, Aur{\'e}lie},
  journal={European Journal of Operational Research},
  volume=235,
  number=3,
  pages={471--483},
  year=2014,
  publisher={Elsevier}
}

@article{GafniBr84,
  author = " E. Gafni and D. P. Bertsekas",
  title = "Two-Metric Projection Methods for Constrained Optimization",
  journal = sicon,
  volume = {22},
  year = 1984,
  pages = {936-964}
}

@article{Gaines79,
author=   	{Gaines, B.R.},
title=    	{Maryanski's Grammatical Inferencer},
journal=  	{IEEE Transactions on Computers},
year=     	1979,
month=    	Jan,
volume=   	{C-27},
number=   	1,
pages=    	{62--66},
comment=  	{Corrects some typographical errors in the Maryanski-Booth
		algorithm for inferring a probabilistic finite-state grammar
	  	from a given set of strings.}
}

@techreport{Gallager79,
author = {Robert Gallager},
title = {Source coding with side information and universal coding},
year = 1979,
institution = {MIT Laboratory for Information and Decision Systems},
number = {LIDS-P-937},
comment = {Gives a nice argument for the equality of (Bayesian) max-min and
  min-max regret in universal coding, and shows the existence of an
  optimal distribution.},
}

@book{Gallager68
,author=	{Robert G. Gallager}
,title=		{Information Theory and Reliable Communication}
,publisher=	{John Wiley \& Sons}
,year=		1968
}

@InProceedings{Gallant86,
  author = 	 {S. I. Gallant},
  title = 	 {Optimal Linear Discriminants},
  booktitle = 	 {Eighth International Conference on Pattern Recognition},
  pages =	 {849-852},
  year =	 1986,
  organization = {IEEE}
}

@inproceedings{GamsLa87,
author=	   	{Gams, M. and N. Lavrac},
title=	   	{Review of Five Empirical Learning Systems Within a
		Proposed Schemata},
booktitle= 	{Progress in Machine Learning--Proceedings of EWSL 87:
	   	2nd European Working Session on Learning},
address=   	{Bled, Yogoslavia},
year=	   	1987,
editor=	   	{Bratko, I. and N. Lavrac},
month=	   	may,
pages=	   	{46--66}
}

@inproceedings{GanapathiViDuKo08,
author = {Varun Ganapathi and David Vickrey and John Duchi and Daphne Koller},
title = {Constrained Approximate Maximum Entropy Learning of
{M}arkov Random Fields},
year = 2008,
booktitle = {Proceedings of the 24th Conference Conference on
  Uncertainty in Artificial Intelligence (UAI)},
}

@inproceedings{GantaKaSm08,
author = {Srivatsava Ranjit Ganta and Shiva Kasiviswanathan and Adam Smith},
title = {Composition Attacks and Auxiliary Information in Data Privacy},
year = 2008,
booktitle = {Proceedings of the 14th ACM SIGKDD Conference on Knowledge
and Data Discovery (KDD)},
comment = {
  Studies some weaknesses of standard definitions of privacy (like
  $k$-anonymity) by showing that they are easy to break, e.g. by an
  intersection attack (where multiple independent data releases of
  a table are intersected with one another to whittle down the possible
  people). Then gives a more semantically flavored definition of privacy:
  specifically, that the posterior beliefs of an adversary cannot change
  by very much given what is actually observed from the prior beliefs of
  the adversary. Obviously differential privacy satisfies such a guarantee;
  if the difference of posterior beliefs is measured additively (i.e. via
  TV-distance) then $(\epsilon, \delta)$-approximate differential privacy
  also guarantees this type of semantic behavior.
},
}

@book{Gantmacher59,
author=		{F. R. Gantmacher},
title=		{Applications of the Theory of Matrices},
publisher=	{Interscience},
year=		1959
}

@article{GaoWe15,
author = {Fuchang Gao and Jon A.\ Wellner},
title = {Entropy of convex functions on $\mathbb{R}^d$},
year = 2015,
journal = {arXiv:1502.01752 [math.ST]},
comment = {Shows a lot of strange properties of covering numbers and
  metric entropies for convex functions. Very strong dependence on
  metric used and properties of the boundary. Does not cover Lipschitz
  convex functions exactly, but is very interesting.},
}

@inproceedings{GarciaWi12,
author = {Dar\'io Garc\'ia-Garc\'ia and Robert C. Williamson},
title = {Divergences and Risks for Multiclass Experiments},
year = 2012,
booktitle = colt12,
}

@article{Gardner02,
author = {R. J. Gardner},
title = {The {B}runn-{M}inkowski Inequality},
year = 2002,
journal = bams,
volume = 39,
number = 3,
pages = {355--405},
}

@inproceedings{GargMaNg14,
author = {Ankit Garg and Tengyu Ma and Huy L. Nguyen},
title = {On Communication Cost of Distributed Statistical Estimation
   and Dimensionality},
year = 2014,
booktitle = nips27,
}

@thesis{Garsia??
,author=	{A. M. Garsia}
,title=		{On the distribution function of a geometric series
		 whose terms have random changes of sign}
}

@book{GareyJo79,
author=   	{Garey, M. and D. Johnson},
title=    	{Computers and Intractability: A Guide to the Theory of
	  	NP-Com\-plete\-ness},
publisher=	{W. H. Freeman},
year=     	1979,
address=  	{San Francisco}
}

@article{Gauvin77,
  title={A necessary and sufficient regularity condition to have bounded multipliers in nonconvex programming},
  author={Gauvin, Jacques},
  journal={Mathematical Programming},
  volume=12,
  number=1,
  pages={136--138},
  year=1977,
  publisher={Springer}
}

@inproceedings{GeHuJiYu15,
  title={Escaping From Saddle Points---Online Stochastic Gradient for Tensor Decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle=colt15,
  year=2015
}
	
@inproceedings{Geisser70,
author=   	{Geisser, Seymour},
title=    	{The Inferential Use of Predictive Distributions},
booktitle=  	{Foundations of Statistical Inference},
editor=   	{Godambe, V. P. and D. A. Sprott},
year=     	1970,
publisher=  	{Holt, Rinehart, and Winston},
comment=  	{Argues for deriving probability density of future observations
		(a predictive distribution) from prior observations.}
}

@article{GeJiZh17,
  title={No Spurious Local Minima in Nonconvex Low Rank Problems: A Unified Geometric Analysis},
  author={Ge, Rong and Jin, Chi and Zheng, Yi},
  journal={arXiv preprint arXiv:1704.00708},
  year={2017}
}

@inproceedings{GeLeMa16,
author = {Rong Ge and Jason D. Lee and Tengyu Ma},
title = {Matrix Completion has No Spurious Local Minimum},
year = 2016,
booktitle = nips29,
}

@book{GelmanCaStDuVeRu13,
author = {Andrew Gelman and John Carlin and Hal Stern and David Dunson
and Aki Vehtari and Donald Rubin},
title = {Bayesian Data Analysis},
year = 2013,
edition = {Third},
publisher = {Chapman \& Hall},
}

@article{Gelman15,
author = {Andrew Gelman},
title = {Working through some issues},
journal = {Significance},
publisher = {Wiley},
year = 2015,
volume = 12,
number = 3,
pages = {33--35},
}

@article{GelmanRu92,
author = {Andrew Gelman and Donald B. Rubin},
title = {Inference from Iterative Simulation Using Multiple Sequences},
year = 1992,
journal = {Statistical Science},
volume = 7,
number = 4,
pages = {457--472},
comment = {Discusses running several Gibbs samplers in parallel from
some dispersed initial distribution, using that as a way to get at least
independent samples from *a* distribution, though not necessarily the
posterior},
}

@incollection{Geman86,
author=   	{Geman, Stuart},
title=    	{Stochastic Relaxation Methods for Image Restoration and
	   	Expert Systems},
booktitle=  	{Automated Image Analysis: Theory and Experiments},
editor=   	{D.B. Cooper and R.L.Launer and D.E. McClure},
publisher=  	{Academic Press},
year=     	1986,
comment=  	{Describes stochastic relaxation technique for maximum entropy
	   	computations and for image restoration.}
}

@article{GemanHw82,
author = {S. Geman and C. R. Hwang},
title = {Nonparametric maximum likelihood estimation by the method of sieves},
journal = aos,
volume = 10,
pages = {401--414},
year = 1982,
}

@article{GemmellSu92,
author=		{Peter Gemmell and Madhu Sudan},
title=		{Highly Resilient Correctors for Polynomials},
journal=	ipl,
volume=		43,
number=		4,
month=		sep,
date=		28,
year=		1992,
pages=		{169--174}
}

@inproceedings{GentileWa98,
	author = "C. Gentile and M. Warmuth",
	title = "Linear Hinge Loss and Average Margin",
	booktitle = nips10,
	year = 1998
}

@inproceedings{GentileLi99,
	author = "C. Gentile and N. Littlestone",
	title = "The Robustness of the p-Norm Algorithms",
	booktitle = colt99,
	year = 1999
}


@InProceedings{Gentile00,
author = {C.~Gentile},
title = {Approximate Maximal Margin Classification with Respect to an Arbitrary Norm},
booktitle = {Advances in Neural Information Processing Systems 14},
year = 2000
}

@article{Gentile01,
author=   	{C.~Gentile},
title=    	{A New Approximate Maximal Margin Classification Algorithm },
journal=  	"Journal of Machine Learning Research",
year=     	2001,
volume=   	2,
pages=    	{213--242},
}



@Article{Gentile02,
  author = 	 {C. Gentile},
  title = 	 {The robustness of the $p$-norm algorithms},
  journal = 	 {Machine Learning},
  year = 	 {2002},
  volume = 	 {53},
  number = 	 {3}
}

@article{George57,
author=   	{George, F. H.},
title=    	{Logical Networks and Probability},
journal=  	{Bulletin of Mathematical Biophysics},
year=     	1957,
volume=   	19,
pages=    	{187--199},
comment=  	{Extends McCulloch-Pitts networks with counters for
		probabilities.}
}

@article{George59,
author=   	{George, F. H.},
title=    	{Inductive machines and the problem of learning},
journal=  	{Cybernetica},
year=     	1959,
volume=   	{II},
pages=    	{109--126},
comment=  	{Discussion of learning; machines which learn associations.}
}

@incollection{GeorgeffWa84,
author=   	{Georgeff, M. P. and C. S. Wallace},
title=    	{A General Selection Criterion for Inductive Inference},
booktitle=	{ECAI 84: Advances in Artificial Intelligence},
publisher=	{Elsevier Science Publishers},
year=     	1984,
pages=    	{473--482}
}

@article{Geusebroek05,
  title={The Amsterdam library of object images},
  author={Geusebroek, Jan-Mark and Burghouts, Gertjan J and Smeulders, Arnold WM},
  journal={International Journal of Computer Vision},
  volume=61,
  number=1,
  pages={103--112},
  year=2005,
  publisher={Springer}
}

@unpublished{GhadimiLa10,
author = {S. Ghadimi and G. Lan},
title = {Optimal stochastic approximation algorithms for strongly convex
stochastic composite optimization},
year = 2010,
}

@article{GhadimiLa12,
author = {Saeed Ghadimi and Guanghui Lan},
title = {Optimal stochastic approximation algorithms for strongly convex stochastic
  composite optimization, {I}: a generic algorithmic framework},
year = 2012,
journal = siopt,
volume = 22,
number = 4,
pages = {1469--1492},
}

@article{GhadimiLa13,
author = {Saeed Ghadimi and Guanghui Lan},
title = {Stochastic first- and zeroth-order methods for nonconvex
  stochastic programming},
journal = siopt,
year = 2013,
volume = 23,
number = 4,
pages = {2341--2368},
comment = {Using the standard single step improvement bound, shows that for
  smooth objective functions (i.e. Lipschitz derivatives), if the expected
  error in gradient is \sigma^2, then a convergence rate of roughly
  $\epsilon = L \sigma R / \sqrt{N}$ can be achieved (in expectation) to find
  a point with $\norm{\nabla f(x)}^2 \le \epsilon$. Also shows a result
  using two-point gradient estimators in the convex smooth case attaining
  convergence rate (with only function evaluations available) of
  $\sqrt{d} \sigma R / \sqrt{N}$ or so.
  url = {http://www.optimization-online.org/DB_HTML/2012/06/3499.html},},
}

@inproceedings{GhoshRoSu09,
author = {Arpita Ghosh and Tim Roughgarden and Mukun Sundararajan},
title = {Universally utility-maximizing privacy mechanisms},
year = 2009,
url = {http://theory.stanford.edu/~tim/papers/priv.pdf},
booktitle = stoc09,
comment = {
  Shows that for a single query of a statistical database (i.e. dataset)
  there is an essentially unique perturbation (geometric, truncated
  to the range of the function) that maximizes utility subject to a
  privacy constraint. This is in contrast to most other work on privacy,
  where the tradeoff is not so explicit. Uses linear programming to
  characterize the optimality. Only applies to count queries (i.e.
  what fraction of the data obeys a certain predicate) and only one
  query may be issued.
},
}

@article{Gilbert08,
author = {Natasha Gilbert},
title = {Researchers criticize genetic data restrictions},
year = 2008,
month = {September},
journal = {Nature News},
doi = {10.1038/news.2008.1083},
}

@article{GilboaSa89
,author=	{Itzhak Gilboa and Dov Samet}
,title=		{Bounded versus unbounded rationality: the tyranny of
		 the weak}
,year=		1989
}

@article{Ginestet12,
author = {Cedric E. Ginestet},
title = {Strong and weak laws of large numbers for {F}r\'echet sample
means in bounded metric spaces},
year = 2012,
journal = {arXiv:1204.3183 [math.ST]},
url = {http://arxiv.org/abs/1204.3183},
comment = {Shows the (almost) set-valued convergence of Frechet means
  under some compactness assumptions.},
}

@article{GinzburgSo??
,author=	{Iris Ginzburg and Haim Sompolinsky}
,title=		{Theory of correlations in stochastic neural networks}
}

@article{GerchbergSa72,
author = {R. W. Gerchberg and W. O. Saxton},
title = {A practical algorithm for the determination of phase from
   image and diffraction},
year = 1972,
journal = {Optik},
volume = 35,
pages = {237–-246},
}

@inproceedings{GionisInMo99,
	author={A. Gionis and P. Indyk and R. Motwani},
	title={Similarity Search in High Dimensions via Hashing},
	booktitle={25th International Conference on Very Large Databases (VLDB)},
	year={1999},
}

@book{Gittins89
,author=	{J. C. Gittins}
,title=		{Multi-armed Bandit Allocation Indices}
,publisher=	wiley
,year=		1989
}

@article{GlassermanBi05,
  title={Large sample properties of weighted monte carlo estimators},
  author={Glasserman, Paul and Yu, Bin},
  journal={Operations Research},
  volume=53,
  number=2,
  pages={298--312},
  year=2005,
  publisher={INFORMS}
}

@article{GlassermanXi14,
  title={Robust risk measurement and model risk},
  author={Glasserman, Paul and Xu, Xingbo},
  journal={Quantitative Finance},
  volume=14,
  number=1,
  pages={29--58},
  year=2014,
  publisher={Taylor \& Francis}
}

@inproceedings{GleichLi11,
author = {D.~Gleich and L.-H.~Lim},
title = {Rank aggregation via nuclear norm minimization},
year = 2011,
booktitle = {Proceedings of the 17th ACM SIGKDD Conference on Knowledge
 Discovery and Data Mining (KDD)},
pages = {60--68},
}

@article{Gleser81,
author = {Leon Jay Gleser},
title = {Estimation in a multivariate ``errors in variables'' regression model:
   large sample results},
year = 1981,
journal = aos,
volume = 9,
number = 1,
pages = {24--44},
}

@inproceedings{GlobersonKoCaCo07,
 author = {A. Globerson and T. Koo and X. Carreras and M. Collins},
 title = {Exponentiated Gradient Algorithms for Log-Linear Structured Prediction},
 booktitle = icml07,
 year = {2007}
}

@inproceedings{GlobersonRo06,
 author = {A. Globerson and S. Roweis},
 title = {Nightmare at test time: robust learning by feature deletion},
 booktitle = icml06,
 year = {2006},
 pages = {353--360},
}

@incollection{GlynnSz02,
  title={Some new perspectives on the method of control variates},
  author={Glynn, Peter W and Szechtman, Roberto},
  booktitle={Monte Carlo and Quasi-Monte Carlo Methods 2000},
  pages={27--49},
  year=2002,
  publisher={Springer}
}

@article{GnedenkoKo54,
  title={Limit distributions for sums of independent random variables},
  author={Gnedenko, BV and Kolmogorov, AN},
  journal={American Journal of Mathematics},
  volume=105,
  pages={28--35},
  year=1954,
  publisher={Addison-Wesley}
}

@article{GneitingRa07,
author = {Tilmann Gneiting and Adrian Raftery},
title = {Strictly Proper Scoring Rules, Prediction, and Estimation},
journal = jasa,
year = 2007,
volume = 102,
number = 477,
pages = {359--378},
comment = {Surveys proper and strictly proper scoring rules and their uses
  for elicitation of probabilities. Shows simple characterization of
  strictly proper scoring rules as $S(P, i) = G(p) - \<G'(p), p\> + G_i'(p)$
  for convex functions $G$, where $i$ is the class actually shown.
  Extends these to arbitrary output/action spaces.
  }
}

@article{GoemansWi95
,author=	{Michel X. Goemans and David P. Williamson}
,title=		{Improved Approximation Algorithms for Maximum Cut and
		 Satisfiability Problems Using Semidefinite Programming}
,pages=		{1115-1145}
,volume=	42
,number=	6
,month=		nov
,year=		1995
,journal=	jacm
}

@techreport{Goetsch86,
author=   	{Goetsch, Gordon J.},
title=    	{CONSENSUS: A Statistical Learning Procedure in a Connectionist
	  	Network},
institution= 	{Carnegie-Mellon Computer Science Department},
year=     	1986,
month=    	May,
number=   	{CMU-CS-86-131},
comment=  	{Layered network built out of communities of units, each with a
	  	supervisor.}
}


@article{Gold67,
author=   	{Gold, E. Mark},
title=    	{Language Identification in the Limit},
journal=  	infctrl,
year=     	1967,
volume=   	10,
pages=    	{447--474},
comment=  	{Classic paper, introducing computer science theory into
		learning.}
}

@article{Gold72,
author=   	{Gold, E. Mark},
title=    	{System Identification via State Characterization},
journal=  	{Automatica},
volume=   	8,
year=     	1972,
pages=    	{621--636}
}


@article{Gold78,
author=   	{Gold, E. Mark},
title=    	{Complexity of Automaton Identification from Given Data},
journal=  	infctrl,
year=     	1978,
volume=   	37,
pages=    	{302--320},
comment=  	{Proves that finding an automaton of $n$ or fewer states
		which agrees with a given list of input/output pairs.}
}

@article{Golden65,
author = {Sidney Golden},
title = {Lower bounds for the {H}elmholtz function},
year = 1965,
journal = {Physical Review},
volume = 137,
number = {4B},
pages = {1127--1128},
}

@phdthesis{Goldman90,
author=		{Sally Ann Goldman},
title=		{Learning Binary Relations, Total Orders, and
		 Read-Once Formulas},
school=		mit,
month=		sep,
year=		1990,
note=		{Available as Technical Report MIT/LCS/TR-483,
		 MIT Laboratory for Computer Science}
}

@inproceedings{GoldmanKe91,
author=		{Sally A. Goldman and Michael J. Kearns},
title=		{On the Complexity of Teaching},
booktitle=	colt91,
pages=		{303--314},
month=		aug,
year=		1991
}

@inproceedings{GoldmanKeSc90,
author=		{Sally A. Goldman and
		 Michael J. Kearns and Robert E. Schapire},
title=		{Exact Identification of Circuits Using Fixed Points of
		 Amplification Functions},
booktitle=	focs90,
pages=		{193--202},
month=		oct,
year=		1990,
note=		{To appear, {\it SIAM Journal on Computing}}
}

@inproceedings{GoldmanKeSc90b,
author=		{Sally A. Goldman and
		 Michael J. Kearns and Robert E. Schapire},
title=		{On the Sample Complexity of Weak Learning},
booktitle=	colt90,
pages=		{217--231},
month=		aug,
year=		1990
}

@article{GoldmanKeSc93,
author=		{Sally A. Goldman and
		 Michael J. Kearns and Robert E. Schapire},
title=		{Exact Identification of Read-once Formulas Using
		 Fixed Points of Amplification Functions},
journal=	sicomp,
pages=		{705--726},
month=		aug,
year=		1993,
volume=		22,
number=		4
}

@article{GoldmanKeSc95,
author=		{Sally A. Goldman and
		 Michael J. Kearns and Robert E. Schapire},
title=		{On the Sample Complexity of Weakly Learning},
journal=	infcomp,
pages=		{276-287},
month=		mar,
year=		1995,
volume=		117,
number=		2
}

@inproceedings{GoldmanRiSc89,
author=		{Sally A. Goldman and Ronald L. Rivest and Robert E.
		 Schapire},
title=		{Learning Binary Relations and Total Orders},
booktitle=	focs89,
month=		oct,
year=		1989,
pages=		{46--51},
note=		{Available as Technical Report MIT/LCS/TM-413, MIT
		 Laboratory for Computer Science.}
}

@article{GoldmanRiSc93
,author=	{Sally A. Goldman and Ronald L. Rivest and Robert E.
		 Schapire}
,title=		{Learning Binary Relations and Total Orders}
,volume=	22
,journal=	sicomp
,number=	5
,year=		1993
,pages=		{1006--1034}
}

@article{GoldmannHaRa92,
author =       "Mikael Goldmann and Johan H\aa stad and Alexander Razborov",
title =        "Majority Gates vs. General Weighted Threshold Gates",
journal =      "Computational Complexity",
volume =       "2",
year =         "1992",
pages=		{277-300}
}

@techreport{Goldreich88,
author=		{Oded Goldreich},
title=		{Towards a Theory of Average Case Complexity (A Survey)},
institution=	{Technion Computer Science Department},
year=		1988,
month=		dec,
number=		{531}
}

@article{GoldreichGoMi86,
author=   	{Goldreich, Oded and Shafi Goldwasser and Silvio Micali},
title=    	{How to Construct Random Functions},
journal = 	jacm,
volume = 	33,
number = 	4,
year=     	1986,
month=    	Oct,
pages=    	{792--807}
}

@inproceedings{GoldreichGoRo96
,author=	{Oded Goldreich and Shafi Goldwasser and Dana Ron}
,title=		{Property Testing and its connection to Learning and
		 Approximation}
,booktitle=	focs96
,pages=		{339-348}
,year=		1996
}

@inproceedings{GoleaBaLeMa98
,author=    {Mostefa Golea and Peter L. Bartlett, Wee Sun Lee and Llew Mason}
,title=     {Generalization in decision trees and {DNF}: Does size matter?}
,booktitle= nips10
,pages=		{259--265}
,year=		1998
}

@Book{GolubVa89,
	author =   "G.H. Golub and C.F. Van Loan",
	title =    "Matrix computations",
	publisher =    "John Hopkins University Press",
	year =     1989
}


@Article{Good53,
  author = 	 {Good, I.J.},
  title = 	 {The population frequencies of species and the estimation of population parameters},
  journal = 	 {Biometrika},
  year = 	 {1953}
}

@article{Good59,
author=   	{Good, I. J.},
title=    	{Kinds of Probability},
journal=  	{Science},
year=     	1959,
month=    	Feb,
volume=   	129,
number=   	3347,
pages=    	{443--447}
}

@article{Good63,
author=   	{Good, I.J.},
title=    	{Maximum entropy for hypothesis formulation, especially for
	   	multidimensional contingency tables},
journal=  	{Annals of Mathematical Statistics},
year=     	1963,
volume=   	34,
pages=    	{911-934},
comment=  	{Uses maximum entropy to judge order of interactions, and the
	   	order of a Markov chain.}
}

@article{Good66,
author=   	{Good, I.J.},
title=    	{A Derivation of the Probabilistic Explication of Information},
journal=  	{Journal of the Royal Statistical Society (Series B)},
year=     	1966,
volume=   	28,
pages=    	{578--581},
comment=  	{Argues from an axiomatic framework that I(H:E|G), the
		information concerning H provided by E given G, should be
		log( P(H.E|G) / (P(H|G)P(E|G)) ) or some monotonic variation
		of this.}
}

@inproceedings{Good70,
author=   	{Good, I. J.},
title=    	{The Probabilistic Explication of Information, Evidence,
		Surprise, Causality, Explanation, and Utility},
booktitle= 	{Foundations of Statistical Inference},
year=     	1971,
publisher= 	{Holt, Reinhart, and Winston},
editor=    	{V. P. Godame and D. A. Sprott},
pages=    	{108--141}
}

@inproceedings{GoodfellowShSz15,
	Author = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
	Booktitle = {International Conference on Learning Representations},
	Title = {Explaining and harnessing adversarial examples},
	Year = 2015
	}

@inproceedings{Gopal16,
  title={Adaptive Sampling for SGD by Exploiting Side Information},
  author={Gopal, Siddharth},
  booktitle={Proceedings of The 33rd International Conference on Machine Learning},
  pages={364--372},
  year=2016
}

@inproceedings{Gordon99,
author = {G.~Gordon},
title = {Regret bounds for prediction problems},
booktitle= colt99,
year= {1999}
}


@InProceedings{Gordon06,
  author = 	 {Gordon, G.},
  title = 	 {No-regret algorithms for Online Convex Programs},
  booktitle = nips19,
  year = 	 {2006}
}

@article{GordonSh85,
author=   	{Gordon, Jean and Edward H. Shortliffe},
title=    	{A Method for Managing Evidential Reasoning in a Hierarchical
		Hypothesis Space},
journal=  	{Artificial Intelligence},
year=     	1985,
month=    	Jul,
volume=   	26,
number=   	3,
pages=    	{323--357},
comment=  	{Dempster-Shafer theory explained and generalized.}
}

@article{Gorin95
,author=        {Allen Gorin}
,title=         {On automated language acquisition}
}

@inproceedings{GorinPaSaWi96,
	author = "A. L. Gorin and B. A. Parker and R. M. Sachs and J. G. Wilpon",
	title = "How may {I} help you?",
	booktitle = "Proceedings Interactive Voice Technology for Telecommunications
		Applications (IVTTA)",
	year = 1996,
	pages = "57--60"
}


@article{GorinRiWr97,
	author = "A. L. Gorin and G. Riccardi and J. H. Wright",
	title = "How may {I} help you?",
	journal = "Speech Communication",
	year = "1997",
volume=23,
number={1-2},
month= oct,
pages={113-127}
}

@article{GorissenHoVa09,
  title={Density-matrix renormalization-group study of current and activity fluctuations near nonequilibrium phase transitions},
  author={Gorissen, Mieke and Hooyberghs, Jef and Vanderzande, Carlo},
  journal={Physical Review E},
  volume=79,
  number=2,
  pages=020101,
  year=2009,
  publisher={APS}
}@article{GormanSe88,
author = 	{R. Paul Gorman and Terrence J. Sejnowski},
title = 	{Analysis of Hidden Units in a Layered Network Trained
	         to Classify Sonar Targets},
journal = 	{Neural Networks},
volume = 	1,
year = 		1988,
pages = 	{75--89}
}

@article{GotohKiLi15,
  title={Robust Empirical Optimization is Almost the Same As Mean-Variance Optimization},
    author={Gotoh, Jun-ya and Kim, Michael Jong and Lim, Andrew},
      journal={Available at SSRN 2827400},
        year=2015
	}

@article{GouldLuRoTo99,
author = {Nicholas I. M. Gould and Stefano Lucidi and Massimo Roma and
  Philippe L. Toint},
title = {Solving the trust-region subproblem using the {L}anczos method},
year = 1999,
journal = siopt,
volume = 9,
number = 2,
pages = {504--525},
}

@article{GouldRoTh10,
author = {Nicholas I. M. Gould and Daniel P. Robinson and H. Sue Thorne},
title = {On solving trust-region and other regularised subproblems in optimization},
year = 2010,
journal = {Mathematical Programming Computation},
volume = 2,
number = 1,
pages = {21--57},
}

@article{GowerRi16,
  title={Randomized quasi-Newton updates are linearly convergent matrix inversion algorithms},
  author={Gower, Robert M and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1602.01768},
  year=2016
}

@article{GrangierBe08,
author = {D. Grangier and S. Bengio},
title = {A discriminative kernel-based model to rank images from text queries},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
volume = 30,
number = 8,
pages = {1371--1384},
year = 2008,
}

@misc{GrantBo11,
  author       = {Michael Grant and Stephen Boyd},
  title        = {{CVX}: Matlab Software for Disciplined Convex
                  Programming, version 1.21},
  howpublished = {\url{http://cvxr.com/cvx/}},
  year         = 2011,
}

@incollection{GrantBo08,
  author    = {Michael Grant and Stephen Boyd},
  title     = {Graph implementations for nonsmooth convex programs},
  booktitle = {Recent Advances in Learning and Control},
  series    = {Lecture Notes in Control and Information Sciences},
  editor    = {V. Blondel and S. Boyd and H. Kimura},
  publisher = {Springer-Verlag},
  pages     = {95--110},
  year      = 2008,
  note      = {\url{http://stanford.edu/~boyd/graph_dcp.html}},
}

@techreport{GravesLa94
,author=	{Todd Graves and Tze Leung Lai}
,title=		{Asymptotically Efficient Adaptive Choice of Control
		 Laws in Controlled Markov Chains}
,year=		1994
}

@book{Gray90,
author = {R.~M. Gray},
title = {Entropy and Information Theory},
year = 1990,
publisher = {Springer},
comment = {Basically deals with measure-theoretic versions of information
theory, which is nice},
}

@article{Gray06,
author = {R. Gray},
title = {Toeplitz and Circulant Matrices: A Review},
year = 2006,
journal = {Foundations and Trends in Communications and Information Theory},
volume = 2,
number = 3,
pages = {155--239},
}

@book{Grenander81,
author=   	{Grenander, Ulf},
title=    	{Abstract Inference},
publisher=	{John WIley \& Sons, Inc.},
year=     	1981
}

@article{GrettonBoRaScSm12,
author = {Arthur Gretton and Karsten Borgwardt and Malte Rasch
  and Bernhard Sch\"{o}lkopf and Alexander Smola},
title = {A Kernel Two-Sample Test},
year = 2012,
journal = jmlr,
volume = 13,
pages = {723--773},
}

@inproceedings{GrettonSrSeStBaPoFu12,
author = {Arthur Gretton and Bharath Sriperumbudur and
Dino Sejdinovic and Heiko Strathmann and Sivaraman Balakrishnan
and Massimiliano Pontil and Kenji Fukumizu},
title = {Optimal kernel choice for large-scale two-sample tests},
year = 2012,
booktitle = nips25,
}

@TechReport{GrigoriadisKh91,
  author = 	 {Michael D. Grigoriadis and Leonid G. Khachiyan},
  title = 	 {Approximate solution of matrix games in parallel},
  institution =  {DIMACS},
  year = 	 1991,
  number =	 {91-73},
  month =	 jul
}

@TechReport{GrigoriadisKh94,
  author = 	 {Michael D. Grigoriadis and Leonid G. Khachiyan},
  title = 	 {A sublinear-time randomized approximation algorithm
		  for matrix games},
  institution =  {Rutgers University Department of Computer Science},
  year = 	 1994,
  number =	 {LCSR-TR-222},
  month =	 {April}
}

@Article{GrigoriadisKh95,
  author = 	 {Michael D. Grigoriadis and Leonid G. Khachiyan},
  title = 	 {A sublinear-time randomized approximation algorithm for
                         matrix games},
  journal = 	 {Operations Research Letters},
  year = 	 1995,
  volume =	 18,
  number =	 2,
  month =	 {Sep},
  pages =	 {53-58}
}

@article{GrigorievKaSi90,
author=		{Dima Yu. Grigoriev and Marek Karpinski and Michael F.
		 Singers},
title=		{Fast Parallel Algorithms for Sparse Multivariate
		 Polynomial Interpolation over Finite Fields},
journal=	sicomp,
volume=		19,
number=		6,
pages=		{1059--1963},
month=		dec,
year=		1990
}

@article{GroeneboomJoWe01,
author = {Piet Groeneboom and Geurt Jongbloed and Jon A. Wellner},
title = {Estimation of a convex function: characterization and 
  asymptotic theory},
year = 2001,
journal = aos,
volume = 29,
number = 6,
pages = {1653--1698},
}

@book{GrossmanMa64,
author = 	{Israel Grossman and Wilhelm Magnus},
title = 	{Groups and Their Graphs },
publisher = 	{Mathematical Association of America},
year = 		{1964},
volume = 	{14},
series = 	{New Mathematical Library},
address = 	{Washington},
comment = 	{A low level introduction to group theory via Cayley graphs}
}


@inproceedings{GroveLiSc97,
author=		{Adam J. Grove and Nick Littlestone and Dale Schuurmans},
title=		{General convergence results for linear discriminant updates},
booktitle = 	 {Proceedings of the Tenth Annual Conference on
		  Computational Learning Theory},
year =	 1997
}




@article{GroveLiSc01,
author=		{A.~J.~Grove and N.~Littlestone and D.~Schuurmans},
title=		{General convergence results for linear discriminant updates},
journal=  	ml,
year=     	2001,
volume=   	43,
number=         3,
pages=    	{173--210},
}

@misc{Grouplens08,
author = {{GroupLens Lab}},
title = {Movie{L}ens dataset},
url = {http://www.grouplens.org/taxonomy/term/14},
institution = {University of Minnesota},
year = 2008,
}

@InProceedings{GroveSc98,
  author = 	 {Adam J. Grove and Dale Schuurmans},
  title = 	 {Boosting in the limit: Maximizing the margin of
                  learned ensembles},
  booktitle = 	 {Proceedings of the Fifteenth National Conference on
                  Artificial Intelligence},
  year =	 1998
}

@article{Grunbaum60,
author = {Branko Gr\"unbaum},
title = {Partitions of mass-distributions and of convex bodies by hyperplanes},
year = 1960,
journal = {Pacific Journal of Mathematics},
volume = 10,
number = 4,
pages = {1257--1261},
url = {http://projecteuclid.org/euclid.pjm/1103038065},
comment = {Shows that any partition of a convex set by a hyperplane through
  its center of mass shaves at least a fraction $(1 - 1/e)$ off the set.},
}

@book{Grunwald07,
author = {Peter Gr\"unwald},
title = {The Minimum Description Length Principle},
year = 2007,
publisher = {MIT Press},
}

@article{GrunwaldDa04,
author = {Peter Gr\"unwald and A. Philip Dawid},
title = {Game theory, maximum entropy, minimum discrepancy,
and robust {B}ayesian decision theory},
journal = aos,
year = 2004,
volume = 32,
number = 4,
pages = {1367--1433},
comment = {Shows how maximum entropy procedures correspond to certain
  robustified Bayesian procedures.},
}

@book{Gu02,
author = {C. Gu},
title = {Smoothing spline ANOVA models},
publisher = {Springer},
year = 2002,
}

@inproceedings{GuermeurElPa00,
 author = "Y. Guermeur and A. Elisseeff and H. Paugam-Moisy",
 title = "A new multi-class {SVM} based on a uniform convergence result",
 booktitle = 	{Proceedings of IJCNN-2000},
 year = 	{2000},
 editor =       {V. Piuri et al.}
}

@inproceedings{GuibasSe78,
	author = {L.J.~Guibas and R.~Sedgewick},
	title = {A Dichromatic Framework for Balanced Trees},
	booktitle = focs78,
	pages = {8--21},
	year = 1978
}

@article{Gulliksen56,
author = {H.\ Gulliksen},
title = {A least squares method for paired comparisons with incomplete data},
year = 1956,
journal = {Psychometrika},
pages = {125--134},
volume = 21,
comment = {Extends Thurstone's least-squares model (via Mosteller) to handle
incomplete data in a natural and simple way},
}

@inproceedings{GuhaHu09,
author = {Sudipto Guha and Zhiyi Huang},
year = 2009,
title = {Revisiting the Direct Sum Theorem and Space
Lower Bounds in Random Order Streams},
booktitle = {36th International Colloquium on Automata, Languages,
and Programming},
url = {http://repository.upenn.edu/cis_papers/399/},
}

@inproceedings{GuhaInMc07,
author = {Sudipto Guha and Piotr Indyk and Andrew McGregor},
title = {Sketching information divergences},
booktitle = colt07,
year = 2007,
url = {http://www.cis.upenn.edu/~sudipto/mypapers/unsketchables.pdf},
}

@inproceedings{GumadiJoYu12,
 author = {Gummadi, Ramakrishna and Johari, Ramesh and Yu, Jia Yuan},
 title = {Mean Field Equilibria of Multiarmed Bandit Games},
 booktitle = {Proceedings of the 13th ACM Conference on Electronic Commerce (EC)},
 year = {2012},
} 

@article{Guntuboyina11,
author = {Adityanand Guntuboyina},
title = {Lower bounds for the minimax risk using $f$-divergences,
and applications},
year = 2011,
journal = ieeeit,
volume = 57,
number = 4,
pages = {2386--2399},
}

@article{Guntuboyina12,
author = {Adityanand Guntuboyina},
title = {Optimal rates of convergence for convex set estimation from
  support functions},
year = 2012,
journal = aos,
volume = 40,
pages = {385--411},
}

@article{GuntuboyinaSe13,
author = {Adityanand Guntuboyina and Bodhisattva Sen},
title = {Covering numbers for convex functions},
year = 2013,
journal = ieeeit,
volume = 59,
number = 4,
pages = {1957--1966},
}

@article{GuntuboyinaSe15,
author = {Adityanand Guntuboyina and Bodhisattva Sen},
title = {Global risk bounds and adaptation in univariate convex regression},
journal = {Probability Theory and Related Fields},
year = 2015,
volume = 163,
pages = {379–-411},
}

@book{Gupal79,
author = {A. M. Gupal},
title = {Stokhasticheskie Methody Resheniya Negladkikh Ekstremal'nykh Zadach
(Stochastic Methods for Solving Nonsmooth Extremal Problems)},
year = 1979,
note = {(In Ukrainian)},
publisher = {Naukova Dumka},
address = {Kiev},
}

@article{GuptaJaGl15,
author = {Abhishek Gupta and Rahul Jain and Peter W. Glynn},
title = {An empirical algorithm for relative value iteration for
average-cost {MDP}s},
year = 2015,
journal = {Submitted},
}

@article{GuptaKu00,
author = {P. Gupta and P. R. Kumar},
title = {The capacity of wireless networks},
year = 2000,
journal = {IEEE Transactions on Information Theory},
volume = 46,
number = 2,
pages = {388--404},
}

@article{GuptaViNeYuWaWo11,
  title={Experimental validation of free-energy-landscape reconstruction from non-equilibrium single-molecule force spectroscopy measurements},
  author={Gupta, Amar Nath and Vincent, Abhilash and Neupane, Krishna and Yu, Hao and Wang, Feng and Woodside, Michael T},
  journal={Nature Physics},
  volume=7,
  number=8,
  pages={631--634},
  year=2011,
  publisher={Nature Research}
}

@InProceedings{GuruswamiSa99,
  author = 	 {Venkatesan Guruswami and Amit Sahai},
  title = 	 {Multiclass Learning, Boosting, and Error-Correcting Codes},
  booktitle = 	 colt99,
  year =	 1999
}

@inproceedings{Gurevich87,
author=   	{Yuri Gurevich},
title=    	{Complete and Incomplete Randomized {NP} Problems},
booktitle=	focs87,
month=    	Oct,
pages=    	{111--117},
year=     	1987
}

@article{Gurevich89,
author=		{Yuri Gurevich},
title=		{The Challenger-Solver game: Variations on the theme
		of {P=?NP}},
journal=	{Bulletin of the European Association for Theoretical
		Computer Science},
year=		1989,
month=		Oct
}

@unpublished{Gurevich89b,
author=		{Yuri Gurevich},
title=		{Matrix Correspondence Problem is Complete for the
		Average Case},
month=		Nov,
year=		1989,
note=		{Unpublished manuscript}
}

@article{Gurevich91,
author=		{Yuri Gurevich},
title=		{Average Case Completeness},
journal=	jcss,
year=		1991,
volume=		42,
number=		3,
pages=		{346--398}
}

@article{Gurevich??,
author=		{Yuri Gurevich},
title=		{Average Case Completeness},
journal=	jcss,
year=		{To appear}
}

@unpublished{GurevichMc87,
author=		{Yuri Gurevich and David McCauley},
title=		{Average Case Complete Problems},
month=		Apr,
year=		1987,
note=		{Unpublished manuscript}
}

@misc{Gurobi,
   author = "Gurobi Optimization, Inc.",
   title = "Gurobi Optimizer Reference Manual",
   year = 2015,
   url = "http://www.gurobi.com"
}@article{Gurvits95
,author=	{Leonid Gurvits}
,title=		{Stability of discrete linear inclusion}
}

@article{GuyonEl03,
author =        {I.~Guyon and A.~Elisseeff},
title =         {An Introduction to Variable and Feature Selection},
journal=	{Journal of Machine Learning Research, Special Issue on Variable and Feature Selection},
volume=	        {3},
year=           {2003},
pages=	        {1157--1182}
}

@book{GyorfiKoKrWa02,
author = {L\'aszl\'o Gy\"orfi and Michael Kohler and Adam Krzy\.zak and Harro
Walk},
title = {A Distribution-Free Theory of Nonparametric Regression},
year = 2002,
publisher = {Springer},
}

@article{GyorfiNe78,
author = {L\'asl\'o Gy\"orfi and Tibor Nemetz},
title = {$f$-dissimilarity: A generalization of the affinity of several
 distributions},
year = 1978,
journal = {Annals of the Institute of Statistical Mathematics},
volume = 30,
pages = {105--113},
}

@inproceedings{GyorgiTi89,
author = 	{G. Gy\"orgi and N. Tishby},
title = 	{Statistical Theory of Learning a Rule},
booktitle = 	{Proceedings of the STATPHYS-17 Workshop on Neural Networks
		 and Spin Glasses},
year = 		1989
}

@Article{Hagelbarger56,
  author = 	 {D. W. Hagelbarger},
  title = 	 {{SEER}, {A} {SE}quence {E}xtrapolating {R}obot},
  journal = 	 {IRE Transactions on Electronic Computers},
  year = 	 1956,
  month =	 mar,
  pages =	 {1-7}
}

@article{HagerZh06,
Author = {Hager, William W and Zhang, Hongchao},
	Journal = {Pacific Journal of Optimization},
	Number = {1},
	Pages = {35--58},
	Title = {A survey of nonlinear conjugate gradient methods},
	Volume = {2},
	Year = {2006},
}

@Article{HagerupRu90,
  author = 	 {Torben Hagerup and Christine R\"{u}b},
  title = 	 {A guided tour of Chernoff bounds},
  journal = 	 {Information Processing Letters},
  year = 	 1990,
  volume =	 33,
  pages =	 {305--308}
}

@inproceedings{HaghighiLiBeKl08,
author = {Aria Haghighi and Percy Liang and Taylor Berg-Kirkpatrick and
  Dan Klein},
title = {Learning bilingual lexicons from monolingual corpora},
year = 2008,
booktitle = {Human Language Technology and Association for
Computational Linguistics (HLT/ACL)},
pages = {771--779},
}

@article{HalevyNoPe09,
author = {Alon Halevy and Peter Norvig and Fernando Pereira},
title = {The unreasonable effectiveness of data},
year = 2009,
journal = {IEEE Intelligent Systems},
volume = 24,
number = 2,
month = {March--April},
pages = {8--12},
}

@article{Hall82,
  title={On some simple estimates of an exponent of regular variation},
  author={Hall, Peter},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={37--42},
  year=1982,
  publisher={JSTOR}
}

@book{Hall92,
author = {Peter Hall},
title = {The Bootstrap and Edgeworth Expansion},
year = 1992,
publisher = {Springer},
comment = {Essentially the go-to reference for classical asymptotic
treatment of bootstrap and Edgeworth expansions. Uses complex analysis
and (essentially) saddle points to show rates of convergence of bootstrap
for confidence intervals},
}

@article{Hall97,
  title={Edgeworth expansion for Student's $ t $ statistic under minimal moment conditions},
  author={Hall, Peter},
  journal={The Annals of Probability},
  volume=15,
  number=3,
  pages={920--931},
  year=1987,
  publisher={Institute of Mathematical Statistics}
}

@phdthesis{Hall13,
author = {Rob Hall},
title = {New Statistical Applications for Differential Privacy},
year = 2013,
school = {Carnegie Mellon University, Departments of
Statistics and Machine Learning},
}

@book{HallHy14,
  title={Martingale limit theory and its application},
  author={Hall, Peter and Heyde, Christopher C},
  year=2014,
  publisher={Academic press}
}

@article{HallRiWa11,
author = {Rob Hall and Alessandro Rinaldo and Larry Wasserman},
year = 2011,
title = {Random differential privacy},
url = {http://arxiv.org/abs/1112.2680},
journal = {arXiv:1112.2680 [stat.ME]},
comment = {Studies some lower and upper bounds (under certain restrictions)
for estimation of histograms. Shows that for \epsilon-differential privacy,
a k-entry histogram has minimax convergence rate k / (n\epsilon). They
relax to a probabilistic differential privacy, and show that if k is
small enough and only r entries of the histogram are non-zero (this part
is an odd assumption) then a rate of r / (n \epsilon) is achieved.
They actually get lower and upper bounds with differential privacy.
},
}

@article{HallRiWa13,
author = {Rob Hall and Alessandro Rinaldo and Larry Wasserman},
title = {Differential Privacy for Functions and Functional Data},
journal = jmlr,
year = 2013,
volume = 14,
pages=  {703--727},
comment = {See below version.},
}

@unpublished{HallRiWa12,
author = {Rob Hall and Alessandro Rinaldo and Larry Wasserman},
year = 2012,
title = {Differential Privacy for Functions and Functional Data},
note = {URL \url{http://arxiv.org/abs/1203.2570}},
comment = {
Looks at release of functional data estimators, focusing pretty much
exclusively on RKHS's, in a differentially private manner. Shows that
when an algorithm is stable in the RKHS norm, then adding Gaussian process
noise to it (of appropriate variance) with kernel given by the RKHS kernel
yields differential privacy--at least for the sigma-algebra generated by
the cylinder sets of functions. Proof technique roughly uses finite
dimensional privacy argument (with Gaussian noise), then a nice limiting
argument to show that vector-based differential privacy (i.e. differential
privacy of any finite number of released function evaluations) yields
differential privacy for the full sigma-field.
One difficulty of the paper (that is not immediate how to overcome): the
learning algorithm/aggregator must be *queried* for the (perturbed) function
values \tilde{f}(x), since it must add Gaussian process noise to each
function value, and it is not clear how to release the full function without
providing the support points. Also gives an algorithm that iteratively updates
sufficient statistics of the GP to release a countable number of function
values.
},
}

@article{HallTeVa92,
  title={The abscissa of convergence of the {L}aplace transform},
  author={Hall, Peter and Teugels, Jozef L and Vanmarcke, Ann},
  journal={Journal of Applied Probability},
  pages={353--362},
  year=1992,
  comment={Gives a minimax upper and lower bound $O(1 / \log n)$ for
                  estimating abscissa of convergence of the moment
                  generating function. For the lower bound, they use
                  asymptotic arguments (LeCam) by using Neyman-Pearson
                  lemma. The basic intuition is that, in order to
                  estimate the abscissa reliably, one needs to observe
                  samples in the tails.}
}

@inbook{Halmos73,
author = 	{Paul R. Halmos},
title = 	{How to Write Mathematics},
pages = 	{19--48},
publisher = 	{American Mathematical Society},
year = 		1973,
note = 		{In book entitled {\sl How to Write Mathematics}, by
		N.E. Steenrod, Paul R. Halmos, M.M. Schiffer, and
		J.A. Dieudonn\'e}
}

@book{HampelRoRoSt86,
author = {Frank Hampel and Elvezio Ronchetti and Peter Rousseeuw and
  Werner Stahel},
title = {Robust Statistics: The Approach Based on Influence Functions},
year = 1986,
publisher = {John Wiley \& Sons},
}

@article{HanAm98,
  title={Statistical inference under multiterminal data compression},
  author={Sun Han and Shunichi Amari},
  journal=ieeeit,
  volume={44},
  number={6},
  pages={2300--2324},
  year={1998},
}

@inproceedings{Hancock90,
author=		{Hancock, Thomas R.},
title=		{Identifying $\mu$-Formula Decision Trees with Queries},
booktitle=	colt90,
pages=		{23--37},
month=		Aug,
year=		1990
}

@techreport{Hancock90b,
author=		{Hancock, Thomas R.},
title=		{Identifying $\mu$-Formula Decision Trees with Queries},
institution=	{Harvard University, Center for Research in Computing
		 Technology},
number=		{TR-16-90},
year=		1990
}

@inproceedings{HancockHe91,
author=		{Thomas Hancock and Lisa Hellerstein},
title=		{Learning Read-Once Formulas over Fields and Extended
		 Bases},
year=		1991,
month=		aug,
booktitle=	colt91,
pages=		{326--336}
}

@inproceedings{HancockMa91,
author=		{Thomas Hancock and Yishay Mansour},
title=		{Learning Monotone {$k\mu$ DNF} Formulas on Product
		 Distributions},
booktitle=	colt91,
month=		aug,
year=		1991,
pages=		{179--183}
}

@book{Hanke95,
author = {M. Hanke},
title = {Conjugate gradient type methods for ill-posed problems},
publisher = {Wiley},
year = 1995,
}

@incollection{Hannan57
,author=	{J. Hannan}
,title=		{Approximation to {B}ayes risk in repeated play}
,booktitle=	{Contributions to the Theory of Games}
,volume=	{III}
,editor=	{M. Dresher and A. W. Tucker and P. Wolfe}
,publisher=	{Princeton University Press}
,year=		1957
,pages=		{97--139}
}

@article{Hansen82,
  title={Large sample properties of generalized method of moments estimators},
  author={Hansen, Lars Peter},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1029--1054},
  year=1982,
  publisher={JSTOR}
}

@article{HardtMo12,
author = {Moritz Hardt and Ankur Moitra},
title = {Can we reconcile robustness and efficiency in unsupervised learning?},
year = 2012,
journal = {arXiv:1211.1041 [cs.CC]},
url = {http://arxiv.org/abs/1211.1041},
comment = {Uses a conjecture known as gap-small-set-expansion (deciding
  whether a graph is an expander for small enough sets, basically) to give
  arguments that it may be challenging to identify an outlier/inlier separation
  for principle components (or something like it). Give a simple randomized
  algorithm for identifying a lower-dimensional manifold containing data
  based on randomly sampling sets of points of the same size as the dimension
  of the problem and looking for collinear (or nearly collinear) points.
  Currently not completely convinced of the lower bounds.},
}

@inproceedings{HardtRo10,
author = {Moritz Hardt and Guy N. Rothblum},
title = {A Multiplicative Weights Mechanism for
Privacy-Preserving Data Analysis},
year = 2010,
booktitle = focs10,
comment = {
  Shows how to answer a number of counting queries on a database while
  maintaining privacy. Technique is to begin with a fake database
  that is uniform on the universe U (of size N, which is presumably *huge*),
  then for each query, compare the answer from the fake and (a perturbed
  answer from the) real database, and if they are close enough return the
  fake answer. Otherwise return the perturbed answer, then do a multiplicative
  update to the fake database to bring it closer to the real histogram.
  Doing a smallish number of updates--as analyzed by the amount of "potential"
  reduced (KL divergence to true database from the fake one)--yields privacy
  and utility. Proofs are pretty CS-theory.
  Long version has a lower bound for answering sufficiently many
  queries (of sufficient dimension, somehow) that says that answering
  lots of queries will yield error rate at least A / \sqrt{n \epsilon},
  where A depends on N, n, and the number of linear queries being issued.
},
}

@inproceedings{HardtTa10,
author = {Moritz Hardt and Kunal Talwar},
title = {On the geometry of differential privacy},
year = 2010,
booktitle = stoc10,
pages = {705--714},
url = {http://arxiv.org/abs/0907.3754},
comment = {
  Give lower bounds on the amount of noise necessary to add for answering
  queries of the form y = Fx, where x is a vector in \R^n and
  F \in [-1, 1]^{d \times n} is a linear mapping. Their main lower bound
  shows that noise of L2-norm roughly d \sqrt{d} / \epsilon * Vol(FB_1)^{1/d}
  must be added, where B_1 is the \ell_1-ball of radius 1. Here \epsilon
  is the differential privacy parameter, and the proof follows from a volume
  (packing) argument. Roughly, differential privacy means that balls around
  all points y in FB_1 must have similar mass, but if the noise is taken
  to be too small, then a large enough packing + differential privacy would
  force more than mass 1 to the resulting distribution.
  For many queries, we get lower bounds that scale as
  d/\epsilon \min\{\sqrt{d}, \sqrt{\log(n/d)}\}
},
}

@article{HardwickSt02,
author = {Janis Hardwick and Quentin F. Stout},
title = {Optimal Few-Stage Designs},
journal = {Journal of Statistical Planning and Inference},
year = 2002,
pages = {121--145},
volume = 104,
}

@book{HardyWr60,
author =  	{G. H. Hardy and E. M. Wright},
title=	  	{An Introduction to the Theory of Numbers},
edition=  	{4th},
year =    	1960,
publisher= 	{Oxford University Press}
}

@article{HareLe04,
author = {Warren Hare and Adrian Lewis},
title = {Identifying Active Constraints via Partial Smoothness and Prox-Regularity},
year = 2004,
journal = {Journal of Convex Analysis},
pages = {251–-266},
volume = 11,
number = 2,
}

@inproceedings{Harrington03,
  author = "E.~F.~Harrington",
  title = " Online Ranking/Collaborative Filtering Using the
Perceptron Algorithm",
  booktitle = icml03,
  year = "2003"
}



@techreport{Hart85,
author=   	{Hart, George W.},
title=    	{Prototype Nonintrusive Appliance Load Monitor},
institution=  	{MIT Energy Laboratory},
year=     	1985,
month=    	Sep,
number=   	{Progress Report #2},
comment=  	{Finite-state automaton inference to determine appliances
		present.}
}

@phdthesis{Hart87,
author=   	{Hart, George W.},
title=    	{Minimum Information Estimation of Structure},
school=   	{MIT Dept.\ of Electrical Engineering and Computer Science},
year=     	1987,
month=    	Apr,
note=     	{Appears as LIDS-TH-1664.},
comment=  	{Studies and applies Rissanen's MDLP.}
}



@Article{HartMasColell00,
  author = 	 {S. Hart and A. Mas-Colell},
  title = 	 {A General Class of Adaptive Strategies},
  journal = 	 {Journal of Economic Theory},
  year = 	 {2000},
  volume = 	 {98},
  number = 	 {1},
  pages = 	 {26-54}
}

@Article{HartMasColell00a,
  author = 	 {S. Hart and A. Mas-Colell},
  title = 	 {A simple adaptive procedure leading to correlated equilibrium},
  journal = 	 {Econometrica},
  year = 	 {2000},
  volume = 	 {68},
  pages = 	 {1127-1150}
}


@book{HartmanisSt66,
author=   	{Hartmanis, J.\ and R. E. Stearns},
title=    	{Algebraic Structure Theory of Sequential Machines},
publisher=	{Prentice-Hall},
year=     	1966
}

@Article{HarunoShOo99,
  author = 	 {Masahiko Haruno and Satoshi Shirai and Yoshifumi Ooyama},
  title = 	 {Using Decision Trees to Construct a Practical Parser},
  journal = 	 {Machine Learning},
  year = 	 1999,
  volume =	 34,
  pages =	 {131-149}
}

@article{HashlamounVaSa94,
author=	{W. A. Hashlamoun and P. K. Varshney and V. N. S. Samarasooriya},
title=	{A tight upper bound on the {Bayesian} probability of error}
}

@article{Hasminskii78,
author = "R. Z. Has'minskii",
title = "A lower bound on the risks of nonparametric estimates
         of densities in the uniform metric",
journal = "Theory of Probability and Applications",
volume = "23",
pages = "794--798",
year = "1978"
}

@article{Hastad01,
author = {Johan H{\aa}stad},
title = {Some optimal inapproximability results},
journal = {jacm},
volume = 48,
number = 4,
year = 2001,
pages = {798--859},
}

@book{HastieTi95,
  author={T.J. Hastie and R.J. Tibshirani},
  title={Generalized additive models},
  publisher={Chapman \& Hall},
  year=1995
}

@article{HastieTi98,
	author = {Trevor Hastie and Robert Tibshirani},
	title = {Classification by pairwise coupling},
	journal = annstat,
	volume = 26,
	number = 1,
	pages = "451--471",
	year = 1998
}

@book{HastieTiFr01,
	author = "Trevor Hastie and Robert Tibshirani and Jerome Friedman",
	title = "The Elements of Statistical Learning",
	year = "2001",
	publisher = "Springer"
}

@book{HastieTiFr09,
author = "Trevor Hastie and Robert Tibshirani and Jerome Friedman",
title = "The Elements of Statistical Learning",
year = "2009",
publisher = "Springer",
edition = {Second},
}

@techreport{HastiePr90,
author = {Trevor Hastie and Daryl Pregibon},
title = {Shrinking Trees},
year = 1990,
institution = {AT\&T Bell Laboratories}
}

@inproceedings{Haussler86,
author=   	{Haussler, David},
title=    	{Quantifying the inductive bias in concept learning},
booktitle=  	{Proceedings  AAAI-86},
organization= 	{American Association for Artificial Intelligence},
year=     	1986,
month=		aug,
pages=		{485--489},
comment=  	{Defines bias=  Vapnik-Chervonenkis dimension. Algorithms for
		learning k-CNF, k-DNF. Many ideas for extensions,
		generalizations.}
}

@inproceedings{Haussler87a,
author=   	{Haussler, David},
title=    	{Bias, Version Spaces and {Valiant's} Learning Framework},
booktitle=	{Proceedings of the Fourth International Workshop on
           	Machine Learning},
address=  	{University of California, Irvine},
year=     	1987,
month=    	Jun,
pages=	  	{324--336}
}

@techreport{Haussler87b,
author=   	{Haussler, David},
title=    	{Learning Conjunctive Concepts in Structural Domains},
institution= 	ucsccrl,
year=     	1987,
month=    	Feb,
number=   	{UCSC-CRL-87-1}
}

@article{Haussler88,
author = 	{Haussler, David},
title = 	{Quantifying Inductive Bias: {AI} Learning Algorithms and
		 {V}aliant's Learning Framework},
journal = 	{Artificial Intelligence},
year = 		1988,
volume = 	36,
pages = 	{177--221}
}

@techreport{Haussler88b,
author=   	{Haussler, David},
title=    	{Space Efficient Learning Algorithms},
institution= 	ucsccrl,
number=   	{UCSC-CRL-88-2},
year=     	1988,
month=    	Mar
}

@inproceedings{Haussler89,
author = 	{Haussler, David},
title = 	{Generalizing the {PAC} Model: Sample Size Bounds from
		 Metric Dimension-based Uniform Convergence Results},
booktitle=	focs89,
pages=		{40--45},
month=    	Oct,
year=		1989
}

@techreport{Haussler89b,
author = 	{Haussler, David},
title = 	{Generalizing the {PAC} Model for Neural Net and
		 Other Learning Applications},
institution= 	ucsccrl,
number=   	{UCSC-CRL-89-30},
year=     	1989,
month=    	Sep,
note=		{To appear, {\it Information and Computation}}
}

@inproceedings{Haussler90,
author=		{David Haussler},
title=		{Decision Theoretic Generalizations of the {PAC}
		 Learning Model},
booktitle=	{Proceedings of the First International Workshop on
		 Algorithmic Learning Theory},
year=		{1990},
pages=		{21--41},
comment=	{address=Tokyo, pub=Japanese Society for Artificial
		 Intelligence}
}

@inproceedings{Haussler90b,
title=		"Probably Approximately Correct Learning",
author=		"David Haussler",
booktitle=	"Proceedings of the 8th National Conference on Artificial
		 Intelligence",
publisher=	"Morgan Kaufmann",
year= 		1990,
pages=		"1101--1108"
}


@article{Haussler92,
author=		{David Haussler},
title=		{Decision Theoretic Generalizations of the {PAC} Model
		 for Neural Net and Other Learning Applications},
journal=	infcomp,
year=		1992,
volume=		100,
number=		1,
pages=		{78--150}
}

@article{Haussler97,
author = {David Haussler},
title = {A general minimax result for relative entropy},
year = 1997,
journal = ieeeit,
volume = 43,
number = 4,
pages = {1276--1280},
comment = {Extends \cite{Gallager79} to more general families of distributions
  by using tightness and relative (weak) compactness in the space of
  probability measures. In particular, shows a generalization of
  redundancy capacity theorem to general alphabets using quantized
  versions of kl divergences.},
}

@inproceedings{HausslerKeLiWa88,
author=   	{Haussler, David and Michael Kearns and Nick Littlestone and
	   	Manfred K. Warmuth},
title=    	{Equivalence of Models for Polynomial Learnability},
booktitle=	colt88,
month=    	Aug,
year=     	1988,
pages = 	{42--55},
note=		{Available as Technical
		 Report UCSC-CRL-88-06, University of California Santa
		 Cruz, Computer Research Laboratory.
		 To appear, {\it Information and Computation}},
comment=	{This reference is out of date -- use HKLW91}
}

@techreport{HausslerKeLiWa88b,
author=   	{Haussler, David and Michael Kearns and Nick Littlestone and
	   	Manfred K. Warmuth},
title=    	{Equivalence of Models for Polynomial Learnability},
number=		{UCSC-CRL-88-06},
institution=	ucsccrl,
month=		Sep,
year=		1988
}

@article{HausslerKeLiWa91,
author=   	{David Haussler and Michael Kearns and Nick Littlestone and
	   	Manfred K. Warmuth},
title=    	{Equivalence of Models for Polynomial Learnability},
journal=	infcomp,
month=    	dec,
year=     	1991,
volume=		95,
number=		2,
pages=		{129--161}
}

@incollection{HausslerKeOpSc92
,author=	{David Haussler and Michael Kearns and Manfred Opper
		 and Robert Schapire}
,title=		{Estimating average-case learning curves using
		 {B}ayesian, statistical physics and {VC} dimension
		 methods}
,booktitle=	{Advances in Neural Information Processing Systems 4}
,publisher=	{Morgan Kaufmann}
,pages=		{855--862}
,year=		1992
,editor=	{John E. Moody and Steve J. Hanson and Richard P.
		 Littmann}
}

@inproceedings{HausslerKeSc91,
author=		{David Haussler and Michael Kearns and Robert E. Schapire},
title=		{Bounds on the Sample Complexity of {B}ayesian Learning
		 Using Information Theory and the {VC} Dimension},
booktitle=	colt91,
month=		aug,
year=		1991
}

@article{HausslerKeSc94,
author=		{David Haussler and Michael Kearns and Robert E. Schapire},
title=		{Bounds on the Sample Complexity of {B}ayesian Learning
		 Using Information Theory and the {VC} Dimension},
journal=	ml,
volume=		14,
year=		1994,
pages=		{83--113}
}

@unpublished{HausslerKeSeTi94
,author=	{David Haussler and Michael Kearns and H. Sebastian
		 Seung and Naftali Tishby}
,title=		{Rigorous learning curve bounds from statistical
		 mechanics}
,year=		1994
}

@inproceedings{HausslerKiWa95
,author=	{David Haussler and Jyrki Kivinen and Manfred K. Warmuth}
,title=		{Tight worst-case loss bounds for predicting with
		 expert advice}
,booktitle=	eurocolt95
,year=		1995
,publisher=	{Springer-Verlag}
,pages=		{69--83}
}

@article{HausslerKiWa98,
author = {David Haussler and Jyrki Kivinen and Manfred K. Warmuth},
title = {Sequential Prediction of Individual
    Sequences Under General Loss Functions},
year = 1998,
journal = ieeeit,
volume = 44,
number = 5,
pages = {1906--1925},
}

@unpublished{HausslerLiWa87,
author = 	{Haussler, David and Nick Littlestone and
	   	Manfred K. Warmuth},
title = 	{Expected mistake bounds for on-line learning algorithms},
month=		Apr,
year=		1987,
note=		{Unpublished manuscript}
}

@inproceedings{HausslerLiWa88,
author = 	{Haussler, David and Nick Littlestone and
	   	Manfred K. Warmuth},
title = 	{Predicting $\{0,1\}$-Functions on Randomly Drawn Points},
booktitle = 	focs88,
month=		oct,
year = 		{1988},
pages = 	{100--109},
comment =	{Tech.\ Report, U. C. Santa Cruz, to appear (longer version).}
}

@article{HausslerLiWa94,
author = 	{Haussler, David and Nick Littlestone and
	   	Manfred K. Warmuth},
title = 	{Predicting $\{0,1\}$-Functions on Randomly Drawn Points},
journal=	infcomp,
volume=		115,
number=		2,
year=		1994,
pages = 	{248-292}
}

@Article{HausslerLo95,
  author = 	 {David Haussler and Philip M. Long},
  title = 	 {A generalization of {S}auer's lemma},
  journal = 	 {Journal of Combinatorial Theory, Series A},
  year = 	 1995,
  volume =	 71,
  number =	 2,
  pages =	 {219-240}
}

@unpublished{Hazan06,
  author = "E. Hazan",
  title = "Approximate Convex Optimization by Online Game Playing",
  note = "Unpublished manuscript",
  year = 2006
}

@article{Hazan16,
author = {Elad Hazan},
title = {Introduction to Online Convex Optimization},
year = 2016,
journal = {Foundations and Trends in Optimization},
volume = {2},
number = {3--4},
pages = {157--325},
}

@incollection{Hazan12,
author = {Elad Hazan},
title = {The convex optimization approach to regret minimization},
year = 2012,
booktitle = {Optimization for Machine Learning},
editors = {S. Sra and S. Nowozin and S. J. Wright},
publisher = {MIT Press},
chapter = 10,
}

@InProceedings{HazanKaKaAg06,
  author = 	 {E. Hazan and A. Kalai and S. Kale and A. Agarwal},
  title = 	 {Logarithmic Regret Algorithms for Online Convex Optimization},
  booktitle = colt06,
  year = 	 {2006}
}

@article{HazanAgKa07,
author = {E.\ Hazan and A.\ Agarwal and S.\ Kale},
title = {Logarithmic regret algorithms for online convex optimization},
year = 2007,
journal = ml,
volume = 69,
number = {2-3},
pages = {169--192},
}

@unpublished{HazanKa10,
author = {E. Hazan and S. Kale},
title = {An optimal algorithm for stochastic strongly convex optimization},
year = 2010,
note = {URL \url{http://arxiv.org/abs/1006.2425}},
}

@inproceedings{HazanKa11,
author = {Elad Hazan and Satyen Kale},
title = {An optimal algorithm for stochastic strongly convex optimization},
year = 2011,
booktitle = colt11,
}

@inproceedings{HazanKa12,
author = {Elad Hazan and Satyen Kale},
title = {Projection-free online learning},
year = 2012,
booktitle = icml12,
comment = {Studies an online variant of the Frank-Wolfe method (for a good
survey, see Jaggi13), showing a 1/sqrt{T} convergence rate if the functions
being minimized are smooth. Proof is a little weaker than it needs to be--the
results chould be sharpened to LD^2 / T + GD / \sqrt{T} with a better
induction---but nice. Each step requires only solving a linear optimization
problem over the domain (often easier than a quadratic), but method
does require keeping around *each* function observed.},
}

@article{HazanKo16,
author = {Elad Hazan and Tomer Koren},
title = {A linear-time algorithm for trust region problems},
year = 2016,
journal = mathproga,
volume = 158,
number = 1,
pages = {363--381},
}

@article{HeWeChCaSo17,
  title={Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong},
  author={He, Warren and Wei, James and Chen, Xinyun and Carlini, Nicholas and Song, Dawn},
  journal={arXiv:1706.04701 [cs.LG]},
  year=2017
}

@inproceedings{HeZhReSu16,
  title={Deep residual learning for image recognition},
    author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
      booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
        pages={770--778},
	  year=2016,
	  comment={Deep residual networks, see
                  https://github.com/KaimingHe/deep-residual-networks
                  for the trained weights.}
		  }

@incollection{Heckerman98,
author = 	 {D. Heckerman},
booktitle = 	 {Learning and Inference in Graphical Models},
editor =         {M. I. Jordan},
title = 	 {A Tutorial on Learning with Bayesian Networks},
pages =          {301--354},
publisher = 	 {Kluwer Academic Press},
year = 	         {1998}
}

@Article{HeckermanGeCh95,
  author = 	 {D. Heckerman and D. Geiger and D.M. Chickering},
  title = 	 {Learning Bayesian Networks: The combination of
		  knowledge and statistical data},
  journal = 	 {ml},
  year = 	 1995,
  volume =	 20,
  pages =	 {197-243}
}

@phdthesis{Hellerstein89,
author=		{Lisa Hellerstein},
title=		{On Characterizing and Learning Some Classes of
		 Read-Once Formulas},
school=		{University of California at Berkeley},
year=		1989
}

@techreport{HellersteinKa90,
author=		{Lisa Hellerstein and Marek Karpinski},
title=		{Read-Once Formulas over Different Bases},
year=		1990,
institution=	{University of Bonn},
number=		{8556-CS}
}

@unpublished{HellersteinWa??,
author=		{Lisa Hellerstein and Manfred Warmuth},
title=		{Interpolating {GF[2]} polynomials},
note=		{Unpublished manuscript}
}

@article{Hellman77,
author=  	{Martin E. Hellman},
title=   	{An Extension of the Shannon Theory Approach to Cryptography},
journal= 	{IEEE Transactions on Information Theory},
volume=  	{IT-23},
number=  	{3},
month=   	May,
year=    	1977,
pages=   	{289--294}
}

@inproceedings{HelmboldKiWa95
,author=	{David P. Helmbold and Jyrki Kivinen and Manfred
		 K. Warmuth}
,title=		{Worst-case loss bounds for sigmoided neurons}
,booktitle=	{Advances in Neural Information Processing Systems 7}
,year=		1995
,pages=		{309--315}
}

@article{HelmboldKiWa99,
	author = "D.~P.~ Helmbold and J. Kivinen and M. Warmuth",
	title = "Relative Loss Bounds for Single Neurons",
	journal = ieeenn,
	volume = 10,
	number = 6,
	pages = "1291--1304",
	year = 1999
}

@inproceedings{HelmboldLo91,
author=		{David P. Helmbold and Philip M. Long},
title=		{Tracking Drifting Concepts Using Random Examples},
booktitle=	colt91,
month=		aug,
year=		1991,
pages=		{13--23}
}

@article{HelmboldLo94,
author=		{David P. Helmbold and Philip M. Long},
title=		{Tracking Drifting Concepts by Minimizing Disagreements},
journal=	ml,
volume=		14,
number=		1,
year=		1994,
pages=		{27--45}
}

@inproceedings{HelmboldSc95
,author=	{David P. Helmbold and Robert E. Schapire}
,title=		{Predicting nearly as well as the best pruning of a
		 decision tree}
,booktitle=	colt95
,pages=		{61-68}
,year=		1995
}

@Article{HelmboldSc97,
  author = 	 {David P. Helmbold and Robert E. Schapire},
  title = 	 {Predicting nearly as well as the best pruning of a
		 decision tree},
  journal = 	 ml,
  year = 	 1997,
  volume =	 27,
  number =	 1,
  pages =	 {51-68},
  month =	 apr
}

@inproceedings{HelmboldScSiWa95
,author=	{D.~P. Helmbold and R.~E. Schapire and Y. Singer and M. Warmuth}
,title=		{A comparison of new and old algorithms for a mixture
		 estimation problem}
,booktitle=	colt95
,pages=		{69-78}
,year=		1995
}

@inproceedings{HelmboldScSiWa96
,author=	{David P. Helmbold and Robert E. Schapire and Yoram
		 Singer and Manfred K. Warmuth}
,title=		{On-Line Portfolio Selection Using Multiplicative Updates}
,booktitle=	ml96
,pages=		{243-251}
,year=		1996
,note=          {Long version available from my web page}
}

@article{HelmboldScSiWa98
,author=	{David P. Helmbold and Robert E. Schapire and Yoram
		 Singer and Manfred K. Warmuth}
,title=		{On-Line Portfolio Selection Using Multiplicative Updates}
,journal=	{Mathematical Finance}
,pages=		{325-347}
,year=		1998
,volume=        8
,number=        4
}

@inproceedings{HelmboldSlWa89,
author=   	{Helmbold, David and Robert Sloan and Manfred K. Warmuth},
title=    	{Learning Nested Differences of Intersection-Closed
		 Concept Classes},
booktitle=	colt89,
month=    	Jul,
year=     	1989,
pages = 	{41--56}
}

@article{HelmboldSlWa90,
author=   	{Helmbold, David and Robert Sloan and Manfred K. Warmuth},
title=    	{Learning Nested Differences of Intersection-Closed
		 Concept Classes},
journal=	ml,
month=    	jun,
volume=		5,
number=		2,
year=     	1990,
pages = 	{165--196}
}

@article{HelmboldSlWa92,
author=		{David Helmbold and Robert Sloan and Manfred K. Warmuth},
title=		{Learning Integer Lattices},
journal=	sicomp,
volume=		21,
number=		2,
year=		1992,
pages=		{240--266}
}

@techreport{HelmboldWa92,
author=		{David P. Helmbold and Manfred K. Warmuth},
title=		{On Weak Learning},
institution=	ucsccrl,
number=		{UCSC-CRL-92-54},
year=		1992,
month=		dec,
note=		{Revised May, 1993}
}

@Article{HelmboldWa95,
  author = 	 {D.~P.~Helmbold and M. Warmuth},
  title = 	 {On weak learning},
  journal = 	 jcss,
  year = 	 1995,
  volume =	 50,
  pages =	 {551-573}
}

@unpublished{HenisLeGo94
,author=	{Ealan A. Henis and Stephen E. Levinson and Allen L.
		Gorin}
,title=		{Mapping natural language and sensory information into
		manipulatory actions}
}

@book{HennessyPa11,
author = {John L. Hennessy and David A. Patterson},
title = {Computer Architecture: A Quantitative Approach},
year = 2011,
edition = {{F}ifth},
publisher = {Morgan Kaufmann},
}

@book{Hennie68,
author=   	{Hennie, Frederick C.},
title=    	{Finite-State Models for Logical Machines},
publisher=	{John Wiley and Sons},
year=     	1968
}

@incollection{HerbrichGrOb00,
	author =       "R.~Herbrich and T.~Graepel and K.~Obermayer",
        title =        "Large Margin Rank Boundaries for Ordinal Regression",
	booktitle =    "Advances in Large Margin Classifiers",
	publisher = "MIT Press",
	year = 2000
}


@InProceedings{Herbster01
,author=	{M.~Herbster}
,title=		{Learning additive models online with fast evaluating kernels}
,booktitle=	colt01
,year=		2001
,pages =        "444--460"
}

@InProceedings{HerbsterWa95
,author=	{Mark Herbster and Manfred Warmuth}
,title=		{Tracking the best expert}
,booktitle=	ml95
,year=		1995
,pages =        "286--294"
,note=		{Long version to appear in {\it Machine Learning} and
		  available from {http://www.cse.ucsc.edu/$\sim$manfred}}
}

@article{HerbsterWa01,
author = "M.~Herbster and M.~Warmuth",
title = "Tracking the Best Linear Predictor",
journal = jmlr,
volume = "1",
pages = "281--309",
year = 2001
}

@InProceedings{HermanskyFo05,
  author = 	 "Hynek Hermansky and Petr Fousek",
  title = 	 "Multi-resolution RASTA filtering for TANDEM-based ASR",
  booktitle =      "Proceedings of Interspeech 2005",
  year = 	 2005
}

@book{Herstein75,
author=		{I. N. Herstein},
title=		{Topics in Algebra},
publisher=	{Wiley},
year=		{1975},
edition=	{Second}
}

@InProceedings{HertzHiWe04,
author=	{T. Hertz and A. Bar-Hillel and D. Weinshall},
title=		{Learning Distance Functions for Image Retrieval},
booktitle=	{CVPR},
year=		2004
}


@book{HertzKrPa91,
author=		{John Hertz and Anders Krogh and Richard G. Palmer},
title=		{Introduction to the Theory of Neural Computation},
publisher=	{Addison-Wesley},
year=		1991
}

@inproceedings{Heskes98,
author = "T.~Heskes",
title = "Solving a Huge Number of Silmilar Tasks: A Combination of Multitask Learning and a Hierarchical Bayesian Approach",
booktitle = icml98,
pages = "233--241",
year = "1998"
}

@article{Hestenes69,
author = {Magnus R. Hestenes},
title = {Multiplier and Gradient Methods},
year = 1969,
journal = jota,
volume = 4,
pages = {303--320},
}

@article{Heuberger04,
author = {C. Heuberger},
title = {Inverse combinatorial optimization: a survey on problems, methods,
and results},
year = 2004,
journal = {Journal of Combinatorial Optimization},
volume = 8,
number = 3,
pages = {329--361},
comment = {Given a (combinatorial) optimization problem and a feasible
 solution to it, the corresponding inverse optimization problem is to find
 a minimal adjustment of the cost function such that the given solution
 becomes optimum.},
}

@article{HeYu12,
author = {Bingsheng He and Xiaoming Yuan},
title = {On the ${O}(1/n)$ convergence rate of {D}ouglas-{R}adford alternating
direction method},
year = 2012,
journal = {SIAM Journal on Numerical Analysis},
volume = 50,
pages = {700--709},
comment = {Uses a variational inequality formulation of Nesterov to show
that the objective function and constraint violations for ADMM converge
at a rate of $1/n$ after $n$ iterations of ADMM.},
url = {http://www.optimization-online.org/DB_FILE/2011/09/3157.pdf},
}

@techreport{HHS13,
author = {{Substance Abuse and Mental Health Services Administration}},
title = {Drug Abuse Warning Network 2011: National Estimates of
Drug-Related Emergency Department Visits},
year = 2013,
institution = {U.S.\ Department of Health and Human Services},
number = {SMA 13-4760},
url = {http://www.samhsa.gov/data/emergency-department-data-dawn/reports?tab=47},
}

@article{Hickernell99,
  title={Goodness-of-fit statistics, discrepancies and robust designs},
  author={Fred J. Hickernell},
  journal={Statistics \& probability letters},
  volume={44},
  number={1},
  pages={73--78},
  year={1999},
  publisher={Elsevier}
}

@Article{Hildreth57,
  author = 	 {C. Hildreth},
  title = 	 {A Quadratic Programming Procedure},
  journal = 	 {Naval Research Logistics Quarterly},
  year = 	 {1957},
  volume = 	 {4},
  pages = 	 {79--85},
  note = 	 {Erratum, ibidem, p.361},
}

@inproceedings{HillStRoFu95,
	author = "Will Hill and Larry Stead and Mark Rosenstein and
                  George Furnas",
	title = "Recommending and Evaluating Choices in a Virtual
		Community of Use",
	booktitle = "Human Factors in Computing Systems {CHI'95}
                  Conference Proceedings",
	pages = "194--201",
	year = 1995
}

@inproceedings{Hinton86,
author=   	{Hinton, Geoffrey E.},
title=    	{Learning Distributed Representations of Concepts},
booktitle= 	{Proceedings of the Eighth Annual Conference of the Cognitive
	   	Science Society},
address=   	{Amherst, Mass},
year=      	1986,
month=     	Aug,
pages=     	{???--???},
comment=   	{Uses a back-propagation learning procedure to learn relational
	   	data items.}
}

@article{HintonDaFrNe95
,author=	{Geoffrey E. Hinton and Peter Dayan and Brendan
		 J. Frey and Radford M. Neal}
,title=		{The ``Wake-Sleep'' algorithm for unsupervised neural
		 networks}
}

@article{HintonDeYuDaMoJaSeVaNgSaKi12,
author = {Geoffrey Hinton and Li Deng and Dong Yu and George E. Dahl and
   Abdel-Rahman Mohamed and Navdeep Jaitly and
  Andrew Senior and Vincent Vanhoucke and Patrick Nguyen and Tara N. Sainath
  and Brian Kingsbury},
title  = {Deep neural networks for acoustic modeling in speech recognition},
year = 2012,
journal = {IEEE Signal Processing Magazine},
volume = 82,
month = {November},
}

@techreport{HintonSeAc84,
author=   	{Hinton, Geoffrey E. and Terrence J. Sejnowski and David H.
		Ackley},
title=    	{Boltzmann Machines: Constraint Satisfaction Networks that
		Learn},
institution= 	{CMU Computer Science Department},
number=   	{CMS-CS-84-119},
year=     	1984,
month=    	May,
comment=  	{Uses simulated annealing to update propositional states in
	  	a connectionist Hopfield-like neural network.}
}

@article{HiranoImRe03,
author = {Keisuke Hirano and Guido Imbens and Geert Ridder},
title = {Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score},
year = 2003,
journal = {Econometrica},
pages = {1161–-1189},
volume = 71,
number = 4,
}

@book{HiriartUrrutyLe93,
author = {J. Hiriart-Urruty and C. Lemar\'echal},
title = {Convex Analysis and Minimization Algorithms {I}},
publisher = {Springer},
address = {New York},
year=1993,
comment = {Builds convex analysis and calculus from first principles,
           lots of subgradient calculus},
}

@book{HiriartUrrutyLe93b,
author = {J. Hiriart-Urruty and C. Lemar\'echal},
title = {Convex {A}nalysis and {M}inimization {A}lgorithms {II}},
publisher = {Springer},
address = {New York},
year=1993,
comment = {Builds convex analysis and calculus from first principles,
           lots of subgradient calculus},
}

@book{HiriartUrrutyLe93ab,
author = {J. Hiriart-Urruty and C. Lemar\'echal},
title = {Convex {A}nalysis and {M}inimization {A}lgorithms {I} \& {II}},
publisher = {Springer},
address = {New York},
year = 1993,
comment = {Builds convex analysis and calculus from first principles,
           lots of subgradient calculus},
}

@book{HiriartUrrutyLe01,
author = {Jean-Baptiste Hiriart-Urruty and Claude Lemar\'echal},
title = {Fundamentals of Convex Analysis},
publisher = {Springer},
year = 2001,
}

@techreport{HirschbergWhPeSiRoPaMa97,
author={Julia Hirschberg and Steve Whittaker and Fernando
        Pereira and Amitabh Singhal and Aaron Rosenberg and
        S. Parthasarathy and Ivan Magrin-Chagnolleau},
title={Browsing and retrieval of speech in audio databases}
}

@article{HjortMcKe09,
  title={Extending the scope of empirical likelihood},
  author={Hjort, Nils Lid and McKeague, Ian W and Van Keilegom, Ingrid},
  journal={The Annals of Statistics},
  pages={1079--1111},
  year=2009,
  publisher={JSTOR}
}

@inproceedings{HoKe96
,author=	{Tin Kam Ho and Eugene M. Kleinberg}
,title=		{Building projectable classifiers of arbitrary
		 complexity}
}

@book{Hoeffding40,
  title={Massstabinvariante korrelationstheorie},
  author={Hoeffding, Wassily},
  year=1940,
  publisher={Teubner}
}

@article{Hoeffding56,
author= {W. Hoeffding},
title = {On the Distribution of the Number of Successes in Independent Trials},
journal = {Annals of Mathematical Statistics},
volume = 27,
pages = {713-721},
year = 1956
}

@article{Hoeffding63,
author = 	{W. Hoeffding},
title = 	{Probability inequalities for sums of bounded random
		variables},
journal = 	{Journal of the American Statistical Association},
year = 		{1963},
volume = 	{58},
number = 	{301},
pages = 	{13--30},
month = 	mar
}

@inproceedings{HoffgenSi92,
author = 	{Klaus-U. H\"offgen and Hans-U. Simon},
title = 	{Robust Trainability of Single Neurons},
booktitle=	{Proceedings of the Fifth Annual ACM Workshop
                 on Computational Learning Theory},
address=  	{Pittsburgh, Pennsylvania},
year=     	1992,
month=    	Jul,
pages=    	{428--439}
}

@article{HoffgenVaSi95,
author = 	{Klaus U. H\"offgen and Kevin S. Van Horn and Hans U. Simon},
title = 	{Robust Trainability of Single Neurons},
year=     	1995,
journal = jcss,
volume = 50,
number = 1,
pages=    	{114--125}
}

@book{Holland75,
author=		{John H. Holland},
title=		{Adaptation in Natural and Artificial Systems},
publisher=	{University of Michigan Press},
year=		1975,
comment=	{full title = ...: an introductory analysis with
		 applications to biology, control, and
		 artificial intelligence.  address= Ann Arbor}
}

@incollection{Holland84,
author=		{John H. Holland},
title=		{Genetic algorithms and adaptation},
booktitle=	{Adaptive Control of Ill-defined Systems},
editor=		{Oliver G. Selfridge and Edwina L. Rissland and
		 Michael A. Arbib},
year=		1984,
publisher=	{Plenum Press},
comment=	{address = New York}
}

@article{Holmstedt70,
title = {Interpolation of quasi-normed spaces},
author = {T.~Holmstedt},
year = 1970,
journal = {Mathematica Scandinavica},
volume = 26,
pages = {177--190}
}

@article{Holte93
,author=	{Robert C. Holte}
,title=		{Very simple classification rules perform well on most
		 commonly used datasets}
,journal=	ml
,volume=	11
,number=	1
,year=		1993
,pages=		{63-91}
}

@article{HomemDeMello07,
  title={A study on the cross-entropy method for rare-event probability estimation},
  author={Homem-de-Mello, Tito},
  journal={INFORMS Journal on Computing},
  volume=19,
  number=3,
  pages={381--394},
  year=2007,
  publisher={INFORMS},
  comment={Considers cross-entropy methods on product
                  measures. Proposes a novel way of updating the
                  rare threshold quantile.}
}

@article{HomerSzReDuTeMuPeStNeCr08,
author = {Nils Homer and Szabolcs Szelinger and Margot Redman and
 David Duggan and Waibhav Tembe and Jill Muehling and John V. Pearson
 and Dietrich A. Stephan and Stanley F. Nelson and David W. Craig},
title = {Resolving individuals contributing trace amounts of {DNA}
to highly complex mixtures using high-density {SNP} genotyping microarrays},
journal = {PLoS Genetics},
year = 2008,
volume = 4,
number = 8,
pages = {e1000167},
}

@article{Ho-NguyenKi16,
author = {Nam Ho-Nguyen and Fatma K{\i}l{\i}n\k{c}-Karzan},
title = {A Second-Order Cone Based Approach for Solving the
Trust-Region Subproblem and Its Variants},
year = 2016,
journal = {arXiv:1603.03366 [math.OC]},
}

@book{HonigMe84
,author=	{Michael L. Honig and David G. Messerschmitt}
,title=		{Adaptive Filters: Structures, Algorithms, and
		 Applications}
,year=		1984
,publisher=	{Kluwer Academic Publishers}
}

@incollection{Hopcroft71,
author=    	{Hopcroft, John},
title=     	{An $n\log(n)$ Algorithm for Minimizing States in a Finite
	   	Automaton},
booktitle= 	{Theory of Machines and Computations},
editor=    	{Zvi Kohavi and Azaria Paz},
publisher= 	{Academic Press},
year=      	1971,
pages=     	{189--196}
}

@book{HopcroftUl79,
author = 	{John Hopcroft and Jeffrey Ullman},
title = 	{Introduction to Automata Theory, Languages, and Computation},
publisher = 	{Addison-Wesley},
year = 		{1979},
address = 	{Reading, MA}
}

@book{HornJo85
,author=	{Roger A. Horn and Charles R. Johnson}
,title=		{Matrix Analysis}
,publisher=	{Cambridge University Press}
,year=		1985
}

@inproceedings{Hosom02,
author = 	{J.P. Hosom},
title = 	{Automatic Phoneme Alignment Based on Acoustic-Phonetic Modeling},
booktitle = "Proceedings of the Seventh International Conference on
		Spoken Language Processing",
pages=		{357-360},
year=		2002
}

@article{HristacheJuSp01,
author = {Marian Hristache and Anatoli Juditsky and Vladimir Spokoiny},
year = 2001,
journal = aos,
title = {Direct estimation of the index coefficient in
a single-index model},
volume = 29,
number = 3,
pages = {595--623},
}

@inproceedings{HsiaoXuCaHe12,
author = {Ko-Jen Hsiao and Kevin S. Xu and Jeff Calder and Alfred O. Hero},
title = {Multi-criteria Anomaly Detection using {P}areto Depth Analysis},
year = 2012,
booktitle = nips25,
}

@article{HsuKaZh12,
author = {Daniel Hsu and Sham Kakade and Tong Zhang},
title = {A tail inequality for quadratic forms of subgaussian random vectors},
year = 2012,
journal = {Electronic Communications in Probability},
volume = 17,
number = 52,
pages = {1--6},
comment = {Provides a bound on the moment generating function of the square
  of a sub-Gaussian random vector. The bound is calculated by the
  usual normal trick: let X be a sub-Gaussian random vector and Z be
  standard normal. Then
  $\E[\exp(\lambda^2 ||X||^2 / 2)] = \E[\exp(\lambda Z^T X)]
  \le \E[\exp(\lambda^2 \sigma^2 ||Z||^2 / 2)]$, where $\sigma$ is
  the sub-Gaussian parameter of the random vector $X$. The final expectation
  is bounded using standard analysis of Gaussian random vectors.},
}

@inproceedings{HuHu09,
  title={On the performance of the cross-entropy method},
  author={Hu, Jiaqiao and Hu, Ping},
  booktitle={Simulation Conference (WSC), Proceedings of the 2009 Winter},
  pages={459--468},
  year=2009,
  organization={IEEE},
  comment={Conference version of HuHuCh12. Gives consistency and rate of
                  convergence to a non-interpretable quantity for a
                  variant of the cross-entropy method. Requires
                  exponential families and polynomially increasing
                  sample sizes.}
}

@article{HuHu11,
  title={Annealing adaptive search, cross-entropy, and stochastic approximation in global optimization},
  author={Hu, Jiaqiao and Hu, Ping},
  journal={Naval Research Logistics (NRL)},
  volume=58,
  number=5,
  pages={457--477},
  year=2011,
  publisher={Wiley Online Library},
  comment={Proposes model-based annealing algorithm for global
                  optimization. If sample sizes increase polynomially,
                  then shows both consistency and rate of convergence
                  to global optimum (assuming that it is suitably
                  stable).}
}

@article{HuHuCh12,
  title={A stochastic approximation framework for a class of randomized optimization algorithms},
  author={Hu, Jiaqiao and Hu, Ping and Chang, Hyeong Soo},
  journal={IEEE Transactions on Automatic Control},
  volume=57,
  number=1,
  pages={165--178},
  year=2012,
  publisher={IEEE},
  comment={Journal version of HuHu09. Gives consistency and rate of
                  convergence to a non-interpretable quantity for a
                  variant of the cross-entropy method. Requires
                  exponential families and polynomially increasing
                  sample sizes.}
}

@inproceedings{HuangKwWaWu17,
  title={Safety verification of deep neural networks},
  author={Huang, Xiaowei and Kwiatkowska, Marta and Wang, Sen and Wu, Min},
  booktitle={International Conference on Computer Aided Verification},
  pages={3--29},
  year=2017,
  organization={Springer}
}

@book{Huber81,
	author = {P. J. Huber},
	title = "Robust Statistics",
	publisher = "John Wiley and Sons, New York",
	year = 1981
}

@book{HuberRo09,
author = {Peter J. Huber and Elvezio M. Ronchetti},
title = {Robust Statistics},
year = 2009,
edition = {Second},
publisher = {John Wiley and Sons},
}

@article{Huber85,
author = {Peter J. Huber},
title = {Projection Pursuit},
journal = aos,
year = 1985,
volume = 13,
number = 2,
pages = {435--475},
}

@incollection{Huber09,
  title={On the non-optimality of optimal procedures},
  author={Peter J. Huber},
  booktitle = {Optimality: The Third Erich L. Lehmann Symposium},
  series={IMS Lecture Notes-Monograph Series},
  publisher = {Institute of Mathematical Statistics},
  pages={31--46},
  year={2009},
}

@inproceedings{HuKwPa09,
author = {C. Hu and J. Kwok and W. Pan},
title = {Accelerated gradient methods for stochastic optimization and online
learning},
year = 2009,
booktitle = nips22,
}

@article{HuZhFa14,
  title={Model-based annealing random search with stochastic averaging},
  author={Hu, Jiaqiao and Zhou, Enlu and Fan, Qi},
  journal={ACM Transactions on Modeling and Computer Simulation (TOMACS)},
  volume=24,
  number=4,
  pages=21,
  year=2014,
  publisher={ACM},
  comment={Proposes model-based annealing algorithm with stochastic
                  averaging and shows that it converges to global
                  optimum in the limit. Stochastic averaging allows us
                  to have constant sample sizes which is an
                  improvement over previous algorithms that required
                  polynomially growing samples.}
}

@inproceedings{HullPeSc96,
        author = {David Hull and Jan Pedersen and Hinrich Schutze},
        booktitle = sigir96,
        pages = {279--288},
        title = {Method Combination for Document Filtering},
        year = {1996}
}

@article{HummerSz01,
  title={Free energy reconstruction from nonequilibrium single-molecule pulling experiments},
  author={Hummer, Gerhard and Szabo, Attila},
  journal={Proceedings of the National Academy of Sciences},
  volume=98,
  number=7,
  pages={3658--3661},
  year=2001,
  publisher={National Acad Sciences}
}

@article{HyafilRi76,
author=    	{Hyafil, Laurent and Ronald L. Rivest},
title=     	{Constructing Optimal Binary Decision Trees is {NP}-Complete},
journal=   	{Information Processing Letters},
year=      	1976,
month=     	May,
volume=    	5,
number=    	1,
pages=     	{15--17},
comment=   	{Proof based on exact-cover by 3-subsets.}
}

@article{Ibragimov62,
  title={Some limit theorems for stationary processes},
  author={Ibragimov, Ildar A},
  journal={Theory of Probability \& Its Applications},
  volume=7,
  number=4,
  pages={349--382},
  year=1962,
  publisher={SIAM}
}

@book{IbragimovHa81,
author = {I. A. Ibragimov and R. Z. Has'minskii},
title = {Statistical Estimation: Asymptotic Theory},
year = 1981,
publisher = {Springer-Verlag},
}

@article{Imbens04,
author = {Guido Imbens},
title = {Nonparametric estimation of average treatment effects
under exogeneity: a review},
journal = {The Review of Economics and Statistics},
year = 2004,
volume = 86,
number = 1,
pages = {4--29},
}

@article{Imbens02,
author = {Guido Imbens},
title = {Generalized Method of Moments and Empirical Likelihood},
year = 2002,
journal = {Journal of Business and Economic Statistics},
volume = 20,
number = 4,
pages = {493--506},
}

@inproceedings{ImpagliazzoZu89,
author = {R. Impagliazzo and D. Zuckerman},
title = {How to recycle random bits},
year = 1989,
booktitle = focs89,
pages = {248--253},
comment = {Uses random walks on expander graphs to get probability
   amplification even when random bits are scarce},
}

@inproceedings{Impagliazzo95,
author = {Russel Impagliazzo},
title = {A personal view of average-case complexity},
booktitle = {Proceedings of the 10th Annual Structure in Complexity
   Theory Conference (SCT'95)},
year = 1995,
}

@incollection{Indyk04,
author = {Piotr Indyk},
title = {Nearest Neighbors in High-Dimensional Spaces},
year = 2004,
booktitle = {Handbook of Discrete and Computational Geometry},
publisher = {CRC Press},
}

@inproceedings{IndykMo98,
author = {Piotr Indyk and Rajeev Motwani},
title = {Approximate nearest neighbors: towards removing the curse
  of dimensionality},
year = 1998,
booktitle = stoc98,
}

@article{Ioannidis05,
author = {John P. Ioannidis},
journal = {PLoS Medicine},
publisher = {Public Library of Science},
title = {Why Most Published Research Findings Are False},
year = 2005,
volume = 2,
number = 8,
doi = {10.1371/journal.pmed.0020124},
}


@article{IrelandKu68,
author=   	{Ireland, C.T. and S. Kullback},
title=    	{Contingency tables with given marginals},
journal=  	{Biometrika},
year=     	1968,
volume=   	55,
number=   	1,
pages=    	{179--188},
comment=  	{Proves geometric convergence of Deming/Stephan procedure for
	   	computing maximum entropy solution.}
}

@article{IshikidaVa94,
	author = "T. Ishikida and P. Varaiya",
	title = "Multi-Armed Bandit Problem Revisited",
	journal = "Journal of Optimization Theory and Applications",
	number = 1,
	volume = 83,
	year = 1994,
	month = oct,
	pages = "113-154"}

@inproceedings{IttnerLeAh95,
    author = "D.~J.~Ittner and D.~D.~Lewis and D.~D.~Ahn",
    title = "Text Categorization of Low Quality Images",
    booktitle = "Symposium on Document Analysis and Information Retrieval",
    organization = "ISRI; Univ. of Nevada, Las Vegas",
    address = "Las Vegas, NV",
    pages = "301--315",
    year = 1995
}


@inproceedings{IwayamaTo95
,author=        {Makoto Iwayama and Takenobu Tokunaga}
,title=         {Cluster-based text categorization: A comparison of
                  category search strategies}
,pages=         {273-281}
,booktitle=     sigir95
,year=          1995
}

@inproceedings{IyerLeScSiSi00,
	author = "Raj Iyer and David Lewis and Robert Schapire and Yoram Singer
		and Amit Singhal",
	title = "Boosting for Document Routing",
	booktitle = "{CIKM}",
	year = 2000
}

@article{Izenman91,
author=		{Alan Julian Izenman},
title=		{Recent Developments in Nonparametric Density
		 Estimation},
journal=	{Journal of the American Statistical Association},
month=		mar,
year=		1991,
volume=		86,
number=		413,
pages=		{205--224}
}

@techreport{JaakkolaJoSi93,
author=		{Tommi Jaakkola and Michael I. Jordan and Satinder P.
		 Singh},
title=		{On the convergence of stochastic iterative dynamic
		 programming algorithms},
institution=	{MIT Computational Cognitive Science},
number=		{9307},
month=		jul,
year=		1993
}

@article{JacksonShSh99,
	author = "J. Jackson and E. Shamir and C. Shwartzman",
	title = "Learning with queries corrupted by clssification noise",
	journal = "Discrete Applied Math",
	volume = 92,
	pages = "157--175",
	year = 1999
}

@inproceedings{JacksonCr96
,author=	{Jeffrey C. Jackson and Mark W. Craven}
,title=		{Learning sparse perceptrons}
,booktitle=	nips8
,pages=		{654-660}
,year=		1996
}

@unpublished{JacksonShSh9?
,author=        {Jeffrey Jackson and Eli Shamir and Clara Shwartzman}
,title=         {Learning with queries corrupted by classification
                  noise}
}

@book{Jacobson74,
author=		{Jacobson, Nathan},
title=		{Basic Algebra},
year=	  	1974,
volume=	  	1,
publisher= 	{W. H. Freeman and Company},
comment = 	{Classic abstract algebra text}
}

@inproceedings{JacoBaVe08,
  author = {L.~Jacob and F.~Bach and J.-P.~Vert},
  title = {Clustered Multi-Task Learning: A Convex Formulation},
  booktitle = nips21,
  year = 2008
}

@inproceedings{Jaggi13,
author = {Martin Jaggi},
title = {Revisiting {F}rank-{W}olfe: projection-free sparse convex
optimization},
year = 2012,
booktitle = icml13,
}

@inproceedings{JainTh13,
author = {Prateek Jain and Abhradeep Thakurta},
title = {Mirror Descent based Database Privacy},
year = 2012,
booktitle = {International Workshop on Randomization and
  Computation (RANDOM)},
}

@inproceedings{JainNeSa13,
author = {Prateek Jain and Praneeth Netrapalli and Sujay Sanghavi},
title = {Low-rank Matrix Completion using Alternating Minimization},
year = 2013,
booktitle = stoc13,
}

@article{JamesHa98,
author=		{G. James and T. Hastie},
title=		{The error coding method and {PiCT}},
journal=	{Journal of computational and graphical stastistics},
volume=		7,
number=		3,
year=		1998,
pages=		{377-387}
}

@inproceedings{JamiesonNoRe12,
author = {Kevin Jamieson and Robert Nowak and Benjamin Recht},
title = {Query Complexity of Derivative-Free Optimization},
year = 2012,
booktitle = nips25,
}

@inproceedings{JamiesonNo11,
  title={Active ranking using pairwise comparisons},
  author={Jamieson, Kevin and Nowak, Robert},
  booktitle=nips24,
  pages={2240--2248},
  year={2011}
}

@inproceedings{JamiesonKaDeNo15,
title={Sparse Dueling Bandits},
author={Jamieson, Kevin and Katariya, Sumeet and Deshpande, Atul
   and Nowak, Robert},
booktitle = aistat15,
year = 2015,
}

@article{Jamshidian92
,author=	{Farshid Jamshidian}
,title=		{Asympotitically optimal portfolios}
}

@inproceedings{Jantke84,
author=   	{Jantke, K. P.},
title=    	{Polynomial-time inference of general pattern languages},
booktitle=	{Proceedings of the Symposium of Theoretical Aspects of
		Computer Science; Lecture Notes in Computer Science},
year=     	1984,
volume=   	166,
pages=    	{314-325},
publisher=	{Springer}
}

@article{JarnerRo02,
     title = {Polynomial Convergence Rates of {M}arkov Chains},
     author = {S. Jarner and G. Roberts},
     journal = {The Annals of Applied Probability},
     volume = {12},
     number = {1},
     pages = {pp. 224-247},
     year = {2002},
     publisher = {Institute of Mathematical Statistics},
    }

@article{JarvelinKe04,
author = {K. J\"arvelin and J. Kek\"al\"ainen},
title = {Cumulated gain-based evaluation of {IR} techniques},
year = 2002,
journal = {ACM Transactions on Information Systems},
volume = 20,
number = 4,
pages = {422--446},
}

@article{Jarzynski97,
  title={Nonequilibrium equality for free energy differences},
  author={Jarzynski, Christopher},
  journal={Physical Review Letters},
  volume=78,
  number=14,
  pages=2690,
  year=1997,
  publisher={APS}
}

@article{Jaynes68,
author=   	{Jaynes, Edwin T.},
title=    	{Prior Probabilities},
journal=  	{IEEE Transactions on Systems Science and Cybernetics},
year=     	1968,
month=    	Sep,
volume=   	{SSC-4},
number=   	3,
pages=    	{227--241},
comment=  	{Presentation and justification for maximum-entropy procedure}
}

@article{Jaynes82,
author=   	{Jaynes, Edwin T.},
title=    	{On the Rationale of Maximum-Entropy Methods},
journal=  	{Proceedings of the IEEE},
volume=   	70,
number=  	9,
year=     	1982,
month=    	Sep,
pages=    	{939--952},
comment=  	{Justification for maximum-entropy methods, and comparison with
	   	full Bayesian and autoregressive models.}
}

@article{Jeffreys46,
author = {Harold Jeffreys},
title = {An invariant form for the prior probability in estimation problems},
year = 1946,
journal = {Proceedings of the Royal Society of London, Series A:
           Mathematical and Physical Sciences},
volume = 186,
pages = {453--461},
}

@techreport{Jelinek83,
author=   	{Jelinek, Frederick},
title=    	{Markov Source Modeling of Text Generation},
institution=  	{IBM T.J. Watson Research Center},
year=     	1983,
comment=  	{Interpolates 1-, 2-, and 3-gram transistion probabilities.}
}

@inproceedings{JenattonMaObBa10,
author = {R. Jenatton and J. Mairal and G. Obozinski and F. Bach},
title = {Proximal methods for sparse hierarchical dictionary learning},
year = 2010,
booktitle = icml10,
}


@article{JerrumSi89,
author=		{M. Jerrum and A. Sinclair},
title=		{Approximating the Permanent},
journal=	sicomp,
volume=		18,
year=		1989,
pages=		{1149--1178},
comment=	{fill in first names and journal number}
}

@article{JerrumSi93
,author=	{Mark Jerrum and Alistair Sinclair}
,title=		{Polynomial-time approximation algorithms for the
		 ising model}
,journal=	sicomp
,volume=	22
,number=	5
,pages=		{1087--1116}
,month=		oct
,year=		1993
}

@incollection{JerrumSi96,
author = {M. Jerrum and A. Sinclair},
title = {The {M}arkov chain {M}onte {C}arlo method: an approach to approximate
counting and integration},
year = 1996,
booktitle = {Approximation Algorithms for NP-hard Problems},
editor = {D. S. Hochbaum},
publisher = {PWS Publishing},
}

@article{JiangGu13,
  title={Data-driven chance constrained stochastic program},
  author={Jiang, Ruiwei and Guan, Yongpei},
  journal={Optimization Online},
  url={http://www.optimization-online.org/DB_FILE/2013/09/4044.pdf},
  year=2013,
}

@article{JiaoVeHaWe14,
author = {Jiantao Jiao and  Kartik Venkat and  Yanjun Han and Tsachy Weissman},
title = {Minimax Estimation of Functionals of Discrete Distributions},
year = 2014,
journal = {arXiv:1406.6956 [cs.IT]},
}


@InProceedings{JinGeNeKaJo17,
	title = 	 {How to Escape Saddle Points Efficiently},
	author = 	 {Chi Jin and Rong Ge and Praneeth Netrapalli and Sham M. Kakade and Michael I. Jordan},
	booktitle = icml17,
	year = 	 {2017},
}

@article{Jittorntrum78,
  title={An implicit function theorem},
  author={Jittorntrum, K},
  journal={Journal of Optimization Theory and Applications},
  volume=25,
  number=4,
  pages={575--577},
  year=1978,
  publisher={Springer}
}

@inproceedings{Joachims97
,author= 	"T. Joachims"
,title=		"A probabilistic analysis of the {R}ochhio algorithm with {TFIDF}
	for text categorization"
,booktitle=     ml97
,year=          1997
,pages=         {143--151}
}

@incollection{Joachims98,
	author =       "T. Joachims",
        title =        "Making Large-scale Support Vector Machine
                  Learning Practical",
	booktitle = " Advances in Kernel Methods - Support Vector Learning",
	publisher = "MIT Press",
	editor = {B. Sch\"olkopf and C. Burges and A. Smola},
	year = 1998
}



@InProceedings{Joachims02,
  author = 	 {T. Joachims},
  title = 	 {Optimizing Search Engines Using Clickthrough Data},
  booktitle = {Proceedings of the ACM Conference on Knowledge Discovery and Data Mining},
  year = 	 {2002},
}

@InProceedings{Joachims05,
  author = 	 {T. Joachims},
  title = 	 {A Support Vector Method for Multivariate Performance Measures},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = 	 {2005}
}


@InProceedings{Joachims06,
  author = 	 {T. Joachims},
  title = 	 {Training Linear {SVM}s in Linear Time},
  booktitle = {Proceedings of the ACM Conference on Knowledge Discovery and Data Mining (KDD)},
  year = 	 {2006}
}


@article{JogdeoSa68
,author=        {Kumar Jagdeo and S. M. Samuels}
,title=         {Monotone convergence of binomial probabilities and a
                  generalization of {R}amanujan's equation}
}

@article{JohanssonRaJo09,
author = {B. Johansson and M. Rabi and M. Johansson},
title = {A randomized incremental subgradient method for distributed
optimization in networked systems},
year = 2009,
journal = siopt,
volume = 20,
number = 3,
pages = {1157--1170},
comment = {Shows a generalization of the randomized incremental gradient
descent work to use Markov chains; uses stopping/revisitation times to
get convergence rates.}
}

@unpublished{JohanssonDuEl11,
author = {M. Johansson and J. C. Duchi and L. El Ghaoui},
title = {Proximal and First-Order Methods under Noise},
year = 2011,
note = {Lecture notes for EE290o, University of California, Berkeley},
}

@article{Johns88,
author = {M. Vernon Johns},
title = {Importance sampling for bootstrap confidence intervals},
year = 1988,
journal = jasa,
volume = 83,
number = 403,
pages = {709--714},
}

@article{Johnson79,
author=   	{Johnson, Rodney W.},
title=    	{Axiomatic Characterization of the Directed Divergences and
		their Linear Combinations},
journal=  	{IEEE Transactions on Information Theory},
volume=   	{IT-25},
number=   	6,
year=     	1979,
month=    	Nov,
pages=    	{709--716},
comment=  	{Characterized by positivity, additivity, and finiteness.
	   	Directed divergence also called expected weight of evidence,
	   	cross-entropy, and discrimination information.}
}


@article{Johnson84,
author=		{David S. Johnson},
title=		{The {NP}-Completeness Column: An Ongoing Guide},
journal=	{Journal of Algorithms},
volume=		5,
number=		2,
month=		jun,
year=		1984,
pages=		{284--299}
}

@article{JohnsonLi84,
  author = {W. Johnson and J. Lindenstrauss},
  journal = {Contemporary Mathematics},
  pages = {189--206},
  title = {Extensions of {L}ipschitz maps into a {H}ilbert space},
  volume = {26},
  year = {1984},
}

@article{JohnsonSh83,
author=   	{Johnson, Rodney W. and John E. Shore},
title=    	{Comments on and Corrections to `Axiomatic Derivation of the
	   	Principle of Maximum Entropy and the Principle of Minimum
	   	Cross-Entropy},
journal=  	{IEEE Transactions on Information Theory},
year=     	1983,
month=    	Nov,
volume=   	{IT-29},
number=   	6,
pages=    	{942--943},
comment=  	{Corrects error in previous paper regarding discrete case.}
}

@inproceedings{JohnsonZh13,
author = {Rie Johnson and Tong Zhang},
title = {Accelerating Stochastic Gradient Descent using
Predictive Variance Reduction},
year = 2013,
booktitle = nips26,
}

@book{Johnstone13,
author = {Iain Johnstone},
title = {Gaussian Estimation: Sequence and Wavelet Models},
year = 2013,
}

@inproceedings{JojicGoKo10,
author = {Vladimir Jojic and Stephen Gould and Daphne Koller},
title = {Accelerated dual decomposition for {MAP} inference},
booktitle = icml10,
year = 2010,
}

@book{Jolliffe86,
author =         {I.~T.~Jolliffe},
title =          {Pincipal component analysis},
publisher =      {Springer},
year =           {1986},
isbn =           {0-387-96269-7}
}

@article{Jones04,
  title={On the Markov chain central limit theorem},
  author={Jones, Galin L},
  journal={Probability Surveys},
  volume=1,
  number={299-320},
  pages={5--1},
  year=2004
}

@Article{Jones92,
  author = 	 {Lee K. Jones},
  title = 	 {A simple lemma on greedy approximation in {H}ilbert
                  space and convergence rates for projection pursuit
                  regression and neural network training},
  journal = 	 {Annals of Statistics},
  year = 	 1992,
  volume =	 20,
  number =	 1,
  pages =	 {608--613}
}

@article{Juang84,
author=   	{Juang, B.-H.},
title=    	{On the Hidden Markov Model and Dynamic Time Warping for Speech
		Recognition -- A Unified View},
journal=  	{AT&T Bell Laboratories Technical Journal},
year=     	1985,
month=    	Sep,
volume=   	63,
number=   	7,
pages=    	{1213--1242},
comment=  	{Gaussian autoregressive models; Markov models.  Baum's
		forward-backward algorithm.  Computing all paths versus
		computing best path.}
}

@techreport{JuangChLe93
,author=	{B. H. Juang and Wu Chou and C. H. Lee}
,title=		{Statistical and discriminitive methods for speech
		recognition}
}

@techreport{Judd87,
author=   	{Judd, J. Stephen},
title=    	{Complexity of Connectionist Learning with Various Node
		Functions},
institution=	{Department of Computer and Information Science,
	     	University of Massachusetts at Amherst},
month=     	Jul,
year=     	1987,
number=    	{87-60},
note=      	{Also presented at the First IEEE International Conference on
		Neural Networks, June 21--24, 1987, San Diego, California}
}


@phdthesis{Judd88,
author=   	{Judd, J. Stephen},
title=    	{Neural Network Design and the Complexity of Learning},
school=   	{University of Massachussets at Amherst, Department of
	   	Computer and Information Science},
year=     	1988
}

@unpublished{JuditskyNe10,
author = {Anatoli Juditsky and Yuri Nesterov},
title = {Primal-dual subgradient methods for minimizing uniformly
   convex functions},
year = 2010,
note = {URL \url{http://hal.archives-ouvertes.fr/docs/00/50/89/33/PDF/Strong-hal.pdf}},
}

@article{JuditskyNe14,
author = {Anatoli Juditsky and Yuri Nesterov},
title = {Deterministic and stochastic primal-dual subgradient algorithms for
  uniformly convex minimization},
year = 2014,
journal = {Stochastic Systems},
volume = 4,
number = 1,
pages = {44–-80},
}

@article{JuditskyNeTa08,
author = {Anatoli Juditsky and Arkadi Nemirovski and Claire Tauvel},
title = {Solving variational inequalities with the stochastic mirror-prox
algorithm},
journal = {arXiv:0809.0815 [math.OC]},
year = 2008,
url = {http://arxiv.org/abs/0809.0815},
comment = {Solves variational inequalities with a stochastic
                  oracle. Seems to be one of the first papers giving
                  variance-based rates of convergence for smooth
                  functions (i.e. Lipschitz monotone operators), even
                  earlier than G. Lan's work.}
}

@article{JuditskyNeTa11,
author = {Anatoli Juditsky and Arkadi Nemirovski and Claire Tauvel},
title = {Solving variational inequalities with the stochastic mirror-prox
algorithm},
year = 2011,
journal = {Stochastic Systems},
volume = 1,
number = 1,
pages = {17--58},
comment = {Solves variational inequalities with a stochastic
                  oracle. Seems to be one of the first papers giving
                  variance-based rates of convergence for smooth
                  functions (i.e. Lipschitz monotone operators), even
                  earlier than G. Lan's work.}
}

@article{JuditskyNe16,
author = {Anatoli Juditsky and Arkadi Nemirovski},
title = {Near-optimality of linear recovery in {G}aussian observation
  scheme under $\|\cdot\|^2_2$-loss},
journal = {arXiv:1602.01355 [math.ST]},
year = 2016,
}

@book{Jumarie90
,author=	{Guy Jumarie}
,title=		{Relative Information: Theories and Applications}
,year=		1990
,publisher=	{Springer-Verlag}
}

@book{Kac59
,author=	{Mark Kac}
,title=		{Statistical Independence in Probability, Analysis and
		 Number Theory}
,publisher=	{John Wiley and Sons}
,year=		1959
}

@unpublished{KahnLiSa93
,author=	{Jeff Kahn and Nathan Linial and Alex Samorodintsky}
,title=		{Inclusion-exclusion: exact and approximate}
,year=		1993
,note=		{Manuscript}
}

@article{Kailath67,
author={Thomas Kailath},
journal={IEEE Transactions on Communication Technology},
title={The Divergence and {B}hattacharyya Distance Measures in Signal Selection},
year={1967},
volume={15},
number={1},
pages={52-60},
}

@inproceedings{KairouzOhVi14,
author = {Peter Kairouz and Sewoong Oh and Pramod Vishwanath},
title = {Extremal mechanisms for local differential privacy},
year = 2014,
booktitle = nips27,
}

@inproceedings{KakadeTe09,
 title = {On the Generalization Ability of Online Strongly Convex Programming Algorithms},
 author = {Sham M. Kakade and Ambuj Tewari},
 booktitle = {Advances in Neural Information Processing Systems 21},
 year = {2009},
 editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
 pages = {801--808},
}

@article{KalaiLe93
,author=	{Ehud Kalai and Ehud Lehrer}
,title=		{Rational learning leads to {Nash} equilibrium}
,year=		1993
}

@article{KalaiLe95
,author=	{Ehud Kalai and Ehud Lehrer}
,title=		{Subjective games and equilibria}
,year=		1995
}

@article{KalaiVe05,
author = {A. Kalai and S. Vempala},
title = {Efficient algorithms for online decision problems},
year = 2005,
journal = {Journal of Computer and System Sciences},
volume = 71,
number = 3,
pages = {291--307},
}

@book{Kallenberg97,
author = {O. Kallenberg},
title = {Foundations of Modern Probability},
year = 1997,
publisher = {Springer},
comment = {Brutal book on everything in probability.},
}

@inproceedings{KamathAn12,
author = {Sudeep Kamath and Venkat Anantharam},
title = {Non-interactive Simulation of Joint Distributions:
  The Hirschfeld-Gebelein-R\'enyi Maximal Correlation and the
  Hypercontractivity Ribbon},
year = 2012,
booktitle = allerton12,
comment = {Considers problem of simulating a sample (U, V) from a joint
  distribution using samples (X, Y) that may be coupled but are accessible
  only at distributed sites. Shows that Renyi maximal correlation between
  random variables can be bounded by a term related to ``hypercontractivity,''
  which is what norms something is bounded by under a Markov kernel. In
  particular shows that nice tensorization properties mean that suitably
  correlated (U, V) cannot be simulated when (X, Y) is suitably
  contractive, which happens when (X, Y) are *less* related (so passing
  through channel U - X - Y - V means more information is lost in the
  X - Y piece).},
}

@article{KasiviswanathanLeNiRaSm11,
author = {Shiva Prasad Kasiviswanathan and Homin K. Lee and Kobbi Nissim
and Sofya Raskhodnikova and Adam Smith},
title = {What can we learn privately?},
year = {2011},
journal = {SIAM Journal on Computing},
volume = 40,
number = 3,
pages = {793--826},
comment = {
Studies the statistical query model (SQ), as defined by Kearns in 1998,
and connects it with what they term local algorithms, which put the
privacy barrier between the algorithm and the dataset. The SQ model answers
"queries" of the form (1/n) \sum_{i=1}^n g(z_i), where z_i is the database
(and g is a boolean function), or more generally, the SQ model answers
a number k so that |E[g(Z)] - k| <= \alpha, where Z is drawn from the
correct distribution.
* They show that SQ learnability and locally private algorithms are the same
(with respect to learning from polynomially many samples, in a very
learning-theoretic/CS theoretic sense). This is because each can
simulate the other.
* The intuition is that that adding random noise to each of the
g(z_i) individually preserves "local" privacy (add enough noise and this
is obvious), but in aggregate, with high probability, the SQ query is
answered for some accuracy alpha.
* To simulate local privacy from an SQ algorithm, the authors must define
a rejection sampling strategy that returns estimates from the SQ algorithm
only when they obey certain probabilistic bounds; this guarantees that
SQ algorithms can simulate locally private algorithms. (There might be
some weird issues with adaptive versus non-adaptive algorithms here.)
* Additionally, the authors have the wrong bound for Laplace concentration
(they say it is sub-Gaussian; that is silly).
url = {http://arxiv.org/abs/0803.0924},
},
}

@inproceedings{KasiviswanathanRuSm13,
author = {Shiva Prasad Kasiviswanathan and Mark Rudelson and Adam Smith},
title = {The Power of Linear Reconstruction Attacks},
year = 2013,
booktitle = stoc13,
url = {http://arxiv.org/abs/1210.2381},
comment = {
  Uses random matrix theory to show that if one wishes to release accurately
  all queries on subsets of size k of a database matrix $[U~s]$, where $s$ are
  "sensitive" attributes and $U \in \R^{n \times d}$ are known, then
  there are blatant failures of privacy if the adversary knows $U$ and the
  noise is not large enough. (Here blatant means that a fraction
  $1 - o(1)$ of $s \in \{0, 1\}^n$ can be recovered directly.) Analysis
  is by random $\{0, 1\}$ matrices $U$, but is a sample-based quantity:
  one must be accurate on \emph{all} matrices.
},
}

@article{KasiviswanathanSm13,
author = {Shiva Prasad Kasiviswanathan and Adam Smith},
title = {On the 'Semantics' of Differential Privacy: A {B}ayesian Formulation},
year = 2013,
journal = {arXiv:0803.3946v2 [cs.CR]},
url = {http://arxiv.org/abs/0803.3946v2},
}

@book{Kandel82,
author=		{Abraham Kandel},
title=		{Fuzzy Techniques in Pattern Recognition},
year=		1982,
publisher=	{Wiley}
}

@book{KapurKe92
,author=	{J. N. Kapur and H. K. Kesavan}
,title=		{Entropy Optimization Principles with Applications}
,year=		1992
,publisher=	{Academic Press}
}

@article{KargerOhSh11,
author = {David Karger and Sewoong Oh and Devavrat Shah},
title = {Budget-Optimal Task Allocation for Reliable Crowdsourcing Systems},
year = 2011,
journal = {arXiv:1110.3564 [cs.LG]},
url = {http://arxiv.org/abs/1110.3564},
comment = {Long version of NIPS paper on same subject. Gives a message-passing
  algorithm for finding labels from noisy workers. Interesting in that
  optimal allocation comes from expander graphs.}
}

@incollection{Karp72,
author=	{R. M. Karp},
title=		{Reducibility among combinatorial problems},
booktitle=	{Complexity of Computer Computations},
publisher=	{Plenum Press},
pages=		{85-103},
year=		1972,
}

@article{KarrKoOgReSa06,
author = {A. F. Karr and C. N. Kohnen and A. Oganian and J. P. Reiter and
  A. P. Sanil},
title = {A Framework for Evaluating the Utility of
Data Altered to Protect Confidentiality},
year = 2006,
journal = {The American Statistician},
volume = 60,
number = 3,
pages = {224--232},
comment = {Proposes using some kind of utility to, you
guessed it, measure utility of a privacy-preserving algorithm. Privacy
preservation is measured in the informal sense of disclosure limitation
(i.e. likelihood of matching). Runs a few simulations.},
}

@article{KarwaSl16,
author = {Vishesh Karwa and Aleksandra Slavkovi\'{c}},
title = {Inference using noisy degrees: differentially
private $\beta$-model and synthetic graphs},
year = 2016,
journal = aos,
volume = 44,
number = 1,
pages = {87--112},
}

@article{KarzanovKh91,
author = {A. Karzanov and L. Khachiyan},
title = {On the conductance of order {M}arkov chains},
year = 1991,
journal = {Order},
volume = 8,
pages = {7--15},
}

@article{KatkovnikKu72,
author = {V. Katkovnik and Y. Kulchitsky},
title = {Convergence of a class of random search algorithms},
year = 1972,
journal = {Automation and Remote Control},
volume = 33,
number = 8,
pages = {1321--1326},
}

@article{Katz87,
	author = "S. Katz",
	title = "Estimation of probabilities from sparsedata for the
		language model component of a speech recognizer",
	journal = "IEEE Transactions on Acoustics, Speech and Signal
		Processing (ASSP)",
	volume = 35,
	number = 3,
	pages = "400--40",
	year = 1987
}

@article{KatzBaDiJuKo17a,
	author = {Katz, Guy and Barrett, Clark and Dill, David and
                  Julian, Kyle and Kochenderfer, Mykel},
	journal = {arXiv:1702.01135 [cs.AI]},
	title = {Reluplex: An efficient SMT solver for verifying deep
                  neural networks},
	year = 2017
	}

@article{KatzBaDiJuKo17b,
  title={Towards proving the adversarial robustness of deep neural networks},
  author={Katz, Guy and Barrett, Clark and Dill, David L and Julian, Kyle and Kochenderfer, Mykel J},
  journal={arXiv:1709.02802 [cs.LG]},
  year=2017
}


@article{Kaufman87
,author=	{Linda Kaufman}
,title=		{Implementing and accelerating the {EM} algorithm for
		positron emission tomography}
}

@article{Kaufman93
,author=	{Linda Kaufman}
,title=		{Maximum likelihood, least squares, and the penalized
		least squares for {PET}}
}

@misc{Kdd12,
title = {{KDD} Cup Track 2 \texttt{soso.com} ads prediction challenge},
year = 2012,
author = {Gordon Sun},
url = {http://www.kddcup2012.org/c/kddcup2012-track2},
note = {Accessed August 1, 2012},
}

@unpublished{Kearns88,
author=		{Michael Kearns},
title=		{Thoughts on Hypothesis Boosting},
year=		1988,
month=		Dec,
note=		{Unpublished manuscript}
}

@phdthesis{Kearns89,
author=   	{Michael Kearns},
title=    	{The Computational Complexity of Machine Learning},
school=   	{Harvard University},
year=     	1989,
month=    	may,
comment=     	{Technical Report TR-13-89,
		 Center for Research in Computing Technology}
}

@book{Kearns90,
author=   	{Michael Kearns},
title=    	{The Computational Complexity of Machine Learning},
year=     	1990,
publisher=	{MIT Press}
}

@inproceedings{Kearns93,
author=   	{Kearns, Michael},
title=    	{Efficient Noise-Tolerant Learning From Statistical
			Queries},
booktitle=	stoc93,
year=     	1993,
pages=    	{392--401}
}

@article{Kearns98,
author = {Michael Kearns},
title = {Efficient Noise-Tolerant Learning From Statistical Queries},
year = 1998,
journal = jacm,
volume = 45,
number = 6,
pages = {983--1006},
}

@inproceedings{KearnsLi88,
author=   	{Kearns, Michael and Ming Li},
title=    	{Learning in the Presence of Malicious Errors},
booktitle= 	stoc88,
pages=		{267--280},
year=     	1988,
month=    	May,
note=		{To appear, {\it SIAM Journal on Computing}},
comment=  	{Studies pac learning in the presence of worst sort of errors}
}

@article{KearnsLi93,
author=   	{Kearns, Michael and Ming Li},
title=    	{Learning in the Presence of Malicious Errors},
journal=	sicomp,
pages=		{807--837},
year=     	1993,
month=		aug,
volume=		22,
number=		4
}

@inproceedings{KearnsLiPiVa87,
author=   	{Kearns, Michael and Ming Li and Leonard Pitt and Leslie
		Valiant},
title=    	{On the Learnability of {B}oolean Formulae},
booktitle=	stoc87,
year=     	1987,
month=    	May,
pages=    	{285--295}
}

@inproceedings{KearnsLiPiVa87b,
author=   	{Kearns, Michael and Ming Li and Leonard Pitt and Leslie
		Valiant},
title=    	{Recent Results on Boolean Concept Learning},
booktitle=	{Proceedings of the Fourth International Workshop on
           	Machine Learning},
address=  	{University of California, Irvine},
year=     	1987,
month=    	Jun,
pages=    	{337--352}
}

@inproceedings{KearnsMa96
,author=	{Michael Kearns and Yishay Mansour}
,title=		{On the Boosting Ability of Top-Down Decision Tree
		 Learning Algorithms}
,booktitle=	stoc96
,year=		1996
}

@inproceedings{KearnsMa98
,author=	{Michael Kearns and Yishay Mansour}
,title=		{A Fast, Bottom-Up Decision Tree Pruning Algorithm with
Near-Optimal Generalization}
,booktitle=	icml97
,year=		1996
}

@inproceedings{KearnsMaNgRo95
,author=	{Michael Kearns and Yishay Mansour and Andrew Y. Ng
		 and Dana Ron}
,title=		{An experimental and theoretical comparison of model
		 selection methods}
,booktitle=	colt95
,year=		1995
}

@inproceedings{KearnsMaRoRuScSe94
,author=	{Michael Kearns and Yishay Mansour and Dana Ron and
		 Ronitt Rubinfeld and Robert E. Schapire and Linda
		 Sellie}
,title=		{On the learnability of discrete distributions}
,booktitle=	stoc94
,year=		1994
,pages=		{273--282}
}

@inproceedings{KearnsPi89,
author=   	{Kearns, Michael and Leonard Pitt},
title=    	{A Polynomial-time Algorithm for Learning $k$-variable
           	Pattern Languages from Examples},
booktitle= 	colt89,
year=      	1989,
month=     	Jul,
pages=     	{57--71}
}

@inproceedings{KearnsSc90,
author=		{Michael J. Kearns and Robert E. Schapire},
title=		{Efficient Distribution-free Learning of Probabilistic
		 Concepts},
booktitle=	focs90,
pages=		{382--391},
month=		oct,
year=		1990,
note=		{To appear, {\it Journal of Computer and System Sciences}}
}

@article{KearnsSc94
,author=	{Michael J. Kearns and Robert E. Schapire}
,title=		{Efficient Distribution-free Learning of Probabilistic
		 Concepts}
,journal=	jcss
,volume=	48
,number=	3
,year=		1994
,pages=		{464--497}
}

@inproceedings{KearnsScSe92,
author=		{Michael J. Kearns and Robert E. Schapire and Linda M.
		 Sellie},
title=		{Toward Efficient Agnostic Learning},
booktitle=	colt92,
year=		1992,
pages=		{341--352},
month=		jul,
note=		{To appear, {\it Machine Learning}}
}

@article{KearnsScSe94,
author=		{Michael J. Kearns and Robert E. Schapire and Linda M.
		 Sellie},
title=		{Toward Efficient Agnostic Learning},
journal=	ml,
volume=		17,
pages=		{115--141},
year=		1994
}

@techreport{KearnsVa88,
author = 	{Michael Kearns and Leslie G. Valiant},
title = 	{Learning {B}oolean Formulae or Finite Automata is as
		 Hard as Factoring},
institution = 	{Harvard University Aiken Computation Laboratory},
month=		Aug,
year = 		1988,
number = 	{TR-14-88}
}

@inproceedings{KearnsVa89,
author = 	{Michael Kearns and Leslie G. Valiant},
title = 	{Cryptographic Limitations on Learning {B}oolean
                 Formulae and Finite Automata},
booktitle=      stoc89,
month=          May,
year = 		1989,
pages = 	{433--444},
note=		{To appear, {\it Journal of the Association for Computing
		 Machinery}}
}

@article{KearnsVa94,
author = 	{Michael Kearns and Leslie G. Valiant},
title = 	{Cryptographic Limitations on Learning {B}oolean
                 Formulae and Finite Automata},
journal=	jacm,
month=          jan,
year = 		1994,
pages = 	{67--95},
volume=		41,
number=		1
}

@book{KearnsVa94b
,author=	{M.J. Kearns and U.V. Vazirani}
,title=		{An Introduction to Computational Learning Theory}
,year=		1994
,publisher=	{MIT Press}
}

@book{Keener10,
author = {Robert W. Keener},
title = {Theoretical Statistics: Topics for a Core Course},
year = 2010,
publisher = {Springer},
}

@techreport{KeerthiGi00,
author = 	{S.S. Keerthi and E.G. Gilbert},
title = 	{ Convergence of a Generalized SMO Algorithm for {SVM} Classifier Design},
institution = 	{Control Division Dept. of Mechanical and Production Engineering National University of Singapore},
year = 		2000,
number = 	{CD-00-01}
}

@techreport{KellyGl89,
author = 	{Kevin T. Kelly and Clark Glymour},
title = 	{Inductive Inference from Theory Laden Data},
institution = 	{CMU Laboratory for Computational Linguistics},
month = 	Oct,
year = 		1989,
number = 	{CMU-LCL-89-5}
}

@inproceedings{KelnerOrSiZh13,
author = {Jonathan Kelner and Lorenzo Orecchia and Aaron Sidford
  and Zeyuan Allen Zhu},
title = {A simple, combinatorial algorithm for solving SDD systems in
     nearly-linear time},
year = 2013,
booktitle = stoc13,
url = {http://arxiv.org/abs/1301.6628},
comment = {Shows how to solve symmetric diaogonally dominant systems with
  an iterative method in time that is, essentially, independent of condition
  number. Technique relies on treating them as a graph Laplacian problem,
  then using a clever well-behaved spanning tree that has a good
  condition number (of some sort). Solve the dual problem of minimizing
  $x^T L x$, where $L$ is a graph Laplacian, by (essentially) doing a
  Kacmarz method. Convergence analysis by duality gap arguments, gradient
  steps are done using specific flows on graph and using importance sampling.},
}

@book{KemenySn62,
author=   	{J.~G.~Kemeny and J.~L.~Snell},
title=    	{Mathematical Models in the Social Sciences},
year=     	1962,
publisher=	{MIT Press},
}

@article{KesavanKa89,
author = 	{H. K. Kesavan and J. N. Kapur},
title = 	{The Generalized Maximum Entropy Principle},
journal = 	{IEEE Transactions on Systems, Man, and Cybernetics},
volume = 	19,
number = 	5,
year = 		1989,
month = 	{September/October},
pages = 	{1042--1052},
comment = 	{Generalizes to include a prior distribution, using
		Kullback/Leibler Minimum Discrimination Information metric}
}

@article{KeshavanMoOh10a,
author = {Raghunandan H. Keshavan and Andrea Montanari and Sewoong Oh},
title = {Matrix Completion from Noisy Entries},
year = 2010,
journal = jmlr,
volume = 11,
pages = {2057--2078},
}

@article{KeshavanMoOh10,
author = {Raghunandan H. Keshavan and Andrea Montanari and Sewoong Oh},
title = {Matrix Completion from a Few Entries},
year = 2010,
journal = ieeeit,
volume = 56,
number = 6,
pages = {2980--2998},
}

@techreport{KeshavLuPhReSa94
,author=	{S. Keshav and Carsten Lund and Steven Phillips and
		Nick Reingold and Huzur Saran}
,title=		{An empirical evaluation of virtual circuit holding
		time policies in {IP}-over-{ATM} networks}
}

@inproceedings{KeshetChBo01,
author=		{J. Keshet and D. Chazan and B.-Z. Bobrovsky},
title=		{Plosive Spotting with Margin Classifiers},
booktitle=	{Proceedings of the Seventh European Conference on Speech Communication and Technology},
pages=		{1637-1640},
year=		2001,
}

@inproceedings{KeshetShBeSiCh06,
author=		{J. Keshet and S. Shalev-Shwartz and S. Bengio and Y. Singer and D. Chazan},
title=		{Discriminative Kernel-Based Phoneme Sequence Recognition},
booktitle=	{Interspeech},
year=		2006,
}


@inproceedings{KeshetShSiCh05,
author=		{J. Keshet and S. Shalev-Shwartz and Y. Singer and D. Chazan},
title=		{Phoneme Alignment Based on Discriminative Learning},
booktitle=	{Interspeech},
year=		2005,
}



@article{Khacian79,
title=    	{A Polynomial Algorithm for Linear Programming},
author=   	{Khacian, L. G.},
journal=  	{Soviet Math. Doklady},
volume=   	20,
pages=    	{191--194},
year=     	1979
}

@article{KhardonWa07,
title= {Noise Tolerant Variants of the Perceptron Algorithm},
author= {R. Khardon and G. Wachman},
journal= jmlr,
volume= 8,
pages= {227--248},
year = 2007}

@article{KieferWo52,
  title={Stochastic estimation of the maximum of a regression function},
  author={Kiefer, Jack and Wolfowitz, Jacob and others},
  journal={The Annals of Mathematical Statistics},
  volume=23,
  number=3,
  pages={462--466},
  year=1952,
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{KiferMa11,
author = {Daniel Kifer and Ashwin Machanavajjhala},
title = {No free lunch in data privacy},
booktitle = {Proceedings of the 2011 ACM International Conference on
Management of Data (SIGMOD)},
year = 2011,
url = {http://www.cse.psu.edu/~dkifer/papers/nflprivacy.pdf},
comment = {
Shows some interesting collapses of differential privacy in the face of
correlated data. Studies deciding whether someone belongs to a database
or not. If an algorithm has utility, shows that there is *some* set of
databases whose privacy can be compromised (the so-called "No Free Lunch"
part), though this compromise is a little silly (relies on databases
being completely arbitrary and being able to output queries in hugely
separate spaces). Shows how a few privacy ideas are broken (social networks
can evolve and show that someone important was in or not; contingency
tables with some pre-released data).
},
}

@inproceedings{KiferMa12,
author = {Daniel Kifer and Ashwin Machanavajjhala},
title = {A Rigorous and Customizable Framework for Privacy},
year = 2012,
booktitle = {Principles of Database Systems},
}

@phdthesis{Kim83,
author=   	{Kim, Jin Hyung},
title=    	{CONVINCE: A Conversational Inference Consolidation Engine},
school=   	{University of California, Los Angeles},
year=     	1983,
comment=  	{Interactive decision support system using Pearl's Bayesian
	   	networks}
}

@article{KimKiFa14,
  title={Recent developments in robust portfolios with a worst-case approach},
  author={Kim, Jang Ho and Kim, Woo Chang and Fabozzi, Frank J},
  journal={Journal of Optimization Theory and Applications},
  volume=161,
  number=1,
  pages={103--121},
  year=2014,
  publisher={Springer}
}

@article{KimKoLuBoGo07,
author=         {Seung-Jean Kim and Kwangmoo Koh and Michael Lustig
                 and Stephen Boyd and Dimitry Gorinevsky},
title=          {An Interior-Point Method for Large-Scale $\ell_1$-Regularized
                 Least Squares},
journal=        {IEEE Journal on Selected Topics in Signal Processing},
year=           2007,
volume=         4,
number=         1,
pages=          {606--617}
}

@incollection{KimPaHe15,
  title={A guide to sample average approximation},
  author={Kim, Sujin and Pasupathy, Raghu and Henderson, Shane G},
  booktitle={Handbook of Simulation Optimization},
  pages={207--243},
  year=2015,
  publisher={Springer}
}

@Article{KimeldorfWa71,
  author = 	 {G. Kimeldorf and G. Wahba},
  title = 	 {Some results on tchebycheffian spline functions},
  journal = 	 {J. Math. Anal. Applic.},
  year = 	 {1971},
  volume = 	 {33},
  pages = 	 {82--95}
}

@article{King89,
  title={Generalized delta theorems for multivalued mappings and measurable selections},
  author={King, Alan J},
  journal={Mathematics of Operations Research},
  volume=14,
  number=4,
  pages={720--736},
  year=1989,
  publisher={INFORMS}
}

@article{KingPaRo13,
author = {Gary King and Jennifer Pan and Margaret Roberts},
title = {How Censorship in {C}hina Allows Government Criticism but Silences
Collective Expression},
year = 2013,
journal = {American Political Science Review},
pages = {1--18},
volume = 107,
number = 2,
}

@article{KingPaRo14,
author = {Gary King and Jennifer Pan and Margaret Roberts},
title = {Reverse-engineering censorship in
  {C}hina: Randomized experimentation and participant observation},
year = 2014,
journal = {Science},
volume = 345,
number = 6199,
doi = {10.1126/science.1251722},
}

@article{KingRo93,
  title={Asymptotic theory for solutions in statistical estimation and stochastic programming},
  author={King, Alan J and Rockafellar, R Tyrrell},
  journal={Mathematics of Operations Research},
  volume=18,
  number=1,
  pages={148--162},
  year=1993,
  publisher={INFORMS},
  comment={Statistical estimation of generalized equations using implicit function theorems of Robinson is studied. Requires smoothness as a natural limitation of the approach.}
}

@article{KingWe91,
  title={Epi-consistency of convex stochastic programs},
  author={King, Alan J and Wets, Roger JB},
  journal={Stochastics and Stochastic Reports},
  volume=34,
  number={1-2},
  pages={83--92},
  year=1991,
  publisher={Taylor \& Francis}
}

@inproceedings{KipnisDu17_allerton,
author = {Alon Kipnis and John C. Duchi},
title = {Mean Estimation from Adaptive One-bit Measurements},
year = 2017,
booktitle = allerton17,
}

@article{Kitamura97,
  title={Empirical likelihood methods with weakly dependent processes},
  author={Kitamura, Yuichi and others},
  journal={The Annals of Statistics},
  volume=25,
  number=5,
  pages={2084--2102},
  year=1997,
  publisher={Institute of Mathematical Statistics}
}

@InProceedings{KivinenSmWi02,
  author    = "J. Kivinen and A. J. Smola and R. C. Williamson",
  title     = "Online Learning with Kernels",
  booktitle = nips14,
  publisher = "MIT Press",
  year      = "2002"
}

@incollection{Kivinen03,
	author = {J. Kivinen},
	title = {Online Learning of Linear Classifiers},
	booktitle = {Advanced Lectures on Machine Learning},
	publisher = {Springer LNCS 2600},
	editor = {S.~Mendelson and A.~J.~Smola},
	year = 2003,
}


@article{KivinenSmWi04,
   author    = "J. Kivinen and A. J. Smola and R. C. Williamson",
   title     = "Online Learning with Kernels",
   journal   = "{IEEE} {T}ransactions on {S}ignal {P}rocessing",
   volume    = "52",
   number    = "8",
   pages     = "2165--2176",
   publisher = "MIT Press",
   year      = "2002"
}




@techreport{KivinenWa94
,author=	{J.~Kivinen and M. Warmuth}
,title=		{Additive Versus Exponentiated Gradient Updates
                 For Learning Linear Functions}
,institution=	ucsccrl
,year=		1994
,number=	{UCSC-CRL-94-16}
}

@inproceedings{KivinenWa94b
,author=	{Jyrki Kivinen and Manfred K. Warmuth}
,title=		{Using experts for predicting continuous outcomes}
,booktitle=	eurocolt93
,year=		1994
,pages=		{109--120}
,publisher=	{Springer-Verlag}
}

@InProceedings{KivinenWa95,
  author = 	 {J.~Kivinen and M.K.~Warmuth},
  title = 	 {Additive Versus Exponentiated Gradient Updates
                 for Linear Prediction},
  booktitle = 	 stoc95,
  year =	 1995,
  pages =	 {209-218},
  note =	 {See also technical report UCSC-CRL-94-16, University
		  of California, Santa Cruz, Computer Research Laboratory}
}

@Article{KivinenWa97,
  author = 	 {J.~Kivinen and M. Warmuth},
  title = 	 {Exponentiated Gradient Versus Gradient Descent for Linear
  Predictors},
  journal = 	 {Information and Computation},
  year = 	 1997,
  volume =	 132,
  number =	 1,
  month =	 jan,
  pages =	 {1-64}
}


@Article{KivinenWa01,
  author = 	 {J.~Kivinen and M. Warmuth},
  title = 	 {Relative Loss Bounds for Multidimensional Regression Problems},
  journal = 	 ml,
  year = 	 2001,
  volume =	 45,
  number =	 3,
  month =	 jul,
  pages =	 {301-329}
}

@article{KivinenWaAu??
,author=	{J. Kivinen and M. K. Warmuth and P. Auer}
,title=		{The {Perceptron} algorithm vs. {Winnow}: linear
		 vs. logarithmic mistake bounds when few input
		 variables are relevant}
}

@article{Kiwiel97,
    author = "K. Kiwiel",
    title = "Free--steering relaxation methods for problems with strictly
        convex costs and linear constraints",
    journal = "Mathematics of Operations Research",
    volume = "22",
    pages = "326--349",
    year = 1997
}

@article{Kiwiel98,
    author = "K. Kiwiel",
    title = "Generalized Bregman projections in convex feasibility problems",
    journal = "Journal of Optimization Theory and Applications",
    volume = "96",
    pages = " 139--157",
    year = 1998
}



@InProceedings{KlapuriViErSe01,
  author = 	 {A. Klapuri and T. Virtanen and A. Eronen and J. Seppanen},
  title = 	 {Automatic transcription of musical recordings},
  booktitle = {Consistent \& Reliable Acoustic Cues Workshop, CRAC-01},
  year = 	 {2001}
}

@InProceedings{KlasnerSi95,
  author = 	 {N.~Klasner and H.U.~Simon},
  title = 	 {From Noise-Free to Noise-Tolerant and from On-line
                  to Batch Learning},
  booktitle = 	 colt95,
  pages =	 {250-264},
  year =	 1995
}

@article{KlautauJeOr03,
author = {Aldebaro Klautau and Nikola Jevti\'c and Alon Orlitsky},
title = {On nearest-neighbor error-correcting output codes with
         application to all-pairs multiclass support vector machines},
journal = jmlr,
volume = {4},
year = {2003},
pages = {1--15},
publisher = {MIT Press},
}

@article{Kleinberg90
,author=	{E. M. Kleinberg}
,title=		{Stochastic discrimination}
}

@article{Kleinberg96
,author=	{E. M. Kleinberg}
,title=         {An overtraining-resistant stochastic modeling method
                  for pattern recognition}
}

unpublished{Kleinberg9?
,author=	{E. M. Kleinberg}
,title=		{An overtraining-resistant stochastic modeling method
		 for pattern recognition}
}

@inproceedings{KleinbergSlUp08,
author = {Robert Kleinberg and Aleksandrs Slivkins and Eli Upfal},
title = {Multi-Armed Bandits in Metric Spaces},
booktitle = stoc08,
year = 2008,
}

@incollection{KleinMa02,
author = {D.\ Klein and C.\ Manning},
title = {Parsing and Hypergraphs},
booktitle = {New Developments in Parsing Technology},
year = 2002,
publisher = {Kluwer Academic},
}

@InProceedings{KleinYo99,
  author = 	 {Philip Klein and Neal Young},
  title = 	 {On the Number of Iterations for {Dantzig-Wolfe}
                  Optimization and Packing-Covering Approximation
                  Algorithms},
  booktitle = 	 {Proceedings of the Seventh Conference on Integer
                  Programming and Combinatorial Optimization},
  year =	 1999
}

@inproceedings{KleinerTaSaJo12,
author = {Ariel Kleiner and Ameet Talwalkar and Purnamrita Sarkar
and Michael Jordan},
year = 2012,
title = {Bootstrapping Big Data},
booktitle = icml12,
}

@book{Knuth68,
author=   	{Knuth, Donald E.},
title=    	{The Art of Computer Programming: Fundamental Algorithms},
publisher=	{Addison-Wesley},
year=     	1968,
volume=   	1
}

@techreport{KnuthLaRo88,
author = 	{Donald E. Knuth and Tracy Larrabee and Paul M. Roberts},
title = 	{Mathematical Writing},
institution = 	{Stanford University Computer Science Department},
month = 	Jan,
year = 		1988,
number = 	{STAN-CS-88-1193}
}

@article{KoHu87,
author=   	{Ko, K. and Hua, C.},
title=    	{A note on the two-variable pattern-finding problem},
journal=  	jcss,
year=     	1987,
volume=   	34,
pages=    	{75--86}
}

@article{KohKiBo07,
author =        {K. Koh and S.J. Kim and S. Boyd},
title =         {An Interior-Point Method for Large-Scale
                 $\ell_1$-Regularized Logistic Regression},
journal =       {Journal of Machine Learning Research},
year =          2007,
volume =        8,
pages =         {1519-1555},
comment =       {Efficiently does both sparse and non-sparse logistic
                 regression using 2nd order method and PCG}
}

@inproceedings{KoMaTz90,
author=		{Ko, Ker-I and Assaf Marron and Wen-Guey Tzeng},
title=		{Learning String Patterns and Tree Patterns from Examples},
booktitle=	{Proceedings of the Seventh International Conference on
		 Machine Learning},
year=		1990,
month=		Jun,
}

@unpublished{KoTz90,
author=		{Ko, Ker-I and Wen-Guey Tzeng},
title=		{Finding Common Patterns is Complete for the Second Level
		 of the Polynomial Time Hierarchy},
year=		1990,
note=		{Unpublished}
}


@article{KotzerCoSh97,
    author = "T. Kotzer, N. Cohen and J. Shamir",
    title = "A projection-based algorithm for consistent and inconsistent
        constraints",
    journal = "SIAM Journal on Optimization ",
    volume = "7",
    pages = "527--546",
    year = 1997
}

@book{KodratoffMi90,
title=		{Machine Learning: An Artificial Intelligence Approach},
editor=   	{Yves Kodratoff and Ryszard Michalski},
volume=		{III},
publisher=	{Morgan Kaufmann},
year=     	{1990}
}


@book{Kohavi78,
author=   	{Kohavi, Zvi},
title=    	{Switching and Finite Automata Theory},
publisher=	{McGraw-Hill},
year=     	{1978},
edition=  	{second},
comment=  	{Chapter on State-Identification and Fault-Detection
		Experiments}
}

@inproceedings{KohaviKu97
,author=	{Ron Kohavi and Clayton Kunz}
,title=		{Option Decision Trees with Majority Votes}
,booktitle=     ml97
,year=          1997
,pages=         {161--169}
}

@inproceedings{KohaviWo96
,author=	{Ron Kohavi and David H. Wolpert}
,title=		{Bias plus variance decomposition for zero-one loss
		 functions}
,booktitle=     ml96
,year=          1996
,pages=         {275--283}
}

@Article{Kolaczyk96,
  author = 	 {Eric D. Kolaczyk},
  title = 	 {A Wavelet Shrinkage Approach to Tomographic Image
		  Reconstruction},
}

@inproceedings{KollerSa97,
	author = "D. Koller and M. Sahami",
	title = "Hierarchically classifying docuemnts using very few words",
	booktitle = ml97,
	pages = "171--178",
	year = 1997
}

@article{KolmogorovTi59,
author = {Andrey Kolmogorov and Vladimir Tikhomirov},
title = {$\varepsilon$-entropy and $\varepsilon$-capacity of sets
  in functional spaces},
year = 1959,
journal = {Uspekhi Matematischeskikh Nauk},
volume = 14,
number = 2,
pages = {3--86},
}

@article{Kolmogorov68,
author=   	{Kolmogorov, Andrei N.},
title=    	{Logical Basis for Information Theory and Probability Theory},
journal=  	{IEEE Transactions on Information Theory},
volume=   	{IT-14},
number=   	5,
year=     	1968,
month=    	Sep,
pages=    	{662--664},
comment=  	{Definition of `Kolmogorov' complexity; analogy to information-
	   	theoretic entropy; notion of random sequences}
}

@article{Koltchinskii06a,
author = {Vladimir Koltchinskii},
title = {Local {R}ademacher complexities and oracle
inequalities in risk minimization},
year = 2006,
journal = aos,
volume = 34,
number = 6,
pages = {2593--2656},
}

@article{Koltchinskii06,
author = {Vladimir Koltchinskii},
title = {Rejoinder: Local {R}ademacher complexities and oracle
inequalities in risk minimization},
year = 2006,
journal = aos,
volume = 34,
number = 6,
pages = {2697--2706},
}

@article{KoltchinskiiMe13,
author = {Vladimir Koltchinskii Shahar Mendelson},
year = 2013,
title = {Bounding the smallest singular value of a
  random matrix without concentration},
journal = {arXiv:1312.3580 [math.PR]},
}

@inproceedings{KoltchinskiiPaLo01,
  author = 	 {V. Koltchinskii and D. Panchenko and F. Lozano},
  title = 	 {Some new bounds on the generalization error of combined classifiers},
  booktitle = 	 nips14,
  year = 	 {2001}
}

@inproceedings{KongDi95
,author=	{Eun Bae Kong and Thomas G. Dietterich}
,title=		{Error-Correcting Output Coding Corrects Bias and
		 Variance}
,booktitle=	ml95
,pages=		{313--321}
,year=		1995
}

@incollection{Kononenko92
,author=	{Igor Kononenko}
,title=		{Combining decisions of multiple rules}
}

@article{KorenBeVo09,
Author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
Journal = {Computer},
Publisher = {IEEE Computer Society},
Title = {Matrix factorization techniques for recommender systems},
volume = 42,
number = 8,
pages = {30--37},
Year = {2009}
}

@article{Kosorok08,
  title={Introduction to Empirical Processes},
  author={Kosorok, Michael R},
  journal={Introduction to Empirical Processes and Semiparametric Inference},
  pages={77--79},
  year=2008,
  publisher={Springer}
}

@unpublished{Koza95
,author=	{John R. Koza}
,title=		{A response to the {ML-95} paper entitled ``Hill
		 climbing beats genetic search on a {B}oolean circuit
		 synthesis problem of {K}oza's''}
}


@inproceedings{KraskaTaDuGrFrJo13,
author = {Tim Kraska and Ameet Talwalkar and John C. Duchi and
  Rean Griffith and Michael Franklin and Michael I. Jordan},
title = {{ML}base: A Distributed Machine-learning System},
year = 2013,
booktitle = {Sixth Biennial Conference on Innovative Data Systems
                  Research (CIDR)},
}

@article{KrauseSaHoZhToDuPhLi16,
  title={The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition},
  author={Krause, Jonathan and Sapp, Benjamin and Howard, Andrew and Zhou, Howard and Toshev, Alexander and Duerig, Tom and Philbin, James and Fei-Fei, Li},
  journal={arXiv:1511.06789 [cs.CV]},
  year=2015
}
@article{KrauthMe87,
author=   	{W. Krauth and M. M\'ezard},
title=    	{Learning algorithms with optimal stability in neural networks.},
journal=  	{Journal of Physics A.},
volume=   	20,
year=     	1987,
pages=    	{745}
}

@Article{KrichevsyTr81,
  author = 	 {R.E. Krichevsky and V.K. Trofimov},
  title = 	 {The performance of universal encoding},
  journal = 	 {ieeeit},
  year = 	 1981,
  volume =	 {IT-27},
  pages =	 {199--207},
  month =	 {March},
  note =	 {The paper where the add 1/2 rule is first shown to be optimal}
}

@article{KrizhevskyHi09,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year=2009,
  publisher={Citeseer},
  journal={Technical Report, University of Toronto}
}
@inproceedings{KrizhevskySuHi12,
author = {Alex Krizhevsky and Ilya Sutskever and Geoffrey Hinton},
title = {ImageNet Classification with Deep Convolutional Neural Networks},
year = 2012,
booktitle = nips25,
}

@article{KroeseRuGl13,
  title={The cross-entropy method for estimation},
  author={Kroese, Dirk P and Rubinstein, Reuven Y and Glynn, Peter W},
  journal={Handbook of Statistics: Machine Learning: Theory and Applications},
  volume=31,
  pages={19--34},
  year=2013,
  publisher={Newnes}
}

@article{Krokhmal07,
  title = {Higher moment coherent risk measures},
  author = {Krokhmal, Pavlo A}, 
  journal = {Quantitative Finance},
  volume = 7,
  number = 4,
  pages = {373--387},
  year = 2007,
  publisher = {Taylor \& Francis}
}

@article{KrokhmalPaUr02,
  title={Portfolio optimization with conditional value-at-risk objective and constraints},
  author={Krokhmal, Pavlo and Palmquist, Jonas and Uryasev, Stanislav},
  journal={Journal of Risk},
  volume=4,
  pages={43--68},
  year=2002
}

@article{KuczynskiWo92,
	Author = {Kuczynski, Jacek and Wozniakowski, Henryk},
	Title = {Estimating the largest eigenvalue by the power and {L}anczos
	algorithms with a random start},
	Journal = simat,
	Number = {4},
	Pages = {1094--1122},
	Publisher = {SIAM},
	Volume = {13},
	Year = {1992}}

@article{Kugel77,
author=   	{Kugel, Peter},
title=    	{Induction, Pure and Simple},
journal=  	infctrl,
volume=   	35,
year=     	1977,
pages=    	{276--336}
}

@inproceedings{Kuhl??
,author=	{Patricia K. Kuhl}
,title=		{Infants' perception and representation of speech:
		 development of a new theory}
,comment=	{from pereira}
}

@article{Kuhn01,
author = {Thomas K\"uhn},
title = {A lower estimate for entropy numbers},
year = 2001,
journal = {Journal of Approximation Theory},
volume = 110,
pages = {120--124},
comment = {Develops techniques for packing the L1-ball with different Lp balls.
   Uses nice combinatorial arguments based on packing a hypercube-type set
   of the form {-1, 0, 1}^n with vectors whose (\ell_0) norms are all
   2m, then bounding the size of their neighborhoods.},
}

@article{Kuhn11,
  title={Covering numbers of {G}aussian reproducing kernel {H}ilbert spaces},
  author={K{\"u}hn, Thomas},
  journal={Journal of Complexity},
  volume=27,
  number=5,
  pages={489--499},
  year=2011,
  publisher={Elsevier},
  comment={Provides asymptotically exact rates (as epsilon goes to
                  zero) for the supremum-norm covering number of a
                  unit ball in the RKHS generated by the Gaussian
                  (RBF) kernel. We embed the ball in RKHS in C(X), the
                  space of continuous functions equipped with the
                  supremum norm. The log metric entropy depends
                  exponentially in the dimension and the usual upper
                  bound given in previous literature [Zhou02] is off
                  by a log log 1/epsilon factor.}
}
 

@inproceedings{KuipersBy88,
author=		{Benjamin J. Kuipers and Yung-Tai Byun},
title=		{A Robust, Qualitative Approach to a Spatial Learning
		 Mobile Robot},
booktitle=	{SPIE Advances in Intelligent Robotics Systems},
month=		nov,
year=		1988
}

@article{Kullback68,
author=   	{Kullback, S.},
title=    	{Probability Densities with Given Marginals},
journal=  	{Annals of Mathematical Statistics},
year=     	1968,
volume=   	39,
number=   	4,
pages=    	{1236--1243},
comment=  	{Extension of Ireland/Kullback results to continuous
		densities.}
}

@article{Kullback71,
author=   	{Kullback, S.},
title=    	{Marginal Homogeneity of Multidimensional Contingency Tables},
journal=  	{Annals of Mathematical Statistics},
year=     	1971,
volume=   	42,
number=   	2,
pages=    	{594--606},
comment=  	{Uses maximum entropy solution to derive minimum discrimination
	   	information statistic.}
}

@article{Kumagai80,
  title={An implicit function theorem: Comment},
  author={Kumagai, Sadatoshi},
  journal={Journal of Optimization Theory and Applications},
  volume=31,
  number=2,
  pages={285--288},
  year=1980,
  publisher={Springer}
}

@inproceedings{KunduRo11,
author = {Gourab Kundu and Dan Roth},
title = {Adapting Text instead of the Model: An Open Domain Approach},
year = 2011,
booktitle = {The SIGNLL Conference on Computational Natural Language Learning
(CoNLL)},
}

@book{Kunze00,
author = {Markus Kunze},
title = {Non-Smooth Dynamical Systems},
year = 2000,
publisher = {Springer},
series = {Lecture Notes in Mathematics},
}

@inproceedings{KushilevitzMa91,
author=		{Eyal Kushilevitz and Yishay Mansour},
title=		{Learning Decision Trees using the {F}ourier Spectrum},
booktitle=	stoc91,
month=		may,
year=		1991,
pages=		{455--464}
}

@article{KushilevitzMa93
,author=	{Eyal Kushilevitz and Yishay Mansour}
,title=		{Learning Decision Trees using the {Fourier} Spectrum}
,journal=	sicomp
,volume=	22
,number=	6
,pages=		{1331--1348}
,year=		1993
}

@book{KushilevitzNi97,
author = {Eyal Kushilevitz and Noam Nisan},
year = 1997,
title = {Communication Complexity},
publisher = {Cambridge University Press},
}


@book{KushnerYi03,
author = {H. J. Kushner and G. Yin},
title = {Stochastic Approximation and Recursive Algorithms and Applications},
year = 2003,
edition = {Second},
publisher = {Springer},
comment = {Book on classical theory of stochastic approximation. Reasonably
  good elucidation of the ODE method to get asymptotic convergence rates
  for optimization problems. Several applications, and results can be
  specialized to convergence of smooth (enough) non-convex problems as
  well as convex problems},
}

@techreport{Kutin02,
	author = {S. Kutin},
	title = {Extensions to McDiarmid's inequality when differences are bounded with high probability},
	institution = {University of Chicago TR-2002-04},
	year = {2002}
}

@incollection{Kusuoka01,
  title={On law invariant coherent risk measures},
  author={Kusuoka, Shigeo},
  booktitle={Advances in mathematical economics},
  pages={83--95},
  year=2001,
  publisher={Springer}
}

@incollection{KwokCa90
,author=	{Suk Wah Kwok and Chris Carter}
,title=		{Multiple decision trees}
,booktitle=	{Uncertainty in Artificial Intelligence 4}
,editor=	{Ross D. Shachter and Tod S. Levitt and Laveen N.
		 Kanal and John F. Lemmer}
,year=		1990
,publisher=	{North-Holland}
,pages=		{327--335}
}

@article{Kyparisis85,
  title={On uniqueness of Kuhn-Tucker multipliers in nonlinear programming},
  author={Kyparisis, Jerzy},
  journal={Mathematical Programming},
  volume=32,
  number=2,
  pages={242--246},
  year=1985,
  publisher={Springer}
}

@inproceedings{Lafferty99,
	author = "John D. Lafferty",
	title = "Additive Models, Boosting and Inference for
		Generalized Divergences",
	booktitle = colt99,
	year = 1999
}

@inproceedings{LaffertyPiPi??
,author=        {John D. Lafferty and Stephen Della Pietra and Vincent
                  Della Pietra}
,title=         {Statistical learning algorithms based on {Bregman}
                  distances}
}

@inproceedings{LaffertyMcPer01,
	author = "J. Lafferty and A. McCallum and F. Pereira",
	title = "Conditional random fields: Probabilistic models for
		segmenting and labeling sequence data",
	booktitle = icml01,
	pages = "282--289",
	year = 2001
}

@article{LaiRo85
,author=   	{T. L. Lai and Herbert Robbins}
,title=		{Asymptotically Efficient Adaptive Allocation Rules}
,journal=       {Advances in Applied Mathematics}
,volume=        {6}
,pages=         {4--22}
,year=          {1985}
}

@article{LaiYa95
,author=   	{Tze-Leung Lai and Sidney Yakowitz}
,title=		{Machine Learning and Nonparametric Bandit Theory}
,journal=       ieeetac
,volume=        {40}
,pages=         {1199--1209}
,number=	7
,month=		jul
,year=          {1995}
}

@book{Laird88,
author = 	{Philip D. Laird},
title = 	{Learning from Good and Bad Data},
publisher = 	{Kluwer Academic Publishers},
year = 		{1988},
series = 	{Kluwer international series in engineering and computer
		science},
address = 	{Boston},
comment = 	{His PhD thesis in book form}
}

@techreport{LairdGa88,
author=  	{Laird, Philip and Evan Gamble},
title=   	{Learning a Probability Distribution Efficiently and Reliably},
institution= 	{NASA Ames Research Center},
month=  	oct,
year=		1988
}

@article{LairdNeRo87,
author = 	{Laird, J.E. and A. Newell and P.S. Rosenbloom},
title = 	{SOAR: An architecture for General Intelligence},
journal = 	{Artificial Intelligence},
year = 		1987,
month = 	Sep,
volume = 	33,
number = 	1,
pages = 	{1--64}
}

@inproceedings{LairdRoNe84,
author=		{Laird, John and Paul Rosenbloom and Allen Newell},
title=		{Towards Chunking as a General Learning Mechanism},
booktitle=	{Proceedings  AAAI-84},
orgainzation=	{American Association for Artificial Intelligence},
year=		1984,
month=		aug,
pages=		{188--192}
}

@article{LairdRoNe86,
author=		{Laird, John and Paul Rosenbloom and Allen Newell},
title=		{Chunking in {S}oar: the anatomy of a general learning
		mechanism},
journal=	ml,
volume=		1,
number=		1,
pages=		{11--46},
year=		1986
}

@book{Lakoff90,
	title = "{W}omen, {F}ire, and {D}angerous {T}hings:
		What Categories Reveal About the Mind",
	author = "George Lakoff",
	publisher = "University of Chicago Press",
	year =  "1990 (reprint eddition)"
}

@article{LakshmananFa08,
title = {Decentralized resource allocation in dynamic networks of agents},
author = {H. Lakshmanan and D. Pucci de Farias},
year = 2008,
journal = siopt,
volume = 19,
number = 2,
pages = {911--940},
}

@article{Lam16,
  title={Robust sensitivity analysis for stochastic systems},
  author={Lam, Henry},
  journal={Mathematics of Operations Research},
  volume={41},
  number={4},
  pages={1248--1275},
  year={2016},
  publisher={INFORMS},
    comment={Shows for the KL divergence that the robust problem is
                  equal to the variance expansion asymptotically as
                  the radius goes to 0. He shows this in a
                  non-statistical setting but for random horizons as
                  well.}
}

@article{Lam16b,
  title={Recovering Best Statistical Guarantees via the Empirical Divergence-based Distributionally Robust Optimization},
  author={Lam, Henry},
  journal={arXiv:1605.09349 [math.OC]},
  year=2016,
  comments={Shows Chi-squared process result for empirical likelihood
                  profile processes and uses this to get two-sided
                  confidence bands on the objective function
                  itself. This (more or less) relaxes the
                  identifiability condition required in DuchiGlNa16.}
}

@inproceedings{LamZh15,
  title={Quantifying Input Uncertainty in Stochastic Optimization},
  author={Lam, Henry and Zhou, Enlu},
  booktitle={Proceedings of the 2015 Winter Simulation Conference},
  year=2015,
  organization={IEEE},
  comments={Studies the empirical likelihood robust formulation and
                  shows chi-squared calibration by using the KKT
                  conditions as estimating equations. This results in
                  a much less general theory compared to DuchiGlNa16
                  and their proof is a straightforward plug-in from
                  standard empirical likelihood theory with estimating
                  equations. In particular, requires differentiability
                  and cov(grad of obj(opt), obj(opt)) to be positive
                  definite. Only applies to effectively unconstrained
                  problems grad obj(opt) = 0.}
}

@article{LamZh17,
  title={The empirical likelihood approach to quantifying uncertainty in sample average approximation},
  author={Lam, Henry and Zhou, Enlu},
  journal={Operations Research Letters},
  volume=45,
  number=4,
  pages={301--307},
  year=2017,
  publisher={Elsevier},
 comments={Studies the empirical likelihood robust formulation and
                  shows chi-squared calibration by using the KKT
                  conditions as estimating equations. This results in
                  a much less general theory compared to DuchiGlNa16
                  and their proof is a straightforward plug-in from
                  standard empirical likelihood theory with estimating
                  equations. In particular, requires differentiability
                  and cov(grad of obj(opt), obj(opt)) to be positive
                  definite. Only applies to effectively unconstrained
                  problems grad obj(opt) = 0.}
}

@article{Lan10,
author = {G. Lan},
title = {An optimal method for stochastic composite optimization},
year = 2010,
journal = {Mathematical Programming},
note = {Online first. URL \url{http://www.ise.ufl.edu/glan/papers/OPT_SA4.pdf}},
}

@phdthesis{Lan09thesis,
author = {G. Lan},
title = {Convex Optimization under Inexact First-order Information},
school = {Georgia Institute of Technology},
year = 2009,
comment = {First appearance of methods that achieve order-optimal
variance-based rates for smooth convex optimization},
}

@article{LanNeSh12,
author = {G. Lan and A. Nemirovski and A. Shapiro},
title = {Validation analysis of robust stochastic approximation method},
year = 2012,
journal = mathproga,
volume = 134,
number = 2,
pages = {425--458},
}

@inproceedings{LanckrietCrBaElJo02,
  author = "G. Lanckriet and N. Cristianini and P. L. Bartlett and L. El Ghaoui
  	and M. Jordan",
  title = "Learning the Kernel Matrix with Semi-Definite Programming",
  booktitle = icml02,
  year = "2002"
}

@article{LanckrietCrBaElJo04,
author = {G. Lanckriet and N. Cristianini and P. L. Bartlett and L. El Ghaoui
  	and M. Jordan},
title = {Learning the kernel matrix with semidefinite programming},
journal = jmlr,
year = 2004,
volume = 5,
pages = {27--72},
}

@inproceedings{Lang92,
author=		{Kevin J. Lang},
title=		{Random {DFA}'s can be approximately learned from
		 sparse uniform examples},
booktitle=	colt92,
year=		1992,
month=		jul,
pages=		{45--52}
}


@inproceedings{Lang95
,author = "K. Lang"
,title = "Newsweeder: Learning to Filter Netnews"
,booktitle = ml95
,year = 1995
,pages = "331--339"
}

@inproceedings{LangfordLiZh08,
author = {J. Langford and L. Li and T. Zhang},
title = {Sparse Online Learning via Truncated Gradient},
year = {2008},
booktitle = nips21,
comment = {Gives regret bounds for L1-type online algorithm; true sparsity
           from a purely subgradient method},
}

@article{LanMo16,
author = {Guanghui Lan and Renato D. C. Monteiro},
title = {Iteration-complexity of first-order augmented {L}agrangian
   methods for convex programming},
journal = mathproga,
volume = 155,
pages = {511--547},
year = 2016,
}


@article{LatteuxRo84,
author = 	{M. Latteux and G. Rozenberg},
title = 	{Commutative One-Counter Languages Are Regular},
journal = 	jcss,
year = 		{1984},
volume = 	{29},
number = 	{1},
pages = 	{54--57},
month = 	aug,
comment = 	{Gives a nice characteriztion of commutative regular languages}
}


@inproceedings{LebanonLa01,
	author = "G. Lebanon and J. Lafferty",
	title = "Boosting and Maximum Likelihood for Exponential Models",
	booktitle = nips14,
	year = 2001
}

@InProceedings{LebrunChCa04,
  author = 	 {G. Lebrun and C. Charrier and H. Cardot},
  title = 	 {{SVM} training time reduction using vector quantization},
  booktitle = 	 {Proceedings of the 17th International Conference on Pattern Recognition},
  year = 2004,
}

@inproceedings{LebanonLa02,
	author = "G. Lebanon and J. Lafferty",
	title = "Conditional Models on the Ranking Poset",
	booktitle = nips15,
	year = 2002
}

@article{LeCam56,
author = {Lucien {Le Cam}},
title = {On the asymptotic theory of estimation and hypothesis testing},
year = 1956,
journal = {Proceedings of the Third Berkeley Symposium on Mathematical
  Statistics and Probability},
pages = {129--156},
comment = { Shows essentially that the gradient of the loss is asymptotically
sufficient. Need to write more here. },
}

@article{LeCam73,
author = {Lucien {Le Cam}},
title = {Convergence of estimates under dimensionality restrictions},
year = 1973,
journal = aos,
volume = 1,
number = 1,
pages = {38--53},
}

@book{LeCam86,
author = {Lucien {Le Cam}},
title = {Asymptotic Methods in Statistical Decision Theory},
year = 1986,
publisher = {Springer-Verlag},
}

@book{LeCamYa00,
author = {Lucien {Le Cam} and Grace Lo Yang},
title = {Asymptotics in Statistics: Some Basic Concepts},
year = 2000,
publisher = {Springer},
}

@article{LeCunBeHi15,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{LeCunBoBeHa98
,author=         {Yann LeCun and L\'eon Bottou and Yoshua Bengio and
                  Patrick Haffner}
,title=          {Gradient-Based Learning Applied to Document
                  Recognition}
,year=           1998
}

@InProceedings{LeCunEtAl95,
  author = 	 {LeCun, Y. and Jackel, L. D. and Bottou, L. and
		  Brunot, A. and Cortes, C. and Denker, J. S. and
		  Drucker, H. and Guyon, I. and Muller, U. A. and
		  Sackinger, E. and Simard, P. and Vapnik, V},
  title = 	 {Comparison of learning algorithms for handwritten
		  digit recognition},
  booktitle = 	 {International Conference on Artificial Neural Networks},
  year =	 1995,
  pages =	 {53-60}
}

@article{LEcuyerBlTuGl10,
author = {Pierre L'ecuyer and Jose Blanchet and Bruno Tuffin and Peter W. Glynn},
title = {Asymptotic robustness of estimators in rare-event simulation},
journal = {ACM Transactions on Modeling and Computer Simulation},
volume = 20,
number = 1,
note = {Article 6},
year = 2010,
}

@book{Ledoux01,
author = {M. Ledoux},
title = {The Concentration of Measure Phenomenon},
year = 2001,
publisher = {American Mathematical Society},
comment = {A graduate-level introduction to/discussion of concentration of
 measure, exploring many aspects including deviation, infimum convolutions
 (i.e. c-convexity), isoperimetry, transport, entropy, and concentration in
 product spaces.}
}

@book{LedouxTa91,
author = {M. Ledoux and M. Talagrand},
title = {Probability in Banach Spaces},
year = 1991,
publisher = {Springer},
comment = {Huge reference book containing tons of concentration facts, etc.
      A bit of a challenging read},
}

@phdthesis{Lee88,
author=	  	{Lee, Kai-Fu},
title=	  	{Large-Vocabulary Speaker-Independent Continuous
	  	Speech Recognition: The SPHINX System},
school=	  	{Carnegie Mellon University Computer Science Dept.},
year=	  	1988,
month=	  	apr,
note=	  	{Tech report number CMU-CS-88-148}
}


@Article{LeeHo89,
  author = 	 {K.-F. Lee and H.-W. Hon},
  title = 	 {Speaker Independent Phone Recognition Using Hidden Markov Models},
  journal =  {IEEE Trans. Acoustic, Speech and Signal Proc.},
  year = 	 1989,
  volume =	 37,
  number =	 2,
  pages =	 {1641-1648}
}


@Article{LeeBaWi96,
  author = 	 {Wee Sun Lee and Peter L. Bartlett and Robert C. Williamson},
  title = 	 {Efficient agnostic learning of neural networks with
                  bounded fan-in},
  journal = 	 ieeeit,
  year = 	 1996,
  volume =	 42,
  number =	 6,
  pages =	 {2118--2132}
}


@Article{LeeBaWi??,
  author = 	 {Wee Sun Lee and Peter L. Bartlett and Robert C. Williamson},
  title = 	 {The importance of convexity in learning with squared loss},
  journal = 	 ieeeit,
  year = 	 {to appear}
}

@inproceedings{LeeSiJoRe16,
  title={Gradient descent converges to minimizers},
  author={Lee, Jason D and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  booktitle = colt16,
year = 2016,
}

@article{LeeWr12,
author = {Sangkyun Lee and Stephen J. Wright},
title = {Manifold Identiﬁcation in Dual Averaging for
Regularized Stochastic Online Learning},
journal = jmlr,
volume = 13,
pages = {1705--1744},
year = 2012,
}

@inproceedings{LeeLeAbNg06,
author = {S. I. Lee and H. Lee and P. Abbeel and A. Y. Ng},
title = {Efficient $\ell_1$-Regularized Logistic Regression},
year = 2006,
booktitle = {Proceedings AAAI-06},
organization = {American Association for Artificial Intelligence},
}

@article{LeeMa88,
author=	  	{Kai-Fu Lee and Sanjoy Mahajan},
title=    	{A Pattern Classification Approach to Evaluation Function
		Learning},
journal=  	{Artificial Intelligence},
year=     	1988,
month=    	Aug,
volume=   	36,
number=   	1,
pages=    	{1--26},
comment=  	{Learns Othello evaluation function based on four features and
           	multivariate normal distribution assumption.}
}

@inproceedings{LeeMa01,
author = {Y.~Lee and O.L.~Mangasarian},
title = {{RSVM: R}educed support vector machines},
booktitle = {Proceedings of the First SIAM International Conference on Data Mining},
year = {2001}
}

@inproceedings{LeeSe00,
    author = "D.D.~Lee and H.S.~Seung",
    title = "Algorithms for Non-negative Matrix Factorization",
    booktitle = nips13,
    pages = "556-562",
    year = "2000"
}

@article{LeeSh09,
author = {Troy Lee and Adi Shraibman},
year = 2009,
title = {Lower bounds in communication complexity},
journal = {Foundations and Trends in Theoretical Computer Science},
volume = 3,
number = 4,
pages = {263--399},
}

@inproceedings{LeeSi13,
  title={Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems},
  author={Lee, Yin Tat and Sidford, Aaron},
  booktitle=focs13,
  pages={147--156},
  year=2013,
  organization={IEEE}
}

@article{LeeSuSa14,
author = {Jason D. Lee and Yuekai Sun and Michael A. Saunders},
title = {Proximal {N}ewton-type methods for minimizing composite functions},
year = 2014,
journal = siopt,
volume = {To appear},
comment = {Shows how Newton methods may be used to solve minimization
  problems of the form min f(x) = g(x) + h(x). When f is strongly convex
  and smooth (and has smooth gradients), they show that with a suitable
  backtracking line search (essentially a composite version of Armijo)
  converges globally and also has quadratic local convergence by a simple
  Taylor expansion argument (along with a treatment of Lipschitz continuity
  of the prox operator). They also show--without constants--the local
  super-linear convergence using a Quasi-Newton method satisfying
  the Dennis-Mor\'e criterion on accuracy of Hessian approxomations in the
  direction of the Newton steps. They also allow inexact Newton methods, so
  long as the resulting "gradient" (combination of current gradient
  and single step ahead subgradient of composite term) is sufficiently
  small. They show that this gives linear or super-linearly to
  the optimal solution, depending on how accurately sub-problems are solved.}
}

@inproceedings{Lei11,
author = {Jing Lei},
title = {Differentially private {M}-estimators},
year = 2011,
booktitle = nips25,
comment = { Main idea of the paper: since most data analysis
                  techniques don't a-priori know the problem being
                  solved, it makes sense to release a summary of the
                  dataset that can be used for many tasks, such as
                  M-estimation. To do so, the paper proposes using a
                  private histogram of the data, then running all
                  statistical analyses based on that private
                  histogram. The issue is that for d-dimensional
                  problems, the computational scaling of this
                  procedure is high, and the convergence rates of the
                  resulting estimators decrease to n^{-4 / (2 + d)} in
                  \ell_2^2. So for any d > 2, this is sub-optimal, and
                  quickly becomes very slow. It is not clear that
                  there are better procedures, but there are some
                  based on the statistical query model so long as
                  queries have bounded VC dimension. Also requires all
                  data to live in [0, 1]^d.},
}

@article{LeiJuChJo17,
	title={Nonconvex Finite-Sum Optimization Via {SCSG} Methods},
	author={Lei, Lihua and Ju, Cheng and Chen, Jianbo and Jordan, Michael I},
	journal={arXiv:1706.09156 [math.OC]},
	year=2017
}

@book{Lehmann99,
author = {Erich L. Lehmann},
title = {Elements of Large Sample Theory},
year = 1999,
publisher = {Springer},
}

@book{LehmannCa98,
author = { Erich L. Lehmann and George Casella },
title = {Theory of Point Estimation, Second Edition},
year = 1998,
publisher = {Springer},
}

@book{LehmannRo05,
author = {Erich L. Lehmann and Joseph P. Romano},
title = {Testing Statistical Hypotheses, Third Edition},
year = 2005,
publisher = {Springer},
}

@article{LemarechalSa97,
author = {C. Lemar\'{e}chal and C. Sagastiz\'{a}bal},
title = {Practical aspects of the {M}oreau-{Y}osida regularization:
theoretical preliminaries},
year = 1997,
journal = siopt,
volume = 7,
number = 2,
pages = {367--385},
}

@TECHREPORT{LemelKaSe86,
  author =       {L. Lemel and R. Kassel and S. Seneff},
  title =        {Speech database development: Design and analysis~},
  institution =  {Proc. {DARPA} Speech Recognition Workshop},
  year =         {1986},
  type =         {Report no.},
  number =       {SAIC-86/1546},
}


@article{Lemmer83,
author=   	{Lemmer, John F.},
title=    	{Generalized Bayesian updating of incompletely specified
	   	distributions},
journal=  	{Large Scale Systems},
year=     	1983,
volume=   	5,
pages=    	{51--68},
comment=  	{Derives sufficient conditions for when marginals are
		consistent with some underlying distribution.}
}

@article{LenstraLeLo82,
author = 	{A. K. Lenstra and H. W. Lenstra and L. Lov\'{a}sz},
title = 	{Factoring Polynomials with Rational Coefficients},
journal = 	{Mathematische Annalen},
year = 		{1982},
volume = 	{261},
pages = 	{515--534}
}


@InProceedings{LeslieEsNo02,
  author = 	 {C. Leslie and E. Eskin and W. Stafford Noble},
  title = 	 {The Spectrum Kernel: A String Kernel for {SVM} protein Classification},
  booktitle = 	 {Proceedings of the Pacific Symposium on Biocomputing},
  year =	 2002
}

@book{LesserOrTa03,
  title     = "{Distributed Sensor Networks: A Multiagent
               Perspective}",
  volume    = "9",
  editor    = "V. Lesser and C. Ortiz and M. Tambe",
  publisher = "Kluwer Academic Publishers",
  year      = "2003",
}

@article{LeventhalLe10,
author = {Dennis Leventhal and Adrian S. Lewis},
title = {Randomized methods for linear constraints: convergence rates
  and conditioning},
year = 2010,
journal = {Mathematics of Operations Research},
volume = 35,
number = 3,
pages = {641--654},
comment = {Considers condition numbers and their interplay with the
  convergence (linear always) of iterative methods for solving
  projection-like problems and linear equalities/inequalities. In particular,
  shows that the analysis of Stromer and Vershynin on the Kaczmarz algorithm
  can be similarly applied to get convergence--involving natural
  condition numbers--for solving Ax = b, Ax \le b, and alternating-projections
  type methods (with random projections to find a point in the intersection
  of multiple sets S_1, S_2, ...). Notions of conditioning are classical
  matrix condition numbers, a constant due to Hoffman, conditions on
  metric regularity of mappings, and Renegars distance to infeasibility.},
}

@techreport{Levin80,
author=   	{Levin, Leonid, A.},
title=    	{A Concept of Independence with Applications in Various Fields
		of Mathematics},
institution=	mitlcs,
year=     	1980,
month=    	Apr,
number=   	{MIT/LCS/TR-235}
}

@inproceedings{Levin84,
author=   	{Leonid A. Levin},
title=    	{Problems, complete in ``average'' instance},
booktitle=	stoc84,
year=     	1984,
month=    	apr,
pages=    	{465}
}

@article{Levin86,
author=		{Leonid A. Levin},
title=		{Average Case Complete Problems},
journal=	{SIAM Journal of Computing},
volume=		15,
number=		1,
year=		1986,
month=		feb,
pages=		{285--286},
}

@book{LevinPeWi08,
author = {D. Levin and Y. Peres and E. Wilmer},
title = {Markov {C}hains and {M}ixing {T}imes},
year = 2008,
publisher = {American Mathematical Society},
comment = {url = {http://www.uoregon.edu/~dlevin/MARKOV/}},
}

@article{LevinsonRaSo83,
author=   	{S. E. Levinson and L. R. Rabiner and M. M. Sondhi},
title=    	{An Introduction to the Application of the Theory of
		Probabilistic Functions
           	of a Markov Process to Automatic Speech Recognition},
journal=  	{Bell System Technical Journal},
year=     	1983,
month=    	Apr,
volume=   	62,
number=   	4,
pages=    	{1035--1074},
comment=  	{Analysis of implementation of Hidden Markov models and the
		Baum-Welch algorithm}
}

@article{Levy16,
	title={The Power of Normalization: Faster Evasion of Saddle Points},
	author={Levy, Kfir Y},
	journal={arXiv:1611.04831 [cs.LG]},
	year={2016}
}

@inproceedings{LevyGo14,
author = {Omer Levy and Yoav Goldberg},
title = {Linguistic Regularities in Sparse and Explicit Word Representations},
year = 2014,
booktitle = {Eighteenth Conference on Computational Neural Language Learning
 (CoNLL)},
}

@inproceedings{LevyMa03,
author = {Roger Levy and Christopher D. Manning},
title = {Is it harder to parse {C}hinese, or the {C}hinese {T}reebank?},
year = 2003,
booktitle = {Association for Computational Linguistics},
}

@TechReport{Lewis92,
    Author="David Lewis",
    Institution="Computer Science Dept., University of
        Massachusetts at Amherst",
    Title="Representation and Learning in Information Retrieval",
    Year="1992",
    Number="91-93",
    Note="PhD Thesis"
}

@unpublished{Lewis95
,author=	{David D. Lewis}
,title=		{Evaluation and optimizing autonomous text
		 classification systems}
}

@article{Lewis96,
author = {Adrian Lewis},
title = {Convex analysis on the {H}ermitian matrices},
year = 1996,
journal = siopt,
volume = 6,
pages = {164--177},
comment = {Uses Von-Neumann's trace inequality to derive a conjugacy
  relation for convex functions of Hermitian matrices. In particular,
  shows that any (weakly) unitarily invariant convex function is a function
  only of the matrix's eigenvalues, and given a convex function (function
  of vector entries) and applying it to the eigenvalues of a Hermitian
  matrix gives a convex function.},
}

@inproceedings{LewisCa94,
    Author = "David Lewis and Jason Catlett",
    Title = "Heterogeneous Uncertainty Sampling for Supervised Learning",
    Booktitle=ml94,
    Year=1994
}

@inproceedings{LewisGa94,
    Author = "David Lewis and William Gale",
    Title = "Training text classifiers by  uncertainty sampling",
    Booktitle="Seventeenth Annual International ACM SIGIR
        Conference on Research and Development in Information Retrieval",
    Year=1994
}

@article{LewisLuMa09,
author = {Adrian S. Lewis and D. R. Luke and Jerome Malick},
title = {Local linear convergence for alternating and averaged nonconvex projections},
journal = focm,
volume = 9,
year = 2009,
pages = {485--513},
number = 4,
comments = {Gives a number of definitions of conditioning for intersections
  of sets, showing that if locally they are pretty nice (e.g. locally
  almost convex, except for lower-order errors in the normal cone, which
  is like a function being prox-regular or lower-$C^2$), then one has
  local linear convergence of projections. Basically things become contractions
  when close enough.},
}

@article{LewisMa08,
  title={Alternating projections on manifolds},
  author={Lewis, Adrian S and Malick, J{\'e}r{\^o}me},
  journal={Mathematics of Operations Research},
  volume={33},
  number={1},
  pages={216--234},
  year={2008},
  publisher={INFORMS}
}

@inproceedings{LewisRi94
,author=        {David D. Lewis and Marc Ringuette}
,title=         {A comparison of two learning algorithms for text
                  categorization}
,booktitle=     {Third Annual Symposium on Document Analysis and
                  Information Retrieval}
,year=          1994
,pages=         {81-93}
}




@article{LewisRuToMcCrLe98,
  title={Practical connection admission control for ATM networks based on on-line measurements},
  author={Lewis, John T and Russell, Raymond and Toomey, Fergal and McGurk, Brian and Crosby, Simon and Leslie, Ian},
  journal={Computer Communications},
  volume=21,
  number=17,
  pages={1585--1596},
  year=1998,
  publisher={Elsevier}
}

@InProceedings{LewisScCaPa96,
  author = 	 {David D. Lewis and Robert E. Schapire and James
                  P. Callan and Ron Papka},
  title = 	 {Training algorithms for linear text classifiers},
  booktitle = 	 {SIGIR '96: Proceedings of the 19th Annual
                  International Conference on Research and Development
                  in Information Retrieval},
  year =	 1996
}

@article{LewisWr08,
author = {Adrian S. Lewis and Stephen J. Wright},
title = {A proximal method for composite minimization},
year = 2008,
journal = {arXiv:0812.0423 [math.OC]},
url = {http://arxiv.org/abs/0812.0423},
}

@article{LewisYaRoLi04,
  author =        {D. Lewis and Y. Yang and T. Rose and F. Li},
  title =         {{RCV}1: A New Benchmark Collection for Text Categorization
                   Research},
  journal =       {Journal of Machine Learning Research},
  year =          2004,
  volume =        5,
  pages =         {361--397},
  comment =       {The citation for the reuter's corpus}
}

@article{Li94
,author=	{Shuhe Li}
,title=		{Dynamic stability and learning processes in
		 {$2\times 2$} coordination games}
}


@inproceedings{Li00,
	author=   	{Y.~Li},
	title=    	{Selective Voting for Perceptron-like On-line Learning},
	booktitle= 	icml00,
	year=     	2000,
}

@article{LiangLi09,
author = {Hua Ling and Runze Li},
title = {Variable Selection for Partially Linear Models With
   Measurement Errors},
year = 2009,
journal = jasa,
volume = 104,
number = 485,
pages = {234--248},
}

@article{LiangPoSh08,
author = {Yingbin Liang and H. Vincent Poor and Shlomo Shamai},
year = 2008,
title = {Information Theoretic Security},
journal = {Foundations and Trends in Communications and Information
Theory},
volume = 5,
number = 4,
pages = {355--580},
}

@misc{Lichman13,
author = {M. Lichman},
year = 2013,
title = {{UCI} Machine Learning Repository},
url = {http://archive.ics.uci.edu/ml},
institution = {University of California, Irvine, Department of Information
                     and Computer Sciences},
}

@article{Liebscher05,
author = {Eckhard Liebscher},
title = {Towards a unified approach for proving geometric ergodicity
  and mixing properties of nonlinear autoregressive processes},
year = 2005,
journal = {Journal of Time Series Analysis},
volume = 26,
number = 5,
pages = {669--689},
comment = {Contains general theorems relating geometric ergodicity
  to $\beta$-mixing. Applies in non-stationary cases. Also gives some
  reasonable and intuitive conditions for geometric ergodicity of a
  non-linear autoregressive process (similar to having spectral radius
  bounded by 1 in the linear case).},
}

@article{LieseVa06,
author = {Friedrich Liese and Igor Vajda},
title = {On divergences and informations in statistics and information
theory},
journal = ieeeit,
year = 2006,
pages = {4394--4412},
volume = 52,
number = 10,
comment = {Proves that all $f$ divergences are equivalent to
  statistical informations (differences between prior and posterior
  Bayes risks) for particular losses. Also gives proofs of many
  data processing inequalities. Uses an integral representation with
  Bayes risks to prove results.}
}

@PhdThesis{Li99,
	author = 	 {Qiang (Jonathan) Li},
	title = 	 {Estimation of Mixture Models},
	school = 	 {Yale University},
	year = 	 1999,
	month =	 {May},
	annote =	 {Student of Andrew Barron}
}

@article{LiHo10,
author = {Heng Li and Nils Homer},
title = {A survey of sequence alignment algorithms for next generation
sequencing},
year = 2010,
journal = {Briefings in Bionformatics},
volume = 11,
number = 5,
pages = {473--483},
}

@inproceedings{LiLiWa09,
author = {Lihong Li and Michael Littman and Thomas Walsh},
year = 2009,
booktitle = icml09,
title = {Knows What It Knows: A Framework For Self-Aware Learning},
}

@InProceedings{LiLo99,
author = {Y.~Li and P.~M.~Long},
title = {The relaxed online maximum margin algorithm},
booktitle = {Advances in Neural Information Processing Systems 13},
year = 1999
}

@article{LiLo02,
author = {Y.~Li and P.~M.~Long},
title = {The relaxed online maximum margin algorithm},
journal=  	ml,
year=     	2002,
volume=   	46,
number=         {1--3},
pages=    	{361--387},
}

@inproceedings{LiRi16,
	author = {Li, Yuanzhi and Risteski, Andrej},
	title = {Algorithms and matching lower bounds for approximately-convex 
	optimization},
	year = 2016,
	booktitle = nips29,
}

@inproceedings{LiWoHuSa02,
    author = {D. Li and K. Wong and Y. Hu and A. Sayeed},
    title = {Detection, Classification and Tracking of Targets in Distributed Sensor Networks},
    booktitle = {IEEE Signal Processing Magazine},
    year = {2002},
    pages = {17--29}
}

@inproceedings{LiereTa97,
	author = "Ray Liere and Prasad Tadepalli",
	title = "Active learning with committees for text categorization",
	booktitle = aaai97,
	year = 1997
}

@inproceedings{Liggett96
,author=	{Thomas M. Liggett}
,title=		{Stochastic models of interacting systems}
}

@article{LimGl12,
author = {Eunji Lim and Peter W. Glynn},
title = {Consistency of multidimensional convex regression},
year = 2012,
journal = {Operations Research},
volume = 60,
pages = {196--208},
}

@article{LionsMe79,
author = {P. L. Lions and B. Mercier},
title = {Splitting algorithms for the sum of two nonlinear operators},
year = 1979,
journal = {SIAM Journal on Numerical Analysis},
volume = 16,
pages = {964--979},
}

@techreport{Lin01,
author=		{C.-J.~Lin},
title=		{Stopping criteria of decomposition methods for support vector machines: a theoretical justification},
institution=	{Depratment of Computer Science and Information Engineering, National Taiwan University},
year=		2001,
month=		May
}

@article{Lin02,
  author = "C.-J.~Lin",
  title = "A formal analysis of stopping criteria of decomposition
    methods for support vector machines",
  journal = ieeenn,
  volume = 13,
  number = 5,
  month = {Sept.},
  year = 2002,
  pages = "1045--1052"
}

@inproceedings{LinialMaNi89,
author =  	{Nathan Linial and Yishay Mansour and Noam Nisan},
title=		{Constant depth circuits, {F}ourier Transform, and
		 Learnability},
booktitle = 	focs89,
month=    	Oct,
year=		1989,
pages = 	{574--579}
}

@article{LinialMaNi93,
author =  	{Nathan Linial and Yishay Mansour and Noam Nisan},
title=		{Constant depth circuits, {F}ourier Transform, and
		 Learnability},
journal = 	jacm,
month=    	jul,
year=		1993,
volume=		40,
number=		3,
pages = 	{607--620}
}

@inproceedings{LinialMaRi88,
author =  	{Nathan Linial and Yishay Mansour and Ronald L. Rivest},
title = 	{Results on Learnability and the {V}apnik-{C}hervonenkis
		Dimension},
booktitle = 	focs88,
year = 		1988,
month =		oct,
pages = 	{120--129}
}

@inproceedings{LinialMaRi88b,
author =  	{Nathan Linial and Yishay Mansour and Ronald L. Rivest},
title = 	{Results on Learnability and the {V}apnik-{C}hervonenkis
		Dimension},
booktitle = 	colt88,
publisher = 	{Morgan-Kaufmann},
year = 		1989,
pages = 	{56--68}
}

@article{LinialMaRi91,
author =  	{Nathan Linial and Yishay Mansour and Ronald L. Rivest},
title = 	{Results on Learnability and the {V}apnik-{C}hervonenkis
		Dimension},
journal=	infcomp,
volume=		90,
number=		1,
month=		jan,
year = 		1991,
pages = 	{33--49}
}

@article{LiphardtDuSmTiBu02,
  title={Equilibrium Information from Nonequilibrium Measurements in an Experimental Test of Jarzynski9s Equality},
  author={Liphardt, Jan and Dumont, Sophie and Smith, Steven B and Tinoco, Ignacio and Bustamante, Carlos},
  journal={Science},
  volume=296,
  number=5574,
  pages={1832--1835},
  year=2002,
  publisher={American Association for the Advancement of Science}
}

@article{Lippmann87b,
author=   	{Lippmann, Richard P.},
title=    	{An Introduction to Computing with Neural Nets},
journal=  	{IEEE ASSP Magazine},
year=     	1987,
month=    	Apr,
pages=    	{4--22},
comment=  	{Good survey article}
}

@inproceedings{LiticheverCh01,
author = {Z.~Litichever and D.~Chazan},
title =  {Classification of transition sounds with application to
automatic speech recognition},
booktitle = {EUROSPEECH},
year = {2001}
}

@book{LittleRu02,
author = {Roderick J. A. Little and Donald B. Rubin},
title = {Statistical Analysis with Missing Data},
year = 2002,
edition = {Second},
publisher = {Wiley-Interscience},
}

@inproceedings{Littlestone87,
author=   	{N.~Littlestone},
title=    	{Learning when Irrelevant Attributes Abound},
booktitle=	focs87,
year=     	1987,
month=    	Oct,
pages=    	{68--77}
}

@article{Littlestone88,
author=   	{N.~Littlestone},
title=    	{Learning Quickly when Irrelevant Attributes Abound: A New
 		Linear-threshold Algorithm},
journal=  	ml,
volume=   	2,
pages=    	{285--318},
year=     	1988
}

@phdthesis{Littlestone88b,
author = 	{N.~Littlestone},
title  = 	{Mistake bounds and logarithmic linear-threshold
		learning algorithms},
school = 	{U. C. Santa Cruz},
year = 		{1989},
month = 	mar
}

@phdthesis{Littlestone89,
author = 	{N. Littlestone},
title  = 	{Mistake bounds and logarithmic linear-threshold
		learning algorithms},
school = 	{U. C. Santa Cruz},
year = 		{1989},
month = 	mar
}

@inproceedings{Littlestone89b,
author=   	{N. Littlestone},
title=    	{From On-line to Batch Learning},
booktitle= 	colt89,
year=      	1989,
month=     	Jul,
pages=     	{269--284}
}

@inproceedings{LittlestoneLoWa91,
author=		{Nicholas Littlestone and Philip M. Long and Manfred
		 K. Warmuth},
title=		{On-Line Learning of Linear Functions},
year=		1991,
month=		may,
booktitle=	stoc91,
pages=		{465--475}
}

@inproceedings{Littlestone91,
  author    = {Nicholas Littlestone},
  title     = {Redundant Noisy Attributes, Attribute Errors, and Linear-Threshold
               Learning Using Winnow.},
  booktitle = colt91,
  year      = {1991},
  pages     = {147-156},
}

@article{LittlestoneLoWa95,
author=		{Nicholas Littlestone and Philip M. Long and Manfred
		 K. Warmuth},
title=		{On-Line Learning of Linear Functions},
journal=	{Computational Complexity},
volume=		5,
number=		1,
year=		1995,
pages=		{1-23}
}

@unpublished{LittlestoneWa86,
author = 	{N. Littlestone and M. Warmuth},
title = 	{Relating Data Compression and Learnability},
note = 		{Unpublished manuscript},
month=		nov,
year = 		1986
}

@unpublished{LittlestoneWa89,
author = 	{Manfred Warmuth and Nick Littlestone},
title = 	{Learning from an adversary},
note = 		{In preparation},
year = 		{1989}
}

@inproceedings{LittlestoneWa89b,
author = 	{Nick Littlestone and Manfred Warmuth},
title = 	{The Weighted Majority Algorithm},
booktitle=	focs89,
pages=		{256--261},
month=    	Oct,
year=		1989
}

@article{LittlestoneWa94
,author = 	{Nick Littlestone and Manfred K. Warmuth}
,title = 	{The Weighted Majority Algorithm}
,journal=	infcomp
,volume=	108
,year=		1994
,pages=		{212--261}
}

@article{LiuMiFa13,
author = {Victor Liu and David A. B. Miller and Shanhui Fan},
title = {Highly Tailored Computational Electromagnetics Methods
for Nanophotonic Design and Discovery},
year = 2013,
journal = {Proceedings of the IEEE},
volume = 101,
number = 2,
pages = {484--493},
}

@article{LiuNo89,
Author = {Dong Liu and Jorge Nocedal},
Journal = mathprog,
Number = {1},
Pages = {503--528},
Title = {On the limited memory {BFGS} method for large scale optimization},
Volume = {45},
Year = {1989}}


@inproceedings{LiuWrReBiSr14,
author = {Ji Liu and Stephen J. Wright and Christopher R\'e
   and Victor Bittorf and Srikrishna Sridhar},
title = {An asynchronous parallel stochastic coordinate descent algorithm},
year = 2014,
booktitle = icml14,
comment = {Shows that a value $H$ associated with the on Hessian (roughly that
  the maximum column $\ell_2$-norm is bounded by $H$ times its maximum
  diagonal entry) governs linear speedup of asynchronous coordinate methods.
  If the delay in the method is bounded(ish) by $\sqrt{n} / H$, then
  speedup over traditional coordinate descent methods is linear. This is
  intuitive, as it means that roughly intermediate updates are (1) unlikely
  to touch the desired coordiante and (2) coordinate updates do not affect
  one another much.},
}

@inproceedings{LjoljeRi91,
author = 	{A. Ljolje and M.D. Riley},
title = 	{Automatic Segmentation and Labeling of Speech},
booktitle=	{Intl. Conf. on Acoustic, Speech and Signal Proc.},
pages=		{473-476},
year=		1991
}

@article{Ljung77,
author = {Lennart Ljung},
title = {Analysis of Recursive Stochastic Algorithms},
year = 1977,
journal = ieeetac,
volume = 22,
number = 4,
pages = {551--575},
}

@techreport{LobelOz09,
author = {I. Lobel and A. Ozdaglar},
title = {Distributed subgradient methods over random networks},
year = 2009,
institution = {MIT LIDS},
number = 2800,
}

@techreport{LobelOz08,
author = {I. Lobel and A. Ozdaglar},
title = {Distributed subgradient methods over random networks},
year = 2008,
institution = {MIT LIDS},
number = 2800,
}

@article{LodhiSTCrWa02,
    author = "Huma Lodhi and John Shawe-Taylor and Nello Cristianini and Christopher J. C. H. Watkins",
    title = "Text Classification using String Kernels",
    journal=	"Journal of Machine Learning Research",
    volume=	"2",
    year=       "2002",
    pages=	"419-444"
}

@article{LohWa12,
author = {Po-Ling Loh and Martin J.\ Wainwright},
year = 2012,
title = {High-dimensional regression with noisy and missing data:
   provable guarantees with nonconvexity},
journal = aos,
volume = 40,
number = 3,
pages = {1637--1664},
}

@article{LohWa13,
author = {Po-Ling Loh and Martin J.\ Wainwright},
year = 2013,
title = {Regularized {M}-estimators with nonconvexity: 
  Statistical and algorithmic theory for local optima},
journal = jmlr,
volume = 16,
pages = {559--616},
}


@article{LongoLoGr90,
author={Longo, Maurizio and Lookabaugh, Tom D. and Gray, Robert M.},
journal={IEEE Transactions on Information Theory},
title={Quantization for decentralized hypothesis testing under communication
  constraints},
year={1990},
volume={36},
number={2},
pages={241--255},
}

@InProceedings{LongWu04,
  author = 	 {P.M. Long and X. Wu},
  title = 	 {Mistake bounds for maximum entropy discrimination},
  booktitle =   nips17,
  year = 	 {2004}
}

@article{Lopez91,
author = {R.~Lopez de~Mantaras},
title = {A distance-based attribute selection measure for decision tree induction},
journal = {Machine Learning Journal},
year = {1991}
}

@article{Lorentz66,
author = {George G. Lorentz},
title = {Metric Entropy and Approximation},
year = 1966,
journal = bams,
volume = 72,
number = 6,
pages = {903--937},
comment = {Gives general techniques for evaluating approximability and metric
  entropies},
}

@book{Lovasz79,
author=		{L. Lov\'asz},
title=		{Combinatorial Problems and Exercises},
publisher=	{North-Holland},
year=		{1979}
}

@article{LowGoKyBiGuHe12,
author = {Yucheng Low and Joseph Gonzalez and Aapo Kyrola
  and Danny Bickson and Carlos Guestrin and Joseph M. Hellerstein},
title = {Distributed GraphLab: A Framework for Machine Learning and
  Data Mining in the Cloud},
journal = {Proceedings of the Very Large Databases Endowment},
year = {2012},
volume = 5,
number = 8,
}

@InProceedings{Lowe04,
  author = 	 {D. Lowe},
  title = 	 {Distinctive image features from scale-invariant keypoints},
  booktitle = {IJCV},
  year = 	 {2004}
}

@techreport{LuNe14,
author = {Yu Lu and Sahand N. Negahban},
title = {Individualized Rank Aggregation using Nuclear
Norm Regularization},
year = 2014,
institution = {Department of Statistics, Yale University},
}

@article{LuXi15,
  title={On the complexity analysis of randomized block-coordinate descent methods},
  author={Lu, Zhaosong and Xiao, Lin},
  journal={Mathematical Programming},
  volume=152,
  number={1-2},
  pages={615--642},
  year=2015,
  publisher={Springer}
}

@book{LuceRa57
,author=	{R. Duncan Luce and Howard Raiffa}
,title=		{Games and Decisions}
,publisher=	{John Wiley \& Sons}
,year=		1957
}

@book{Luenberger69,
title = {Optimization by Vector Space Methods},
author = {David Luenberger},
year = 1969,
publisher = {Wiley},
comment = {Beautiful book on optimization, with a focus on infinite
  dimensional spaces that does not complicate things. Geometric principles
  unite everything. Starts by reviewing vector space theory (in infinite
  dimensions), then goes through separation, differentiability, and duality
  in infinite dimensional space. Uses Euclidean notions to give
  intuition.},
}

@article{LugosiVa04,
author = {G\'abor Lugosi and Nicolas Vayatis},
title = {On the {B}ayes-risk consistency of regularized boosting methods},
year = 2004,
journal = aos,
volume = 32,
number = 1,
pages = {30--55},
}

@article{LugosiWe04,
author = {G. Lugosi and M. Wegkamp},
title = {Complexity regularization via localized random penalties},
year = 2004,
journal = aos,
volume = 32,
number = 4,
pages = {1679--1697},
}

@unpublished{LundPhRe94
,author=	{Carsten Lund and Steven Phillips and Nick Reingold}
,title=		{Adaptive holding policies for {IP} over {ATM}
		networks}
}

@article{Luo05,
author = {Zhi-Quan Luo},
title = {Universal Decentralized Estimation in a Bandwidth Constrained
  Sensor Network},
year = 2005,
journal = ieeeit,
volume = 51,
number = 6,
pages = {2210--2219},
comment = {Considers estimation of the mean of a distribution where
  observations come as $\theta + Z_i$, where $Z_i$ are indpendent bounded
  noise variables. In a distributed setting, if each sensor $i$ sees a single
  observation $\theta + Z_i$ and $|Z_i| \le U$, then usual minimax lower
  bounds imply that $U^2 / \epsilon^2$ sensors are necessary to estimate
  $\theta$ to within $\epsilon$. Under a restriction of sensors sending only a
  single bit, this paper shows that an asymptotically identical number
  of sensors are sufficient. The scheme is as follows: divide the
  sensors into $K = \log(U / \epsilon)$ sub-groups, where the $k$th
  subgroup has a fraction $2^{-k}$ of the sensors. Within subgroup $k$,
  send a quantized version of the $k$th bit of the observation, then
  re-assemble at the fusion center using the binary expansion of a number.},
}


@article{LuoTs92,
    author = "Z.Q. Luo and P. Tseng",
    title = "On the convergence of the coordinate descent method for convex
      differentiable minimization",
    journal = "Journal of Optimization Theory and Applications",
    volume = 72,
    number = 1,
    pages = "7--35",
    year = 1992
}

@article{LuoTs93,
  title={On the communication complexity of distributed algebraic computation},
  author={Luo, Zhi-Quan and Tsitsiklis, John N},
  journal=jacm,
  volume={40},
  number={5},
  pages={1019--1047},
  year={1993},
}

@article{LuoTs94,
author = {Zhi-Quan Luo and John N. Tsitsiklis},
title = {Data fusion with minimal communication},
year = 1994,
journal = ieeeit,
volume = 40,
number = 5,
pages = {1551--1563},
comment = {Considers problem of exactly computing a function f(x, y), where
  the data x, y is stored on two computers. Focuses first on case when
  messages must be linear, i.e. m(x) = Mx, and then on analytic messages.
  Shows rank-based conditions on size of messages (which makes sense for
  functions of form f(x, y) = Ax + By and exact computation). },
}


@article{Lust-PiquardPi91,
author = {F. Lust-Piquard and G. Pisier},
title = {Noncommutative {K}hintchine and {P}aley inequalities},
year = 1991,
journal = {Arkiv f\"or Matematik},
volume = 29,
number = 2,
pages = {241--260},
}

@inproceedings{LuxburgBo03,
	author = "U. von Luxburg and O. Bousquet",
	title = "Distance-Based Classification with {L}ipschitz Functions",
	booktitle = colt03,
	year = 2003
}

@techreport{LuxburgRaHe10,
author = {U. von Luxburg and A. Radl and M. Hein},
title = {Hitting times, commute distances, and the spectral gap for
large random geometric graphs},
year = 2010,
url = {http://arxiv.org/abs/1003.1266},
}

@article{LykourisSyTa15,
  author    = {Thodoris Lykouris and
               Vasilis Syrgkanis and
               {\'{E}}va Tardos},
  title     = {Learning and Efficiency in Games with Dynamic Population},
  journal   = {arXiv:1505.00391 [cs.GT]},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.00391},
}

@article{Lyszyk99,
    author = "D. Lyszyk and J. Shamir",
    title = "Signal processing under uncertain conditions by parallel
        projections onto fuzzy sets",
    journal = "Journal of the Optical Society of America A",
    volume = "16",
    pages = "1602--1611",
    year = 1999
}

@inproceedings{MaassTu89,
author = 	{Wolfgang Maass and Gyorfy Turan},
title = 	{On the complexity of Learning From Counterexamples},
booktitle = 	focs89,
month=		oct,
year = 		{1989},
pages = 	{262--267},
}

@article{Mahoney11,
author = {Michael Mahoney},
title = {Randomized algorithms for matrices and data},
year = 2011,
journal = {Foundations and Trends in Machine Learning},
volume = 3,
number = 2,
pages = {123--224},
url = {http://arxiv.org/abs/1104.5557},
}

@article{MaMaYu15,
  title={A statistical perspective on algorithmic leveraging},
  author={Ping Ma and Michael W. Mahoney and Bin Yu},
  journal=jmlr,
  volume={16},
  pages={861--911},
  year={2015}
}

@article{MaWu13,
author = {Zongming Ma and Yihong Wu},
title = {Volume Ratio, Sparsity, and Minimaxity
   under Unitarily Invariant Norms},
year = 2013,
journal = {arXiv:1306.3609 [math.ST]},
url = {http://arxiv.org/abs/1306.3609},
}

@article{MackeyJoChFaTr12,
author = {Lester W. Mackey and Michael I. Jordan and Richard Y. Chen and
Brendan Farrell and Joel A. Tropp},
title = {Matrix concentration inequalities via the method of
exchangeable pairs},
year = 2012,
journal = {arXiv:1201.6002 [math.PR]},
url = {http://arxiv.org/abs/1201.6002},
comment = {Really nice paper. Abstract:
  This paper derives exponential concentration inequalities and polynomial
  moment inequalities for the spectral norm of a random matrix. The analysis
  requires a matrix extension of the scalar concentration theory developed by
  Sourav Chatterjee using Stein's method of exchangeable pairs. When applied
  to a sum of independent random matrices, this approach yields matrix
  generalizations of the classical inequalities due to Hoeffding, Bernstein,
  Khintchine, and Rosenthal. The same technique delivers bounds for sums of
  dependent random matrices and more general matrix-valued functions of
  dependent random variables. Curious how it applies to self-adjoint
  matrices for different inner products.},
}

@inproceedings{MackeyTaJo11,
author = {Lester Mackey and Ameet Talwalkar and Michael I. Jordan},
title = {Divide-and-conquer matrix factorization},
year = 2011,
booktitle = nips24,
}


@InProceedings{MaclinOp97,
  author = 	 {Richard Maclin and David Opitz},
  title = 	 {An Empirical Evaluation of Bagging and Boosting},
  booktitle = 	 aaai97,
  year =	 1997,
  pages =	 {546-551}
}

@unpublished{Macskassy98
,author=         {Sofus Macskassy}
,title=          {A comparison of two on-line algorithms that adapt to
                  concept drift}
}

@book{MadalaIv94
,author=	{Hema R. Madala and Alexy G. Ivakhnenko}
,title=		{Inductive Learning Algorithms for Complex Systems
		 Modeling}
,year=		1994
,publisher=	{CRC Press}
}

@inproceedings{MadiganGeLeFr05,
	author = {D.~Madigan and A.~Genkin and D.~D.~Lewis and D.~Fradkin},
	title = {{B}ayesian Multinomial Logistic Regression for Author
		Identification},
	booktitle = {25th International Workshop on Bayesian Inference and
		Maximum Entropy Methods in Science and Engineering},
	year = 2005
}

@article{MadimanBa07,
author={Madiman, Mokshay and Barron, Andrew}, 
journal = ieeeit,
title={Generalized Entropy Power Inequalities and Monotonicity Properties of Information},
year={2007}, 
volume={53}, 
number={7}, 
pages={2317--2329}, 
}

@article{MadryMaScTsVl17,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv:1706.06083 [stat.ML]},
  year=2017
}

@book{MagnusKaSo66,
author = 	{Wilhelm Magnus and Abraham Karrass and Donald Solitar},
title = 	{Combinatorial Group Theory:  Presentation of Groups in
		Terms of Generators and Relations},
publisher = 	{John Wiley \& Sons},
year = 		{1966},
address = 	{New York},
comment= 	{Discusses word problem and Cayley graph of a group}
}

@inproceedings{MairalBaPoSaZi08,
author = {Julien Mairal and Francis Bach and Jean Ponce and
  Guillermo Sapiro and Andrew Zisserman},
title = {Supervised Dictionary Learning},
year = 2008,
booktitle = nips21,
}

@inproceedings{MairalJeObBa10,
author = {J. Mairal and R. Jenatton and G. Obozinski and F. Bach},
title = {Network flow algorithms for structured sparsity},
year = 2010,
booktitle = nips23,
url = {http://arxiv.org/abs/1008.5209},
}

@article{MakhoulRoGi85,
author=   	{Makhoul, John and Salim Roucos and Herbert Gish},
title=    	{Vector Quantization in Speech Coding},
journal=  	{Proceedings of the IEEE},
volume=   	73,
number=   	11,
month=    	Nov,
year=     	1985,
pages=    	{1551--1588},
comment=  	{Excellent overview and introduction to vector quantization.}
}

@article{MaLi10,
author = {Yanyuan Ma and Runze Li},
title = {Variable selection in measurement error models},
year = 2010,
journal = {Bernoulli},
volume = 16,
number = 1,
pages = {274--300},
}

@article{MakMoWo99,
  title={Monte {C}arlo bounding techniques for determining solution
   quality in stochastic programs},
  author={Mak, Wai-Kei and Morton, David P and Wood, R Kevin},
  journal={Operations Research Letters},
  volume=24,
  number=1,
  pages={47--56},
  year=1999,
  publisher={Elsevier}
}

@article{MallatZa93,
	title = "Matching Pursuits with Time-Frequency Dictionaries",
	author = "S. Mallat and Z. Zhang",
	journal = "IEEE Transactions on Signal Processing",
	volume = 41,
	pages = "3397--3415",
	year = 1993
}

@article{Mallows57,
     title = {Non-Null Ranking Models},
     author = {Mallows, C. L.},
     journal = {Biometrika},
     volume = {44},
     number = {1/2},
     pages = {pp. 114-130},
     year = {1957},
 }

@article{Mallows73,
     title = {Some Comments on ${C}_P$},
     author = {Mallows, C. L.},
     journal = {Technometrics},
     volume = {15},
     number = {4},
     pages = {661--675},
     year = 1973,
}

@InProceedings{MaltzahnRiGrMa99,
  author = 	 {Carlos Maltzahn and Kathy Richardson and Dirk
                  Grunwald and James Martin},
  title = 	 {On Bandwidth Smoothing},
  booktitle = 	 {Fourth International Web Caching Workshop},
  year =	 1999
}

@article{Mammen91,
author = {Enno Mammen},
title = {Nonparametric regression under qualitative smoothness assumptions},
year = 1991,
journal = aos,
volume = 19,
number = 2,
pages = {741--759},
}

@article{MammenTs99,
author = {E.\ Mammen and A.\ B.\ Tsybakov},
title = {Smooth discrimination analysis},
year = 1999,
journal = aos,
volume = 27,
pages = {1808--1829},
}

@article{ManevaSi08,
author = {Elitza Maneva and Alistair Sinclair},
title = {On the satisfiability threshold and clustering of solutions of
   random 3-{SAT} formulas},
year = 2008,
journal = {Theoretical Computer Science},
volume = 407,
pages = {359--369},
number = {1--3},
url = {http://arxiv.org/abs/0710.0805},
}

@article{Mangasarian79,
author = {Olvi L. Mangasarian},
title = {Uniqueness of solution in linear programming},
year = 1979,
journal = {Linear Algebra and its Applications},
volume = 25,
pages = {151--162},
comment = {Shows that a necessary and sufficient condition for a vector
to be the unique solution to a linear program is that the vector still
be the solution if the objective $c^T x$ is perturbed by an arbitrarily
small linear term to be $(c + \epsilon)^T x$. The argument is via KKT
conditions still holding for such problems. Other equivalent conditions
are also given.},
}

@article{Mangasarian99,
    author = "O.L.~Mangasarian",
    title = "Arbitrary-norm separating plane",
    journal = "Operations Research Letters",
    volume = "24(1--2)",
    pages = "15--23",
    year = "1999"
}

@article{MangasarianFr67,
  title={The Fritz John necessary optimality conditions in the presence of equality and inequality constraints},
  author={Mangasarian, Olvi L and Fromovitz, Stanley},
  journal={Journal of Mathematical Analysis and Applications},
  volume=17,
  number=1,
  pages={37--47},
  year=1967,
  publisher={Elsevier},
  comment={Constraint qualification for KKT conditions that guarantees the set of dual optima is bounded.}
}

@Article{MangasarianMu99,
  author = 	 {O. Mangasarian and D. Musicant},
  title = 	 {Successive Overrelaxation for Support Vector Machines},
  journal = 	 {IEEE Transactions on Neural Networks},
  year = 	 {1999},
  volume = 	 {10}
}


@book{ManningRaSc08,
author = {C. Manning and P. Raghavan and H. Sch\"utze},
title = {Introduction to Information Retrieval},
year = 2008,
publisher = {Cambridge University Press},
}

@book{ManningSc99,
author = {Christopher Manning and Hinrich Sch\"utze},
year = 1999,
title = {Foundations of Statistical Natural Language Processing},
publisher = {MIT Press},
}

@inproceedings{MannMcMoSiWa09,
author = {Gideon Mann and Ryan McDonald and Mehryar Mohri and Nathan Silberman and Dan Walker},
booktitle = nips22,
pages = {1231--1239},
title = {{Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models}},
year = {2009},
}

@article{MannorMeZh03,
author = {Shie Mannor and Ron Meir and Tong Zhang},
title = {Greedy algorithms for classification---consistency,
   convergence rates and adaptivity},
year = 2003,
journal = jmlr,
volume = 4,
pages = {713--741},
}

@unpublished{Mansour90,
author=		{Yishay Mansour},
title=		{Learning via {F}ourier transform},
month=		apr,
year=		1990,
note=		{Unpublished manuscript}
}

@inproceedings{Mansour92,
author=		{Yishay Mansour},
title=		{Randomized interpolation and approximation of sparse
		 polynomials},
booktitle=	icalp92,
month=		jul,
year=		1992,
pages=		{261--272}
}

@InProceedings{Mansour97,
  author = 	 {Yishay Mansour},
  title = 	 {Pessimistic decision tree pruning based on tree size},
  booktitle = 	 {ml97},
  year =	 1997,
  pages =	 {195-201}
}

@article{MarcusSaMa94,
author = {M.P.\ Marcus and B.\ Santorini and M.A.\ Marcinkiewicz},
title = {Building a large annotated corpus of {E}nglish: the {P}enn {T}reebank},
year = 1994,
journal = {Computational Linguistics},
volume = 19,
pages = {313--330},
}

@article{MarcusSpSr13,
author = {Adam Marcus and Daniel Spielman and Nikhil Srivastava},
year = 2013,
title = {Interlacing Families {II}: Mixed Characteristic Polynomials and
The {K}adison-{S}inger Problem},
journal = {arXiv:1306.3969 [math.CO]},
url = {http://arxiv.org/abs/1306.3969},
}

@inproceedings{MargineantuDi97,
author =	{Dragos D. Margineantu and Thomas G. Dietterich},
title =		{Pruning Adaptive Boosting},
booktitle =	ml97,
pages =		{211--218},
year =		1997
}

@article{Marimon93
,author=	{Ramon Marimon}
,title=		{Adaptive learning, evolutionary dynamics and
		 equilibrium selection in games}
,journal=	{European Economic Review}
,volume=	37
,year=		1993
,pages=		{603--611}
}

@article{Markowitz52,
author = {H. Markowitz},
title = {Portfolio selection},
year = 1952,
journal = {The Journal of Finance},
volume = 7,
number = 1,
pages = {77--91},
}

@article{Marron87,
author=   	{Marron, Assaf and Ker-I Ko},
title=    	{Identification of Pattern Languages from Examples and
		Queries},
journal=  	infcomp,
volume=   	74,
number=   	2,
year=     	1987,
month=    	Aug,
pages=    	{91--112}
}

@techreport{Marroquin85,
author=   	{Marroquin, Jose Luis},
title=    	{Probabilistic Solution of Inverse Problems},
institution=  	{MIT AI Laboratory},
year=     	1985,
month=    	Sep,
number=   	{AI-TR-860},
comment=  	{Vision problems, Markov Random Fields, simulation techniques
		similar to simulated annealing used for Bayesian estimation.}
}

@article{Marsden68,
author = {James E. Marsden},
title = {Countable and Net Convergence},
year = 1968,
journal = {American Mathematical Monthly},
volume = 75,
number = 4,
}

@book{MarsdenHo93,
title = {Elementary Classical Analysis, Second Edition},
author = {Jerrold Marsden and Michael Hoffman},
year = 1993,
publisher = {W.H. Freeman},
}

@article{MarshallOl60,
author = {Albert W. Marshall and Ingram Olkin},
title = {Multivariate {C}hebyshev Inequalities},
year = 1960,
journal = {Annals of Mathematical Statistcs},
volume = {31},
number = 4,
pages = {1001--1014},
comment = {Considers estimation of probabilities $P(X \in T)$ for
 $X$ a random vector and $T$ a convex set. Uses polar characterizations
 of the sets $T$ and Markov's inequality to get (usuall quadratic) upper
 bounds on such probabilities. The applications are usually to
 products of the $X$ or minima.},
}

@book{MarshallOlAr11,
author = {Albert W. Marshall and Ingram Olkin and Barry C. Arnold},
title = {Inequalities: Theory of Majorization and Its Applications},
year = 2011,
edition = {Second},
publisher = {Springer},
}

@article{Marton98,
author = {K. Marton},
title = {Measure concentration for a class of random processes},
year = 1998,
journal = {Probability Theory and Related Fields},
volume = 110,
pages = {427--439},
comment = {One of the earlier works on concentration inequalities for
mixing processes, though perhaps not as easy to use as others, e.g. Samson's
work or Kontorovich's.},
}

@inproceedings{Massey90,
author = {James Massey},
title = {Causality, feedback and directed information},
year = 1990,
booktitle = {Proceedings of the International Symposium on Information
  Theory and its Applications (ISITA)},
pages = {303--305},
}

@article{Mason82,
  title={Laws of large numbers for sums of extreme values},
  author={Mason, David M},
  journal={The Annals of Probability},
  pages={754--764},
  year=1982,
  publisher={JSTOR}
}

@TechReport{MasonBaBa98,
  author = 	 {L. Mason and P. L. Bartlett and J. Baxter},
  title = 	 {Direct optimization of margins improves
                  generalization in combined classifiers},
  institution =  {Deparment of Systems Engineering, Australian
                  National University},
  year = 	 1998
}

@incollection{MasonBaBaFr99,
 author = "Llew Mason and Jonathan Baxter and
   Peter L. Bartlett and Marcus Frean",
	title = "Functional gradient techniques for combining hypotheses",
	booktitle = "Advances in Large Margin Classifiers",
	publisher = "MIT Press",
	year = 1999,
 comment = {Shows that boosting can be viewed as doing a coordinate-descent
  type algorithm in a function space, where at each iteration the weak
  learner chooses the function from the function space that maximizes
  an inner product with the gradient. Gives convergence arguments for some
  algorithms; arguments are nicely simple and straightforward. },
}

@InCollection{MasonBaBaFr99b,
  author = 	 {L. Mason and J. Baxter and P. L. Bartlett and M. Frean},
  title = 	 {Functional Gradient Techniques for Combining Hypotheses},
  booktitle = 	 {Advances in Large Margin Classifiers},
  publisher =	 {MIT Press},
comment= {editor=          {Alexander J. Smola and Peter J. Bartlett and
                  Bernhard Sch\"olkopf and Dale Schuurmans}},
  year =	 1999
}

@incollection{Massart03,
    author = {Pascal Massart},
    title = {Concentration Inequalities and Model Selection},
    year = {2003},
    booktitle = {Ecole d'Et\'e de Probabilit\'es de Saint-Flour XXXIII - 2003 Series},
    editor = {J. Picard},
    publisher = {Springer}
}

@mastersthesis{Mataric90,
author=		{Maja J. Mataric},
title=		{A Distributed Model for Mobile Robot
		 Environment-Learning and Navigation},
year=		1990,
month=		may,
school=		mit,
note=		{Technical Report AI-TR 1228, MIT Artificial
		 Intelligence Laboratory}
}

@book{Matousek02,
author = {Jiri Matousek},
title = {Lectures on Discrete Geometry},
year = 2002,
publisher = {Springer},
}

@article{Matthews91,
author=		{P. Matthews},
title=		{Generating a Random Linear Extension of a Partial
		 Order},
journal=	anprob,
volume=		19,
number=		3,
year=		1991,
pages=		{1367--1392}
}

@article{Maurey91,
  title={Some deviation inequalities},
  author={Bernard Maurey},
  journal={Geometric \& Functional Analysis GAFA},
  volume={1},
  number={2},
  pages={188--197},
  year={1991},
  publisher={Springer}
}

@article{MazurHa78
,author=	{James E. Mazur and Reid Hastie}
,title=		{Learning as accumulation: a reexamination of the
		 learning curve}
,year=		1978
}


@InProceedings{McCallumNi98,
	title = "Employing {EM} in Pool-Based Active Learning for
		Text Classification",
	author = "Andrew McCallum and Kamal Nigam",
	booktitle = ml98,
	year = 1998
}


@inproceedings{McCallumRoMiNg98,
    author = "A. K. McCallum and R. Rosenfeld and T. M. Mitchell and A. Y. Ng",
    title = "Improving text classification by shrinkage in a hierarchy of classes",
    booktitle = "Proceedings of {ICML}-98",
    pages = "359--367",
    year = "1998",
}


@InProceedings{McAllester98,
  author = 	 {David A. McAllester},
  title = 	 {Some PAC-Bayesian Theorems},
  year = 	 1998,
  booktitle = 	 colt98
}

@Inproceedings{McAllester03,
  author    = {David A. McAllester},
  title     = {Simplified {PAC}-Bayesian Margin Bounds.},
  year      = {2003},
  pages     = {203-215},
  booktitle = colt03
}

@Inproceedings{McAllesterSc00,
  author    = {D.A. McAllester and R.E. Schapire},
  title     = {On the convergence rate of good-turing estimators},
  year      = {2000},
  booktitle = colt00
}


@article{McCarthy56,
author=   	{McCarthy, John},
title=    	{Measures of the Value of Information},
journal=  	{Proceedings of the National Academy of Sciences},
year=     	1956,
volume=   	42,
pages=    	{654--655},
comment=  	{How to pay a weatherman to make honest predictions.
		Generalizes rule that pays him log(Pi) if event predicted with
		prob Pi happens.}
}

@inproceedings{McCarthy58,
author=   	{McCarthy, John},
title=    	{Programs with common sense},
booktitle=	{Proceedings of the Symposium on the Mechanization of Thought
           	Processes},
organization=	{National Physical Laboratory},
year=     	1958,
volume=   	1,
pages=    	{77-84},
note=     	{Reprinted in Minsky's (ed.) {\em Semantic Information
		Processing}, MIT Press(1968), 403--409}
}

@book{McClellandRu88,
editor=   	{McClelland, James L. and Rumelhart, David E.},
title=    	{Explorations in Parallel Distributed Processing: A Handbook
		of Models, Programs, and Exercises},
publisher=	{MIT Press},
year=     	1988,
comment=  	{Contains example of back-prop never converging on 1:1:1
		network}
}

@Article{McDiarmid89,
  author = 	 {C. McDiarmid},
  title = 	 {On the method of bounded differences},
  journal = 	 {Surveys in Combinatorics},
  year = 	 {1989},
  pages = 	 {148-188}
}

@inproceedings{McDonaldCrPe05,
    author = "Ryan McDonald and Koby Crammer and Fernando Pereira",
    title = "Online Large-Margin Training of Dependency Parsers",
    booktitle = "43rd Annual Meeting of the Association for Computational Linguistics",
    year = "2005",
    note = "to appear"
}

@inproceedings{McDonaldHaMa10,
author = {R. McDonald and K. Hall and G. Mann},
title = {Distributed Training Strategies for the Structured Perceptron},
booktitle = {North American Chapter of the Association for Computational Linguistics (NAACL)},
year = {2010},
}

@inproceedings{McDonaldPeRiHa05,
author = {Ryan McDonald and Fernando Pereira and Kiril Ribarov and Jan
                  Hajic},
title = {Non-Projective Dependency Parsing using Spanning Tree Algorithms},
booktitle = emnlp,
year = {2005},
}

@inproceedings{McGregorMiPiReTaVa10,
author = {Andrew McGregor and Ilya Mironov and Toniann Pitassi and
                  Omer Reingold and Kunal Talwar and Salil Vadhan},
title = {The limits of two-party differential privacy},
year = 2010,
booktitle = focs10,
comment = {
  Long version at
  \url{http://research.microsoft.com/en-us/people/mironov/2dplimits.pdf}.
  Studies privacy in a distributed setting where two parties perform
  analysis of joint data while preserving privacy for both datasets.
  Give lower bounds that show \Theta(\sqrt{n}) noise necessary for estimating
  the inner product of two binary vectors. Some questions on independence
  assumptions and results used in proof of this theorem (based on transcripts
  of what is communicated).
  Also shows that communication complexity and differential privacy
  are somewhat related, and gives bounds on some information-theoretic
  quantities as a function of differential privacy. Best bound
  is that if X = (X_1, \ldots, X_n) and Y = (Y_1, \ldots, Y_n) are private
  from one another in a communication protocol, then mutual information
  between them and a (private) transcript they compute, \Pi(X, Y), is bounded
  by I(X, Y; \Pi(X, Y)) \le \epsilon n. (Here \epsilon is differential
  privacy parameter.)
  This shows that 2-party privacy is strong: there are functions for
  which approximation to within o(n) requires n bits communicated, so
  they will have high error in any differentially private scheme.
},
}

@inproceedings{McSherryTa07,
author = {Frank McSherry and Kunal Talwar},
title = {Mechanism design via differential privacy},
year = 2007,
booktitle = focs07,
comment = {Shows that sometimes, differential privacy can be quite beneficial.
  Shows that if an auction is kept differentially private (or other mechanism
  design problem), then truth telling is almost dominant (lying can't
  improve things much). Also describes the exponential mechanism, which is
  to release an item v with probability proportional to
  exp(-\epsilon * L(v(x), v)), where L measures a loss for releasing v
  when v(x) is the true output on the data x.},
}

@Misc{McJones97,
	author = "P.~McJones",
	howpublished = "DEC Systems Research Center",
	title = "EachMovie collaborative filtering data set",
	note = "http:/$\!$/www.research.digital.com/SRC/eachmovie/",
	year = "1997"
}

@article{McKean85
,author=	{Kevin McKean}
,title=		{Decisions, decisions}
,year=		1985
}


@article{MacQueen65,
author=	{J. MacQueen},
title = {On convergence of k-means and partitions with minimum average variance},
journal = {Ann. Math. Statist.},
year = {1965},
}

@inproceedings{MaSaSaVo09,
title = {Identifying Malicious URLs: An Application of
 Large-Scale Online Learning},
author = {Justin Ma and Lawrence K. Saul and Stefan Savage
and Geoffrey M. Voelker},
year = 2009,
booktitle = icml09,
}

@inproceedings{MaurerPo09,
author = {Andreas Maurer and Massimiliano Pontil},
title = {Empirical {B}ernstein Bounds and Sample Variance Penalization},
year = 2009,
booktitle = colt09,
comment = {Shows a number of bounds based on minimizing empirical risk
 plus standard error of loss. Cute ideas.},
}

@inproceedings{McMahanSt10,
author = {Brendan McMahan and Matthew Streeter},
title = {Adaptive Bound Optimization for Online Convex Optimization},
booktitle = colt10,
year = 2010,
}

@article{Megiddo80
,author=   	{N. Megiddo}
,title=		{On repeated games with incomplete information played
		 by non-{Bayesian} players}
,journal=       {International Journal of Game Theory}
,volume=        {9}
,number=        {3}
,pages=         {157--167}
,year=          {1980}
}

@techreport{Megiddo86,
author=   	{Megiddo, Nimrod},
title=    	{On The Complexity of Polyhedral Separability},
institution= 	{IBM Almaden Research Center},
year=     	1986,
month=    	Aug,
number=   	{RJ 5252}
}

@article{MegiddoVi88,
author=		{Megiddo, Nimrod and Uzi Vishkin},
title=		{On Finding a Minimum Dominating Set in a Tournament},
journal=	{Theoretical Computer Science},
year=		1988,
month=          Nov,
volume=		61,
number=		{2-3},
pages=		{307--316},
comment=  	{A problem that is equiv. to CNF with log**2 n variables}
}

@article{MeiBaMo16,
author = {Song Mei and Yu Bai and Andrea Montanari},
title = {The Landscape of Empirical Risk for Non-convex Losses},
year = 2016,
journal = {arXiv:1607.06534 [stat.ML]},
}

@article{MeinshausenBu06,
author = {N. Meinshausen and P. B\"uhlmann},
title = {High dimensional graphs and variable selection with the {L}asso},
year = 2006,
journal = {Annals of Statistics},
volume = 34,
pages = {1436-1462},
}

@article{Meir00,
author = {R. Meir},
title = {Nonparametric time series prediction through adaptive model
 selection},
year = 2000,
journal = mlj,
volume = 39,
pages = {5--34},
}

@inproceedings{MeirRa03,
author=   	{R. Meir and G. R\"{a}tsch },
title=    	{An introduction to boosting and leveraging},
booktitle=	{Advanced Lectures on Machine Learning},
editor=         {S. Mendelson and A. Smola},
year=     	2003,
pages=    	{119-184},
publisher=	{Springer}
}

@article{MeirZh03,
 author = {Ron Meir and Tong Zhang},
 title = {Generalization error bounds for Bayesian mixture algorithms},
 journal = jmlr,
 volume = 4,
 year = 2003,
 issn = {1533-7928},
 pages = {839--860},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
 }

@article{Mendelson02,
  title={Geometric parameters of kernel machines},
  author={Mendelson, Shahar},
  journal={Lecture notes in computer science},
  pages={29--43},
  year=2002,
  publisher={Springer}
}

@article{Mendelson02b,
  title={Improving the sample complexity using global data},
  author={Mendelson, Shahar},
  journal={IEEE transactions on Information Theory},
  volume=48,
  number=7,
  pages={1977--1991},
  year=2002,
  publisher={IEEE},
  comment={Gives covering number bounds in a number of scenarios,
                  including kernel classes.}
}

@article{Mendelson03,
  title={On the performance of kernel classes},
  author={Mendelson, Shahar},
  journal={Journal of Machine Learning Research},
  volume=4,
  number={Oct},
  pages={759--771},
  year=2003,
  comment={Gives a bound on the second-moment localized Rademacher
                  complexity of kernel classes that depends on the
                  spectrum of the kernel. These bounds are
                  distribution dependent results in that the
                  eigenvalues considered here are defined with respect
                  to the L_2(P)-norm where P is the underlying measure
                  of interest. See ShiBeYu08, ShiBeYu09, MinhNiYa06.}
}


@inproceedings{Mendelson14,
author = {Shahar Mendelson},
title = {Learning without Concentration},
year = 2014,
booktitle = colt14,
comment = {Shows sharper localized complexity bounds for regression
  tasks, including for some heavy-tailed data, by arguing that in
  many cases one only needs bounds of the form
  $(1/2) \E[f^2] \le \hat{E}[f^2]$, at least for parts of the
  local complexity structure, which is much easier to satisfy
  (as large infrequence values $f(X)$ only help.) Defines some
  new notions of complexity that take into account the interaction
  of the class of functions with the noise, which can yield faster rates.},
}

@article{MendelsonNe10,
  title={Regularization in kernel learning},
  author={Mendelson, Shahar and Neeman, Joseph and others},
  journal={The Annals of Statistics},
  volume=38,
  number=1,
  pages={526--565},
  year=2010,
  publisher={Institute of Mathematical Statistics},
  comment={One minor lemma they show is a Mendelson03-type bound on
                  localized Rademacher averages of the star-hull of
                  the original function class.}
}
@inproceedings{MengWeWiHe13,
author = {Z. Meng and D. Wei and Ami Wiesel and Alfred O. Hero},
title = {Distributed Covariance Estimation in Gaussian
  Graphical Models},
year = 2013,
booktitle = aistat13,
}

@article{MengersenTw96,
     title = {Rates of Convergence of the Hastings and Metropolis Algorithms},
     author = {Mengersen, K. L. and Tweedie, R. L.},
     journal = {The Annals of Statistics},
     volume = {24},
     number = {1},
     pages = {pp. 101-121},
     year = {1996},
     publisher = {Institute of Mathematical Statistics},
    }


@article{MerhavFe93
,author=	{N. Merhav and M. Feder}
,title=		{Universal Schemes for Sequential Decision from
		 Individual Data Sequences}
,journal=	{IEEE Transactions on Information Theory}
,volume=	39
,number=	4
,year=		1993
,pages=		{1280-1292}
}

@article{MerhavFe95,
author = {Neri Merhav and Meir Feder},
title = {A strong version of the redundancy-capacity theorem of universal
  coding},
journal = ieeeit,
year = 1995,
volume = 41,
number = 3,
pages = {714--722},
comment = {Shows that, in universal coding, minimax priors/optimal coding
  schemes are also nearly optimal (not very reduntant) for "most"
  points in the space.},
}

@article{MerhavFe98,
author = {Neri Merhav and Meir Feder},
title = {Universal Prediction},
year = 1998,
journal = ieeeit,
volume = 44,
number = 6,
pages = {2124--2147},
comment = {Survey of much of universal prediction literature up to 1998},
}

@Article{MerhavFeGu93,
  author = 	 {Neri Merhav and Meir Feder and Michael Gutman},
  title = 	 {Some Properties of Sequential Predictors for Binary
		{M}arkov Sources},
  journal = 	 ieeeit,
  year = 	 1993,
  volume =	 39,
  number =	 3,
  month =	 may,
  pages =	 {887-892}
}

@inproceedings{Merialdo91
,author=	{Bernard Merialdo}
,title=		{Tagging text with a probabilistic model}
,year=		1991
}

@misc{MerzMu98,
   author = "C. J. Merz and P. M. Murphy",
   year = "1998",
   title = "{UCI} Repository of machine learning databases",
   url = "http://www.ics.uci.edu/$\sim$mlearn/MLRepository.html",
   institution = "University of California, Irvine, Department of Information
                     and Computer Sciences" ,
   note= "www.ics.uci.edu/$\sim$mlearn/MLRepository.html"
}

@misc{MerzMu99,
   author = "C. J. Merz and P. M. Murphy",
   year = "1999",
   title = "{UCI} Repository of machine learning databases",
   url = "http://www.ics.uci.edu/$\sim$mlearn/MLRepository.html",
   institution = "University of California, Irvine, Department of Information
                     and Computer Sciences" ,
   note= "www.ics.uci.edu/$\sim$mlearn/MLRepository.html"
}

@InProceedings{Mesterharm99,
author = {C.~Mesterharm},
title = {A Multi-clss Linear Learning Algorithm Related to Winnow},
booktitle = {Advances in Neural Information Processing Systems 13},
year = 1999
}

@inproceedings{Mesterharm05,
author = {Chris Mesterharm},
title = {On-line learning with delayed feedback},
year = 2005,
booktitle = {Algorithmic Learning Theory},
pages = {399--413},
}

@book{MeynTw09,
author = {S. Meyn and R. L. Tweedie},
title = {Markov Chains and Stochastic Stability},
year = 2009,
edition = {{S}econd},
publisher = {Cambridge University Press},
}

@incollection{Michalski86,
author=   	{Michalski, Ryszard},
title=    	{Understanding the Nature of Learning: Issues and Research
		Directions},
booktitle=	{Machine Learning, An Artificial Intelligence Approach
		(Volume II)},
publisher=	{Morgan Kaufman},
year=     	1986,
pages=    	{3--25}
}

@book{MichalskiCaMi83,
editor = 	{Ryszard S. Michalski and Jaime G. Carbonell and Tom M. Mitchell},
title = 	{Machine Learning: An Artificial Intelligence Approach},
publisher = 	{Morgan Kaufmann},
year = 		1983,
comment = 	{This is volume I of the series.
		 address = Los Altos, California}
}

@book{MichalskiCaMi86,
editor = 	{Ryszard S. Michalski and Jaime G. Carbonell and Tom M. Mitchell},
title = 	{Machine Learning: An Artificial Intelligence Approach},
publisher = 	{Morgan Kaufmann},
year = 		1986,
volume=		{II},
comment=	{address = {Los Altos, California}}
}

@article{MikaRaWeScSmMu03,
   author = {Mika, S. and G. R\"{a}tsch and J. Weston and B. Sch\"olkopf and
        A.J. Smola and K.-R. M\"{u}ller},
   title = {Constructing Descriptive and Discriminative Non-linear
        Features: Rayleigh Coefficients in Kernel Feature Spaces},
   year = {2003},
   volume = {25},
   number = {4},
   journal = {IEEE Transactions on Pattern Analysis and Machine
Intelligence}
}

@inproceedings{MikolovSuChCoDe13,
author = {Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado
  and Jeff Dean},
title = {Distributed representations of words and phrases and their
  compositionality},
year = 2013,
booktitle = nips26,
}

@article{Miller56,
author=		{Miller, G.},
title=		{The magic number seven, plus or minus two:  Some limits on
		our capacity for processing information},
journal=	{Psychology Review},
volume=		63,
year=		1956,
pages=		{81--97},
comment=	{The classic paper that says humans can hold 7 +/- 2 'chunks'
		in short term memory. But it also talks about perception of
                relative versus non-relative judgments.}
}

@inproceedings{MinhNiYa06,
  title={Mercer's theorem, feature maps, and smoothing},
  author={Minh, Ha Quang and Niyogi, Partha and Yao, Yuan},
  booktitle={COLT},
  volume=6,
  pages={154--168},
  year=2006,
  organization={Springer},
  comment={Among other things, gives eigen-analysis for the polynomial
                  and Gaussian kernel with respect to various L_2
                  norms (uniform on the sphere, hypercube etc).}
}

@book{MinskyPa69,
author = 	{M. Minsky and S. Papert},
title = 	{Perceptrons: An Introduction to Computational Geometry},
publisher = 	{The MIT Press},
year = 		1969,
comment = 	{Classic analysis of the capabilities of the perceptron.}
}

@article{Mingers89,
author = {J.~Mingers},
title = {An empirical comparison of selection measures for decision-tree
  induction},
journal = {Machine Learning Journal},
year = {1989}
}

@inproceedings{Mironov17,
author = {Ilya Mironov},
title = {R\'{e}nyi Differential Privacy},
year = 2017,
booktitle = {30th IEEE Computer Security Foundations Symposium (CSF)},
pages = {263--275},
}

@inproceedings{Mitchell77,
author=   	{Mitchell, Tom M.},
title=    	{Version Spaces: A Candidate Elimination Approach to Rule
		Learning},
booktitle=	{Proceedings of the
		 5th International Joint Conference on Artificial
		 Intelligence},
year=     	1977,
month=    	Aug,
pages=    	{305--310}
}

@article{Mitchell93
,author=	{Douglas W. Mitchell}
,title=		{Computationally convenient optimal intertemporal
		 portfolios under linear constraints}
}

@book{Mitchell97,
author=		{Tom M. Mitchell},
title=		{Machine Learning},
publisher=	{McGraw Hill},
year=		1997
}

@incollection{MitchellBuDeDiRoWa90,
author=		{Tom Mitchell and Bruce Buchanan and Gerald DeJong and
		 Thomas Dietterich and Paul Rosenbloom and Alex Waibel},
title=		{Machine Learning},
booktitle=	{Annual Review of Computer Science},
volume=		4,
year=		{1990},
editor=		{Joseph F. Traub and Barbara J. Grosz and Butler W.
		 Lampson and Nils J. Nilsson},
publisher=	{Annual Reviews},
pages=		{417--433},
comment=	{address= Palo Alto}
}

@book{MitchellCaMi86,
editor=		{Tom M. Mitchell and Jaime G. Carbonell and
		 Ryszard S. Michalski},
title=		{Machine Learning: A Guide to Current Research},
publisher=	{Kluwer Academic Publishers},
year=		1986,
comment=	{address= Boston/Dordrecht/Lancaster}
}

@article{MiyatoMaKoNaIs15,
  title={Distributional smoothing with virtual adversarial training},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Nakae, Ken and Ishii, Shin},
  journal={arXiv:1507.00677 [stat.ML]},
  year=2015
}

@article{Mokkadem88,
author = {Abdelkader Mokkadem},
title = {Mixing properties of {ARMA} processes},
year = 1988,
journal = {Stochastic Processes and their Applications},
volume = 29,
number = 2,
pages = {309--315},
comment = {Discusses geometric ergodicity of linear ARMA models. A little
  hard to read, but reasonably understandable.},
}

@article{Mokkadem90,
  title={Propri{\'e}t{\'e}s de m{\'e}lange des processus autor{\'e}gressifs polynomiaux},
  author={Mokkadem, Abdelkader},
  journal={Ann. Inst. H. Poincar{\'e} Probab. Statist},
  volume=26,
  number=2,
  pages={219--260},
  year=1990,
  comment={The article is in French. Gives sufficient conditions for
                  polynomial AR processes to be geometrically
                  beta-mixing (absolutely regular). See Section 2.4.1
                  of Doukhan94's book Mixing for a more readable
                  version in English.}
		  }
		  
@article{MonteiroBe13,
	title={An accelerated hybrid proximal extragradient method for convex optimization and its implications to second-order methods},
	author={Monteiro, Renato DC and Svaiter, Benar Fux},
	journal={SIAM Journal on Optimization},
	volume=23,
	number=2,
	pages={1092--1125},
	year=2013,
	publisher={SIAM}
}

@incollection{Moore56,
author=		{Edward F. Moore},
title=		{Gedanken-Experiments on Sequential Machines},
pages=		{129--153},
booktitle=	{Automata Studies},
editor=		{C. E. Shannon and J. McCarthy},
year=		1956,
publisher=	{Princeton University Press}
}

@unpublished{MooreAt94
,author=	{Andrew W. Moore and Christopher G. Atkeson}
,title=		{The parti-game algorithm for variable resolution
		 reinforcemnt learning in multidimensional
		 state-spaces}
}

@unpublished{MooreAt??
,author=	{Andrew W. Moore and Christopher G. Atkeson}
,title=		{Prioritized sweeping: reinforcement learning with
		 less data and less real time}
}

@inproceedings{Moosavi-DezfooliFaFr16,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2574--2582},
  year=2016
  }

@article{Moreau75,
author = {J. Moreau},
title = {Intersection of moving convex sets in a normed space},
year = 1975,
journal = {Mathematica Scandinavica},
pages = {159--173},
volume = 36,
}

@article{Mosk-AoyamaRoSh2010,
author = {D. Mosk-Aoyama and T. Roughgarden and D. Shah},
title = {Fully Distributed Algorithms for Convex Optimization Problems},
publisher = {SIAM},
year = {2010},
journal = {SIAM Journal on Optimization},
volume = {20},
number = {6},
pages = {3260-3279},
}

@article{Mosteller51,
author = {F.\ Mosteller},
title = {Remarks on the method of paired comparisons: {I}. {T}he least squares
solution assuming equal standard deviations and equal correlations},
year = 1951,
journal = {Psychometrika},
volume = 16,
number = 1,
pages = {3--9},
}

@Book{MostellerRoTh61,
  author = 	 {Mosteller, F. and Rourke, R. E. K. and Thomas, G. B.},
  title = 	 {Probability and Statistics},
  publisher = 	 {Addison-Wesley},
  year = 	 {1961}
}

@book{MotwaniRa95,
author = {Rajeev Motwani and Prabhakar Raghavan},
title= {Randomized Algorithms},
year = 1995,
publisher = {Cambridge University Press},
}

@Article{MotzkinSt65,
  author = 	 {T.S. Motzkin and E.G. Straus},
  title = 	 {Maxima for graphs and a new proof of a theorem by Turan},
  journal = 	 {Canadian Journal of Math.},
  year = 	 1965,
  volume =	 17,
  pages =	 {533--540}
}

@inproceedings{MoulinierRaGa96
,author=        {Isabelle Moulinier and Gailius {Ra\v{s}kinis} and
                  Jean-Gabriel Ganascia}
,title=         {Text categorization: a symbolic approach}
,booktitle=     {Fifth Annual Symposium on Document Analysis and
                  Information Retrieval}
,pages=         {87-99}
,year=          1996
}

@article{MurtyKa87,
author = {Katta Murty and Santosh Kabadi},
title = {Some {NP}-Complete Problems in Quadratic and Nonlinear Programming},
year = 1987,
journal = mathprog,
volume = 39,
pages = {117--129},
comment = {Shows how even deciding whether the point $x = 0$ is a
  local minimum for the optimization problem $\min. x^T A x$
  s.t. $x \ge 0$, where $A$ is indefinite, is NP hard. Reduces problem
  to subset sum.},
}

@article{MurphyPa94
,author=	{Patrick M. Murphy and Michael J. Pazzani}
,title=		{Exploring the decision forest: an empirical
		 investigation of {Occam's} razor in decision tree
		 induction}
}

@inproceedings{MuscoMu15,
	title={Randomized block {K}rylov methods for stronger and faster
approximate singular value decomposition},
	author={Musco, Cameron and Musco, Christopher},
	booktitle=nips28,
	year={2015},
}

@article{Mykland95,
  title={Dual likelihood},
  author={Mykland, Per Aslak},
  journal={The Annals of Statistics},
  pages={396--421},
  year=1995,
  publisher={JSTOR}
}

@article{NagaevCh11,
author = {S. V. Nagaev and V. I. Chebotarev},
title = {On the bound of proximity of the binomial distribution to the
normal one},
year = 2011,
journal = {Doklady Mathematics},
pages = {19--21},
volume = 83,
number = 1,
}

@article{NagarajPa14,
  title={Stochastically constrained simulation optimization on integer-ordered spaces: The cgR-SPLINE algorithm},
  author={Nagaraj, Kalyani and Pasupathy, Raghu},
  journal={Optimization Online Preprint},
  url={http://www.optimization-online.org/DB_FILE/2015/10/5139.pdf},
  year=2014
}

@article{NakamuraAb95
,author=	{Atsuyoshi Nakamura and Naoki Abe}
,title=		{Exact learning of linear combinations of monotone
		 terms from function value queries}
}

@inproceedings{NamkoongDu16,
author = {Hongseok Namkoong and John C. Duchi},
title = {Stochastic Gradient Methods for Distributionally
  Robust Optimization with $f$-divergences},
year = 2016,
booktitle = nips29,
}

@inproceedings{NamkoongDu17,
 author = {Hongseok Namkoong and John C. Duchi},
 title = {Variance Regularization with Convex Objectives},
 year = 2017,
 booktitle = nips30,
 }

@article{NarendraTh74,
author=   	{Narendra, Kumpati S. and M. A. L. Thathachar},
title=    	{Learning Automata -- A Survey},
journal=  	{IEEE Transactions on Systems, Man, and Cybernetics},
year=     	1974,
volume=   	{SMC-4},
number=   	4,
pages=    	{323--334},
comment=  	{Stochastic automata that adapt behavior under reinforcement
		schemes}
}

@book{NarendraTh89
,author=   	{Kumpati S. Narendra and Mandayam A. L. Thathachar}
,title=    	{Learning Automata: An Introduction}
,year=		1989
,publisher=	{Prentice Hall}
}

@article{NashSo96,
author = {Stephen Nash and Ariela Sofer},
title = {Preconditioning reduced matrices},
year = 1996,
journal = simat,
volume = 17,
number = 1,
pages = {47--68},
}

@inproceedings{Natarajan87,
author=   	{B. K. Natarajan},
title=    	{On Learning Boolean Functions},
booktitle=	stoc87,
address=  	{New York, New York},
year=     	1987,
month=    	May,
pages=    	{296--304}
}

@inproceedings{Natarajan89,
author=   	{B. K. Natarajan},
title = 	{On Learning From Excercises},
booktitle = 	colt89,
address = 	{Santa Cruz, Cal.\ },
year = 		1989,
month=          August,
pages=          {72--87}
}

@article{Natarajan95,
author = {Balas K. Natarajan},
title = {Sparse approximate solutions to linear systems},
year = 1995,
journal = {SIAM Journal on Computing},
volume = 24,
number = 2,
pages = {227--234},
}

@slides{Neapolitan97
,author=         {Rich Neapolitan}
,title=          {Learning causes from statistical data}
}

@article{NecoaraNeGl11,
  title={A random coordinate descent method on large optimization
                  problems with linear constraints},
  author={Necoara, I and Nesterov, Y and Glineur, F},
  journal={University Politehnica Bucharest, Tech. Rep},
  year=2011
}

@phdthesis{Nedic02,
author = {Angelia Nedi\'{c}},
title = {Subgradient Methods for Convex Minimization},
year = 2002,
school = mit,
}

@article{NedicBe01,
author = {A. Nedi\'{c} and D. P. Bertsekas},
title = {Incremental subgradient methods for nondifferentiable optimization},
year = 2001,
journal = siopt,
volume = 12,
pages = {109--138},
comment = {One of the earlier papers on stochastic gradient; specifically
for functions of the form $f(x) = \sum_{i=1}^n f_i(x)$, shows that randomly
choosing an index gives good expected convergence rate.}
}

@incollection{NedicBeBo01,
author = {A. Nedi\'{c} and D.P. Bertsekas and V.S. Borkar},
title = "Distributed asynchronous incremental subgradient methods",
editor = {D. Butnariu and Y. Censor and S. Reich},
booktitle = "Inherently Parallel Algorithms in Feasibility and Optimization and their Applications",
publisher = "Elsevier",
year = "2001",
volume = "8",
pages = {381--407},
series = "Studies in Computational Mathematics",
}

@article{NedicOz09,
author = {A. Nedi\'{c} and A. Ozdaglar},
title = {Distributed subgradient methods for multi-agent optimization},
journal = ieeetac,
volume = 54,
pages = {48--61},
year = 2009,
}

@article{NedicOlOzTs09,
author = {Nedi\'{c}, A. and Olshevsky, A. and Ozdaglar, A. and Tsitsiklis, J. N.},
journal={IEEE Transactions on Automatic Control},
title={On Distributed Averaging Algorithms and Quantization Effects},
year={2009},
volume={54},
number={11},
pages={2506 -2517},
}

@inproceedings{NeedellWaSr14,
  title={Stochastic gradient descent, weighted sampling, and the randomized
   {K}aczmarz algorithm},
  author={Needell, Deanna and Ward, Rachel and Srebro, Nati},
  booktitle=nips27,
  pages={1017--1025},
  year=2014
}

@inproceedings{NegahbanWa08,
  author = "S.~Negahban and M.~Wainwright",
  title = "Phase transitions for high-dimensional joint support recovery",
  booktitle = nips21,
  year = 2008
}

@article{NegahbanWa10,
author = {S. Negahban and M. J. Wainwright},
title = {Estimation of (near) low-rank matrices with noise and high-dimensional
         scaling},
journal = aos,
year = 2011,
volume = 39,
number = 2,
pages = {1069--1097},
}

@article{NegahbanRaWaYu12,
author = {Sahand Negahban and Pradeep Ravikumar and Martin Wainwright and
Bin Yu},
title = {A Unified Framework for High-Dimensional Analysis of ${M}$-Estimators
 with Decomposable Regularizers},
year = 2012,
journal = {Statistical Science},
volume = 27,
number = 4,
pages = {538--557},
}

@article{Nemirovski04,
author = {Arkadi Nemirovski},
title = {Prox-method with rate of convergence $O(1/t)$ for
variational inequalities with {L}ipschitz continuous
monotone operators and smooth convex-concave
saddle point problems},
year = 2004,
journal = siopt,
volume = 15,
pages = {229--251},
}

@unpublished{Nemirovski94,
author = {Arkadi Nemirovski},
title = {Efficient Methods in Convex Programming},
note = {Technion: The Israel Institute of Technology},
year = 1994,
}

@article{Nemirovski92,
author = {Arkadi Nemirovski},
title = {Information-based complexity of linear operator equations},
year = 1992,
journal = {Journal of Complexity},
volume = 8,
number = 2,
pages = {153--175},
}

@unpublished{Nemirovski05,
author = {Arkadi Nemirovski},
year = 2005,
title = {Lectures on Modern Convex Optimization},
note = {Georgia Institute of Technology},
}

@article{NemirovskiJuLaSh09,
author = {A. Nemirovski and A. Juditsky and G. Lan and A. Shapiro},
title = {Robust stochastic approximation approach to stochastic programming},
year = 2009,
journal = siopt,
volume = 19,
number = 4,
pages = {1574--1609},
}

@article{NemirovskiSh06,
  title={Convex approximations of chance constrained programs},
  author={Nemirovski, Arkadi and Shapiro, Alexander},
  journal={SIAM Journal on Optimization},
  volume=17,
  number=4,
  pages={969--996},
  year=2006,
  publisher={SIAM}
}

@book{NemirovskiYu83,
author = {A. Nemirovski and D. Yudin},
title = {Problem Complexity and Method Efficiency in Optimization},
year = 1983,
publisher = {Wiley},
comment = {Huge book that shows all the lower complexity results for convex
           optimization. Very very difficult and also hard to find.}
}

@book{NesterovNe94,
author = {Y. Nesterov and A. Nemirovski},
title = {Interior-Point Polynomial Algorithms in Convex Programming},
publisher = {SIAM Studies in Applied Mathematics},
year = {1994}
}

@article{Nesterov83,
author = {Yurii Nesterov},
title = {A method of solving a convex programming problem with convergence rate ${O}(1/k^2)$},
Number = {2},
pages = {372--376},
Volume = {27},
Journal = {Soviet Mathematics Doklady},
Year = {1983}}


@incollection{Nesterov00,
author = {Yurii Nesterov},
title = {Squared Functional Systems and Optimization Problems},
year = 2000,
booktitle = {High Performance Optimization},
publisher = {Springer},
pages = {405--440},
volume = 33,
series = {Applied Optimization},
}

@book{Nesterov04,
author = {Y. Nesterov},
title = {Introductory Lectures on Convex Optimization},
publisher = {Kluwer Academic Publishers},
year = {2004},
}

@TechReport{Nesterov05,
  author = 	 {Y. Nesterov},
  title = 	 {Primal-dual subgradient methods for convex problems},
  institution =  {Center for Operations Research and Econometrics (CORE), Catholic University of Louvain (UCL)},
  year = 	 {2005}
}

@article{Nesterov05b,
author = {Y. Nesterov},
title = {Smooth minimization of nonsmooth functions},
journal = mathproga,
year = 2005,
volume = 103,
pages = {127--152},
}

@techreport{Nesterov07,
author = {Y. Nesterov},
title = {Gradient methods for minimizing composite objective function},
year = 2007,
institution = {Center for Operations Research and Econometrics (CORE),
   Catholic University of Louvain (UCL)},
number = 76,
}

@article{Nesterov09,
  author = 	 {Y. Nesterov},
  title = 	 {Primal-dual subgradient methods for convex problems},
  journal = {Mathematical Programming},
  volume = 120,
  year = 	 {2009},
  pages = {261--283},
  number = 1,
}

@techreport{Nesterov11,
author = {Yurii Nesterov},
title = {Random Gradient-Free Minimization of Convex Functions},
year = 2011,
institution = {Center for Operations Research and Econometrics (CORE),
  Catholic University of Louvain (UCL)},
number = 2011001,
comment = {See also Alekh Agarwal's paper in COLT 2010 doing the
  same thing. Uses normal smoothing to use two-sample views of a function
  to get unbiased estimates of the gradient. Suffers a dimension-dependent
  penalty for using function values rather than gradients.
},
}

@article{Nesterov12b,
	Author = {Yurii Nesterov},
	Journal = {Optima},
	Title = {How to Make the Gradients Small},
	Year = {2012},
volume = 88,
}

@article{Nesterov12,
  title={Efficiency of coordinate descent methods on huge-scale
                  optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume=22,
  number=2,
  pages={341--362},
  year=2012,
  publisher={SIAM}
}

@article{Nesterov15,
author = {Yurii Nesterov},
title = {Universal gradient methods for convex optimization problems},
year = 2015,
journal = {Mathematical Programming Series A},
volume = 152,
pages = {381--404},
comment = {Provides gradient-based methods that are universally optimal for
  all classes of convex optimization problems with H\"older-continuous
  gradients, meaning $\dnorm{\nabla f(x) - \nabla f(y)} \le L \norm{x - y}^\nu$
  for some $\nu \in [0, 1]$. Using appropriate Bregman divergences, shows
  that with small enough stepsize, it is possible to get $\epsilon$-close to
  guaranteed descent directions with the usual quadratic/Bregman divergence
  model of the local version of the objective function. Also gives a
  line-search method that makes it unnecessary to know either the constant
  L or even the parameter $\nu$. The simple gradient-type method achieves
  convergence rate $(1/\epsilon)^{2 / (1 + \nu)}$, while an accelerated
  method achieves rate $(1/\epsilon)^{2 / (1 + 3\nu)}$, which is universally
  optimal.},
}

@article{NesterovPo06,
author = {Yurii Nesterov and Boris Polyak},
title = {Cubic regularization of {N}ewton method and its global performance},
year = 2006,
journal = mathproga,
volume = 108,
pages = {177--205},
}

@book{NeterWaKu83,
author = {J.~Neter and W.~Wasserman and M.~Kutner},
title = {Applied Linear Regression Models},
publisher = {McGraw-Hill},
year = {1983}
}

@inproceedings{NetrapalliJaSa13,
author = {Praneeth Netrapalli and Prateek Jain and Sujay Sanghavi},
title  = {Phase Retrieval using Alternating Minimization},
year = 2013,
booktitle = nips26,
}

@article{Neumann28,
author = {J. von Neumann},
title = {Zur Theorie der Gesellschaftsspiele (On the Theory of Parlor Games)},
journal = {Math. Ann.},
volume = {100},
year = {1928},
pages = {295–-320}
}

@article{Neumaier15,
author = {Arnold Neumaier},
title = {{OSGA}: a fast subgradient algorithm with optimal complexity},
journal = mathproga,
doi = {10.1007/s10107-015-0911-4},
volume = {online first},
month = {May},
year = 2015,
}

@Book{Neveu75,
  author = 	 {J. Neveu},
  title = 	 {Discrete-Parameter Martingales},
  publisher = 	 {North Holland},
  year = 	 1975
}

@article{NeweySm04,
author = {Whitney Newey and Richard Smith},
title = {Higher Order Properties of Gmm and Generalized Empirical 
    Likelihood Estimators},
journal = {Econometrica},
volume = 72,
number = 1,
pages = {219–-255},
year = 2004,
}

@inproceedings{NgGoLo97
,author=         {H.~T.~Ng and W.~B.~Goh and K.~L.~Low}
,title=          {Feature Selection, Perceptron Learning, and a
                  Usability Case Study for Text Categorization}
,booktitle=      sigir97
,year=           1997
,pages=          {67-73}
}

@inproceedings{NgJoWe01,
	author =  "A.Y.~Ng and M.I.~Jordan and Y.~Weiss",
	title = "On Spectral Clustering: Analysis and an Algorithm",
	booktitle = nips14,
	year = 2001
}

@inproceedings{Ng04,
	author =  "A.Y.~Ng",
	title = "Feature Selection, $L_1$ vs. $L_2$ regularization, and rotational invariance",
	booktitle = icml04,
	year = 2004
}

@inproceedings{NgoPoReRu12,
author = {Hung Ngo and Ely Porat and Christopher R\'e and Atri Rudra},
year = 2012,
title = {Worst case optimal join algorithms},
booktitle = {Principles of Database Systems},
}

@article{NguyenWaJo05,
author = {Xuanlong Nguyen and Martin J. Wainwright and Michael I. Jordan},
title = {Nonparametric decentralized detection using kernel methods},
year = 2005,
journal = {IEEE Transactions on Signal Processing},
volume = 53,
number = 11,
}

@article{NguyenWaJo09,
author = {Xuanlong Nguyen and Martin J. Wainwright and Michael I. Jordan},
title = {On surrogate loss functions and $f$-divergences},
year = 2009,
journal = aos,
volume = 37,
number = 2,
pages = {876--904},
}

@inproceedings{NguyenYoCl15,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={427--436},
  year=2015
}

@inproceedings{Niblett87,
author=	   	{Niblett, T.},
title=	   	{Constructing Decision Trees in Noisy Domains},
booktitle= 	{Progress in Machine Learning--Proceedings of EWSL 87:
	   	2nd European Working Session on Learning},
address=   	{Bled, Yugoslavia},
year=	   	1987,
editor=	   	{Bratko, I. and N. Lavrac},
month=	   	may,
pages=	   	{67--78}
}

@article{NigamMcThMi00,
        author = "K. Nigam and A. McCallum and S. Thrun
                  and T. Mitchell",
        title = "Text Classification from Labeled and
                 Unlabeled Documents using EM",
        journal = "Machine Learning",
        volume = "39(2/3)",
        pages = "103--134",
        year = 2000
}

@InProceedings{NigamMcThMi98,
	author = "Kamal Nigam and Andrew McCallum and
		Sebastian Thrun and Tom Mitchell",
	title = "Learning to Classify Text from Labeled and Unlabeled Documents",
	booktitle = aaai98,
	year = 1998,
	note = "Long version to appear in {Machine Learning}"
}

@inproceedings{NikolovTaZh13,
author = {Aleksandar Nikolov and Kunal Talwar and Li Zhang},
title = {The geometry of differential privacy: the sparse and approximate
case},
booktitle = stoc13,
year = 2013,
}

@inproceedings{NissimRaSm07,
author = {Kobbi Nissim and Sofya Raskhodnikova and Adam Smith},
title = {Smooth Sensitivity and Sampling in Private Data Analysis},
year = 2007,
booktitle = stoc07,
comment = {Describes algorithms that take advantage of local smoothness
  in a function f being released when evaluated on a sample or data set $X$.
  Specifically, if the local modulus of
  continuity (not their words) of $f$ at $x$ is small, then not very much
  noise needs to be added to $f(x)$ to maintain privacy.
  They give a construction of privacy based on smoothing out the local
  modulus of continuity, then adding some type of noise, but the density
  of noise added for differential privacy was a bit strange (required
  sampling from a Cauchy, and it was quite unclear how to do in higher
  dimensions). General strategy, for when sensitivity is unknown, of
  aggregating median of $f(x_U)$ where $U$ is some sub-sampled version
  of the dataset is a neat idea, though.},
}

@inproceedings{NiuReReWr11,
author = {Feng Niu and Benjamin Recht and Christopher Re and Stephen Wright},
title = {Hogwild: a lock-free approach to parallelizing stochastic gradient
descent},
year = 2011,
booktitle = nips24,
}

@InProceedings{NilesSi90,
  author = 	 {L.T. Niles and H.F. Silverman},
  title = 	 {Combining hidden Markov model and neural network classifiers},
  booktitle = {ICASSP},
  year = 	 {1990}
}

@book{Nilsson65,
	author = "N. J. Nilsson",
	title = "{L}earning {M}achines: Foundations of trainable pattern
	classification systems",
	year = 1965,
	publisher = "McGraw-Hill",
	address =  "New York"
}

@unpublished{NiyogiBe9?
,author=	{Partha Niyogi and Robert C. Berwick}
,title=		{A dynamical systems model for language change}
}

@techreport{NiyogiGi94
,author=	{Partha Niyogi and Federico Girosi}
,title=		{On the relationship between generalization error,
		 hypothesis complexity, and sample complexity for
		 radial basis functions}
}

@article{NobelDe93,
  title={A note on uniform laws of averages for dependent processes},
  author={Nobel, Andrew and Dembo, Amir},
  journal={Statistics \& Probability Letters},
  volume=17,
  number=3,
  pages={169--172},
  year=1993,
  publisher={Elsevier},
  comment={For permissible class of random variables, if a class of
                  RVs is Glivenko-Cantelli for
                  i.i.d. sequences, then it is G-C for beta-mixing
                  (absolutely regular) sequences.}
}

@book{NocedalWr06,
author = {Jorge Nocedal and Stephen J. Wright},
year = 2006,
title = {Numerical Optimization},
publisher = {Springer},
}

@article{NolanPo87,
author=		{Deborah Nolan and David Pollard},
title=		{U-processes: Rates of Convergence},
journal=	{Annals of Statistics},
volume=		15,
number=		2,
pages=		{780--799},
year=		1987
}

@InProceedings{Novikoff62,
  author = 	 {A. B. J. Novikoff},
  title = 	 {On convergence proofs on perceptrons},
  booktitle = 	 {Proceedings of the Symposium on the Mathematical
		  Theory of Automata},
  volume =	 {XII},
  year =	 1962,
  pages =	 {615--622}
}

@article{NutiniScLaFrKo15,
  title={Coordinate descent converges faster with the Gauss-Southwell rule than random selection},
  author={Nutini, Julie and Schmidt, Mark and Laradji, Issam H and Friedlander, Michael and Koepke, Hoyt},
  journal={arXiv preprint arXiv:1506.00552},
  year=2015
}

@techreport{ObozinskiTaJo07,
author = {G.~Obozinski and B.~Taskar and M.~Jordan},
title = {Joint covariate selection for grouped classification},
year = 2007,
number = 743,
institution = {Dept. of Statistics, University of California Berkeley},
comment = {Proposes mixed l1/lp norms for jointly regularizing variables}
}

@inproceedings{ObozinskiWaJo08,
  author = "G.~Obozinski and M.~Wainwright and M.~Jordan",
  title = "High-dimensional union support recovery in multivariate regression",
  booktitle = nips21,
  year = 2008
}

@phdthesis{Oh10,
author = {Sewoong Oh},
title = {Matrix Completion: Fundamental Limits and Efficient Algorithms},
year = 2010,
school = {Stanford University},
}

@article{OhVi13,
author = {Sewoong Oh and Pramod Viswanath},
title = {The Composition Theorem for Differential Privacy},
year = 2013,
journal = {arXiv:1311.0776 [cs.DS]},
}

@techreport{Oja95
,author=	{Erkki Oja}
,title=		{The nonlinear {PCA} learning rule and signal
		separation --- mathematical analysis}
}

@inproceedings{OliverHa94
,author=	{Jonathan J. Oliver and David Hand}
,title=		{Averaging over decision stumps}
,pages=		{231--241}
,year=		1994
,booktitle=	ecml94
,publisher=	{Springer-Verlag}
}

@inproceedings{OliverHa95
,author=	{Jonathan J. Oliver and David J. Hand}
,title=		{On pruning and averaging decision trees}
,pages=		{430--437}
,year=		1995
,booktitle=	ml95
}

@article{Omohundro87,
author=		{Omohundro, S.},
title=		{Efficient algorithms with neural networks behavior},
journal=	{Complex Systems},
year=		1987,
volume=		1,
pages=		{273--347}
}

@article{OlshevskyTs09,
  title={Convergence speed in distributed consensus and averaging},
  author={Olshevsky, Alex and Tsitsiklis, John N},
  journal=sicon,
  volume={48},
  number={1},
  pages={33--55},
  year={2009},
  publisher={SIAM}
}

@inproceedings{OlshevskyTs10,
author = {A. Olshevsky and J. N. Tsitsiklis},
title = {A lower bound on distributed averaging},
year = {2010},
booktitle = {49th IEEE Conference on Decision and
                  Control},
}

@inproceedings{OngSmWi02
,author=	{C.S. Ong and A.J. Smola and R.C. Williamson}
,title=		{Superkenels}
,year=		2002
,booktitle=	nips15
}

@inproceedings{OrabonaCe11,
author = {Francesco Orabona and Nicol\`{o} Cesa-Bianchi},
title = {Better algorithms for selective sampling},
booktitle = icml11,
year = 2011,
}

@inproceedings{OrlitskySaZh03,
author = {Alon Orlitsky and Narayana Santhanam and Junan Zhang},
title = {Always {G}ood-Turing: asymptotically optimal probability estimation},
year = 2003,
booktitle = focs03,
}


@inproceedings{OrlitskySu15,
author = {Alon Orlitsky and Ananda Suresh},
title = {Competitive Distribution Estimation:
  Why is {G}ood-{T}uring Good?},
year = 2015,
booktitle = nips28,
}

@article{OshersonStWe84,
author=   	{Osherson, Daniel N. and Michael Stob and Scott Weinstein},
title=    	{Learning Theory and Natural Language},
journal=  	{Cognition},
year=     	1984,
volume=   	17,
pages=    	{1--28},
comment=  	{Presents argument that number of natural languages is finite.}
}

@book{OshersonStWe86,
author=   	{Osherson, Daniel N. and Michael Stob and Scott Weinstein},
title=    	{Systems that Learn: An Introduction to Learning Theory
		for Cognitive and Computer Scientists},
publisher=  	{MIT Press},
year=     	1986,
comment=  	{Comprehensive recursion-theoretic treatment.}
}

@unpublished{OshersonStWe86b,
author=   	{Osherson, Daniel N. and Michael Stob and Scott Weinstein},
title=    	{Mathematical Learners pay a price for {B}ayesianism},
year=     	1986,
note=     	{(MIT Dept.\ of Brain and Cognitive Science)}
}

@article{OshersonWe82,
author=   	{Osherson, Daniel N. and Scott Weinstein},
title=    	{Criteria of Language Learning},
journal=  	InfCtrl,
year=     	1982,
volume=   	52,
pages=    	{123--138},
comment=  	{Studies relationship between intensional/extensional
		learning.}
}

@article{OstendorfDiKi96,
author=   	{M. Ostendorf and V.V. Digalakis and O.A. Kimball},
title=    	{From HMM's to Segment Models: A Unified View to Stochastic
		Modeling for Speech Recognition},
journal=  	{IEEE Trans. Speech and Audio Proc.},
year=     	1996,
volume=   	4,
number=  5,
pages=    	{360--378},
}

@article{OsterreicherVa93,
author = {F.\ \"{O}sterreicher and Igor Vajda},
title = {Statistical Information and Discrimination},
year = 1993,
journal = ieeeit,
volume = 39,
number = 3,
pages = {1036--1039},
comment = {Shows that all $f$ divergences are equivalent to statistical
  informations (differences between prior and posterior Bayes risks).
  See also LieseVa06.}
}

@book{OsteyeeGo74,
author=   	{Osteyee, David Bridston},
title=    	{Information, Weight of Evidence, the Singularity between
		Probability Measures and Signal Detection},
year=     	1974,
publisher= 	{Springer-Verlag},
series=    	{Lecture Notes in Mathematics},
number=    	376,
comment=  	{Text.}
}

@incollection{OsunaGi99,
author = "E.~Osuna and F.~Girosi",
title = "Reducing the run-time complexity of support vector machines",
year = 1999,
editor = "B.~{Sch\"olkopf} and C.~Burges and A.~Smola",
booktitle = "Advances in Kernel Methods: Support Vector Learning",
publisher = "MIT Press",
pages = {271--284}
}

@Book{Owen82,
  author = 	 {Guillermo Owen},
  title = 	 {Game Theory},
  publisher = 	 {Academic Press},
  year = 	 1982,
  edition =	 {second}
}

@article{Owen88,
  title={Empirical likelihood ratio confidence intervals for a single functional},
  author={Owen, Art B},
  journal={Biometrika},
  volume=75,
  number=2,
  pages={237--249},
  year=1988,
  publisher={Biometrika Trust}
}

@article{Owen90,
  title={Empirical likelihood ratio confidence regions},
  author={Owen, Art},
  journal={The Annals of Statistics},
  pages={90--120},
  year=1990,
  publisher={JSTOR}
}

@book{Owen01,
  title={Empirical likelihood},
  author={Owen, Art B},
  year=2001,
  publisher={CRC press}
}

@book{Owen15,
title = {Monte Carlo Theory, Methods, and Examples},
author = {Art B. Owen},
year = 2015,
note = {Online at \url{http://statweb.stanford.edu/~owen/mc/}},
}

@techreport{Owen06,
author = {Art Owen},
title = {A robust hybrid of lasso and ridge regression},
institution = {Stanford University},
year = 2006,
}

@techreport{PagalloHa89,
author=		{Giulia Pagallo and David Haussler},
title=		{A Greedy Method for Learning {$\mu$DNF} Functions
		 under the Uniform Distribution},
institution=	ucsccrl,
number=		{UCSC-CRL-89-12},
year=		1989,
month=		jun
}

@book{Palay85,
author=   	{Palay, Andrew J.},
title=    	{Searching with Probabilities},
year=     	1985,
publisher= 	{Pitman},
comment=  	{Integration of probabilities into B* algorithm (Ph.D. thesis
	  	with Hans Berliner).}
}

@article{PanageasPi16,
	title={Gradient Descent Converges to Minimizers: The Case of Non-Isolated 
	Critical Points},
	author={Panageas, Ioannis and Piliouras, Georgios},
	journal={arXiv:1605.00405 [math.DS]},
	year={2016}
}

@InProceedings{PandaChWu06,
  author = 	 {N. Panda and E. Y. Chang and G. Wu},
  title = 	 {Concept Boundary Detection for Speeding up {SVM}s},
  booktitle = 	 icml06,
  year = 2006,
}



@article{PaoCa78,
author=   	{Pao, T. W. and J. W. {Carr III}},
title=    	{A solution of the syntactical induction-inference problem
		for regular languages},
journal=  	{Computat. Lang.},
volume=   	3,
year=     	1978,
pages=    	{53--64}
}

@techreport{PapadimitriouTs85,
author=   	{Papadimitriou, Christos H. and John N. Tsitsiklis},
title=    	{The Complexity of Markov Decision Processes},
year=     	1985,
institution=  	{MIT Laboratory for Information and Decision Sciences},
number=   	{LIDS-P-1479},
comment=  	{Ordinary versions are complete for P; partially observed
		are PSPACE-complete.}
}

@unknown{PapkaCaBa9?
,author=       {Ron Papka and James P. Callan and Andrew G. Barto}
,title=        {Text-based information retrieval using exponentiated
                  gradient descent}
}

@article{PapernotMc16,
  title={On the effectiveness of defensive distillation},
  author={Papernot, Nicolas and McDaniel, Patrick},
  journal={arXiv:1607.05113 [cs.CR]},
  year=2016
}

@article{PapernotMcGoJhCeSw16,
  title={Practical black-box attacks against deep learning systems using adversarial examples},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  journal={arXiv:1602.02697 [cs.CR]},
  year=2016
}

@inproceedings{PapernotMcWuJhSw16,
  title={Distillation as a defense to adversarial perturbations against deep neural networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
  booktitle={Security and Privacy (SP), 2016 IEEE Symposium on},
  pages={582--597},
  year=2016,
  organization={IEEE}
}

@book{Pardo05,
  title={Statistical inference based on divergence measures},
  author={Pardo, Leandro},
  year=2005,
  publisher={CRC Press}
}

@article{ParikhBo14,
author = {Neal Parikh and Stephen Boyd},
title = {Block splitting for distributed optimization},
year = 2014,
journal = mathprogc,
pages = {77--102},
volume = 6,
}

@article{ParikhBo13,
author = {Neal Parikh and Stephen Boyd},
title = {Proximal Algorithms},
year = 2013,
journal = {Foundations and Trends in Optimization},
volume = 1,
number = 3,
pages = {123--231},
}

@article{PaskVF60,
author=   	{Pask, Gordon and Heinz Von Foerster},
title=    	{A predictive model for self organizing systems, Parts I and
		II},
journal=  	{Cybernetica},
year=     	{1960 and 1961},
volume=   	{III and IV},
pages=    	{258--300 and 20--55},
comment=  	{n-person game theory. Learning automata.}
}

@book{PatelRe82,
author=		{Jagdish K. Patel and Campbell B. Read},
title=		{Handbook of the Normal Distribution},
year=		1982,
publisher=	{Marcel Dekker}
}

@article{PatrascuNeTr15,
  title={Adaptive inexact fast augmented Lagrangian methods for constrained convex optimization},
  author={Patrascu, Andrei and Necoara, Ion and Tran-Dinh, Quoc},
  journal={Optimization Letters},
  pages={1--18},
  year={2015},
  publisher={Springer}
}

@techreport{Paturi88,
author=   	{Paturi, Ramamohan},
title=    	{The Light Bulb Problem},
institution= 	{Computer Science and Engineering},
address=  	{University of California, San Diego},
month=	  	aug,
year=     	1988
}

@InProceedings{PavanPe03,
  author = 	 {M. Pavan and M. Pelillo},
  title = 	 {A new graph-theoretic approach to clustering and segmentation},
  booktitle = 	 cvpr,
  year =	 2003
}

@article{Pearl78,
author=   	{Pearl, Judea},
title=    	{On the Connection Between the Complexity and Credibility of
		Inferred Models},
journal=  	{Journal of General Systems},
year=     	1978,
volume=   	4,
pages=    	{255--264},
comment=  	{Studies tradeoff between uniqueness and ambiguity in the
		selection of hypotheses.
           	Introduces the use of the Vapnik-Chervonenkis dimension.}
}

@article{Pearl79,
author=   	{Pearl, Judea},
title=    	{Capacity and Error Estimates for Boolean Classifiers with
		Limited Complexity},
journal=  	{IEEE Transactions on Pattern Analysis and Machine
		Intelligence},
year=     	1979,
month=    	Oct,
volume=   	{PAMI-1},
number=   	4,
pages=    	{350--355},
comment=  	{An extension of [Pe78].}
}

@unpublished{Pearl84,
author=   	{Pearl, Judea},
title=    	{Jeffrey's Rule and the Problem of Autonomous Inference
		Agents},
year=     	1984,
note=     	{Class notes for 274A, Fall 1984},
comment=  	{Stresses dangers of using posterior probabilities as new prior
	   	probabilities.}
}

@techreport{Pearl85a,
author=   	{Pearl, Judea},
title=    	{Bayesian Networks: A Model of Self-Activated Memory for
	   	Evidential Reasoning},
institution= 	{UCLA Computer Science Department},
year=     	1985,
month=    	June,
number=   	{CSD-850021, R-43},
comment=  	{Describes Bayesian networks and propagation in
		singly-connected networks.}
}

@techreport{Pearl85b,
author=   	{Pearl, Judea},
title=    	{How to do with Probabilities What People Say You Can't},
institution= 	{UCLA Computer Science Department},
year=     	1985,
month=    	Sep,
number=   	{CSD-850031, R-49},
comment=  	{Describes Bayesian networks and propagation of beliefs.}
}

@techreport{PearlPa85,
author=   	{Pearl, Judea and Azaria Paz},
title=    	{GRAPHOIDS: A Graph-Based Logic for Reasoning about Relevance
	  	Relations, or When would x tell you more about y if you already
	  	know z},
institution= 	{UCLA Computer Science Department},
year=     	1985,
month=    	Dec,
comment=  	{Axiomatic definition of graphoids.}
}

@inproceedings{PearlPa86,
author=   	{Pearl, Judea and Azaria Paz},
title=    	{On the Logic of Representing Dependencies by Graphs},
booktitle=  	{Proceedings 1986 Canadian AI Conference},
year=     	1986,
month=    	May,
comment=  	{Defines and studies graphoids for representing dependencies}
}

@article{Pearlmutter94,
	title={Fast exact multiplication by the {H}essian},
	author={Pearlmutter, Barak A},
	journal={Neural computation},
	volume={6},
	number={1},
	pages={147--160},
	year={1994},
	publisher={MIT Press}
}

@article{Peng01,
  title={Estimating the mean of a heavy tailed distribution},
  author={Peng, Liang},
  journal={Statistics \& Probability Letters},
  volume=52,
  number=3,
  pages={255--264},
  year=2001,
  publisher={Elsevier}
}

@article{Peng04,
  title={Empirical-likelihood-based confidence interval for the mean
                  with a heavy-tailed distribution},
  author={Peng, Liang},
  journal={Annals of Statistics},
  pages={1192--1214},
  year=2004,
  publisher={JSTOR}
}

@article{PengQi06,
  title={Confidence regions for high quantiles of a heavy tailed distribution},
  author={Peng, Liang and Qi, Yongcheng},
  journal={Annals of Statistics},
  pages={1964--1986},
  year=2006,
  publisher={JSTOR}
}
@book{Penrose03,
author = {M. Penrose},
title = {Random Geometric Graphs},
year = 2003,
publisher = {Oxford University Press},
}

@Article{PenroseNeFi85,
  author = 	 {K.W.~Penrose and A.G.~Nelson and A.G.~Fisher},
  title = 	 {Generalized Body Composition Prediction Equation for Men Using Simple Measurement Techniques},
  journal = 	 {Medicine and Science in Sports and Exercise},
  year = 	 {1985},
  volume = 	 {17},
  number = 	 {2},
  pages = 	 {189},
}

@article{PerchetRiChSn16,
author = {Vianney Perchet and Philippe Rigollet and Sylvain Chassang
  and Erik Snowberg},
title = {Batched bandit problems},
year = 2016,
journal = aos,
volume = 44,
number = 2,
pages = {660–681},
}

@inproceedings{PereiraRiSp??
,author=	{Fernando Pereira and Michael Riley and Richard
		 Sproat}
,title=		{Weighted rational transductions and their application
		 to human language processing}
}

@inproceedings{PereiraSc92,
	author = "Fernando Pereira and Yves Schabes",
	title = "Inside-outside reestimation from partially bracketed corpora",
	booktitle = "30th Annual Meeting of the Association for Computational
		Linguistics",
	pages = "128--135",
	year = 1992
}

@article{PereiraSi99,
    author = "F.C. Pereira and  Y. Singer",
    title = "An efficient extension to mixture techniques for prediction
        and decision trees",
    journal = "Machine Learning",
    volume = 36,
    number = 3,
    pages = "183-199",
    year = 1999
}

@article{PermuterKiWe11,
author = {Haim H. Permuter and Young-Han Kim and Tsachy Weissman},
title = {Interpretations of Directed Information in Portfolio
  Theory, Data Compression, and Hypothesis Testing},
year = 2011,
journal = ieeeit,
volume = 57,
number = 6,
pages = {3248--3259},
}

@mastersthesis{Perugini89,
author = 	{Nancy Perugini},
title = 	{Neural Network Learning: Effects of Network and Training
		 Set Size},
school =       	{MIT Department of Electrical Engineering and Computer
		 Science},
month = 	Jun,
year = 		1989
}

@article{PetersWa78a,
    author = {Peters, B.C. and Walker, H.F.},
	title = {An iterative procedure for obtaining maximum-likelihood estimates
		of the parameters for a mixture of normal distributions},
	journal =	{SIAM Journal of Applied Mathematics},
	volume = {35},
	year = {1978},
	pages = {362--378}
}

@article{PetersWa78b,
    author = {Peters, B.C. and Walker, H.F.},
	title = "The numerical evaluation of the maximum-likelihood estimates of
		a subset of mixture proportions",
	journal = "SIAM Journal of Applied Mathematics",
	volume = 35,
	year = 1978,
	pages = "447--452"
}

@article{Petrov65,
  title={On the probabilities of large deviations for sums of independent random variables},
  author={Petrov, Valentin Vladimirovich},
  journal={Theory of Probability \& Its Applications},
  volume=10,
  number=2,
  pages={287--298},
  year=1965,
  publisher={SIAM}
}
		
@incollection{Petz94,
author = {D\'enes Petz},
title = {A survey of certain trace inequalities},
year = 1994,
booktitle = {Banach Center Publications},
pages = {287--298},
volume = 30,
comment = {Several nice proofs of trace inequalities that are fairly elementary
  including the Golden-Thompson inequality.},
}

@book{PflugRo07,
  title={Modeling, measuring and managing risk},
  author={Pflug, Georg Ch and R{\"o}misch, Werner},
  volume=20,
  year=2007,
  publisher={World Scientific}
}

@article{PflugWo07,
  title={Ambiguity in portfolio selection},
  author={Pflug, Georg and Wozabal, David},
  journal={Quantitative Finance},
  volume=7,
  number=4,
  pages={435--442},
  year=2007,
  publisher={Taylor \& Francis}
}

@article{PflugWo10,
  title={Asymptotic distribution of law-invariant risk functionals},
  author={Pflug, Georg and Wozabal, Nancy},
  journal={Finance and Stochastics},
  volume=14,
  number=3,
  pages={397--418},
  year=2010,
  publisher={Springer}
}

@article{PhandinhLeLe86,
author=		{Phan Dinh Dieu and Le Cong Thanh and Le Tuan Hoa},
title=		{Average Polynomial Time Complexity of Some {NP}-Complete
		Problems},
journal=	{Theoretical Computer Science},
volume=		46,
number=		{2, 3},
year=		1986,
pages=		{219--327}
}

@book{Phelps01,
author = {R.~R. Phelps},
title = {Lectures on Choquet's Theorem, Second Edition},
year = 2001,
publisher = {Springer},
comment = {Very measure-theoretic treatment of Choquet theory. Proves that
any point $x$ in a compact convex set is represented by a measure on the
extreme points of the set in the sense that (roughly) $x = \int y d\mu(y)$.
Also gives some nice measurability guarantees.},
}

@book{Pickett80,
author = 	{J.M. Pickett},
title = 	{The Sound of Speech Communication},
publisher = 	{Pro-Ed, Inc.},
year = 		1980
}

@inproceedings{Pinelis92,
author = {Iosif Pinelis},
title = {An approach to inequalities for the distributions of
  infinite-dimensional martingales},
year = 1992,
booktitle = {Proceedings of the Eighth International Conference on Probability
in Banach Spaces},
pages = {128--134},
}

@techreport{PinkerPi87,
author=   	{Steven Pinker and Alan Prince},
title=    	{On Language and Connectionism:
           	Analysis of a Parallel Distributed Processing Model
           	of Language Acquisition},
institution=	{MIT Center for Cognitive Science},
year=      	1987,
number=    	{Occasional Paper \#33},
comment=  	{Critique of Rumelhart and McClelland's connectionist approach
		to learning English past tense construction.}
}

@article{Pisier12,
author = {Gilles Pisier},
title = {Grothendieck's {T}heorem, past and present},
journal = bams,
year = 2012,
pages = {237--323},
volume = 49,
}

@BOOK{Pisier89,
AUTHOR = {G. Pisier},
TITLE = "The {V}olume of {C}onvex {B}odies and {B}anach {S}pace {G}eometry",
PUBLISHER = "Cambridge University Press",
SERIES = "Cambridge Tracts in Mathematics",
VOLUME = 94,
ADDRESS = "Cambridge, UK",
YEAR = "1989"
}

@inproceedings{Pisoni??
,author=	{David B. Pisoni}
,title=		{Some comments on invariance, variability and
		 perceptual normalization in speech recognition}
,comment=	{from pereira}
}

@techreport{Pitt85,
author=   	{Pitt, Leonard Brian},
title=    	{Probabilistic Inductive Inference},
institution= 	{Yale University Computer Science Department},
year=     	1985,
month=    	Jun,
number=   	{YALEU/DCS/TR-400},
comment=  	{Ph.D. thesis. Defines probabilistic inference and shows
		probabilistic inference equivalence to teams of inductive
		inference machines; and shows strict hierarchy on probability
		with cut-points 1/2, 1/3, 1/4, ...}
}

@techreport{Pitt89,
author=		{Pitt, Leonard},
title=		{Inductive Inference, {DFA}s, and Computational Complexity},
institution=	{University of Illinois at Urbana-Champaign, Department
		 of Computer Science},
month=		jul,
year=		1989,
number=		{UIUCDCS-R-89-1530},
note=		{Also appears in {\it Proceedings of the 1989
		 International Workshop on Analogical and Inductive
		 Inference}, Springer-Verlag Lecture Notes in Computer
		 Science}
}

@techreport{PittSm86,
author=   	{Pitt, Leonard and Carl H. Smith},
title=    	{Probability and Plurality for Aggregations of Learning
		Machines},
institution= 	{University of Maryland Computer Science Department},
year=     	1986,
month=    	Jul,
number=   	{CS-TR-1686},
comment=  	{Show that one can not always trade off probabilism for
		plurality and vice-versa.}
}

@techreport{PittVa86,
author=   	{Pitt, Leonard and Leslie G. Valiant},
title=    	{Computational Limitations on Learning from Examples},
institution= 	{Harvard University Aiken Computation Laboratory},
year=     	1986,
month=    	Jul,
comment=  	{It is NP-Complete to learn disjunction of two monomials,
		Boolean threshold functions, Boolean formulae where each
		variable occurs at most once.}
}

@article{PittVa88,
author=   	{Pitt, Leonard and Leslie G. Valiant},
title=    	{Computational Limitations on Learning from Examples},
journal = 	jacm,
volume =  	35,
number =  	4,
month=		Oct,
year = 	  	1988,
pages =   	{965--984}
}

@unpublished{PittWa88,
author=   	{Pitt, Leonard and Manfred K. Warmuth},
title=    	{The Minimum {DFA} Consistency Problem Cannot be
           	Approximated within any Polynomial},
year=     	1988,
note=     	{(unpublished manuscript)}
}

@inproceedings{PittWa88b,
author=   	{Pitt, Leonard and Manfred K. Warmuth},
title = 	{Reductions Among Prediction Problems:  On the Difficulty of
		Predicting Automata},
booktitle = 	{3rd IEEE Conference on Structure in Complexity Theory},
year = 		{1988},
pages = 	{60--69},
month = 	jun
}

@techreport{PittWa88c,
author=		{Pitt, Leonard and Manfred K. Warmuth},
title=		{Prediction Preserving Reducibility},
institution=	ucsccrl,
year=		1988,
month=		Nov,
number=		{UCSC-CRL-88-26}
}

@inproceedings{PittWa89,
author=   	{Pitt, Leonard and Manfred K. Warmuth},
title=    	{The Minimum Consistent {DFA} Problem Cannot be
           	Approximated within any Polynomial},
booktitle=      stoc89,
month=          May,
year = 		1989,
note=		{Available as Technical Report UIUCDCS-R-89-1499,
		 University of Illinois at Urbana-Champaign,
		 Department of Computer Science.
		 To appear, {\it Journal of the Association for
		                Computing Machinery}}
}

@article{PittWa90,
author=		{Pitt, Leonard and Manfred K. Warmuth},
title=		{Prediction-Preserving Reducibility},
journal=	jcss,
volume=		41,
number=		3,
month=		dec,
year=		1990,
pages=		{430--467}
}

@article{PittWa93,
author=   	{Pitt, Leonard and Manfred K. Warmuth},
title=    	{The Minimum Consistent {DFA} Problem Cannot be
           	Approximated within any Polynomial},
journal=	jacm,
volume=		40,
number=		1,
pages=		{95--142},
month=		jan,
year=		1993
}

@misc{PiZhGu16,
author = {Fengmei Pi and Hui Zhang and Peixuan Guo},
title = {{RNA} nanoparticles in cancer cells},
year = 2016,
howpublished = {National Cancer Institute Visuals Online},
note = {Accessed April 1, 2017},
url = {https://visualsonline.cancer.gov/details.cfm?imageid=11167},
}

@book{Plaskota96,
author = {Leszek Plaskota},
title = {Noisy Information and Computational Complexity},
year = 1996,
publisher = {Cambridge University Press},
}

@incollection{Platt98,
	author = "J.~C. Platt",
	title = "Fast Training of {Support Vector Machines} using
		Sequential Minimal Optimization",
	booktitle = " Advances in Kernel Methods - Support Vector Learning",
	publisher = "MIT Press",
	editor = {B. Sch\"olkopf and C. Burges and A. Smola},
	year = 1998
}

@incollection{PlattCrSh00,
	author = "J.~C. Platt and N. Cristianini and J. Shawe-Taylor",
	title = "Large Margin {DAG}s for Multiclass Classification",
	booktitle = "Advances in Neural Information Processing Systems 12",
	publisher = "MIT Press",
	year = 2000,
        pages = "547-553"
}


@article{PlotkinShTa95
,author=	{Serge A. Plotkin and David B. Shmoys and \'Eva
		 Tardos}
,title=		{Fast approximation algorithms for fractional packing
		 and covering problems}
,journal=	{Mathematics of Operations Research}
,volume=	20
,number=	2
,year=		1995
,month=		may
,pages=		{257-301}
}

@article{PoggioGi90,
	author = "T. Poggio and F. Girosi",
	title = "Networks for approximation and learning",
	journal = "Proceedings of the IEEE",
	volume =78,
	number = 9,
	year = 1990
}

@article{PoliquinRo96,
author = {Ren\'{e} Poliquin and R. Tyrell Rockafellar},
title = {Prox-regular functions in variational analysis},
journal = {Transactions of the American Mathematical Society},
year = 1996,
volume = 348,
number = 5,
pages = {1805--1838},
}

@article{PoliquinRo98,
author = {Ren\'{e} A. Poliquin and R. Tyrell Rockafellar},
title = {Tilt Stability of a Local Minimum},
journal = siopt,
volume = {8},
number = {2},
pages = {287--299},
year = {1998},
}

@article{PolitisRo92,
  title={A general resampling scheme for triangular arrays of
                  $\alpha$-mixing random variables with application to
                  the problem of spectral density estimation},
    author={Politis, Dimitris N and Romano, Joseph P},
      journal={The Annals of Statistics},
        pages={1985--2007},
	  year=1992,
	    publisher={JSTOR}
	    }

@book{PolitisRoWo99,
author = {Dimitris N. Politis and Joseph P. Romano and Michael Wolf},
title = {Subsampling},
year = 1999,
publisher = {Springer},
}


@book{Pollard84,
author = 	{David Pollard},
title = 	{Convergence of Stochastic Processes},
publisher = 	{Springer-Verlag},
year = 		1984
}

@incollection{Pollard97,
author = {David Pollard},
title = {Another look at Differentiability in Quadratic Mean},
year = 1997,
booktitle = {Festschrift for Lucien Le Cam: Research Papers in Probability
and Statistics},
editor = {David Pollard and Erik Torgersen and Grace Yang},
chapter = {19},
publisher = {Springer},
}

@incollection{Polyak79,
author="Polyak, Boris T.",
editor="Bensoussan, A. and Lions, J. L.",
title={On the {B}ertsekas' method for minimization of composite functions},
booktitle = {International Symposium on Systems Optimization and Analysis},
year="1979",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages={178--186},
isbn="978-3-540-35232-7",
doi="10.1007/BFb0002653",
url="http://dx.doi.org/10.1007/BFb0002653",
comment = {See also Bertsekas77},
}

@book{Polyak87,
author = {B. T. Polyak},
title = {Introduction to Optimization},
year = 1987,
publisher = {Optimization Software, Inc.},
}

@article{PolyakJu92,
author = {B. T. Polyak and A. B. Juditsky},
title = {Acceleration of stochastic approximation by averaging},
year = 1992,
journal = sicon,
volume = 30,
number = 4,
pages = {838--855},
comment = {Shows that even though in a stochastic approxmation problem
one can obtain optimal rates of convergence of (x_t - x^*) to zero with
the exact right stepsizes (and some other bells and whistles that may
not be implementable), averaging iterates to get \bar{x}_t yields optimal
rates of convergence for a wider variety of step sizes. Obtains results
in classical style, showing \sqrt{t}(\bar{x}_t - x^*) converges in
distribution to a normal with appropriate limiting variances.
Techniques are to first consider simple quadratic problem with
independent noise (i.e. solve Ax = b with noise), with fixed stepsizes,
then do this with decreasing stepsizes, then show the general problem
is asymptotically equivalent. (The attained limiting variances are
optimal in a Fisher-information/Bahadur efficiency sense.)
A few minor typos in assumptions and proof: Assumption 3.3 should have
dependence on \Delta_{t-1} = x_{t-1} - x^* instead of x_{t-1} in the stochastic
terms (and similarly in proof). Eq. (10) should be \gamma_t^{1 + \lambda/2}.
Proofs are classical statistics-type proofs.},
}

@article{PolyakTs80,
author = {B. T. Polyak and J. Tsypkin},
title = {Robust Identification},
year = 1980,
journal = {Automatica},
volume = 16,
pages = {53--63},
doi = {10.1016/0005-1098(80)90086-2},
url = {http://dx.doi.org/10.1016/0005-1098(80)90086-2},
comment = {Considers nonlinear models of the form
 $y = f(x; \theta) + \varepsilon$, where $f$ is smooth enough and
 $\varepsilon$ is noise from some unknown distribution. Shows robust
 estimation strategies based on families for $\varepsilon$.},
}

@article{PoorTh77,
author={Poor, H. Vincent and Thomas, John B.},
journal={IEEE Transactions on Communications},
title={Applications of Ali-Silvey Distance Measures in the Design of
   Generalized Quantizers for Binary Decision Systems},
year={1977},
volume={25},
number={9},
pages={893--900},
}

@book{Porat97,
	author = "Boaz Porat",
	title = "A course in Digital Signal Processing",
	publisher = "Wiley",
	year = 1997
}


@techreport{Porat87,
author=   	{Sara Porat},
title=    	{Stability and Looping in Connectionist Models with
		Assymmetric Weights},
institution= 	{University of Rochester Computer Science Department},
year=     	{1987},
month=    	Mar,
number=   	{TR 210},
comment=  	{Show that determining whether a network stabilizes is
		NP-hard, under both synchronous and fair asynchronous updating
		rules.}
}

@article{Portnoy88,
  title={Asymptotic behavior of likelihood methods for exponential families when the number of parameters tends to infinity},
  author={Portnoy, Stephen},
  journal={The Annals of Statistics},
  volume=16,
  number=1,
  pages={356--366},
  year=1988,
  publisher={Institute of Mathematical Statistics}
}

@incollection{Powell69,
author = {Michael J. D. Powell},
title = {A Method for Nonlinear Constraints in Minimization Problems},
year = 1969,
booktitle = {Optimization},
editor = {Roger Fletcher},
publisher = {Academic Press},
pages = {283--298},
}

@article{Powell73
,author=        {M. J. D. Powell}
,title=         {On search directions for minimization algorithms}
}

@phdthesis{Price13,
author = {Eric Price},
title = {Sparse Recovery and Fourier Sampling},
year = 2013,
school = {Massachusetts Institute of Technology},
}

@article{PronzatoPa13,
  title={Design of experiments in nonlinear models},
  author={Luc Pronzato and Andrej P{\'a}zman},
  journal={Lecture notes in statistics},
  volume={212},
  year={2013},
  publisher={Springer}
}

@book{Pukelsheim93,
author = {Friedrich Pukelsheim},
title = {Optimal Design of Experiments},
year = 1993,
publisher = {SIAM},
series = {Classics in Applied Mathematics},
}

@article{Qi08,
  title={Bootstrap and empirical likelihood methods in extremes},
  author={Qi, Yongcheng},
  journal={Extremes},
  volume=11,
  number=1,
  pages={81--97},
  year=2008,
  publisher={Springer}
}

@article{QinLa94,
  title={Empirical likelihood and general estimating equations},
  author={Qin, Jin and Lawless, Jerry},
  journal={The Annals of Statistics},
  pages={300--325},
  year=1994,
  publisher={JSTOR}
}

@article{QinZhTsWaLiLi08,
  author    = {T.\ Qin and
               X.-D.\ Zhang and
               M.-F.\ Tsai and
               D.-S.\ Wang and
               T.-Y.\ Liu and
               H.\ Li},
  title     = {Query-level loss functions for information retrieval},
  journal   = {Information Processing \& Management},
  volume    = {44},
  number    = {2},
  year      = {2008},
  pages     = {838-855},
}

@unpublished{QinLiDiXuLi11,
author = {T.\ Qin and T.-Y.\ Liu and W.\ Ding and J.\ Xu and H.\ Li},
title = {Microsoft Learning to Rank Datasets},
year = 2011,
note = {URL \url{http://research.microsoft.com/en-us/projects/mslr/}, accessed
   March 1, 2012}},
}

@article{Quinlan83,
author=   	{Quinlan, J. R.},
title=    	{Inferno: A Cautious Approach to Uncertain Inference},
journal=  	{The Computer Journal},
year=     	1983,
volume=   	26,
number=   	3,
pages=    	{255--269},
comment=  	{Survey of previous inference schemes. Proposes `cautious'
		scheme.}
}

@article{Quinlan86,
author=   	{Quinlan, J. R.},
title=    	{Induction of Decision Trees},
journal=  	ml,
year=     	1986,
volume=   	1,
pages=    	{81--106},
comment=  	{Overview of the induction of decision trees.  Proposes
		information-theoretic measure for choosing decision
		attributes.  Discusses issue of noise and unknown attribute
		values.}
}

@article{Quinlan86b,
author=   	{Quinlan, J. R.},
title=    	{Simplifying Decision Trees},
journal=  	{International Journal of Man-Machine Studies},
year=     	1987,
note=     	{(To appear.)}
}

@incollection{Quinlan86c,
author = 	{J.~R.~Quinlan},
title = 	{The Effect of Noise on Concept Learning},
booktitle = 	{Machine Learning, An Artificial Intelligence Approach
		(Volume II)},
publisher = 	{Morgan Kaufmann},
year = 		{1986},
chapter = 	{6},
pages = 	{149--166},
comment = 	{An empirical study of the effects of noise on a
		particular learning algorithm.  Concludes that classification
		noise is more harmful than attribute noise.}
}

@book{Quinlan93
,author=	{J.~R.~Quinlan}
,title=		{C4.5: Programs for Machine Learning}
,year=		1993
,publisher=	{Morgan Kaufmann}
}

@inproceedings{Quinlan96
,author=	{J. R. Quinlan}
,title=		{Bagging, Boosting, and {C4.5}}
,pages=		{725-730}
,year=		1996
,booktitle=	{Proceedings of the Thirteenth National Conference on
		Artificial Intelligence}
}

@InProceedings{Quinlan96b,
  author = 	 {J. R. Quinlan},
  title = 	 {Boosting First-Order Learning}
}

@article{QuinlanRi89,
author =  	{Quinlan, J. Ross and Ronald L. Rivest},
title =   	{Inferring Decision Trees Using the Minimum Description Length
		 Principle},
journal = 	infcomp,
volume = 	80,
number = 	3,
year = 		1989,
month = 	Mar,
pages = 	{227--248},
note = 		{(An early version appeared as MIT LCS Technical report
		MIT/LCS/TM-339 (September 1987).)}
}

@article{RabbatFiNo08,
author = {Michael Rabbat and M\'ario Figueiredo and Robert Nowak},
year = 2008,
title = {Network inference from co-occurrences},
journal = ieeeit,
volume = 54,
number = 9,
}

@inproceedings{RabbatNo04,
author = {M. Rabbat and R. Nowak},
title = {Distributed optimization in sensor networks},
year = 2004,
booktitle = {The 3rd International Symposium on Information Processing in
Sensor Networks},
pages = {20--27},
}

@article{RabinerJu86,
author=   	{L.R. Rabiner and B.H. Juang},
title=    	{An Introduction to Hidden Markov Models},
journal=  	{IEEE ASSP Magazine},
year=     	1986,
month=    	Jan,
volume=   	3,
number=   	1,
pages=    	{4--16},
comment=  	{Good introductory overview.}
}

@book{RabinerJu93
,author=   	{L. Rabiner and B.H. Juang}
,title=    	{Fundamentals of Speech Recognition}
,year=     	1993
,publisher=	{Prentice Hall}
}

@article{RabinerLeSo83,
author=   	{Rabiner, L. R. and S. E. Levinson and M. M. Sondhi},
title=    	{On the Application of Vector Quantization and Hidden Markov
		Models to Speaker-Independent, Isolated Word Recognition},
journal=  	{Bell System Technical Journal},
year=     	1983,
month=    	Apr,
volume=   	62,
number=   	4,
pages=    	{1075--1105},
comment=  	{Gets 96.5 percent accuracy on 100-speaker set for digits.}
}

@book{RabinerSc78
,author=	{L. R. Rabiner and R. W. Schafer}
,title=		{Digital Processing of Speech Signals}
,year=		1978
,publisher=	{Prentice-Hall}
}

@inproceedings{Raginsky09,
author = {Maxim Raginsky},
title = {Achievability Results for Statistical Learning Under
   Communication Constraints},
year = 2009,
booktitle = {Proceedings of the IEEE International Symposium
   on Informaiton Theory},
}

@article{RaginskyRa11,
author = {Maxim Raginsky and Alexander Rakhlin},
title = {Information-based complexity, feedback, and dynamics in
  convex programming},
year = 2011,
journal = ieeeit,
volume = 57,
number = 10,
pages = {7036--7056},
}

@inproceedings{RagunathanFrDuLi16,
author = {Aditi Ragunathan and Roy Frostig and John Duchi and Percy
Liang},
title = {Estimation from Indirect Supervision with Linear Moments},
year = 2016,
booktitle = icml16,
}

@inproceedings{RakhlinShSr12,
author = {Alexander Rakhlin and Ohad Shamir and Karthik Sridharan},
title = {Making gradient descent optimal for strongly convex
   stochastic optimization},
year = 2012,
booktitle = icml12,
comment = {Shows how a type of suffix-averaging can give 1/T rates for
stochastic gradient descent; also provides a few arguments for convergence
of the final predictor. Gives high probability bounds too},
}

@article{RakhlinSr15,
author = {Alexander Rakhlin and Karthik Sridharan},
title = {On Equivalence of Martingale Tail Bounds and
Deterministic Regret Inequalities},
year = 2015,
journal = {arXiv:1510.03925 [math.PR]},
}

@article{RakotomamonjyBaCaGr08,
	author = {A. Rakotomamonjy and F. Bach and S. Canu and Y. Grandvalet},
	title = {Simple{MKL}},
	journal = jmlr,
	volume = 9,
	pages = {2491--2521},
	year = 2008
}

@article{RamaswamyTaRiMuYeAnLaReLaMePoGeLoLaGo01,
author = {Sridhar Ramaswamy and Pablo Tamayo and Ryan Rifkin
  and Sayan Mukherjee and Chen-Hsiang Yeang and Michael Angelo and
 Christine Ladd and Michael Reich and Eva Latulippe and Jill P. Mesirov and
 Tomaso Poggio and William Gerald and Massimo Loda and Eric S. Lander and
 Todd R. Golub},
title = {Multiclass cancer diagnosis using tumor gene expression signatures},
year = 2001,
journal = pnas,
volume = 98,
number = 26,
pages = {15149–-15154},
}

@inproceedings{RamdasSi13,
  title={Optimal rates for stochastic convex optimization under Tsybakov noise condition},
  author={Ramdas, Aaditya and Singh, Aarti},
  booktitle=icml13,
  pages={365--373},
  year={2013}
}

@inproceedings{RamdasRePoSiWa15,
author = {Aaditya Ramdas and Sashank Reddi and Barnab\`{a}s P\`{o}czos
and Aarti Singh and Larry Wasserman},
title = {On the decreasing power of kernel and distance-based nonparametric
hypothesis tests in high dimensions},
year = 2015,
booktitle = aaai15,
}

@article{RamNeVe09a,
title = {Incremental stochastic subgradient algorithms for
   convex optimization},
author = {S. Sundhar Ram and Angelia Nedi\'c and Venugopal V. Veeravalli},
year = 2009,
journal = siopt,
volume = 20,
number = 2,
pages = {691--717},
}

@inproceedings{RamNeVe09,
author = {S. Sundhar Ram and A. Nedic and V. V. Veeravalli},
title = {Distributed subgradient projection algorithm for convex optimization},
booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},
year = {2009},
pages = {3653-3656},
}

@article{RamNeVe10,
author = {S. S. Ram and A. Nedi\'c and V. V. Veeravalli},
title = {Distributed stochastic subgradient projection algorithms for
convex optimization},
pages = {516--545},
journal = jota,
volume = 147,
number = 3,
year = 2010,
}

@unknown{RaoTi97
,author=        {J. Sunil Rao and Robert Tibshirani}
,title=         {The out-of-bootstrap method for model averaging and
                  selection}
}

@inproceedings{Raghavan88,
author=   	{Raghavan, Prabhakar},
title=    	{Learning in Threshold Networks},
booktitle=	colt88,
month=    	Aug,
year=     	1988,
publisher = 	{Morgan-Kaufmann},
pages = 	{19--27}
}

@inproceedings{RahimiRe07,
author=   	{Ali Rahimi and Benjamin Recht},
title=    	{Random Features for Large-Scale Kernel Machines},
booktitle=	nips20,
year=     	{2007}
}

@inproceedings{RahimiRe08,
author = {Ali Rahimi and Benjamin Recht},
title = {Weighted sums of random kitchen sinks: replacing minimization
  with randomization in learning},
year = 2008,
booktitle = nips21,
}

@article{Raphael99,
author=   	{C. Raphael},
title=    	{Automatic Segmentation of Acoustic Musical Signals Using Hidden Markov Models},
journal=  	{IEEE transactions on Pattern Analysis and Machine Intelligence},
year=     	1999,
month=    	Apr,
volume=   	21,
number=   	4,
}

@inproceedings{Raphael04,
	author=   	{C. Raphael},
	title = "A Hybrid graphical model for aligning polyphonic audio with musical scores",
	booktitle = {Proceedings of the 5th International Conference on Music Information Retrieval},
	year = 2004,
}

@ARTICLE{RaskuttiWaYu11,
author = {Garvesh Raskutti and Martin J. Wainwright and Bin Yu},
title = {Minimax rates of estimation for high-dimensional linear regression
over $\ell_q$-balls},
YEAR = 2011,
VOLUME = 57,
NUMBER = 10,
PAGES = "6976---6994",
JOURNAL = ieeeit,
comment = {Provides metric entropy calculations showing how to get
  minimax rates of estimation over $\ell_q$-balls, where $q < 1$. Shows
  that in many cases, the lasso is sharp.},
}

@inproceedings{RatliffBaZi06,
author = {Nathan Ratliff and J. Andrew Bagnell and Martin Zinkevich},
title = {Maximum margin planning},
year = 2006,
booktitle = icml06,
}

@inproceedings{RatschOnMu98,
	author = {G. R\"{a}tsch and T.Onoda and K.-R. M\"{u}ller},
	title = "Regularizing AdaBoost",
	booktitle = nips12,
	year = 1998
}

@phdthesis{Ratsch01,
author = 	{G. R\"{a}tsch},
title = 	{Robust Boosting and Convex Optimization},
school = 	{University of Potsdam},
year = 		2001
}



@Article{RatschWa05,
  author = 	 {G. Ratsch and M. Warmuth},
  title = 	 {Efficient margin maximizing with boosting},
  journal = 	 {Journal of Machine Learning Research},
  vol = {6},
  pages = {2153--2175},
  year = 	 {2005}
}

@inproceedings{RaviItJoSi16,
  title={Experimental Design on a Budget for Sparse Linear Models and Applications},
  author={Sathya N. Ravi and Vamsi K. Ithapu and Sterling C. Johnson and Vikas Singh},
  booktitle={Proceedings of The 33rd International Conference on Machine Learning},
  pages={583--592},
  year={2016}
}

@inproceedings{RavikumarTeYa11,
author = {P. Ravikumar and A. Tewari and E. Yang},
title = {On {NDCG} consistency of listwise ranking methods},
year = 2011,
booktitle = aistat11,
}

@article{RavikumarWaLa10,
author = {P. Ravikumar and M. J. Wainwright and J. D. Lafferty},
title = {High-dimensional {I}sing model selection using $\ell_1$-regularized
logistic regression},
year = 2010,
journal = aos,
volume = 38,
number = 3,
pages = {1287--1319},
}

@article{Recht11,
author = {Benjamin Recht},
title = {A simpler approach to matrix completion},
journal = jmlr,
volume = 12,
pages = {3413--3430},
year = 2011,
}

@article{RechtFaPa08,
author = {Benjamin Recht and Maryam Fazel and Pablo Parrilo},
title = {Guaranteed minimum-rank solutions of linear matrix equations via
nuclear norm minimization},
journal = {SIAM Review},
volume = 52,
number = 3,
pages = {471--501},
year = 2010,
}

@inproceedings{RechtRe12,
author = {Benjamin Recht and Christopher R\'{e}},
title = {Beneath the valley of the noncommutative arithmetic-geometric mean
   inequality: conjectures, case-studies, and consequences},
year = 2012,
booktitle = colt12,
}

@inproceedings{RechtReWrNi11,
author = {Feng Niu and Benjamin Recht and Christopher R\'{e}
    and Stephen Wright},
title = {Hogwild: a lock-free approach to parallelizing stochastic gradient
descent},
year = 2011,
booktitle = nips24,
}

@inproceedings{ReddiHeSrPoSm16,
	title = 	 {Stochastic Variance Reduction for Nonconvex Optimization},
	author = 	 {Sashank J. Reddi and Ahmed Hefny and Suvrit Sra and Barnabas Poczos and Alex Smola},
	booktitle = icml16,
	year = 	 2016
}

@article{RednerWa84
,author=	{Richard A. Redner and Homer F. Walker}
,title=		{Mixture densities, maximum likelihood and the {EM}
		 algorithm}
,year=		1984
}

@article{ReidWi11,
author = {Mark Reid and Robert Williamson},
title = {Information, divergence, and risk for binary experiments},
year = 2011,
journal = jmlr,
volume = 12,
pages = {731--817},
}

@article{Reiter05,
author = {Jerome P. Reiter},
title = {Estimating Risks of Identification Disclosure in Microdata},
year = 2005,
journal = jasa,
volume = 100,
pages = {1103--1113},
note = {URL \url{http://sisla06.samsi.info/ndhs/dc/Papers/JerryJasa05.pdf}},
comment = {
Essentially a survey of statistical techniques for disclosure limitation,
specifically, identification disclosure risks. (This follows the Duncan-Lambert
approach.) The approach is to release a dataset {y_1, ..., y_N},
providing a perturbed version Z = {z_1, ..., z_r}. Each entry
z_i may consist of both perturbed and unperterbed entries. The disclosure
risk is measured by the probability P(J = j | t, Z), where t is some known
characteristics (features) of a sample, Z is the (perturbed) released dataset,
and J is a random variable equaling j when z_j truly corresponds to t (i.e.
the identification is correct). This can be further broken down into known
and unknown parts of t/Z, as well as parts that are and are not perturbed.
The paper as a whole is not that deep, though, and just seems to do what
Duncan and Lambert already did (perhaps somewhat more clearly).
Put succinctly (copying from the paper):
"The utility of the resulting released data is not considered here."
Nothing about maintaining utility or general results on privacy.
},
}

@inproceedings{ResnickIaSuBeRi94,
	author = "Paul Resnick and Neophytos Iacovou and Mitesh Sushak and
		Peter Bergstrom and John Riedl",
	title = "GroupLens: An Open Architecture for Collaborative
		Filtering of Netnews",
	booktitle = "Proceedings of Computer Supported Cooperative Work",
	year = {1995a}
}

@inproceedings{RiccardiGoLjRi97,
	author = "G. Riccardi and A. L. Gorin and A. Ljolje and M. Riley",
	title = "Spoken language understanding for automated call routing",
	booktitle = "Proceedings of the 1997 IEEE International
                  Conference on Acoustics, Speech, and Signal Processing",
	year = 1997,
	pages = "1143--1146"
}

@article{RichtarikTa14,
  title={Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Mathematical Programming},
  volume=144,
  number={1-2},
  pages={1--38},
  year=2014,
  publisher={Springer}
}

@article{RichtarikTa15,
author = {Peter Richt\'arik and Martin Tak\'a\v{c}},
title = {Parallel Coordinate Descent Methods for Big Data Optimization},
year = 2015,
journal = {Mathematical Programming},
pages = {Online first},
url = {http://link.springer.com/article/10.1007/s10107-015-0901-6},
}

@article{RichtarikTa12,
author = {Peter Richt\'arik and Martin Tak\'a\v{c}},
title = {Parallel Coordinate Descent Methods for Big Data Optimization},
year = 2012,
journal = {arXiv:1212.0873 [math.OC]},
url = {http://arxiv.org/abs/1212.0873},
}

@article{RichtarikTa15b,
  title={On optimal probabilities in stochastic coordinate descent methods},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Optimization Letters},
  pages={1--11},
  year=2015,
  publisher={Springer}
}

@techreport{Rietman94
,author=	{E. A. Rietman}
,title=		{Classical control theory, {K}olmogorov's theorem, and
		automata networks}
}

@book{Rijsbergen79,
	author = {C. J. van Rijsbergen},
	address = {London},
	publisher = {Butterworths},
	title = {Information Retrieval},
	year = {1979}
}

@book{Rio17,
  title={Asymptotic Theory of Weakly Dependent Random Processes},
  author={Rio, Emmanuel},
  year=2017,
  publisher={Springer}
}

@article{RiquelmeJoZh16,
  title={Online Active Linear Regression via Thresholding},
  author={Carlos Riquelme and Ramesh Johari and Baosen Zhang},
  journal={arXiv preprint arXiv:1602.02845},
  year={2016}
}

@article{Rissanen78,
author=   	{Rissanen, Jorma},
title=    	{Modeling By Shortest Data Description},
journal=  	{Automatica},
year=     	1978,
volume=   	14,
pages=    	{465--471},
comment=  	{Proposes that the best model is the one that minimizes the
		overall description length of the data, including the
		parameters of the model.}
}

@article{Rissanen83,
author=   	{Rissanen, Jorma},
title=    	{A Universal Prior for Integers and Estimation by Minimum
	  	Description Length},
journal=  	{The Annals of Statistics},
year=     	1983,
volume=   	11,
number=   	2,
pages=    	{416--431}
}

@article{Rissanen83b,
  author =       "Jorma Rissanen",
  title =        "A Universal Data Compression System",
  journal =      ieeeit,
  volume =       "IT-29",
  number =       "5",
  month =        sep,
  year =         "1983",
  pages =        "656--664"
}

@article{Rissanen84,
author = {Jorma Rissanen},
title = {Universal coding, information, prediction, and estimation},
journal = ieeeit,
year = 1984,
volume = 30,
pages = {629--636},
}

@article{Rissanen86a,
author=	  	{Rissanen, Jorma},
title=    	{Stochastic Complexity and Modeling},
journal=  	{The Annals of Statistics},
year=     	1986,
volume=   	14,
number=   	3,
pages=    	{1080--1100},
comment=  	{Minimum Description Length Principle, and applications.}
}

@techreport{Rissanen86b,
author=   	{Rissanen, Jorma},
title=    	{Stochastic Complexity and Sufficient Statistics},
institution= 	{IBM Research Laboratory (San Jose)},
year=     	1986,
comment=  	{Defines notion of stochastic complexity of a string relative
		to a class of models.  Describes to ways to approximate
		stochastic complexity.}
}

@article{RissanenLa81,
author=   	{Rissanen, Jorma and Langdon, Jr., Glen G.},
title=    	{Universal Modeling and Coding},
journal=  	{IEEE Transactions on Information Theory},
volume=   	{IT-27},
number=   	1,
year=     	1981,
month=    	Jan,
pages=    	{12--23},
comment=  	{Overview of first-in first-out arithmetic codes. Proves that
		alphabet extensions don't help coding efficiency.}
}


@article{RissanenSpYu92,
author=		{Jorma Rissanen and Terry P. Speed and Bin Yu},
title=		{Density Estimation by Stochastic Complexity},
journal=	{IEEE Transactions on Information Theory},
volume=		38,
number=		2,
month=		mar,
year=		1992,
pages=		{315--323}
}

@article{Rivest87,
author = 	{Rivest, Ronald L.},
title = 	{Learning Decision Lists},
journal = 	ml,
year = 		1987,
volume = 	2,
number = 	3,
pages = 	{229--246}
}

@misc{Rivest88p,
author = 	{Rivest, Ronald L.},
year = 		{Personal communication}
}

@inproceedings{RivestSc87a,
author=   	{Rivest, Ronald L. and R.E. Schapire},
title=    	{A New Approach to Unsupervised Learning in Deterministic
           	Environments},
booktitle=	{Proceeding of the Fourth International Workshop on
           	Machine Learning},
comment=	{editor=   	{Pat Langley},
		 address=  	{Irvine, California}},
month=    	Jun,
pages=    	{364--375},
year=     	1987
}

@inproceedings{RivestSc87b,
author=   	{Rivest, Ronald L. and R.E. Schapire},
title=    	{Diversity-Based Inference of Finite Automata},
booktitle=	focs87,
comment=	{address=  	{Los Angeles, California}},
month=    	Oct,
pages=    	{78--87},
year=     	1987,
note=		{To appear, {\it Journal of the Association for
		 Computing Machinery}}
}

@inproceedings{RivestSc89,
author = 	{Ronald L. Rivest and R.E. Schapire},
title = 	{Inference of Finite Automata Using Homing Sequences},
booktitle = 	stoc89,
year = 		1989,
month = 	May,
pages = 	{411-420},
note=		{To appear, {\it Information and Computation}}
}

@incollection{RivestSc90,
author=		{Rivest, Ronald L. and R.E. Schapire},
title=   	{A new approach to unsupervised learning in deterministic
		environments},
booktitle=	{Machine Learning: An Artificial Intelligence Approach},
editor=   	{Yves Kodratoff and Ryszard Michalski},
volume=		{III},
publisher=	{Morgan Kaufmann},
year=     	{1990},
pages=		{670--684}
}

@article{RivestSc93,
author = 	{Ronald L. Rivest and R.E. Schapire},
title = 	{Inference of Finite Automata Using Homing Sequences},
journal=	infcomp,
volume=		103,
number=		2,
month=		apr,
year=		1993,
pages=		{299--347}
}

@article{RivestSc94
,author=   	{Rivest, Ronald L. and R.E. Schapire}
,title=    	{Diversity-Based Inference of Finite Automata}
,journal=	jacm
,year=		1994
,volume=	41
,number=	3
,pages=		{555--589}
,month=		may
}

@inproceedings{RivestSl88a,
author=		{Rivest, Ronald L. and Robert Sloan},
title=		{A New Model for Inductive Inference},
booktitle=	{Proceedings of the Second Conference on Theoretical
		Aspects of Reasoning about Knowledge},
publisher=      {Morgan Kaufmann},
month=		Mar,
year=		1988,
editor=		{Moshe Vardi},
pages=		{13--27}
}

@inproceedings{RivestSl88b,
author = 	{Ronald L. Rivest and Robert Sloan},
title = 	{Learning Complicated Concepts Reliably and Usefully},
year = 		1988,
month =		aug,
booktitle = 	{Proceedings AAAI-88},
orgainzation=	{American Association for Artificial Intelligence},
pages=		{635--639}
}

@inproceedings{Robbins51,
author = {H. Robbins},
title = {Asymptotically subminimax solutions of compound statistical
decision problems},
booktitle = {Proceedings of the 2nd Berkeley Symposium on Mathematical
Statistics and Probability},
year = {1951},
pages = {131--148}
}

@article{Robbins52
,author=	{Herbert Robbins}
,title=		{Some aspects of the sequential design of experiments}
,journal=	{Bulletin American Mathematical Society}
,volume=	55
,year=		1952
,pages=		{527--535}
}

@article{Robbins56
,author=   	{Herbert Robbins}
,title=		{A sequential decision problem with a finite memory}
,journal=       {Proceedings of the National Academy of Science}
,volume=        {42}
,pages=         {920--933}
,year=          {1956}
}

@article{RobbinsMo51,
author = {H. Robbins and S. Monro},
title = {A stochastic approximation method},
year = 1951,
journal = {Annals of Mathematical Statistics},
volume = 22,
pages = {400--407},
}

@incollection{RobbinsSi71,
author = {Herbert Robbins and David Siegmund},
title = {A convergence theorem for non-negative almost supermartingales
  and some applications},
year = 1971,
pages = {233--257},
booktitle = {Optimizing Methods in Statistics},
publisher = {Academic Press},
address = {New York},
}

@book{RobertCa04,
author = {C. Robert and G. Casella},
title = {Monte Carlo Statistical Methods},
year = 2004,
publisher = {Springer},
edition = {{S}econd},
}

@article{Robinson94,
    author = "A. J. Robinson",
    title = "An Application of Recurrent Nets to Phone Probability Estimation",
    journal = "IEEE Transactions on Neural Networks",
    volume = "5",
    number = "2",
    month = "March",
    pages = "298--305",
    year = "1994",
}

@article{Rockafellar69,
author = {R. Tyrell Rockafellar},
title = {Measurable Dependence of Convex Sets and Functions on Parameters},
year = 1969,
journal = {Journal of Mathematical Analysis and Applications},
volume = 28,
pages = {4--25},
}

@Book{Rockafellar70,
  author = 	 {R. Tyrell Rockafellar},
  title = 	 {Convex Analysis},
  publisher = 	 {Princeton University Press},
  year = 	 {1970},
  comment = {The early Bible on convex analysis. No pictures.},
}

@article{Rockafellar76,
author = {R. T. Rockafellar},
title = {Monotone operators and the proximal point algorithm},
year = 1976,
journal = sicon,
volume = 14,
pages = {877--898},
}

@article{Rockafellar76b,
author = {R. T. Rockafellar},
title = {Augmented {L}agrangians and applications of the proximal point
algorithm in convex programming},
year = 1976,
journal = {Mathematics of Operations Research},
volume = 1,
number = 2,
pages = {97--116},
}


@article{RockafellarUr00,
  title={Optimization of conditional value-at-risk},
  author={Rockafellar, R Tyrrell and Uryasev, Stanislav},
  journal={Journal of Risk},
  volume=2,
  pages={21--42},
  year=2000
}

@article{RockafellarWe82,
author = {R. T. Rockafellar and R. J. B. Wets},
title = {On the interchange of subdifferentiation and conditional expectation
for convex functionals},
year = 1982,
journal = {Stochastics: An International Journal of Probability and Stochastic
Processes},
volume = 7,
pages = {173--182},
}

@Book{RockafellarWe98,
  author = 	 {R. T. Rockafellar and R. J. B. Wets},
  title = 	 {Variational Analysis},
  publisher = 	 {Springer},
  address =	 {New York},
  year = 	 {1998}
}

@article{Rockafellar93,
author = {R. Tyrrell Rockafellar},
title = {Lagrange Multipliers and Optimality},
journal = {SIAM Review},
year = 1993,
volume = 35,
pages = {183–-283},
}

@article{Rockafellar07,
  title={Coherent approaches to risk in optimization under uncertainty},
  author={Rockafellar, R Tyrrell},
  journal={Tutorials in operations research},
  volume=3,
  pages={38--61},
  year=2007,
  publisher={Institute for Operations Research and the Management Sciences, INFORMS}
}

@bookchapter{Rocchio6?
,author=	{J. J. Rocchio, Jr.}
,title=		{Relevance feedback in information retrieval}
}

@incollection{Rocchio71,
    Author="J. Rocchio",
    Title="Relevance feedback information retrieval",
    Booktitle="The {Smart} retrieval system---experiments in automatic
        document processing",
    Editor="Gerard Salton",
    Publisher="Prentice-Hall",
    Address="Englewood Cliffs, NJ",
    Pages="313-323",
    Year=1971
}

@article{Rodriguez89
,author=	{Carlos C. Rodriguez}
,title=		{The metrics induced by the {K}ullback number}
}

@article{RohwerAnTo15,
  title={Convergence of large-deviation estimators},
  author={Rohwer, Christian M and Angeletti, Florian and Touchette, Hugo},
  journal={Physical Review E},
  volume=92,
  number=5,
  pages=052104,
  year=2015,
  publisher={APS}
}

@article{Romisch05,
  title={Delta method, infinite dimensional},
  author={R{\"o}misch, Werner},
  journal={Encyclopedia of Statistical Sciences},
  year=2005,
  publisher={Wiley Online Library}
}

@article{RonRu??
,author=	{Dana Ron and Ronitt Rubinfeld}
,title=		{Learning fallible deterministic finite automata}
}

@inproceedings{RonSiTi94
,author=	{Dana Ron and Yoram Singer and Naftali Tishby}
,title=		{Learning probabilistic automata with variable memory
		 length}
,booktitle=	colt94
,year=		1994
,pages=		{35--46}
}

@article{RonSiTi98,
	author = "Dana Ron and Yoram Singer and Naftali Tishby",
	title = "On the learnability and usage of acyclic probabilistic
		finite automata",
	journal = "Journal of Computer and System Sciences",
	volume = 56,
	number = 2,
	pages = "133--152",
	year = 1998
}

@article{RonSiTi96,
	author = {Dana Ron and Yoram Singer and Naftali Tishby},
	title = {The power of amnesia: learning probabilistic
		automata with variable memory length},
	journal  = "Machine Learning",
	volume = 25,
	number = 2,
	pages = "117--150",
	year = 1996
}

@article{RoscasoBeDe10,
author = {Lorenzo Rosasco and Mikhail Belkin and Ernesto {De Vito}},
title = {On learning with integral operators},
year = 2010,
journal = jmlr,
volume = 11,
pages = {905--934},
comment = {
  Studies "learning" with integral operators and kernel functions. That is,
  shows some convergence results--building on a Hilbert-space convergence
  result for bounded vectors by Pinelis92--that show that empirical versions
  of the kernel matrix (Gram matrix) converge to the linear (integral) operator
  defined by $\mc{K}f(x) = \int k(x, y) f(y) dP(y)$. They do this via a
  spectral decomposition of $\mc{K}$ and defining the vectors (in Hilbert
  space) $\phi_i(\cdot) = (1/n) \sum_{i=1}^n k(\cdot, x_i) u_{i,j}$, where
  $u_i$ is the $i$th eigenvector of $K_n$, the empirical Gram matrix. Then
  using the "expansion" into the Hilbert space defined by
  $\mc{K}_n = \sum_{i=1}^n \sqrt{\lambda_i} \<\phi_i(\cdot), f\> \phi_i$
  for all $f$ in the Hilbert space converges to $\mc{K}$. (Or something close
  to this, at least, modulo some corrections in eigenvalues.)
},
}

@article{RoseGuFo90
,author=	{Kenneth Rose and Eitan Gurewitz and Geoffrey C. Fox}
,title=		{Vector quantization by deterministic annealing}
}

@article{Rosenblatt58,
author = 	{F.~Rosenblatt},
title = 	{The Perceptron: A Probabilistic Model for Information Storage
		 and Organization in the Brain},
journal = 	{Psychological Review},
year = 		1958,
volume = 	65,
pages = 	{386--407},
comment = 	{Classic article introducing the perceptron model},
note = 		{(Reprinted in {\sl Neurocomputing} (MIT Press, 1988).)}
}

@Book{Rosenblatt62,
  author = 	 {Rosenblatt, F.},
  title = 	 {Principles of Neurodynamics},
  publisher = 	 {Spartan},
  year = 	 1962,
  address =	 {New York}
}

@article{Rosenthal70,
author = {Haskell Rosenthal},
title = {On the subspaces of ${L}^p$ ($p > 2$) spanned by sequences of
  independent random variables},
year = 1970,
journal = {Israel Journal of Mathematics},
volume = 8,
pages = {273--303},
comment = {Proves the Rosenthal inequalities for sums of independent
  random variables using symmetrization. That is, shows how
  $E[(\sum_{i=1}^n X_i)^{2m}]$ is bounded by
  $E[\sum_{i=1}^n X_i^{2m}]$ and $(\sum_{i=1}^n E[X_i^2])^m$},
}

@article{RothBe91,
author=		{Ron M. Roth and Gyora M. Benedek},
title=		{Interpolation and approximation of sparse
		 multivariate polynomials over {GF(2)}},
journal=	sicomp,
volume=		20,
number=		2,
pages=		{291--314},
month=		apr,
year=		1991
}

@article{RousuSaSzSh06,
author =        {J. Rousu and C. Saunders and S. Szedmak and J. Shawe-Taylor},
title =         {Kernel-Based Learning of Hierarchical Multilabel Classification Models},
journal =       {Journal of Machine Learning Research},
volume  =       {7},
pages =         {1601--1626},
year =          {2007}
}

@article{Rousseeuw84,
author = {Peter Rousseeuw},
title = {Least median of squares regression},
journal = jasa,
volume = 79,
number = 388,
pages = {871--880},
year = 1984,
}

@article{RoweisSa00,
author =        {S.~T.~Roweis and L.~K.~Saul},
title =         {Nonlinear dimensionality reduction by locally linear embedding},
journal =       {Science},
volume  =       {290},
pages =         {2323--2326},
year =          {2000}
}

@book{Royden88,
author = {Halsey Royden},
year = 1988,
title = {Real Analysis},
edition = {Third},
publisher = {Pearson},
}

@article{RozsaGuBo16,
  title={Towards robust deep neural networks with BANG},
  author={Rozsa, Andras and Gunther, Manuel and Boult, Terrance E},
  journal={arXiv:1612.00138 [cs.CV]},
  year=2016
}

@article{Rubin74,
author = {Donald B. Rubin},
title = {Estimating causal effects of treatments in randomized and
                  nonrandomized studies},
year = 1974,
journal = {Journal of Educational Pyschology},
pages = {688--701},
volume = 66,
number = 5,
}

@article{Rubin05,
author = {Donald B. Rubin},
title = {Causal Inference Using Potential Outcomes: Design,
     Modeling, Decisions},
year = 2005,
journal = jasa,
pages = {322--331},
volume = 100,
number = 469,
}

@book{Rubinstein81,
author = {R. Y. Rubinstein},
title = {Simulation and the Monte Carlo Method},
year = 1981,
publisher = {Wiley},
}

@article{RubinsteinBaHuTa12,
author = {Benjamin I. P. Rubinstein and Peter L. Bartlett and Ling Huang
and Nina Taft},
title = {Learning in a large function space: privacy-preserving mechanisms
for {SVM} learning},
year = 2012,
journal = {Journal of Privacy and Confidentiality},
volume = 4,
number = 1,
pages = {65--100},
comment = {Similar to Chaudhuri's work, some results on differential privacy
for the released weight vector that results from SVM learning. Shows
some privacy-utility trade-off. Main results include differential privacy
by perturbation + a stability analysis. Handles kernels by using Recht and
Rahimi's random basis functions approach. Theorems 18 and 20 in the paper
show a tradeoff: there is either privacy or (high probability) utility, but
not both. I don't believe the trade-off is sharp. Includes nice background
section with several relevant references.
url = {http://arxiv.org/abs/0911.5708v1},
},
}

@article{RubinsteinKr04,
  title={The cross-entropy method: A unified approach to Monte Carlo simulation, randomized optimization and machine learning},
  author={Rubinstein, Reuven Y and Kroese, Dirk P},
  journal={Information Science \& Statistics, Springer Verlag, NY},
  year=2004
}

@article{Rudelson99,
author = {Mark Rudelson},
title = {Random vectors in the isotropic position},
year = 1999,
journal = {Journal of Functional Analysis},
volume = 164,
pages = {60--72},
}

@article{RudelsonVe07,
author = {Mark Rudelson and Roman Vershynin},
title = {Sampling from large matrices: an approach through geometric functional analysis},
year = 2007,
journal = jacm,
volume = 54,
number = 4,
pages = {21:1--21:19},
}


@inproceedings{Rudich85,
author = 	{Rudich, S.},
title = 	{Inferring the structure of a {M}arkov chain from its output},
booktitle = 	focs85,
month = 	Oct,
year = 		1985,
pages = 	{321--326}
}


@inproceedings{RudinCoMoSc05,
author = 	{C. Rudin and C. Cortes and M. Mohri and R.E.  Schapire},
title = 	{Margin-Based Ranking and Boosting Meet in the Middle},
booktitle = 	colt05,
year = 		2005,
pages = 	{63--78}
}

@book{Rudin91,
author = {W. Rudin},
title = {Functional Analysis, Second Edition},
year = 1991,
publisher = {McGraw Hill},
comment = {Essentially, the bible on functional analysis. Has tons of
good results, though proofs are sometimes a bit terse.},
}

@book{Rudin76,
author = {Walter Rudin},
title = {Principles of Mathematical Analysis, Third Edition},
year = 1976,
publisher = {McGraw-Hill},
}

@inproceedings{Rudin06,
author = {C. Rudin},
title = {Ranking with a $p$-norm push},
year = 2006,
booktitle = colt06,
}

@article{RudinOsFa92,
author = {Leonid Rudin and Stanley Osher and Emad Fatemi},
title = {Nonlinear total variation based noise removal algorithms},
year = 1992,
journal = {Physica D},
volume = 60,
pages = {259--268},
}

@article{RudinSc09,
author=  {Cynthia Rudin and Robert E. Schapire},
title = {Margin-Based Ranking and an Equivalence between {A}da{B}oost and {R}ank{B}oost},
journal = jmlr,
volume = {10},
month={Oct},
year= {2009},
pages= {2193--2232}
}

@article{Rudin09,
author = {C. Rudin},
title = {The $p$-norm push: a simple convex ranking algorithm that
   concentrates at the top of the list},
journal = jmlr,
year = 2009,
pages = {2233--2271},
volume = 10,
}

@Article{RudinScDa07,
  author = 	 {C. Rudin and R.E. Schapire and I. Daubechies},
  title = 	 {Analysis of Boosting Algorithms using the Smooth Margin Function},
  journal = 	 {Annals of Statistics,},
  year = 	 {2007}
}

@incollection{RumelhartHiMc86,
author=   	{Rumelhart, David E. and Geoffrey E. Hinton and J. L.
		McClelland},
title=    	{A General Framework for Parallel Distributed Processing},
chapter=  	2,
booktitle=	{Parallel Distributed Processing (Volume I: Foundations)},
editor=   	{David E. Rumelhart and James L. McClelland},
publisher=	{MIT Press},
year=     	1986,
pages=    	{45--76},
comment=  	{Overview of various models}
}

@techreport{RumelhartHiWi85,
author=   	{Rumelhart, David E. and Geoffrey E. Hinton and Ronald J.
		Williams},
title=    	{Learning Internal Representations by Error Propagation},
institution=  	{Institute for Cognitive Science, U.C. San Diego},
year=     	1985,
month=    	Sep,
number=   	{ICS Report 8506},
note=     	{To appear in {\sl Parallel Distributed Processing:
		Explorations in the Microstructure of Cognition}, Vol. 1,
		edited by Rumelhart and McClelland (MIT Press)},
comment=  	{Introduces `generalized delta rule' for back-propagating
		information in a network of deterministic sigmoid (logistic)
		rules.}
}

@incollection{RumelhartHiWi86,
author=   	{Rumelhart, David E. and Geoffrey E. Hinton and Ronald J.
		Williams},
title=    	{Learning Internal Representations by Error Propagation},
booktitle=	{Parallel Distributed Processing -- Explorations in the
		Microstructure of Cognition},
editor=   	{David E. Rumelhart and James L. McClelland},
publisher= 	{MIT Press},
year=      	1986,
chapter=   	8,
pages=     	{318--362},
comment=   	{Classic paper introducing the generalized delta rule
		(back-propagation).}
}

@book{RumelhartMc86,
editor=   	{Rumelhart, David E. and McClelland, James L.},
title=    	{Parallel Distributed Processing},
publisher=	{MIT Press},
year=     	1986,
comment=  	{Overview of various models}
}

@article{RumelhartZi85,
author=   	{Rumelhart, David E. and David Zipser},
title=    	{Feature Discovery by Competitive Learning},
journal=  	{Cognitive Science},
year=     	1985,
volume=   	9,
pages=    	{75--112},
comment=  	{Historical survey of perceptrons etc.; competitive learning
		in a layered network with inhibitory clusters}
}

@inproceedings{RushPe12,
author = {Alexander Rush and Slav Petrov},
title = {Vine Pruning for Efficient Multi-Pass Dependency Parsing},
year = 2012,
booktitle = {Proceedings of the 2012 Conference of the North American Chapter
of the Association for Computational Linguistics (NAACL)},
pages = {498--507},
}

@misc{RushCo11,
author = {Alexander Rush and Michael Collins},
title = {A Tutorial on Dual Decomposition and Lagrangian Relaxation for
  Inference in Natural Language Processing},
year = 2011,
howpublished = {Presented at the 49th Annual Meeting of the
  Association for Computational Linguistics},
url = {http://www.cs.columbia.edu/~mcollins/acltutorial.pdf},
}

@inproceedings{RushSoCoJa10,
author = {Alexander Rush and David Sontag and Michael Collins and Tommi
Jaakkola},
title = {On dual decomposition and linear programming relaxations
for natural language processing},
booktitle = emnlp,
year = 2010,
}

@article{RussakovskyDeSuKrSaMaHuKaKhBeBeFe14,
author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and
Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and
Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
title = {Image{N}et Large Scale Visual Recognition Challenge},
year = 2014,
journal = {arXiv:1409.0575 [cs.CV]},
}

@article{RussoVa14c,
author = {Daniel Russo and Benjamin {Van Roy}},
title = {Learning to Optimize Via Posterior Sampling},
year = 2014,
journal = {Mathematics of Operations Research},
pages = {1221--1243},
volume = 39,
number = 4,
}

@article{RussoVa14,
author = {Daniel Russo and Benjamin {Van Roy}},
title = {An information-theoretic analysis of {T}hompson Sampling},
year = 2014,
journal = jmlr,
pages = {To appear},
}

@inproceedings{RussoVa14b,
author = {Daniel Russo and Benjamin {Van Roy}},
title = {Learning to optimize via information-directed sampling},
year = 2014,
booktitle = nips27,
}

@article{RussoZo15,
author = {Daniel Russo and James Zou},
title = {Controlling bias in adaptive data analysis using information theory},
year = 2015,
journal = {arXiv:1511.05219 [stat.ML]},
comment = {Uses some simple information theoretic inequalities to bound
  the bias of ``adaptive'' choices of data to release in simple mean
  estimation problems},
}

@article{RuszczynskiSh06,
  title={Optimization of convex risk functions},
  author={Ruszczynski, Andrzej and Shapiro, Alexander},
  journal={Mathematics of operations research},
  volume=31,
  number=3,
  pages={433--452},
  year=2006,
  publisher={INFORMS}
}

@article{Saaty03,
author = {T.~L.~Saaty},
title = {Decision making with the {AHP}: why is the principal eigenvector
necessary},
year = 2003,
journal = {European Journal of Operational Research},
volume = 145,
pages = {85--91},
}

@article{Saaty08,
author = {T.~L.~Saaty},
title = {Relative measurement and its generalization in decision making},
year = 2008,
journal = {Review of the Royal Spanish Academy of Sciences, Series A,
 Mathematics},
volume = 102,
number = 2,
pages = {251--318},
}

@inproceedings{SabatoMu14,
  title={Active regression by stratification},
  author={Sivan Sabato and Remi Munos},
  booktitle={Advances in Neural Information Processing Systems},
  pages={469--477},
  year={2014}
}

@article{SairaYoTaMoAvPe12,
  title={Test of the Jarzynski and Crooks fluctuation relations in an electronic system},
  author={Saira, O-P and Yoon, Y and Tanttu, T and M{\"o}tt{\"o}nen, M and Averin, DV and Pekola, Jukka P},
  journal={Physical review letters},
  volume=109,
  number=18,
  pages=180601,
  year=2012,
  publisher={APS}
}

@phdthesis{Sakakibara91,
author=		{Yasubumi Sakakibara},
title=		{Algorithmic Learning of Formal Languages and Decision
		 Trees},
month=		oct,
year=		1991,
school=		{Tokyo Institute of Technology},
note=		{Research Report IIAS-RR-91-22E,
		 International Institute for Advanced Study of Social
		 Information Science, Fujitsu Laboratories, Ltd.}
}

@article{SalinettiWe79,
author = {Gabriella Salinetti and Roger J.-B. Wets},
title = {On the convergence of sequences of sets in finite dimensions},
year = 1979,
journal = {SIAM Review},
pages = {18--33},
volume = 21,
number = 1,
comment = {Considers 4 different types of convergence for sets, including
  Kuratowski convergence ($\limsup$ and $\liminf$ of sets), Hausdorff
  convergence, and what they call $*$-convergence, which means that
  the support functions of the sets converge pointwise. For sequences of
  compact convex sets, all these types of convergence coincide. },
}


@Article{SaltonBu88,
  author = 	 {G. Salton and C. Buckley},
  title = 	 {Term weighting approaches in automatic text retrieval},
  journal = 	 {Information Processing and Management},
  year = 	 {1988},
  volume = 	 {24},
  number = 	 {5}
}


@inproceedings{SalomonKiOs02,
author=		{J. Salomon and S. King and M. Osborne},
title=		{Framewise phone classification using support vector machines},
booktitle = "Proceedings of the Seventh International Conference on
		Spoken Language Processing",
pages=		{2645-2648},
year=		2002
}

@book{Salton89,
        author = {Gerard Salton},
        publisher = {Addison-Wesley},
        title = {Automatic text processing: the transformation,
                analysis and retrieval of information by computer},
        year = {1989}
}

@article{Salton91,
    Author="G.~Salton",
    Title="Developments in Automatic Text Retrieval",
    Journal="Science",
    Volume=253,
    Pages="974-980",
    Year="1991"
}

@book{SaltonMc83,
        author = {Gerard Salton and Michael J. McGill},
        publisher = {McGraw-Hill},
        title = {Introduction to Modern Information Retrieval},
        year = {1983}
}

@techreport{Salzberg88,
author = 	{Steven Salzberg},
title = 	{Exemplar-based learning:  theory and implementation},
institution = 	{Harvard University},
year = 		{1988},
type = 		{Center for Research in Computing Technology},
number = 	{TR-10-88},
address = 	{Cambridge, Mass.},
month = 	oct,
comment= 	{Actually uses learning of differences of orthogonal
		rectangles stuff in a practical application (analyzing breast
		cancer statistics)}
}

@article{Samaranayake92
,author=	{K. Samaranayake}
,title=		{Stay-with-a-winner rule for dependent {B}ernoulli
		bandits}
}

@article{Samson00,
author = {P. Samson},
title = {Concentration of measure inequalities for {M}arkov chains and
 $\phi$-mixing processes},
year = 2000,
journal = aop,
volume = 28,
number = 1,
pages = {416--461},
comment = {Provides some T2-type inequalities (convex distance inequalities)
for measure concentration using strongly-mixing processes. Uses the entropy
method to do so. Also shows that convex Lipschitz functions
are really tightly concentrating.}
}

@article{Samuel59,
author = 	{A. L. Samuel},
title = 	{Some studies in machine learning using the game of checkers},
journal = 	{IBM Journal of Research and Development},
year = 		1959,
month = 	Jul,
volume = 	3,
pages = 	{211--229},
note = 		{(Reprinted in {\em Computers and Thought}, (eds.
		  E. A. Feigenbaum and J. Feldman), McGraw-Hill, 1963,
		  pages 39--70).}
}

@article{Samuelson69
,author=	{Paul A. Samuelson}
,title=		{Lifetime portfolio selection by dynamic stochastic
		 programming}
,year=		1969
}

@article{Samuelson71
,author=	{Paul A. Samuelson}
,title=		{The ``fallacy'' of maximizing the geometric mean in
		 long sequences of investing or gambling}
,year=		1979
}

@article{Samuelson79
,author=	{Paul A. Samuelson}
,title=		{Why we should not make mean log of wealth big though
		 years to act are long}
,year=		1979
}

@article{SankarSpTe06,
author = {Arvind Sankard and Daniel Spielman and Shang-Hua Teng},
title = {Smoothed analysis of the condition numbers and growth factors
  of matrices},
year = 2006,
journal = simat,
pages = {446--476},
volume = 28,
number = 2,
comment = {Shows that under Gaussian perturbation, a matrix is unlikely
  to have a bad condition number. In particular, $\kappa(A) \le x$ with
  probability at least $1 - (15 n (1 + \sqrt{log(x) / 9n})) / x \sigma$,
  where $A$ is the Gaussian perturbation of an arbitrary square matrix
  $\bar{A}$ satisfying $\norm{\bar{A}} \le \sqrt{n}$.
  Argument is by showing that $A$ is close to $\bar{A}$ with high
  probability, and then noting that $\norm{A^{-1} v} \le x$ with
  probability decreasing as $x^{-1}$, which follows via an anti-concentration
  of Gaussian inverses argument. Things get much harder with rectangular
  matrices or perturbations that do not touch zeros.},
}

@inproceedings{SankarRaPo10,
author = {Lalitha Sankar and S. Raj Rajagopalan and H. Vincent Poor},
title = {An information-theoretic approach to privacy},
year = 2010,
booktitle = {The 48th Allerton Conference on Communication, Control,
and Computing},
pages = {1220--1227},
}

@article{SanthaVa86,
author=		{M. Santha and U. V. Vazirani},
title=		{Generating Quasi-random Sequences from Semi-random
		 Sources},
journal=	jcss,
volume=		33,
number=		1,
month=		aug,
year=		1986,
pages=		{75--87}
}

@ARTICLE{SanthanamWa12,
        AUTHOR = "N. P. Santhanam and M. J. Wainwright",
        TITLE = "Information-theoretic limits of selecting binary graphical
models in high dimensions",
       JOURNAL = ieeeit,
       YEAR = 2012,
       VOLUME = 58,
       NUMBER = 7,
       PAGES = "4117--4134"
}

@article{Sard42,
author = {Arthur Sard},
title = {The measure of the critical values of differentiable maps},
journal = {Bulletin of the American Mathematical Society},
year = 1942,
volume = {48},
number = 12,
pages = {883--890},
comment = {Shows (among other results) that if a function
  $f : \R^n \to \R$ is $C^n$, then the measure of the image of
  its critical points is 0. This set may have higher Hausdorff dimension
  though. (The hypothesis on $C^n$ cannot be weakened due to
  Whitney35.)},
}

@techreport{Sarkar91
,author=	{D. Sarkar}
,title=		{Nonsubscriber card behavior score model development
		--- overlimit accounts}
}

@unknown{Saul98
,author=         {Lawrence K. Saul}
,title=          {Automatic segmentation of continuous trajectories
                  with invariance to nonlinear warpings of time}
,year=           1998
}

@article{SatoAbTa88
,author=	{Mitsuo Sato and Kenichi Abe and Hiroshi Takeda}
,title=		{Learning control of finite markov chains with an
		 explicit trade-off between estimation and control}
}

@unknown{SaulPe??
,author=        {Lawrence Saul and Fernando Pereira}
,title=         {Aggregate and mixed-order {Markov} models for
                  statistical language processing}
}

@unknown{SaulRa98
,author=         {Lawrence K. Saul and Mazin Rahim}
,title=          {Maximum likelihood and minimum classification error
                  factor analysis for automatic speech recognition}
,year=           1998
}

@Article{Sauer72,
  author = 	 {N. Sauer},
  title = 	 {On the density of families of sets},
  journal = 	 {Journal of Combinatorial Theory Series A},
  year = 	 1972,
  volume =	 13,
  pages =	 {145-147}
}

@unpublished{SaulJo93
,author=	{Lawrence Saul and Michael Jordan}
,title=		{Learning in Boltzman Trees}
}

@article{Scarsini99,
author = {Marco Scarsini},
title = {Multivariate convex orderings, dependence, and stochastic equality},
journal = {Journal of Applied Probability},
volume = 35,
pages = {93--103},
year = 1999,
comment = {Shows some equality in distribution results that are implied by
  a number of convex ordering constraints. In particular, shows that
  $X \le_{\rm lcx} Y$, meaning that $\E[\phi(a^T X)] \le \E[\phi(a^T Y)]$
  for all vectors $a \in \R^d$ (the linear convex ordering), coupled with
  $\E[X_i^2] = \E[Y_i^2]$, implies that $X = Y$ in distribution. The
  proof follows by noting that $\E[X] = \E[Y]$ because of the linear convex
  ordering constraint, then showing there are versions of $X$ and $Y$ (on
  different probability spaces) with $\E[\tilde{Y} \mid \tilde{X}]
  = \tilde{X}$, so that $\var(\tilde{Y} \mid \tilde{X}) = 0$. (This is by
  the conditional expectation decomposition of variance and Strassen's theorem
  on random variables.) In particular, by the fact that the extremal
  $1$-dimensional convex functions are of the form $\max\{x - t, 0\}$, we
  have that $X = Y$ in distribution if and only if
  (1) $\E[\max\{a^T X - b, 0\}] \le \E[\max\{a^T Y - b, 0\}]$ for all
  $a, b$ and $\E[||X||^2] \ge \E[||Y||^2]$.},
}

@article{Schaffer93
,author=	{Cullen Schaffer}
,title=		{Overfitting avoidance as bias}
}

@mastersthesis{Schapire88,
author=		{Schapire, Robert Elias},
title=		{Diversity-based Inference of Finite Automata},
school=		mit,
year=		1988,
month=		may,
note=           {Supervised by Ronald L. Rivest.
		 Technical Report MIT/LCS/TR-413,
		 MIT Laboratory for Computer Science}
}

@inproceedings{Schapire89,
author=		{Schapire, R.E.},
title=		{The Strength of Weak Learnability},
booktitle=	focs89,
pages=		{28--33},
month=    	Oct,
year=		1989
}

@inproceedings{Schapire90,
author=		{Schapire, R.E.},
title=		{Pattern Languages Are Not Learnable},
booktitle=	colt90,
pages=		{122--129},
month=		Aug,
year=		1990
}

@article{Schapire90b,
author=		{R.E. Schapire},
title=		{The Strength of Weak Learnability},
journal=	ml,
year=		1990,
volume=		5,
number=		2,
pages=		{197--227}
}

@techreport{Schapire90c,
author=		{R.E. Schapire},
title=		{The Emerging Theory of Average-case Complexity},
institution=	mitlcs,
year=		1990,
month=		Jun,
number=		{Technical memo MIT/LCS/TM-431}
}

@phdthesis{Schapire91,
author=		{Robert Elias Schapire},
title=		{The Design and Analysis of Efficient Learning Algorithms},
year=		1991,
month=		feb,
school=		mit,
note=		{Supervised by Ronald~L. Rivest.
		 Technical Report MIT/LCS/TR-493,
		 MIT Laboratory for Computer Science}
}

@inproceedings{Schapire91b,
author=		{R.E. Schapire},
title=		{Learning Probabilistic Read-once Formulas on Product
		 Distributions},
booktitle=	colt91,
month=		aug,
year=		1991,
note=		{To appear, {\it Machine Learning}}
}

@book{Schapire92,
author=		{R.E. Schapire},
title=		{The Design and Analysis of Efficient Learning
		 Algorithms},
publisher=	{MIT Press},
year=		1992
}

@article{Schapire94
,author=	{R.E. Schapire}
,title=		{Learning Probabilistic Read-once Formulas on Product
		 Distributions}
,journal=	ml
,volume=	14
,number=	1
,pages=		{47--81}
,year=		1994
}

@inproceedings{Schapire97
,author=	{R.E. Schapire}
,title=		{Using output codes to boost multiclass learning problems}
,booktitle=	ml97
,year=		1997
,pages=         {313-321}
}



@InCollection{Schapire03,
  author = 	 {R.E. Schapire},
  title = 	 {The boosting approach to machine learning: An overview},
  booktitle = 	 {Nonlinear Estimation and Classification},
  publisher = {Springer},
  year = 	 {2003},
  editor = 	 {D.D. Denison and M.H. Hansen and C. Holmes and B. Mallick and B. Yu},
}

@inproceedings{SchapireFrBaLe97
,author=	{R.E.~Schapire and Y.~Freund and P.~Bartlett
		 and W.S.~Lee}
,title=		{Boosting the margin: A new explanation for the
		 effectiveness of voting methods}
,booktitle=	ml97
,year=		1997
,pages=         {322-330}
,note=          {To appear, {\em The Annals of Statistics}}
}

@InProceedings{Schapire99b,
  author = 	 {R.E. Schapire},
  title = 	 {Drifting Games},
  booktitle = 	 colt99,
  year =	 1999
}

@Article{SchapireFrBaLe98,
  author=	{R.E.~Schapire and Y.~Freund and P.~Bartlett
		 and W.S.~Lee},
  title = 	 {Boosting the margin: A new explanation for the
		 effectiveness of voting methods},
  journal = 	 annstat,
  year = 	 1998,
  month = 	 {October},
  volume = 	 26,
  number = 	 5,
  pages=         {1651-1686}
}

@book{SchapireFr12,
author = {Robert E. Schapire and Yoav Freund},
title = {Boosting: Foundations and Algorithms},
publisher = {MIT Press},
year = 2012,
}

@InProceedings{SchapireRoRaGu02,
	author = "R.E. Schapire and M. Rochery and M. Rahim and N. Gupta",
	title = "Incorporating prior knowledge into boosting",
	booktitle = ml02,
	year = 2002
}

@inproceedings{SchapireSe93
,author=	{R.E. Schapire and Linda M. Sellie}
,title=		{Learning sparse multivariate polynomials over a field
		 with queries and counterexamples}
,booktitle=	colt93
,month=		jul
,year=		1993
,pages=		{17--26}
}

@article{SchapireSe96
,author=	{R.E. Schapire and Linda M. Sellie}
,title=		{Learning sparse multivariate polynomials over a field
		 with queries and counterexamples}
,journal=	jcss
,month=		apr
,year=		1996
,pages=		{201-213}
,volume=	52
,number=	2
}

@article{SchapireSi99
,author=	{R.~E.~Schapire and Y.~Singer}
,title=		{Improved boosting algorithms using confidence-rated predictions}
,journal=     ml
,year=		1999
,pages=         {1--40}
,volume=	37
,number=	3
}

@inproceedings{SchapireSi98
,author=	{R.E. Schapire and Y. Singer}
,title=		{Improved boosting algorithms using confidence-rated predictions}
,booktitle=     colt98
,year=		1998
,pages=         {80-91}
,note=          {To appear, {\it Machine Learning}}
}

@article{SchapireSi98b,
  author = 	 {R.E. Schapire and Y. Singer},
  title = 	 {{BoosTexter}: A boosting-based system for
                  text categorization},
	journal = 	 ml,
	volume = 32,
  number =	 {2/3},
  year =	 {2000}
}

@InProceedings{SchapireSiSi98,
  author = 	 {R.~E.~Schapire and Y.~Singer and A.~Singhal},
  title = 	 {Boosting and {R}occhio applied to text filtering},
  booktitle = 	 {SIGIR '98: Proceedings of the 21st Annual
                  International Conference on Research and Development
                  in Information Retrieval},
  year =	 1998
}

@inproceedings{SchapireWa94
,author=	{R.E. Schapire and Manfred K. Warmuth}
,title=		{On the worst-case analysis of temporal-difference
		 learning algorithms}
,booktitle=	ml94
,month=		jul
,year=		1994
,pages=		{266--274}
,publisher=	{Morgan Kaufmann}
,note=		{To appear, {\it Machine Learning}}
}

@Article{SchapireWa96,
  author = 	 {R.E. Schapire and Manfred K. Warmuth},
  title = 	 {On the worst-case analysis of temporal-difference
		 learning algorithms},
  journal = 	 ml,
  year = 	 1996,
  volume =	 22,
  number =	 {1/2/3},
  pages =	 {95-121}
}

@article{SchechtmanElCoChMiSe15,
author = {Yoav Schechtman and Yonina C. Eldar and Oren Cohen
 and Henry N. Chapman and Jianwei Miao and Mordechai Segev},
title = {Phase Retrieval with Application to Optical Imaging},
year = 2015,
journal = {IEEE Signal Processing Magazine},
pages = {87--109},
month = {May},
}

@article{Schlegel70,
author = {P. Schlegel},
title = {The explicit inverse of a tridiagonal matrix},
year = 1970,
journal = {Mathematics of Computation},
volume = 24,
number = 111,
pages = 665,
}

@article{Schmidhuber15,
	Author = {Schmidhuber, J\"{u}rgen},
	Journal = {Neural networks},
	Pages = {85--117},
	Publisher = {Elsevier},
	Title = {Deep learning in neural networks: An overview},
	Volume = {61},
	Year = {2015}
}

@inproceedings{SchmidtLeBa11,
author = {Mark Schmidt and Nicolas Le Roux and Francis Bach},
title = {Convergence rates of inexact proximal-gradient methods
  for convex optimization},
year = 2011,
booktitle = nips24,
}

@inproceedings{ScholkopfBuVa95,
	author = "B. {Sch\"olkopf} and C. Burges and V.N. Vapnik",
	title = "Extracting support data for a given task",
	booktitle = "First International Conference on Knowledge
		Discovery {\&} Data Mining ({KDD})",
	editor = "U.M. Fayyad and R. Uthurusamy",
	publisher = "{AAAI} Press",
	year = 1995
}


@phdthesis{Scholkopf97,
	author = "B. {Sch\"olkopf}",
	title = "Support Vector Learning",
	school = "GMD First",
	year = 1997
}


@book{ScholkopfBuSm98,
	editor = {B. Sch\"olkopf and C. Burges and A. Smola},
	title = " Advances in Kernel Methods - Support Vector Learning",
	publisher = "MIT Press",
	year = 1998
}

@article{ScholkopfMiBuKnMuRaSm99,
title = "Input space versus feature space in kernel-based methods",
author = "B.~Sch{\"o}lkopf and S.~Mika and C.J.C.~Burges and P.~Knirsch and K-R M{\"u}ller and G.~R{\"a}tsch and A.J.~Smola",
journal = ieeenn,
volume = 10,
number = 5,
month = {September},
year = {1999},
pages = {1000--1017}
}

@article{ScholkopfSmMu98,
  author = {Bernhard Sch\"olkopf and Alexander Smola
      and Klaus-Robert M\"uller},
  title = "Nonlinear component analysis as a kernel eigenvalue problem",
   journal = 	 {IEEE Transactions on Information Theory},
  year = 	 1998,
  volume =	 10,
  number =	 5,
  pages =	 {1299--1319},
}

@TechReport{ScholkopfSuBuGiNiPoVa97,
	author = "B. {Sch\"olkopf} and K. Sung and C. Burges and
		F. Girosi and P. Niyogi and T. Poggio and V. Vapnik",
	title = "Comparing support vector machines with {G}aussian kernels
		to radial basis function classifiers",
	number = "A.I.~Memo No. 1599",
	institution = "Massachusetts Institute of Techology",
	year = 1996
}

@TechReport{ScholkopfSmWiBa98,
	author = {B. Sch\"olkopf and A. Smola and R. Williamson and P. L. Bartlett},
	title = "New Support Vector Algorithms",
	institution = "NeuroColt2",
	year = "1998",
	number = "NC2-TR-1998-053"
}


@inbook{ScholkopfSmMu99,
   booktitle = {Advances in Kernel Methods - Support Vector Learning},
   author = {Sch\"olkopf, B. and A.J. Smola and K.-R. M\"{u}ller},
   title = {Kernel principal component analysis.},
   year = {1999},
   publisher = {MIT Press},
   pages = {327-352}
}

@article{ScholkopfMiBuKnMuRaSm99,
  author = {B. Sch\"olkopf and S. Mika and C.J.C. Burges and P. Knirsch
  	and K. M\"uller and G. R\"atsch and A.J. Smola},
  title = {Input Space vs. Feature Space in Kernel-Based Methods},
  journal = 	 {IEEE Transactions on Neural Networks},
  year = 	 {1999},
  volume =	 {10},
  number =	 {5},
  pages =	 {1000--1017}
}

@inproceedings{ScholkopfHeSmWi00,
	author = {B.~Sch\"olkopf and R.~Herbrich and A.~Smola and R.~Williamson},
	title = {A Generalized Representer Theorem},
	booktitle = colt00,
	year = 2000
}

@article{ScholkopfPlShSmWi01,
  author = {B.~Sch\"olkopf and J.~Platt and J.~Shawe-Taylor and A.~J.~Smola and R.~C.~Williamson},
  title = {Estimating the support of a high-dimensional distribution},
  journal = 	 {Neural Computation},
  year = 	 {2001},
  volume =	 {13},
  number =	 {7},
  pages =	 {1443--1472}
}


@book{ScholkopfSm02,
	author = {B. Sch\"olkopf and A.~J. Smola},
	title = "Learning with Kernels:
                 Support Vector Machines, Regularization, Optimization and Beyond",
	publisher = "MIT Press",
	year = 2002
}


@InProceedings{SchutzeSi94,
	author = "H. Schutze and Y. Singer",
	title = "Part-of-speech tagging using a variable memory {Markov} model",
	booktitle = "32rd Annual Meeting of the Association for Computational
		Linguistics",
	year = 1994
}

@InProceedings{Schwenk99,
  author = 	 {Holger Schwenk},
  title = 	 {Using boosting to improve a hybrid {HMM}/neural
                  network speech recognizer},
  booktitle = 	 {IEEE International Conference On Acoustics, Speech,
                  and Signal Processing},
  pages =	 {II:1009-1012},
  year =	 1999
}

@InProceedings{SchwenkBe98,
  author = 	 {Holger Schwenk and Yoshua Bengio},
  title = 	 {Training methods for adaptive boosting of neural
                  networks},
pages={647-653},
  booktitle = 	 nips10,
  year =	 1998
}

@article{Schraudolph02,
	title={Fast curvature matrix-vector products for second-order gradient 
	descent},
	author={Schraudolph, Nicol N},
	journal={Neural computation},
	volume={14},
	number={7},
	pages={1723--1738},
	year={2002},
	publisher={MIT Press}
}

@article{Scott79,
author = {David Scott},
title = {On optimal and data-based histograms},
year = 1979,
journal = {Biometrika},
volume = 66,
number = 3,
pages = {605--610},
comment = {Computes optimal width of histogram bins and shows that the
asymptotic risk for this family, even in the case of 2 bounded derivatives,
is $O(n^{-2/3})$, which is sub-optimal but might be fine. Suggestive that
histograms are only good for Lipschitz densities.},
}

@article{SejnowskiRo87,
author=   	{Sejnowski, Terrence J. and Charles R. Rosenberg},
title=    	{Parallel Networks that Learn to Pronounce English Text},
journal=  	{Journal of Complex Systems},
year=     	1987,
month=    	Feb,
volume=   	1,
number=   	1,
pages=    	{145--168},
comment=  	{Classic paper covering the NETtalk system, which learns to
		convert English text to speech.}
}

@unpublished{SelfCh87,
author=   	{Self, Matthew and Cheeseman, Peter C.},
title=    	{Bayesian Prediction for Artificial Intelligence},
note=     	{(unpublished manuscript)}
}

@book{Seneta81,
author=		{E. Seneta},
title=		{Non-negative Matrices and Markov Chains},
edition=	{second},
year=		1981,
publisher=	{Springer-Verlag}
}

@book{Serfling80,
author = {Robert Serfling},
title = {Approximation Theorems of Mathematical Statistics},
year = 1980,
publisher = {John Wiley \& Sons},
}

@inproceedings{Servedio01,
    author = "Rocco A. Servedio",
    title = "Smooth Boosting and Learning with Malicious Noise",
    booktitle = "14th Annual Conference on Computational Learning Theory, {COLT} 2001 and 5th {E}uropean Conference on Computational Learning Theory, {EuroCOLT} 2001, Amsterdam, The Netherlands, July 2001, Proceedings",
    volume = "2111",
    publisher = "Springer, Berlin",
    pages = "473--489",
    year = "2001",
    url = "citeseer.nj.nec.com/443804.html"
}

@article{Servedio03,
author = {R.A. Servedio},
title = {Smooth Boosting and Learning with Malicious Noise},
journal = {Journal of Machine Learning Research},
volume = {4},
year = {2003},
pages = {633-648}
}

@inproceedings{Servedio06,
   author = {R. Servedio},
   title = {Every Linear Threshold Function has a Low-Weight Approximator},
   booktitle = {Eighteenth Annual Conference on Computational Complexity (CCC)},
   year = {2006}
}

@inproceedings{SeungOpSo92,
	author=	"H. S. Seung and M. Opper and H. Sompolinsky",
	title = "Query by committee",
	booktitle = colt92,
	year = 1992
}

@article{SeungSoTi92
,author=	{H. S. Seung and H. Sompolinsky and N. Tishby}
,title=		{Statistical mechanics of learning from example}
,year=		1992
}

@inproceedings{ShaSaLe02,
author=		{F.~Sha and L.K.~Saul and D.D.~Lee},
title=		{Multiplicative updates for nonnegative quadratic programming in support vector machines},
year=		2002,
booktitle=	nips15,
editor=         {S.~Becker and S.~Thrun and K.~Obermayer}
}


@inproceedings{ShackelfordVo88,
author = 	{George Shackelford and Dennis Volper},
title = 	{Learning {k-DNF} with Noise in the Attributes},
booktitle = 	{First Workshop on Computatinal Learning Theory},
year = 		{1988},
address = 	{Cambridge, Mass.\},
month = 	aug,
pages = 	{97--103},
publisher = 	{Morgan Kaufmann},
comment= 	{Shows how to pac learn kDNF with random attribute noise of
		up to one half.}
}

@inproceedings{Shafieezadeh-AbadehEsKu15,
  title={Distributionally Robust Logistic Regression},
  author={Shafieezadeh-Abadeh, Soroosh and Esfahani, Peyman Mohajerin and Kuhn, Daniel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1576--1584},
  year=2015,
  comment={Gives a convex reformulation for a distributionally robust
                  logistic regression problem with Wasserstein
                  distances. Shows that DRO with Wasserstein is just a
                  regularization with the corresponding dual
                  norm. Uses the know Wasserstein concentration
                  result to give statistical guarantees.}
}

@article{ShahMe13,
author = {Rajen Shah and Nicolai Meinshausen},
title = {Min-wise hashing for large-scale regression and classification
  with sparse data},
year = 2013,
journal = {arXiv:1308.1269 [math.ST]},
}

@Unpublished{Shalev06,
  author = 	 {S.~Shalev-Shwartz},
  title = 	 {Analysis for {H}ildreth Algorithm},
  note = 	 {http://www.cs.huji.ac.il/$\sim$shais/}
}

@article{Shalev12,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai},
  journal={Foundations and Trends in Machine Learning},
  volume=4,
  number=2,
  pages={107--194},
  year=2012,
}

@book{ShalevBe14,
author = {Shai Shalev-Shwartz and Shai Ben-David},
title = {Understanding Machine Learning: From Theory to Algorithms},
year = 2014,
publisher = {Cambridge University Press},
}

@InProceedings{ShalevKeSi04,
  author = 	 {S.~Shalev-Shwartz and J.~Keshet and Y.~Singer},
  title = 	 {Learning to Align Polyphonic Music},
  booktitle =    {Proceedings of the 5th International Conference on Music Information Retrieval},
  year = 	 {2004},
}


@InProceedings{ShalevSiNg04,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer and A.~Ng},
  title = 	 {Online and Batch Learning of Pseudo-Metrics},
  booktitle = icml04,
  year = 	 {2004},
}

@InProceedings{ShalevDuFrSi2002,
  author = 	 {Shalev-Shwartz, S. and Dubnov, S. and Friedman, N. and Singer, Y.},
  title = 	 {Robust Temporal and Spectral Modeling for Query by Melody},
  booktitle =    sigir02,
  year = 	 {2002},
}

@InProceedings{ShalevSi05,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {A New Perspective on an Old Perceptron Algorithm},
  booktitle =  colt05,
  year = 	 {2005},
}



@TechReport{ShalevSi06_tech,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Online Learning meets Optimization in the Dual},
  institution =  {The Hebrew University},
  year = 	 {2006},
  note=          {Available at
		  http://www.cs.huji.ac.il/$\sim$shais}
}

@TechReport{ShalevSi06b_tech,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Efficient Learning of Label Ranking by Soft Projections onto Polyhedra},
  institution =  {The Hebrew University},
  year = 	 {2006},
  note=          {Available at
		  http://www.cs.huji.ac.il/$\sim$shais}
}


@InProceedings{ShalevSi06,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Online Learning meets Optimization in the Dual},
  booktitle =  colt06,
  year = 	 {2006}
}

@InProceedings{ShalevSi07aistat,
  author = {S.~Shalev-Shwartz and Y.~Singer},
  title = {A Unified Algorithmic Approach for Efficient Online Label Ranking},
  booktitle =  {aistat07},
  year = 	 {2007}
}

@InProceedings{ShalevSi07b,
  author = {S.~Shalev-Shwartz and Y.~Singer},
  title = {A Unified Algorithmic Approach for Efficient Online Label Ranking},
  booktitle =  {aistat07},
  year = 	 {2007}
}


@article{ShalevSi07MLJ,
	author = {S.~Shalev-Shwartz and Y.~Singer},
	title = {A Primal-Dual Perspective of Online Learning Algorithms},
	journal = {Machine Learning Journal},
	year = 2007
}


@article{ShalevSi07c,
	author = {S.~Shalev-Shwartz and Y.~Singer},
	title = {A Primal-Dual Perspective of Online Learning Algorithms},
	journal = {Machine Learning Journal},
	year = 2007
}



@article{ShalevSi06b,
	author = {S.~Shalev-Shwartz and Y.~Singer},
	title = {Efficient Learning of Label Ranking by Soft Projections onto Polyhedra},
	journal = {Journal of Machine Learning Research},
	volume = {7 (July)},
	pages = {1567--1599},
	year = 2006
}


@TechReport{ShalevSi06_tech_Fenchelon,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Convex Repeated Games and Fenchel Duality},
  institution =  {The Hebrew University},
  year = 	 {2006},
  note=          {Available at
		  http://www.cs.huji.ac.il/$\sim$shais}
}

@TechReport{ShalevSi06d,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Convex Repeated Games and Fenchel Duality},
  institution =  {The Hebrew University},
  year = 	 {2006},
  note=          {Available at
		  http://www.cs.huji.ac.il/$\sim$shais}
}


@inproceedings{ShalevSi06c,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Convex Repeated Games and Fenchel Duality},
  booktitle = nips19,
  year = 	 {2006}
}


@TechReport{ShalevSi07_tech,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Logarithmic Regret Algorithms for Strongly
    Convex Repeated Games},
  institution =  {The Hebrew University},
  year = 	 {2007},
  number = {42},
  note = {URL \url{http://www.cs.huji.ac.il/~shais}},
}

@TechReport{ShalevSi07a,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {Logarithmic Regret Algorithms for Strongly
    Convex Repeated Games},
  institution =  {The Hebrew University},
  year = 	 {2007},
  note=          {Available at
		  http://www.cs.huji.ac.il/$\sim$shais}
}

@inproceedings{ShalevSiSr07,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer and N.~Srebro},
  title = 	 {Pegasos:  Primal Estimated sub-GrAdient SOlver for {SVM}},
  booktitle = ICML07,
  year = 	 {2007}
}

@article{ShalevSiSrCo11,
author = {S.\ Shalev-Shwartz and Y.\ Singer and N.\ Srebro and A.\ Cotter},
title = {Pegasos: primal estimated sub-gradient solver for {SVM}},
journal = {Mathematical Programming, Series B},
volume = 127,
number = 1,
pages = {3--30},
year = 2011,
}

@inproceedings{ShalevSi08,
  author = 	 {S.~Shalev-Shwartz and Y.~Singer},
  title = 	 {On the equivalence of weak learnability and linear
		separability: new relaxations and efficient algorithms},
  booktitle = colt08,
  year = 	 {2008}
}

@inproceedings{ShalevTe09,
author = {S. Shalev-Shwartz and A. Tewari},
title = {Stochastic Methods for $\ell_1$-Regularized Loss Minimization},
year = {2009},
booktitle = ICML09,
}

@PhdThesis{Shalev07,
  author = 	 {S. Shalev-Shwartz},
  title = 	 {Online Learning: Theory, Algorithms, and Applications},
  school = 	 {The Hebrew University},
  year = 	 {2007}
}

@MastersThesis{Shalev2002,
  author = 	 {Shalev-Shwartz, S.},
  title = 	 {Robust Temporal and Spectral Modeling for Query by Melody},
  school = 	 {School of Computer Science and Engineering, the Hebrew university},
  year = 	 {2002}
}

@article{ShalevShSr16,
  title={Learning kernel-based halfspaces with the 0-1 loss},
  author={Shalev-Shwartz, Shai and Shamir, Ohad and Sridharan, Karthik},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  pages={1623--1646},
  year={2011},
  publisher={SIAM}
}

@inproceedings{ShalevShTr12,
author = {Shai Shalev-Shwartz and Ohad Shamir and Eran Tromer},
title = {Using more data to speed-up training time},
year = 2012,
booktitle = aistat12,
}

@inproceedings{ShalevSr08,
author = {Shai Shalev-Swhartz and Nati Srebro},
year = 2008,
title = {{SVM} optimization: inverse dependence on training set size},
booktitle = icml08,
}

@article{ShalevSrZh10,
author = {Shai Shalev-Shwartz and Nati Srebro and Tong Zhang},
title = {Trading accuracy for sparsity in optimization problems
    with constraints},
year = 2010,
journal = siopt,
volume = 20,
number = 6,
pages = {2807--2832},
comment = {Studies risk minimization problems over L1 or simplicial type
  constraints with greedy algorithms. Presents a few theorems. The first
  shows random subsampling of the coordinates (based on their absolute
  values) does an OK job sparsifying. The next theorems cover greedy
  coordinate descent methods, and they provide convergence rates of
  (roughly) LB^2 / k, where L is Lipschitz constant of gradient, B is
  bound of constraints in L1 norm, and k is number of iterations. Proofs
  use duality in a nice way. Final theorems give linear convergence
  rates under strong convexity.},
}

@inproceedings{ShalevWeSh11,
author = {Shai Shalev-Shwartz and Yonatan Wexler and Amnon Shashua},
title = {Share{B}oost: efficient multiclass learning with feature sharing},
booktitle = nips24,
year = 2011,
comment = {Performs greedy coordinate descent for a multiclass problem where
  we desire sharing features. Algorithm adds the (set of) feature(s) that
  maximizes the 1-norm of the associated gradient entries (i.e. the
  correct row of the weight matrix). Proves that algorithm attains a 1/epsilon
  convergence rate using arguments similar to ShalevSrZh10, since each
  step yields a sufficient decrease in the loss. Experiments suggest it
  is better than the regularized boosting algorithms of DuchiSi09a.},
}

@inproceedings{ShalevWe16,
author = {Shai Shalev-Shwartz and Yonatan Wexler},
title = {Minimizing the Maximal Loss: How and Why?},
year = 2016,
booktitle = icml16,
comment = {Use bandit algorithms to optimize maximum loss. Propose
                  tree structure for sampling efficiently,
                  http://arxiv.org/pdf/1602.01690}
}

@article{ShalevZh12,
  title={Proximal stochastic dual coordinate ascent},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={arXiv preprint arXiv:1211.2717},
  year=2012
}

@article{ShalevZh13,
title = {Stochastic dual coordinate ascent methods
for regularized loss minimization},
author = {Shai Shalev-Shwartz and Tong Zhang},
journal= jmlr,
year = 2013,
pages = {567--599},
volume = 14,
}

@inproceedings{Shamir14,
author = {Ohad Shamir},
title = {Fundamental Limits of Online and Distributed Algorithms
  for Statistical Learning and Estimation},
year = 2014,
booktitle = nips27,
}

@inproceedings{Shamir13,
author = {Ohad Shamir},
title = {On the Complexity of Bandit and Derivative-Free
  Stochastic Convex Optimization},
year = 2013,
booktitle = colt13,
pages = {3--24},
comment = {Gives a simple optimal algorithm for quadratic optimization;
  provides lower bounds of $\Omega(\sqrt{d^2 / T})$ for strongly convex
  bandit optimization. That is, optimization when only a single function
  evaluation is available for each random sample. The lower bounds are proved
  by clever constructions that are similar to Assouad's lemma,
  which allows a $1 / \sqrt{T}$ lower bound on each coordinate (which
  then sums to a $d / \sqrt{T}$ lower bound).},
}

@inproceedings{ShashuaLe02,
	author = "A. Shashua and A. Levin",
	title = "Ranking with Large Margin Principle: Two Approaches",
	booktitle = nips15,
	year = 2002
}


@Article{Shannon48,
  author = 	 {C. E. Shannon},
  title = 	 {A Mathematical Theory of Communication},
  journal = 	 {The Bell System Technical Journal},
  year = 	 1948
}


@article{Shannon49,
author=   	{Shannon, Claude},
title=    	{Communication theory of secrecy systems},
journal=  	{Bell System Technical Journal},
year=     	1949,
month=    	Oct,
volume=   	28,
pages=    	{656--715}
}

@article{Shannon51,
author = {C.E. Shannon},
title = {Prediction and Entropy of Printed English},
journal = {Bell Sys. Tech. Jour.},
volume= {30},
pages = {51--64},
year = {1951}
}

@techreport{Shapiro81,
author=   	{Shapiro, Ehud Y.},
title=    	{Inductive Inference of Theories From Facts},
institution= 	{Yale University Department of Computer Science},
year=     	1981,
month=    	Feb,
number=   	{Research Report 192},
comment=  	{Uses Horn clauses as representation and backtracing as a
		method to discover axiom system for a given set of examples}
}

@incollection{Shapiro00,
  title={Statistical inference of stochastic optimization problems},
  author={Shapiro, Alexander},
  booktitle={Probabilistic Constrained Optimization},
  pages={282--307},
  year=2000,
  publisher={Springer}
}

@article{Shapiro88,
  title={Sensitivity analysis of nonlinear programs and differentiability properties of metric projections},
  author={Shapiro, Alexander},
  journal=sicon,
  volume=26,
  number=3,
  pages={628--645},
  year=1988,
  publisher={SIAM}
}

@article{Shapiro89,
  title={Asymptotic properties of statistical estimators in stochastic programming},
  author={Shapiro, Alexander},
  journal={Annals of Statistics},
  pages={841--858},
  year=1989,
  publisher={JSTOR},
  comment={Asymptotic expansion of sample optimum is given when the feasible set is fixed.}
}

@article{Shapiro90,
  title={On differential stability in stochastic programming},
  author={Shapiro, Alexander},
  journal={Mathematical Programming},
  volume=47,
  number={1-3},
  pages={107--116},
  year=1990,
  publisher={Springer},
  comment={Directional derivative and asymptotic distribution of the
                  optimal solution under Mangasarian-Fromovitz
                  constraint qualification is given. Second order
                  sufficient conditions are used.}
}

@article{Shapiro91,
  title={Asymptotic analysis of stochastic programs},
  author={Shapiro, Alexander},
  journal={Annals of Operations Research},
  volume=30,
  number=1,
  pages={169--186},
  year=1991,
  publisher={Springer},
  comment={Asymptotics of the optimal value is shown by the functional delta method. Feasible set is unknown and is estimated using data.}
}

@article{Shapiro93,
  title={Asymptotic behavior of optimal solutions in stochastic programming},
  author={Shapiro, Alexander},
  journal={Mathematics of Operations Research},
  volume={18},
  number={4},
  pages={829--845},
  year={1993},
  publisher={INFORMS},
  comment={Shows that o(n^{-1})-approximate empirical optimum problem
                  is asymptotically equivalent to linearly perturbed
                  population probelm with the perturbation vector v =
                  \nabla_{x}\E_{\what{P}_n - P_0}[\ell(x; \xi)]. Cases
                  where the feasible set is fixed and estimated are
                  both considered. The latter analysis uses
                  generalized equations but by exploiting structure,
                  relaxes the smoothness requirement of
                  KingRo93. Second order growth conditions are used.}
}

@book{ShapiroDeRu09,
author = {Alexander Shapiro and Darinka Dentcheva and Andrzej Ruszczy\'nski},
title = {Lectures on Stochastic Programming: Modeling and Theory},
year = 2009,
publisher = {SIAM and Mathematical Programming Society},
}

@inproceedings{ShardanandMa95,
	author = "Upendra Shardanand and Pattie Maes",
	title = "Social Information Filtering: Algorithms for Automating
		``Word of Mouth''",
	booktitle = "Human Factors in Computing Systems {CHI'95}
                  Conference Proceedings",
	year = 1995
}

@book{ShavlikDi90,
editor=		{Jude W. Shavlik and Thomas G. Dietterich},
title=		{Readings in Machine Learning},
publisher=	{Morgan Kaufmann},
year=		1990,
comment=	{address= San Mateo}
}

@InProceedings{Shawe-TaylorBaWiAn96,
  author =       "John Shawe-Taylor and Peter~L. Bartlett
		and Robert C.~Williamson and Martin Anthony",
title =        "A Framework for Structural Risk Minimisation",
  booktitle =    colt96,
  year =         "1996",
  pages =        "68--76",
comment=		{See also NeuroCOLT tech report NC-TR-96-053}
}

@TechReport{Shawe-TaylorBaWiAn96b,
author = "John Shawe-Taylor and Peter~L. Bartlett
        and Robert C.~Williamson and Martin Anthony",
title = "Structural risk minimization over data-dependent
hierarchies",
institution = "Neurocolt",
year = "1996",
number = "NC-TR-96-053",
}

@techreport{Shawe-TaylorCr98
,author=         {John Shawe-Taylor and Nello Cristianini}
,title=          {Robust Bounds on Generalization from the Margin
                  Distribution}
,institution=    {NeuroCOLT2}
,year=           1998
,number=         {NC2-TR-1998-029}
,month=          oct
}

@InProceedings{Shawe-TaylorCr99,
  author = "J. Shawe-Taylor and N. Cristianini",
  title = "Further results on the margin distribution",
  booktitle = colt99,
  year = "1999" }


@InProceedings{Shawe-TaylorCr99a,
  author = "J. Shawe-Taylor and N. Cristianini",
  title = "Margin distribution bounds on generalization",
  booktitle = "Proceedings of the European Conference on Computational Learning Theory",
  pages = "pages 263--273",
  year = "1999" }


@InCollection{Shawe-TaylorCr00,
  author = "J. Shawe-Taylor and N. Cristianini",
  title = "Margin distribution and soft margin",
  booktitle =    "Advances in Large MArgin Classifiers",
  publisher = "MIT Press",
  editor = { A. Smola and B. Sch\"olkopf and D. Schuurmans},
  year = 2000}

@InProceedings{Shawe-TaylorWi97,
  author = 	 {John Shawe-Taylor and Robert C.~Williamson},
  title = 	 {A PAC Analysis of a Bayesian Estimator},
  booktitle = 	 colt97,
  year =	 1997,
  pages =	 {2--9}
}

@InProceedings{ShehEl03,
author = {A. Sheh and D Ellis},
title = {Chord Segmentation and Recognition using EM-Trained Hidden Markov Models},
booktitle = {Proceedings of the International Symposium on Music
          Information Retrieval},
year = {2003}
}

@article{ShenTsZhWo03,
author = 	{X.Shen, G. C. Tseng, X. Zhang and W. H. Wong.},
title = 	{On psi-Learning.I},
journal = 	{Journal of American Statistical Association},
year = 		2003
}



@InProceedings{ShentalHeWePa02,
  author = 	 {N. Shental and T. Hertz and D. Weinshall and M. Pavel},
  title = 	 {Adjustment Learning and Relevant Component Analysis},
  booktitle = {seventh European Conference of Computer Vision},
  year = 	 {2002},
}

@inproceedings{Shevtsova14,
  title={On the absolute constants in the Berry-Esseen-type inequalities},
  author={Shevtsova, IG},
  booktitle={Doklady Mathematics},
  volume=89,
  number=3,
  pages={378--381},
  year=2014,
  organization={Springer}
}

@inproceedings{ShiBeYu08,
  title={Data spectroscopy: Learning mixture models using eigenspaces of convolution operators},
  author={Shi, Tao and Belkin, Mikhail and Yu, Bin},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={936--943},
  year=2008,
  organization={ACM}
}

@article{ShiBeYu09,
  title={Data spectroscopy: Eigenspaces of convolution operators and clustering},
  author={Shi, Tao and Belkin, Mikhail and Yu, Bin},
  journal={The Annals of Statistics},
  pages={3960--3984},
  year=2009,
  publisher={JSTOR},
  comment={Although not the point of the paper, gives an
                  eigen-analysis of the Gaussian (RBF) kernel
                  integration operator with respect to the L_2(P)-norm
                  where P is again a Gaussian distribution.}
}

@article{ShiffrinNo94,
author = {R.~Shiffrin and R.~Nosofsky},
title = {Seven plus or minus two: a commentary on capacity limitations},
year = 1994,
journal = {Psychological Review},
volume = 101,
number = 2,
pages = {357--361},
}

@article{ShimojoIc89,
author = 	{Shinsuke Shimojo and Shin'ichi Ichikawa},
title = 	{Intuitive reasoning about probability:
		 Theoretical and experimental analyses of the
		 ``problem of the three prisoners''},
journal = 	{Cognition},
volume = 	32,
year = 		1989,
pages = 	{1--24}
}

@article{ShinoharaMi91,
author=		{Ayumi Shinohara and Satoru Miyano},
title=		{Teachability in Computational Learning},
journal=	{New Generation Computing},
volume=		8,
year=		1991,
pages=		{337--347}
}

@inproceedings{ShivaswamyJe10,
author = {Pannagadatta K. Shivaswamy and Tony Jebara},
title = {Empirical {B}ernstein Boosting},
year = 2010,
booktitle = aistat10,
}

@inproceedings{ShivaswamyJe11,
author = {Pannagadatta K. Shivaswamy and Tony Jebara},
title = {Variance Penalizing {A}da{B}oost},
year = 2011,
booktitle = nips24,
}

@book{Shor85,
author = {Naum Zuselevich Shor},
title = {Minimization Methods for Nondifferentiable Functions},
translator = {Krzystof Kiwiel and Andrzej Ruszczy\'nski},
publisher = {Springer-Verlag},
year = 1985,
comment = {Describes subgradient methods as well as "space dilation along
  gradient" methods (SDG), which build approximations to guarantee that
  subgradient-like directions are actually moving in directions to get
  close to optimality by removing previous subgradient directions, making
  movements "more" orthogonal (or perhaps conjugate) to them. Gives
  a number of applications.},
}

@book{Shor98,
author = {Naum Zuselevich Shor},
title = {Nondifferentiable Optimization and Polynomial Problems},
year = 1998,
publisher = {Springer},
}

@article{Shorack72,
  title={Functions of order statistics},
  author={Shorack, Galen R},
  journal={The Annals of Mathematical Statistics},
  pages={412--427},
  year=1972,
  publisher={JSTOR}
}

@book{ShorackWe09,
  title={Empirical processes with applications to statistics},
  author={Shorack, Galen R and Wellner, Jon A},
  volume=59,
  year=2009,
  publisher={Siam}
}

@article{ShoreGr82,
author=   	{Shore, John E. and Robert M. Gray},
title=    	{Minimum Cross-Entropy Pattern Classification and Cluster
		Analysis},
journal=  	{IEEE Transactions on Pattern Analysis and Machine
		Intelligence},
year=     	1982,
month=    	Jan,
volume=   	{PAMI-4},
number=   	1,
pages=    	{11--17},
comment=  	{Uses minimum cross-entropy distribution to derive variation on
	   	nearest-neighbor classification rules.}
}

@article{ShoreJo80,
author=   	{Shore, John E. and Rodney W. Johnson},
title=    	{Axiomatic Derivation of the Principle of Maximum Entropy and
	   	the Principle of Minimum Cross-Entropy},
journal=  	{IEEE Transactions on Information Theory},
volume=   	{IT-26},
number=   	1,
year=     	1980,
month=    	Jan,
pages=    	{26--37},
comment=  	{Derives maximum entropy principle from principles of
		uniqueness, invariance under coordinate systems, system
		independence, and subset independence}
}

@article{ShoreJo81,
author=   	{Shore, John E. and Rodney W. Johnson},
title=    	{Properties of Cross-Entropy Minimization},
journal=  	{IEEE Transactions on Information Theory},
volume=   	{IT-27},
number=   	4,
year=     	1981,
month=    	Jul,
pages=    	{472--482},
comment=  	{General overview of properties.}
}

@inproceedings{ShpigelmanSiPaVa02,
	author = "L. Shpigelman and Y. Singer and R. Paz and E. Vaadia",
	title = "Spikernels: Embedding Spiking Neurons in Inner-Product Spaces",
	booktitle = nips15,
	year = "2002"
}


@Article{Shtarkov87,
  author = 	 {Y. M. Shtar`kov},
  title = 	 {Universal Sequential Coding of Single Messages},
  journal = 	 {Problems of information Transmission (translated
		  from Russian)},
  year = 	 1987,
  volume =	 23,
  month =	 {July-September},
  pages =	 {175--186}
}

@unpublished{Shvaytser88,
author = 	{Haim Shvaytser},
title = 	{Linear Manifolds are Learnable From Positive Examples},
note = 		{Unpublished manuscript},
month = 	apr,
year = 		{1988}
}

@InBook{Siegel94,
  author =	 {Siegel, Eric V.},
  title = 	 {Competitively evolving decision trees against fixed
                  training cases for natural language processing},
  year = 	 1994
}

@inproceedings{SiegelmannSo92,
author=		{Hava T. Siegelmann and Eduardo D. Sontag},
title=		{On the computational power of neural nets},
booktitle=	colt92,
year=		1992,
month=		jul,
pages=		{440--449}
}

@book{Siegmund85,
author = {David O. Siegmund},
year = 1985,
title = {Sequential Analysis},
publisher = {Springer},
}

@inproceedings{SimardLeDe93,
author =        "Simard, P. and LeCun, Y. and Denker J.",
title =         "Efficient pattern recognition using a new transformation distance",
booktitle =     "Advances in Neural Information Processing Systems",
volume =        "5",
publisher =     "Morgan Kaufmann",
editor =        "Hanson, S. and Cowan, J. and Giles, L.",
year =          "1993"
}

@article{SimchowitzAlRe17,
	author    = {Max Simchowitz and Ahmed El Alaoui and Benjamin Recht},
	title     = {On the Gap Between Strict-Saddles and True Convexity: An {$\Omega(\log d)$} Lower Bound for Eigenvector Approximation},
	journal   = {arXiv:1704.04548 [cs.LG]},
	year      = 2017,
}

@article{SimmonsNeSi11,
author = {Joseph P. Simmons and Leif D. Nelson and Uri Simonsohn},
title = {False-positive psychology: Undisclosed flexibility in data collection
   and analysis allows presenting anything as significant},
year = 2011,
journal = {Psychological Science},
volume = 22,
number = 11,
pages = {1359–-1366},
}

@article{Simon54,
author=   	{Simon, Herbert A.},
title=    	{Spurious Correlation: A Causal Interpretation},
year=     	1954,
journal=  	{Journal of the American Statistical Association},
pages=    	{407--479},
comment=  	{Concludes we need a priori assumptions of independence or
		causality.}
}

@article{Simon56,
author=   	{Simon, Herbert A.},
title=    	{Rational Choice and the Structure of the Environment},
journal=  	{Psychological Review},
year=     	1956,
volume=   	63,
number=   	2,
pages=    	{129--138},
comment=  	{Model of a creature with multiple goals (e.g. food, water),
		in a tree-structured environment with limited look-ahead.}
}

@incollection{Simon83,
author=   	{Simon, Herber A.},
title=    	{Why Should Machines Learn?},
booktitle=	{Machine Learning, An Artificial Intelligence Approach},
editor=   	{R. S. Michalski and J. G. Carbonell and T. M. Mitchell},
publisher=	{Tioga},
address=  	{Palo Alto, California},
year=     	1983}

@article{Simon96
,author=        {Hans Ulrich Simon}
,title=         {General bounds on the number of examples needed for
                  learning probabilistic concepts}
}

@book{Simon02,
author = {Marvin K. Simon},
title = {Probability Distributions Involving Gaussian Random Variables:
A Handbook for Engineers and Scientists},
year = 2002,
publisher = {Springer},
}

@article{SinclairJe89,
author = 	{Sinclair, Alistair and Mark Jerrum},
title = 	{Approximate Counting, Uniform Generation and
		 Rapidly Mixing Markov Chains},
journal = 	infcomp,
year = 		1989,
month = 	Jul,
volume = 	82,
number = 	1,
pages = 	{93--133}
}

@inproceedings{SindhwaniKe06,
author = {V. Sindhwani and S.S. Keerthi},
title = {Large scale semi-supervised linear {SVM}s},
booktitle = {Proceedings of the 29th annual international ACM SIGIR conference on Research and
development in information retrieval},
pages = {477--484},
year = {2006}
}


@inproceedings{SinghalBuMa96,
    author = "A.~Singhal and C.~Buckley and M.~Mitra",
    title = "Pivoted Document Length Normalization",
    booktitle = "Research and Development in Information Retrieval",
    pages = "21-29",
    year = "1996"
}


@techreport{SinghalBuMiSa95,
Author = {A.~Singhal and C.~Buckley and M.~Mitra and G.~Salton},
Title = {Pivoted Document Length Normalization},
Number = {TR95-1560},
Institution ={Cornell University},
Year=1995
}

@Article{Singer97,
  author = 	 {Yoram Singer},
  title = 	 {Adaptive mixtures of probabilistic transducers},
  journal =  {Neural Computation},
  year = 	 {1997},
  volume = 	 9,
  number = 	 8,
  pages =	 {1711--1734}
}

@Article{Singer9?,
  author = 	 {Yoram Singer},
  title = 	 {Switching Portfolios},
  journal = 	 {International Journal of Neural Systems},
  year = 	 {(to appear)},
  note =	 {Available via email from singer@research.att.com}
}

@inproceedings{SinhaDu16,
author = {Aman Sinha and John C.\ Duchi},
title = {Learning Kernels with Random Features},
booktitle = nips29,
year = 2016,
}

@article{SinhaNaDu17,
author = {Aman Sinha and Hongseok Namkoong and John C. Duchi},
title = {Certifiable distributional robustness with principled adversarial
  training},
journal = {arXiv:1710.10571 [stat.ML]},
year = 2017,
}

@article{Sipos79,
  title={Integral representations of non-linear functionals},
  author={{\v{S}}ipo{\v{s}}, J{\'a}n},
  journal={Mathematica Slovaca},
  volume=29,
  number=4,
  pages={333--345},
  year=1979,
  publisher={Mathematical Institute of the Slovak Academy of Sciences}
}

@unpublished{Skalak97
,author=	{David B. Skalak}
,title=		{The Sources of Increased Accuracy for Two Proposed
		 Boosting Algorithms}
}

@unpublished{Sloan87,
author=   	{Sloan, Robert H.},
title=    	{Some Notes on {C}hernoff Bounds},
note=     	{(Unpublished)},
year=     	1987}

@inproceedings{Sloan88,
author = 	{Robert H. Sloan},
title = 	{Types of Noise in Data for Concept Learning},
booktitle=	colt88,
year = 		{1988},
pages = 	{91--96},
month = 	aug
}

@inproceedings{Smith11,
author = {Adam Smith},
title = {Privacy-preserving Statistical Estimation with Optimal
Convergence Rates},
year = 2011,
booktitle = stoc11,
comment = {
  Studies the differential privacy of asymptotically normal statistical
  estimators that have small bias by using an aggregating mechanism.
  Roughly, the idea is as follows. If T is an estimator of the population
  quantity $T(P)$, and $E[T_n] - T(P) = O(1/n)$, and additionally
  $\sqrt{n}(T_n - T(P)) \rightarrow N(0, \sigma_P^2)$, then a mechanism
  that blocks estimators into $Z_i = T(x_{ni/k}, \ldots, x_{n(i + 1)/k})$
  (that is, $k$ blocks of size $n/k$) and uses $(1/k) \sum_i Z_i$ as the
  estimator will still have the desired asymptotic normality--because the
  bias is small and the $Z_i$ are independent--so long as $k$ is not
  too large. Then some small amount of perturbation to the $Z_i$ (or $T$)
  can yield differential privacy. (If the $Z_i$ are bounded by $\Lambda$,
  then adding Laplace noise of variance $2\Lambda^2 / (k^2 \epsilon^2)$ yields
  differential privacy.)
  See also the earlier (and more understandable) arXiv paper
  http://arxiv.org/abs/0809.4794.
},
}

@unpublished{SmithTh12,
author = {Adam Smith and Abhradeep Thakurta},
title = {Differentially Private Feature Selection via Stability Arguments,
 and the Robustness of the {L}asso},
year = 2012,
url = {http://www.cse.psu.edu/~asmith/pubs/ST13/},
}

@inproceedings{SmithThUp17,
author = {Adam Smith and Abhradeep Thakurta and Jalaj Upadhyay},
title = {Is Interaction Necessary for Distributed Private Learning?},
year = 2017,
booktitle = {IEEE Symposium on Security and Privacy},
}

@TechReport{SmolaSc98,
	author = "A. Smola and B. {Sch\"olkopf}",
	title = "A Tutorial on Support Vector Regression",
	number = "{NC2-TR-1998-030}",
	institution = "{NeuroCOLT2}",
	year = 1998
}


@article{SmolaMiScWi01,
   author = {Smola, A.J. and S. Mika and B. Sch\"olkopf and R.C.  Williamson},
   title = {Regularized principal manifolds.},
   year = {2001},
   volume = {1},
   pages = {179-209},
   journal = {Journal of Machine Learning Research}
}

@inproceedings{SmolaViLe07,
author = 	{A. Smola and S.V.N. Vishwanathan and Q. Le},
title = 	{Bundle Methods for Machine Learning},
booktitle=	nips20,
year = 		{2007}
}

@article{Solomonoff64a,
author=   	{Solomonoff, R. J.},
title=    	{A Formal Theory of Inductive Inference. Part I.},
year=     	1964,
journal=  	InfCtrl,
volume=   	7,
pages=    	{1--22},
comment=  	{Concerned with extrapolation of sequences.  Defines
		probability of extension via likelihood random TM program
		will generate it.}
}

@article{Solomonoff64b,
author=   	{Solomonoff, R. J.},
title=    	{A Formal Theory of Inductive Inference. Part II.},
year=     	1964,
journal=  	InfCtrl,
volume=   	7,
pages=    	{224--254},
comment=  	{Continues Part I.  Inference of probabilities and grammars.}
}

@article{SompolinskyBa93
,author=	{H. Sompolinsky and N. Barkai}
,title=		{Theory of learning from examples}
}




@InProceedings{SoulezRoSc03,
  author = 	 {F.~Soulez and X.~Rodet and D.~Schwarz},
  title = 	 {Improving polyphonic and poly-instrumental music to score alignment},
  booktitle = {Proceedings of the International Symposium on Music Information Retrieval},
  year = 	 {2003},
}

@book{Spall03,
author = {James C. Spall},
title = {Introduction to Stochastic Search and Optimization: Estimation,
Simulation, and Control},
year = 2003,
publisher = {Wiley},
}

@article{Specht67,
author = 	{D. F. Specht},
title = 	{Generation of polynomial discriminant functions for pattern
		recognition},
journal = 	{IEEE Transactions on Electronic Computers},
volume = 	{EC-16},
year = 		1967,
number = 	3,
pages = 	{308--319}
}

@book{Spencer87,
author=		{Spencer, Joel},
title=		{Ten Lectures on the Probabilistic Method},
publisher=	{Society for Industrial and Applied Mathematics},
address=	{Philadelphia},
year=		1987
}

@book{SpiegelhalterTa94,
author = {D. Spiegelhalter and C. Taylor},
title = {Machine Learning, Neural and Statistical Classification},
year = 1994,
publisher = {Ellis Horwood},
}

@inproceedings{SrebroSrTe10,
  title={Smoothness, low noise and fast rates},
  author={Srebro, Nathan and Sridharan, Karthik and Tewari, Ambuj},
  booktitle={nips23},
  pages={2199--2207},
  year=2010
}

@article{Staiger98
,author=        {Ludwig Staiger}
,title=         {A tight upper bound on {Kolmogorov} complexity and
                  uniformly optimal prediction}
}

@article{Steihaug83,
	title={The conjugate gradient method and trust regions in large scale 
	optimization},
	author={Steihaug, Trond},
	journal={SIAM Journal on Numerical Analysis},
	volume={20},
	number={3},
	pages={626--637},
	year={1983},
	publisher={SIAM}
}

@article{Stein45,
author = {Charles Stein},
title = {A two-sample test for a linear hypothesis whose power
   is independent of the variance},
year = 1945,
journal = aoms,
volume = 16,
number = 3,
pages = {243--258},
}

@inproceedings{SteinhardtDu15,
author = {Jacob Steinhardt and John C. Duchi},
title = {Minimax rates for memory-bounded sparse linear regression},
year = 2015,
booktitle = colt15,
}

@inproceedings{SteinhardtLi14,
author = {Jacob Steinhardt and Percy Liang},
title = {Adaptivity and Optimism: An Improved Exponentiated Gradient
   Algorithm},
year = 2014,
booktitle = icml14,
}

@inproceedings{SteinkeUl15,
author = {Thomas Steinke and Jonathan Ullman},
title = {Between Pure and Approximate Differential Privacy},
booktitle = colt15,
year = 2015,
}


@article{Steinwart05,
author = {Ingo Steinwart},
title = {Consistency of Support Vector Machines and
  Other Regularized Kernel Classifiers},
year = 2005,
journal = ieeeit,
volume = 51,
number = 1,
pages = {128--142},
comment = {
  Shows that regularized kernel-based classifiers are consistent on compact
  domains X for suitable losses (e.g. convex decreasing) so long as
  regularization strength grows suitably slowly. Proof is by arguing that
  population regularized solutions converge to a true Bayes-risk minimizer,
  since empirical solutions have concentration around population regularized
  solutions. Requires that kernel is universal for these things to hold.
},
}

@article{Steinwart07,
author = {I. Steinwart},
title = {How to compare different loss functions},
year = 2007,
journal = {Constructive Approximation},
volume = 26,
pages = {225--287},
}

@article{SteinwartSc07,
  title={Fast rates for support vector machines using Gaussian kernels},
  author={Steinwart, Ingo and Scovel, Clint},
  journal={The Annals of Statistics},
  pages={575--607},
  year=2007,
  publisher={JSTOR},
  comment={Gives fast rates for SVMs with Gaussian (RBF) kernels. In
                  particular, Theorem 2.1 provides a bound on the
                  L_2-covering number of a unit ball in the RKHS
                  generated by the Gaussian kernel. The log metric
                  entropy depends exponentially in the dimension.}
}

@article{Stern04,
author = {H.~S.~Stern},
title = {Statistics and the college football championship},
year = 2004,
journal = {The American Statistician},
volume = 58,
number = 3,
}

@article{StewartBrCh05,
author = {N.~Stewart and G.~Brown and N.~Chater},
title = {Absolute identification by relative judgment},
year = 2005,
journal = {Psychological Review},
volume = 112,
number = 4,
pages = {881--911},
comment = {The introduction gives a nice overview of studies on perception
of absolute versus relative judgments. The rest is some kind of model of
this process.},
}

@book{StewartSu90,
author = {G. W. Stewart and Ji-Guang Sun},
title = {Matrix Perturbation Theory},
year = 1990,
publisher = {Academic Press},
}

@article{Stockmeyer85,
author=		{L. Stockmeyer},
title=		{On Approximation Algorithms for {\#P}},
journal=	sicomp,
volume=		14,
year=		1985,
pages=		{849--861},
comment=	{fill in first name and journal number}
}

@Book{StolerBu92,
  author =	 {J. Stoler and R. Bulrisch},
  title = 	 {Introduction to Numerical Analysis},
  publisher = 	 {Springer-Verlag},
  year = 	 1992
}

@article{Stone80,
author = {Charles J. Stone},
title = {Optimal rates of convergence for nonparametric estimators},
year = 1980,
journal = aos,
volume = 8,
number = 6,
pages = {1348--1360},
comment = {Shows that for estimating certain natural
  functionals (usually the $k$th derivative (at 0))
  of either a regression function or density, defined on $\R^d$, where
  the function being estimated has locally Lipschitz $s-1$th derivative,
  then best possible rate is $n^{(s - k) / (2s + d)}$, so exponential
  pain in dimension, but improved by smoothness a lot. Proof technique
  is usually by constructing a two-point hypothesis test---using some
  asymptotically constructed well-separated functions--- and arguing that
  Bayes estimator must have suitably high probability of error.
},
}

@article{Stone82,
author = {Charles J. Stone},
title = {Optimal global rates of convergence for nonparametric regression},
year = 1982,
journal = aos,
volume = 10,
number = 4,
pages = {1040--1053},
}

@book{Strang86,
author=   	{Strang, Gilbert},
title=    	{Introduction to Applied Mathematics},
publisher=	{Wellesley-Cambridge Press},
year=     	{1986}
}

@article{StrohmerVe09,
author = {T. Strohmer and Roman Vershynin},
title = {A randomized {K}aczmarz algorithm with exponential convergence},
year = 2009,
journal = {Journal of Fourier Analysis and Applications},
pages = {262--278},
volume = 15,
number = 2,
}

@inproceedings{SrebroReJa04,
author = {N. Srebro and J. Rennie and T. Jaakkola},
title = {Maximum margin matrix factorization},
year = 2004,
booktitle = nips17,
}


@book{Strook12,
  title={An introduction to the theory of large deviations},
  author={Stroock, Daniel W},
  year=2012,
  publisher={Springer Science \& Business Media}
}

@article{Suchanskiy87
,author=        {M. Ye. Suchanskiy}
,title=         {Adaptive algorithm for determination of weakly
                  efficient variant under randomness}
}

@article{SunQuWr15,
author = {Ju Sun and Qing Qu and John Wright},
title = {When Are Nonconvex Problems Not Scary?},
year = 2015,
journal = {arXiv:1510.06096 [math.OC]},
}

@article{SunQuWr17,
author = {Ju Sun and Qing Qu and John Wright},
title = {A Geometric Analysis of Phase Retrieval},
year = 2017,
journal = focm,
volume = {To appear},
}

@article{SussmanWi92
,author=	{Gerald Jay Sussman and Jack Wisdom}
,title=		{Chaotic evolution of the solar system}
,year=		1992
}

@article{Sutton88,
author=		{Richard S. Sutton},
title=		{Learning to predict by the methods of temporal
		 differences},
journal=	ml,
volume=		3,
pages=		{9--44},
year=		1988
}

@article{SuttonBa81,
author=   	{Sutton, Richard S. and Andrew G. Barto},
title=    	{Toward a Modern Theory of Adaptive Networks: Expectation and
		Prediction},
journal=  	{Psychological Review},
year=     	1981,
volume=   	88,
number=   	2,
pages=    	{135--170},
comment=  	{Model of neuron where neuron increases output in expectation
		of being stimulated}
}

@unpublished{SuttonBa85,
author=   	{Sutton, Richard S. and Andrew G. Barto},
title=    	{An adaptive network that constructs and uses an internal model
	   	of its world},
year=     	1985,
comment=  	{Maze-learning with adaptive predictor neuron models.}
}

@inproceedings{SwaminathanJo15,
author = {Adith Swaminathan and Thorsten Joachims},
title = {Counterfactual Risk Minimization},
year = 2015,
booktitle = {Proceedings of the 32nd World Wide Web Conference (WWW)},
}

@article{Szarek83,
author = {Stanislaw J. Szarek},
title = {The finite dimensional basis problem with an appendix
on nets of {G}rassman manifolds},
year = 1983,
journal = {Acta Mathematica},
volume = 151,
pages = {153--179},
}

@incollection{Szarek98,
author = {Stanislaw J. Szarek},
title = {Metric entropy of homogeneous spaces},
year = 1998,
booktitle = {Quantum Probability (Gda\`{n}sk 1997)},
volume = 43,
publisher = {Banach Center Publications},
pages = {395--410},
address = {Polish Academy of Sciences, Warsaw},
note = {Preprint available at arXiv:math/970123 [math.MG]},
}

@inproceedings{SzechtmanGl01,
  title={Constrained Monte Carlo and the method of control variates},
  author={Szechtman, Roberto and Glynn, Peter W},
  booktitle={Proceedings of the 33nd conference on Winter simulation},
  pages={394--400},
  year=2001,
  organization={IEEE Computer Society}
}

@article{SzegedyZaSuBrErGoFe14,
  author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever,
                  Ilya and Bruna, Joan and Erhan, Dumitru and
                  Goodfellow, Ian and Fergus, Rob},
  title = {Intriguing properties of neural networks},
  year = 2013,
  journal = {arXiv preprint arXiv:1312.6199}
}

@inproceedings{TakacBiRiSr13,
author = {Martin Tak\'a\v{c} and Avleen Bijral
  and Peter Richt\'arik and Nati Srebro},
title = {Mini-Batch Primal and Dual Methods for {SVM}s},
year = 2013,
booktitle = icml13,
}

@article{TakenouchiEg04,
author=        {T. Takenouchi and S. Eguchi.},
title=         {Robustifying AdaBoost by adding the naive error rate},
year=          2004,
journal=       {Neural Computation},
volume=        16
}


@unpublished{TakimotoHiMaVo97
,author=        {Eiji Takimoto and Ken'ichi Hirai and Akira Maruoka
                  and Volodya Vovk}
,title=         {Simple algorithms for predicting nearly as well as
                  the best pruning of a decision tree}
}

@article{TakimotoMa??
,author=	{Eiji Takimoto and Akira Maruoka}
,title=		{Conservativeness and monotonicity for learning
		algorithms}
}

@article{Talagrand94
,author=        {M. Talagrand}
,title=         {Sharper bounds for Gaussian and empirical processes}
,year=          1994
}

@article{Talagrand96,
  title={New concentration inequalities in product spaces},
  author={Talagrand, Michel},
  journal={Inventiones mathematicae},
  volume=126,
  number=3,
  pages={505--563},
  year=1996,
  publisher={Springer}
}

@article{TanizakiNa09,
  title={Simulation Studies on the Cressie-Read Power Divergence Test Statistic under the Empirical Likelihood Setup},
  author={Tanizaki, Hisashi and Namba, Akio},
  journal={Kobe University Economic Review},
  volume=55,
  pages={35--51},
  year=2009,
  publisher={神戸大学大学院経済学研究科/神戸大学経済学部}
}

@article{TaoAn98,
author = {Pham Dinh Tao and Le Thi Hoai An},
title = {A {D.C.} optimization algorithm for solving
  the trust-region subproblem},
year = 1998,
journal = siopt,
pages = {476--505},
volume = 8,
number = 2,
}

@unpublished{Tao11_brunn,
author = {Terence Tao},
title = {The {B}runn-{M}inkowski inequality for nilpotent groups},
year = 2011,
note = {URL \url{http://terrytao.wordpress.com/tag/prekopa-leindler-inequality/}},
}

@article{Tarjan75,
author=   	{Tarjan, R.E.},
title=    	{Efficiency of a good but not linear set union algorithm},
journal=  	jacm,
volume=   	22,
number=   	2,
month=    	Apr,
year=     	1975,
pages=    	{215--225}
}

@book{Tarjan83,
author=       {Robert E. Tarjan},
title=        {Data Structures and Network Algorithms},
publisher=    {Society for Industrial and Applied Mathematics},
year=         {1983},
}

@techreport{TarsiPe84,
author=   	{Tarsi, Michael and Judea Pearl},
title=    	{Algorithmic Reconstruction of Trees},
institution= 	{UCLA Computer Science Department},
year=     	1984,
month=    	Dec,
number=   	{UCLA-ENG-8498},
comment=  	{Describes how to build a tree with n leaves in time n log(n)
	   	using only test as to whether deepest common ancester of u
		and v is on the path from root to w, if the max degree is
		bounded.}
}

@inproceedings{TaskarGuKo03,
	author = "B. Taskar and C. Guestrin and D. Koller",
	title = "Max-Margin Markov Networks",
	booktitle = nips16,
	year = 2003
}

@inproceedings{TaskarKlCoKoMa04,
author = {B.\ Taskar and D.\ Klein and M.\ Collins and D.\ Koller and C.\ Manning},
title = {Max-margin parsing},
booktitle = {Empirical Methods in Natural Language Processing},
year = 2004,
}

@phdthesis{Taskar05,
author = "Ben Taskar",
title = "Learning Structured Prediction Models: A Large Margin Approach",
school = "Stanford University",
year = 2005
}



@phdthesis{Tax01,
	author = "D.M.J.~Tax",
	title = "One-class classification; Concept-learning in the absence of counter-examples",
	school = "Delft University of Technology",
	year = 2001
}

@inproceedings{TaxDu99,
author=		{D.M.J.~Tax and R.P.W.~Duin},
title=		{Data domain description using support vectors},
year=		1999,
month=		apr,
pages=		{251--256},
booktitle=	{Proceedings of the European Symposium on Artificial Neural Networks}
}

@article{TenenbaumDeLa00,
	author = "J.B. Tenenbaum and V. De {S}ilva and J. C. Langford",
	title = "A global geometric framework for
		nonlinear dimensionality reduction",
	journal = "Science",
	volume = 290,
	number = 5000,
	pages = "2319--2323",
	year = 2000
}

@article{TennessenEtAl12,
author = {Tennessen, Jacob A. and Bigham, Abigail W. and O’Connor, Timothy D.
 and Fu, Wenqing and Kenny, Eimear E. and Gravel, Simon and McGee, Sean
 and Do, Ron and Liu, Xiaoming and Jun, Goo and Kang, Hyun Min
 and Jordan, Daniel and Leal, Suzanne M. and Gabriel, Stacey
 and Rieder, Mark J. and Abecasis, Goncalo and Altshuler, David
 and Nickerson, Deborah A. and Boerwinkle, Eric and Sunyaev, Shamil
 and Bustamante, Carlos D. and Bamshad, Michael J. and Akey, Joshua M.
 and Broad GO and Seattle GO and on behalf of the NHLBI Exome
 Sequencing Project},
title = {Evolution and Functional Impact of Rare Coding Variation from
   Deep Sequencing of Human Exomes},
volume = {337},
number = {6090},
pages = {64--69},
year = {2012},
abstract ={As a first step toward understanding how rare variants
contribute to risk for complex diseases, we sequenced 15,585 human
 protein-coding genes to an average median depth of 111× in 2440 individuals
 of European (n = 1351) and African (n = 1088) ancestry. We identified over
 500,000 single-nucleotide variants (SNVs), the majority of which were rare
 (86\% with a minor allele frequency less than 0.5\%), previously unknown (82\%),
 and population-specific (82\%). On average, 2.3\% of the 13,595 SNVs each person
 carried were predicted to affect protein function of \~313 genes per genome,
 and \~95.7\% of SNVs predicted to be functionally important were rare. This
 excess of rare functional variants is due to the combined effects of
 explosive, recent accelerated population growth and weak purifying selection.
 Furthermore, we show that large sample sizes will be required to associate
 rare variants with complex traits.},
journal = {Science},
comment = {doi = {10.1126/science.1219240}},
}

@article{Tesauro87,
author = 	{Tesauro, Gerald},
title = 	{Scaling relationships in back-propagation learning:
		 dependence on training set size},
journal = 	{Complex Systems},
year = 		1987,
volume = 	1,
pages = 	{367--372},
comment = 	{Studies learning of 32-bit parity with 8 or 16 or 32 hidden
	         units.  Training time seems to go as 4/3 power of number of
		 samples, up to point where capacity is exceeded.}
}

@article{TesauroSe87,
author = 	{Gerald Tesauro and Terrence J. Sejnowski},
title = 	{A `Neural' Network that Learns to Play Backgammon},
journal = 	{Artificial Intelligence},
volume = 	{39},
number = 	{3},
year = 		1989,
month = 	Jul,
pages = 	{357--390}
}

@article{TesauroSe89,
author = 	{Gerald Tesauro and Terrence J. Sejnowski},
title = 	{A Parallel Network that Learns to Play Backgammon},
journal = 	{Artificial Intelligence},
volume = 	{in press},
year = 		1989
}

@article{TewariBa07,
author = {A. Tewari and P. L. Bartlett},
title = {On the Consistency of Multiclass Classification Methods},
journal = {Journal of Machine Learning Research},
year = 2007,
volume = 8,
pages = {1007--1025}
}

@inproceedings{ThomasKrScSh??
,author=	{Timothy R. Thomas and Charlotte Kruger and Clint
		 Scovel and Joseph Shumate}
,title=		{Text to information: sampling uncertainty in an
		 example from physician/patient encounters}
}

@article{Thompson33,
author = {William R. Thompson},
title = {On the likelihood that one unknown probability exceeds
   another in view of the evidence of two samples},
journal = {Biometrika},
year = 1933,
volume = 25,
number = {3-4},
pages = {285--294},
}

@inproceedings{ThompsonCaMo99,
	author = "C.A. Thompson and M.E. Califf and R.J. Mooney",
	title = "Active Learning for Natural Language Parsing and
		Information Extraction",
	booktitle = ml99,
	year = 1999
}

@article{Thurstone27,
title={A law of comparative judgment},
volume={34},
number={4},
journal={Psychological Review},
author={L.~L.\ Thurstone},
year={1927},
pages={273--286}
}

@techreport{Tibshirani96
,title=       "Bias, variance and prediction error for classification rules"
,author=      {Robert Tibshirani}
,institution= {University of Toronto}
,month=		nov
,year=        1996
,comment=      "available electronically from http://utstat.toronto.edu/tibs/research.html"
}

@techreport{Tibshirani96
,title=       "Bias, variance and prediction error for classification rules"
,author=      {Robert Tibshirani}
,institution= {University of Toronto}
,month=		nov
,year=        1996
,comment=      "available electronically from http://utstat.toronto.edu/tibs/research.html"
}



@Article{Tibshirani96b,
  author = 	 {R. Tibshirani},
  title = 	 {Regression shrinkage and selection via the lasso},
  journal = 	 {J. Royal. Statist. Soc B.},
  year = 	 {1996},
  volume = 	 {58},
  number = 	 {1},
  pages = 	 {267--288}
}

@article{TibshiraniTaLoTi14,
author = {Ryan Tibshirani and Jonathan Taylor and Richard Lockhart and
Robert Tibshirani},
title = {Exact post-selection inference for sequential regression
procedures},
year = 2014,
journal = jasa,
pages = {To appear},
}

@article{LockhardtTaTiTi14,
author = {Richard Lockhardt and Jonathan Taylor and Ryan Tibshirani
and Robert Tibshirani},
title = {A significance test for the {L}asso},
year = 2014,
journal = aos,
volume = 42,
number = 2,
pages = {413--468},
}

@TechReport{TieuVi99,
  author = 	 {Kinh H. Tieu and Paul Viola},
  title = 	 {Boosting Image Database Retrieval},
  institution =  {MIT Artificial Intelligence Laboratory},
  year = 	 1999,
  number =	 1669
}

@article{TikochinskyTiLe84,
author=   	{Tikochinsky, Y. and N. Z. Tishby and R. D. Levine},
title=    	{Consistent Inference of Probabilities for Reproducible
		Experiments},
journal=  	{Physical Review Letters},
year=     	1984,
volume=   	52,
number=   	16,
pages=    	{1357--1360},
comment=  	{Justification for maximum-entropy approach.}
}

@article{TishbyGo94
,author=        {Naftali Tishby and Allen Gorin}
,title=         {Algebraic learning of statistical associations for
                  language acquisition}
}

@inproceedings{TishbyPeBi99,
	author = "N. Tishby and F.C. Pereira and W. Bialek",
	title = "The Information Bottleneck Method",
	booktitle = "The 37'th Allerton Conference on Communication, Control,
	and Computing",
	year = 1999
}

@Book{TitteringtonSmMa85,
  author =	 {D.M. Titterington and A.F.M. Smith and U.E. Makov},
  title = 	 {Statistical Analysis of Finite Mixture Distributions},
  publisher = 	 {John Wiley \& Sons},
  year = 	 1985
}

@article{ToledanoGoGr03,
author= 	{D.T. Toledano and L.A.H. Gomez and L.V. Grande},
title=		{Automatic Phoneme Segmentation},
journal=	{IEEE Trans. Speech and Audio Proc.},
pages=		{617-625},
volume = 11,
number=6,
year=		2003,
}



@InBook{Torkkola06,
  author = 	 {K.~Torkkola},
  ALTeditor = 	 {I. Guyon and S. Gunn and M. Nikravesh and L. Zadeh},
  title = 	 {Feature Extraction, Foundations and Applications.
I. Guyon, S. Gunn, M. Nikravesh, L. Zadeh, editors},
  chapter = 	 {Information theoretic methods},
  publisher = 	 {Springer},
  year = 	 {2006}
}

@article{Touchette09,
  title={The large deviation approach to statistical mechanics},
  author={Touchette, Hugo},
  journal={Physics Reports},
  volume=478,
  number=1,
  pages={1--69},
  year=2009,
  publisher={Elsevier}
}

@book{TrakhtenbrotBa73,
author=		{B. A. Trakhtenbrot and Ya. M. Barzdin'},
title=		{Finite Automata: Behavior and Synthesis},
publisher=	{North-Holland},
year=		1973
}

@article{TramerKuPa17,
  title={Ensemble Adversarial Training: Attacks and Defenses},
  author={Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Boneh, Dan and McDaniel, Patrick},
  journal={arXiv:1705.07204 [stat.ML]},
  year=2017
}

@book{TraubWe99,
author = {Joseph Traub and Arthur Werschulz},
year = 1999,
title = {Complexity and Information},
publisher = {Cambridge University Press},
}

@book{TraubWaWa88,
author = {Joseph Traub and H. Wasilkowski and H. Wozniakowski},
year = 1988,
title = {Information-Based Complexity},
publisher = {Academic Press},
}

@book{TrefethenBa97,
  title={Numerical Linear Algebra},
  author={Trefethen, Lloyd N and Bau III, David},
  year={1997},
  publisher={SIAM}
}

@article{Tropp06,
author = {J. A. Tropp},
title = {Just relax: convex programming methods for identifying sparse
    signals},
year = 2006,
journal = ieeeit,
volume = 51,
pages = {1030--1051},
}

@article{Tropp11,
author = {Joel A. Tropp},
title = {User-friendly tail bounds for sums of random matrices},
journal = {Foundations of Computational Mathematics},
year = 2011,
note = {Published online 02 August},
}

@article{Tropp11b,
author = {Joel A. Tropp},
title = {Improved analysis of the subsampled randomized {H}adamard transform},
year = 2011,
journal = {Advances in Adaptive Data Analysis},
volume = 3,
number = {1--2},
note = {Special issue on Sparse Representation of Data and Images},
pages = {115--126},
}

@unpublished{Tseng08,
author = {P. Tseng},
title = {On Accelerated Proximal Gradient Methods for Convex-Concave
 Optimization},
year = 2008,
url = {http://www.math.washington.edu/~tseng/papers/apgm.pdf},
comment = {note = {URL \url{http://www.math.washington.edu/~tseng/papers/apgm.pdf}}},
}

@article{Tsitsiklis??
,author=	{John N. Tsitsiklis}
,title=		{Asynchronous stochastic approximation and {Q}-learning}
}

@phdthesis{Tsitsiklis84,
author = {J. Tsitsiklis},
title = {Problems in decentralized decision making and computation},
year = 1984,
school = {Massachusetts Institute of Technology},
}

@article{TsitsiklisBeAt86,
author = {J. N. Tsitsiklis and D. P. Bertsekas and M. Athans},
title = {Distributed Asynchronous Deterministic and Stochastic Gradient Optimization Algorithms},
year = {1986},
journal = {IEEE Transactions on Automatic Control},
volume = {31},
pages = {803--812},
}

@incollection{Tsitsiklis93,
author = {John N. Tsitsiklis},
title = {Decentralized Detection},
year = 1993,
booktitle = {Advances in Signal Processing, Vol.~2},
publisher = {JAI Press},
pages = {297--344},
}

@article{TsitsiklisLu87,
author = {John N. Tsitsiklis and Zhi-Quan Luo},
title = {Communication Complexity of Convex Optimization},
year = 1987,
journal = {Journal of Complexity},
volume = 3,
pages = {231--243},
comment = {
  Considers complexity (in bits communicated) of finding an \epsilon-optimal
  solution to min. f_1(x) + f_2(x), where f_1 and f_2 are known only to
  distinct processors. Shows simple argument that O(n \log(1/\epsilon))
  or O(n \log(n / \epsilon)) bits are necessary by a volume argument (otherwise
  the number of outputs possible cannot cover the \ell_\infty or \ell_2 ball).
  Upper bounds of n^2 \log^2(1/\epsilon) are given using the center of
  gravity method, and a bisection-based algorithm achieves \log(1/\epsilon)
  for 1-dimensional problems (each computer keeps track of each direction
  of the search). In the strongly convex case, a gradient-based method
  with innacurate gradients, where at each iteration a few bits specifies
  the sign direction the gradient entries should go in, requires
  \log(1/\epsilon) iterations and has O(n) communication per round.
},
}

@article{TsitsiklisRo??
,author=	{John N. Tsitsiklis and Benjamin Van Roy}
,title=		{Feature-based methods for large scale dynamic programming}
}

@inproceedings{TsochantaridisHoJoAl04,
   author    = {I. Tsochantaridis and T. Hofmann and T. Joachims and Y. Altun},
   title     = {Support Vector Machine Learning for Interdependent and Structured Output Spaces},
   booktitle = icml04,
   year =       {2004}
}

@article{Tsybakov04,
  title={Optimal aggregation of classifiers in statistical learning},
  author={Tsybakov, Alexandre B},
  journal={Annals of Statistics},
  pages={135--166},
  year=2004,
  publisher={JSTOR}
}

@inproceedings{TuBoSiSoRe16,
author = {Stephen Tu and Ross Boczar and Max Simchowitz and Mahdi Soltanolkotabi and Benjamin Recht},
title = {Low-rank Solutions of Linear Matrix Equations via Procrustes Flow},
year = 2016,
booktitle = icml16,
url = {http://arxiv.org/abs/1507.03566},
comment = {Considers gradient descent methods for finding low rank matrices
  satisfying $\mc{A}(UV^T) = b$, where $\mc{A}$ is a linear operator.
  Shows that a gradient-like algorithm works when the measurement operator
  $\mc{A}$ satisfies restricted isometry.},
}

@article{TuRoVeRe16,
author = {Stephen Tu and Rebecca Roelofs and Shivaraman Venkataraman and
  Benjamin Recht},
title = {Large Scale Kernel Learning using Block Coordinate Descent},
year = 2016,
journal = {arXiv:1602.035310 [cs.LG]},
url = {https://arxiv.org/abs/1602.05310},
}

@inproceedings{TuretskyEl03,
	author = "R. Turetsky and D. Ellis",
	title = "Ground-Truth Transcriptions of Real Music from Force-Aligned MIDI Syntheses",
	booktitle = "Proceedings of the International Symposium on Music Information Retrieval",
	year = 2003
}

@techreport{TsukidaGu11,
author = { K.\ Tsukida and M.~R.\ Gupta},
title = {How to analyze paired comparison data},
year = {2011},
institution = {University of Washington Department of Electrical Engineering},
number = {UWEETR-2011-0004},
comment = {Very readable tutorial on aggregation and related ideas for
ranking problems, focusing specifically on recovering rankings from
paired data},
}

@book{Tsybakov09,
author = {Alexandre B. Tsybakov},
title = {Introduction to Nonparametric Estimation},
year = 2009,
publisher = {Springer},
comment = {A nice introduction to non-parametrics, much of the form of
density estimation and non-parametric integration. First chapter covers
estimation strategies for these problems, including histogram, kernel, and
orthogonal series/projection estimators, while second and third chapters move
toward lower bounds and oracle inequalities. Readable for young students,
and nice proofs of some Sobolev class inequalities and containments.},
}

@article{Turing50,
author = 	{A. M. Turing},
title = 	{Computing Machinery and intelligence},
journal = 	{Mind},
volume = 	59,
year = 		1950,
month = 	Oct,
pages = 	{433--460},
note = 		{(Reprinted in {\em Computers and Thought}, (eds.
		  E. A. Feigenbaum and J. Feldman), McGraw-Hill, 1963,
		  pages 11--38).},
comment = 	{Classic article on whether computers can think; introduces
		 the `Turing test'.}
}

@inproceedings{ToutanovaMa02,
	author = "K. Toutanova and C.D. Manning",
	title = "Feature Selection for a Rich {HPSG} Grammar Using Decision Trees",
	booktitle = "Proceedings of the Sixth Conference on Natural Language
		Learning (CoNLL)",
	year = 2002
}


@inproceedings{ToutanovaKlMaSi03,
	author = "K. Toutanova and D. Klein and C.D. Manning and Y. Singer",
	title = "Feature-Rich Part-of-Speech Tagging with a
		Cyclic Dependency Network ",
	booktitle = "Proceedings of the North American chapter of the
	Association for Computational Linguistics (NAACL)",
	year = 2003
}

@inbook{Tuy94,
author=         {Hoang Tuy},
editor=   	{Horst and Pardalos},
title=    	{Handbook of Global Optimization},
year=     	1994,
chapter=  	{{D.C.} optimization: Theory, Methods and Algorithms},
publisher= 	{Kluwer},
pages=     	{149-216}
}

@inproceedings{UdellMoZeHoDiBo14,
  title={Convex optimization in {J}ulia},
  author={Udell, Madeleine and Mohan, Karanveer and Zeng, David and Hong, Jenny and Diamond, Steven and Boyd, Stephen},
  booktitle={First Workshop on High Performance Technical Computing in Dynamic Languages},
  pages={18--28},
  year=2014,
  organization={IEEE}
}

@article{Vajda72,
author = {Igor Vajda},
title = {On the $f$-divergence and singularity of probability measures},
year = 1972,
journal = {Periodica Mathematica Hungarica},
volume = 2,
number = {1--4},
pages = {223--234},
comment = {Gives definitions of a variety of general formulations of
  $f$-divergences and $f$-informations, showing the measure-theoretic
  details necessary for their existence. Uses a Martingale limit theorem
  to show that $f$-divergences may be taken as limits of finite
  quantizations of the underlying probability measures.},
}

@article{Valiant79
,author=	{L. G. Valiant}
,title=		{The complexity of enumeration and reliability
		 problems}
,journal=	sicomp
,volume=	8
,number=	3
,pages=		{410--421}
,year=		1979
}

@article{Valiant84,
author=   	{Valiant, L.~G.},
title=    	{A Theory of the Learnable},
journal=  	cacm,
year=     	1984,
month=    	Nov,
volume=   	27,
number=   	11,
pages=    	{1134--1142},
comment=  	{Defines `learnability' wrt EXAMPLES and ORACLE using arbitrary
		probability measure on event space.  Shows k-CNF learnable from
		examples only.}
}

@inproceedings{Valiant85,
author= 	{Valiant, L. G.},
title=		{Learning disjunctions of conjunctions},
booktitle=	ijcai85,
pages=		{560--566},
year=		1985,
month=		aug
}

@inproceedings{ValiantVa16,
author = {Gregory Valiant and Paul Valiant},
title = {Instance Optimal Learning of Discrete Distributions},
year = 2016,
booktitle = stoc16,
}

@inproceedings{ValiantVa13,
  author = "Gregory Valiant and Paul Valiant",
title = "Estimating the unseen: improved estimators for entropy
 and other properties",
  booktitle= nips26,
  year = "2013",
}


@BOOK{vandeGeer00,
AUTHOR = "Sara van de Geer",
TITLE = "Empirical Processes in M-Estimation",
PUBLISHER = "Cambridge University Press",
YEAR = "2000"
}

@article{Vanderbei99,
  author = "R.J. Vanderbei",
  title = "{LOQO}: {An} interior point code for quadratic programming",
  journal = "Optimization Methods and Software",
  volume = 12,
  pages = "451--484",
  year = 1999
}

@incollection{VanDerVaart97,
author = {Aad W. van der Vaart},
title = {Superefficiency},
year = 1997,
booktitle = {Festschrift for Lucien Le Cam},
editor = {D. Pollard and E. Torgersen and G. Yang},
publisher = {Springer},
chapter = 27,
}

@book{VanDerVaart98,
author = {Aad W. van der Vaart},
title = {Asymptotic Statistics},
series = {Cambridge Series in Statistical and Probabilistic Mathematics},
publisher = {Cambridge University Press},
city = {Cambridge},
year = {1998},
isbn = {0-521-49603-9},
}

@Book{VanDerVaartWe96,
  author =	 {A. W. van der Vaart and J. A. Wellner},
  title = 	 {Weak Convergence and Empirical Processes: With Applications to Statistics},
  publisher = {Springer},
  address = {New York},
  year = 	 1996,
  key =		 {ISBN: 0387946403},
  comment =	 {This book is recommended by Dudley as a reference for the analysis of BootStrap}
}

@article{VanLehn87,
author= 	{VanLehn, Kurt},
title= 		{Learning One Subprocedure per Lesson},
journal= 	{Artificial Intelligence},
volume = 	31,
number = 	1,
month = 	Jan,
year= 		1987,
pages= 		{1--40}
}

@book{Vapnik82,
author = 	{Vapnik, V. N.},
title = 	{Estimation of Dependences Based on Empirical Data},
publisher = 	{Springer-Verlag},
year = 		{1982},
comment=	{address=NY}
}

@incollection{Vapnik92,
author=		{V. Vapnik},
title=		{Principles of Risk Minimization for Learning Theory},
booktitle=	{Advances in Neural Information Processing Systems 4},
editor=		{John E. Moody and Steve J. Hanson and Richard P. Lippmann},
publisher=	{Morgan Kaufmann},
year=		1992,
pages=		{831--838}
}

@Book{Vapnik95,
  author =	 {V.N. Vapnik},
  title = 	 {The Nature of Statistical Learning Theory},
  publisher = 	 {Springer},
  year = 	 1995
}

@Book{Vapnik98,
  author = 	 {V.~N.~Vapnik},
  title = 	 {Statistical Learning Theory},
  publisher = 	 {Wiley},
  year = 	 {1998}
}

@article{VapnikCh71,
author=   	{Vapnik, V. N. and A. Ya. Chervonenkis},
title=    	{On the Uniform Convergence of Relative Frequencies of Events
		to their probabilities},
journal=  	{Theory of Probability and its Applications},
volume=   	{XVI},
number=   	2,
year=     	1971,
pages=    	{264--280},
comment=  	{Shows that a sufficient condition for the probability of every
	   	set converging to its correct probability is finite VC
		dimension.}
}


@Book{VapnikCh74,
  author = 	 {V. N. Vapnik and A. Ya. Chervonenkis},
  title = 	 {Theory of Pattern Recognition},
  publisher = 	 {Nauka},
  year = 	 1974,
  address =	 {Moscow},
  note =	 {(In Russian)}
}

@article{VardiShKa85
,author=	{Y. Vardi and L. A. Shepp and L. Kaufman}
,title=		{A statistical model for positron emission tomography}
}

@article{Vavasis09,
author = {Stephen A. Vavasis},
title = {On the complexity of nonnegative matrix factorization},
year = 2009,
journal = siopt,
pages = {1364--1377},
volume = 20,
number = 3,
comment = {Proofs that exactly solving the non-negative matrix factorization
  problem is NP hard. (Problem is given $A \in \R_+^{m \times n}$, are
  there non-negative matrices $(W, H) \in \R^{m \times k}$ and
  $\R^{k \times n}$ such that $A = WH$.)
  The proof is by a reduction to a problem called
  Intermediate Simplex, which is given a polyhedron $\{Ax \ge b\}$, where
  $A \in \R^{n \times k-1}$ such that $[A b]$ has rank $k$ and a set
  $S \subset \R^{k - 1}$ of $m$ points contained in $P$ and
  affinely spanning $\R^{k-1}$. Is there a $(k-1)$-simplex $T$ such that
  $S \subset T \subset P$. The proof that this is NP hard is from 3SAT,
  building a gadget that constructs lots of mini-simplexes, each of which
  solves an intermediate simplex problem setting a variable to true/false
  based on the smaller simplex problem.
  },
}

@article{Vazirani87,
author=		{U. V. Vazirani},
title=		{Strong communication complexity or generating
		 quasi-random sequences from two communicating
		 semi-random sources},
journal=	{Combinatorica},
volume=		7,
year=		1987,
pages=		{375--392}
}

@inproceedings{VaziraniVa85,
author=		{U. V. Vazirani and V. V. Vazirani},
title=		{Random polynomial time is equal to slightly-random
		 polynomial time},
booktitle=	focs85,
year=		1985,
month=		oct,
pages=		{417--428}
}

@book{Vazirani01,
author = {Vijay V.\ Vazirani},
title = {Approximation Algorithms},
year = 2001,
publisher = {Springer},
}

@inproceedings{VenkatesanLe88,
author=		{Ramarathnam Venkatesan and Leonid A. Levin},
title=		{Random Instances of a Graph Coloring Problem Are Hard},
booktitle=	stoc88,
year=		1988,
month=		May,
pages=		{217--222}
}

@inproceedings{Verbeurgt90,
author=		{Karsten Verbeurgt},
title=		{Learning {DNF} under the Uniform Distribution in
		 Quasi-polynomial Time},
booktitle=	colt90,
pages=		{314--326},
month=		Aug,
year=		1990
}

@article{Vershynin00,
author = {R. Vershynin},
title = {On large random almost {E}uclidean bases},
year = 2000,
journal = {Acta Mathematica Universitatis Comenianae},
volume = 69,
number = 2,
pages = {137--144},
}

@incollection{Vershynin12,
author = {Roman Vershynin},
title = {Introduction to the non-asymptotic analysis of random matrices},
year = 2012,
pages = {210--268},
chapter = 5,
booktitle = {Compressed Sensing: Theory and Applications},
publisher = {Cambridge University Press},
comment = {Editors Yonina Eldar and G. Kutyniok,
url = {http://www-personal.umich.edu/~romanv/papers/non-asymptotic-rmt-plain.pdf}},
}

@unpublished{Vershynin17,
author = {Roman Vershynin},
title = {High Dimensional Probability: An Introduction with Applications
  in Data Science},
year = 2017,
}

@article{Vershynin16,
  title = {High Dimensional Probability},
  author = {Roman Vershynin},
  year = {2016},
}


@book{Vidyasagar97,
author =   "M.~Vidyasagar",
title =    "A Theory of Learning and Generalization",
publisher =    "Springer",
year =     1997
}

@book{Villani09,
author = {Cedric Villani},
title = {Optimal Transport: Old and New},
year = 2009,
publisher = {Springer},
}

@article{Vitanyi11,
author = {Paul M. B. Vit\'anyi},
title = {Information distance in multiples},
journal = ieeeit,
year = 2011,
volume = 57,
number = 4,
pages = {2451–-2456},
}

@inproceedings{Vovk90
, author =      "Volodimir G. Vovk"
, title =       "Aggregating Strategies"
, booktitle =   colt90
, year =        1990
, pages =       "371--383"
}

@article{Vovk92
,author=	{V. G. Vovk}
,title=		{Universal forcasting algorithms}
,year=		1992
,journal=       {Information and Compuatation}
,number=        96
,pages=         {245--277}
}

@techreport{Vovk93
,author=	{V. G. Vovk}
,title=		{On-line learning in a finite-state environment:
		 decision theoretic approach}
,year=		1993
}

@article{Vovk93b
,author=	{V. G. Vovk}
,title=		{A logic of probability, with application to the
		 foundations of statistics}
,journal=	{Journal of the Royal Statistical Society Series
		 B-Methodological}
,volume=	55
,number=	2
,year=		1993
,pages=		{317-351}
}

@inproceedings{Vovk94
,author=	{V. G. Vovk}
,title=		{An optimal-control application of two paradigms of
		 on-line learning}
,booktitle=	colt94
,year=		1994
,pages=		{98--109}
}

@article{Vovk98
,author=	{V. G. Vovk}
,title=		{A game of prediction with expert advice}
,journal=       jcss
,year=          1998
,volume=        56
,number=        2
,month=         apr
,pages=         {153-173}
}

@unpublished{Vovk97
,author=	{V. Vovk}
,title=         {Probability theory for the {Brier} game}
}

@unpublished{Vovk??
,author=	{V. G. Vovk}
,title=		{An optimality property of the weighted majority
		algorithm}
}

@article{Vovk01,
author = {V. Vovk},
title = {Competitive on-line statistics},
journal = {International Statistical Review},
volume = {69},
year = {2001},
pages = {213--248}
}

@article{WaegemanBo06,
title = {A ensemble of weighted support vector machines for ordinal regression},
author = {W. Waegeman and L. Boullart},
year = 2006,
journal = {Transactions on Engineering, Computing and Technology},
volume = 12,
pages = {71--75}
}

@techreport{WahBrWePeBe11,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = 2011,
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}@techreport{WaibelHaHiSh87,
author = 	{A. Waibel and T. Hanazawa and G. Ginton and K Shikano},
title = 	{Phoneme Recognition Using Time-Delay Neural Networks},
year = 		1987,
institution = 	{ATR Interpreting Telephony Laboratories}
}

@article{Wainwright09,
author = {Martin J. Wainwright},
title = {Sharp thresholds for high-dimensional and noisy sparsity recovery
using $\ell_1$-constrained quadratic programming ({L}asso)},
year = 2009,
journal = ieeeit,
volume = 55,
number = 5,
pages = {2183--2202},
}

@article{WainwrightJo08,
author = {Martin J.\ Wainwright and Michael I.\ Jordan},
title = {Graphical models, exponential families, and variational inference},
journal = {Foundations and Trends in Machine Learning},
volume = 1,
number = {1--2},
pages = {1--305},
year = 2008,
comment = {Great survey of Martin's and Mike's research on graphical models
  and their variational representations.},
}

@article{Wald39,
author = {Abraham Wald},
title = {Contributions to the theory of statistical estimation and
  testing hypotheses},
year = 1939,
journal = {Annals of Mathematical Statistics},
volume = 10,
number = 4,
pages = {299--326},
}

@article{Wald45,
author = {Abraham Wald},
title = {Statistical decision functions which minimize the maximum risk},
year = 1945,
journal = {Annals of Mathematics},
volume = 46,
number = 2,
pages = {265--280},
}

@article{WaldspurgerDaMa15,
title = {Phase Recovery, MaxCut and Complex Semidefinite Programming},
author = {Ir\`{e}ne Waldspurger and Alexandre d'Aspremont and
   St\`{e}phane Mallat},
journal = mathproga,
year = 2015,
pages = {47--81},
volume = 149,
number = {1--2},
}

@phdthesis{Wallace89,
author = 	{Richard Scott Wallace},
title = 	{Finding Natural Clusters Through Entropy Minimization},
school = 	{Carnegie Mellon Computer Science Department},
year =		1989,
month = 	jun
}

@article{WallaceBo68,
author=   	{Wallace, C.S. and D.M. Boulton},
title=    	{An Information Measure for Classification},
journal=  	{The Computer Journal},
year=     	1968,
volume=   	11,
number=   	2,
pages=    	{185--194},
comment=  	{Introduces idea that `best classification is that which
		results in the briefest recording of all the attribute
		information'}
}

@inproceedings{WalmsleyGoRa99,
author=   	{P.J. Walmsley and S.J. Godsill and P.J.W. Rayner},
title=    	{Polyphonic Pitch Tracking Using Joint Bayesian Estimation Of Multiple Frame Parameters},
booktitle =     { Proc. 1999 Ieee Workshop on Applications of Signal Processing to Audio and Acoustics},
year=     	1999,
month= Oct,
comment=  	{}
}

@book{Wahba90,
author = {Grace Wahba},
title = {Spline Models for Observational Data},
year = 1990,
publisher = {Society for Industrial and Applied Mathematics},
address = {Philadelphia},
}

@book{Walrand88
,author=	{Jean Walrand}
,book=		{An Introduction to Queueing Networks}
,year=		1988
,publisher=	{Prentice Hall}
}

@article{WangGiEl16,
author = {Gang Wang and Georgios B. Giannakis and Yonina C. Eldar},
title = {Solving Systems of Random Quadratic
   Equations via Truncated Amplitude Flow},
year = 2016,
journal = {arXiv:1605.08285 [stat.ML]},
}


@article{Wang13,
  title={The L1 penalized LAD estimator for high dimensional linear regression},
  author={Lie Wang},
  journal={Journal of Multivariate Analysis},
  volume={120},
  pages={135--151},
  year={2013},
  publisher={Academic Press, Inc.}
}

@article{WangAh08,
  title={Sample average approximation of expected value constrained stochastic programs},
  author={Wang, Wei and Ahmed, Shabbir},
  journal={Operations Research Letters},
  volume=36,
  number=5,
  pages={515--519},
  year=2008,
  publisher={Elsevier}
}

@article{WangGlYe13,
  title={Likelihood robust optimization for data-driven problems},
  author={Wang, Zizhuo and Glynn, Peter and Ye, Yinyu},
  journal={arXiv:1307.6279 [math.OC]},
  year=2013
}

@article{WangGlYe15,
  title={Likelihood robust optimization for data-driven problems},
  author={Wang, Zizhuo and Glynn, Peter and Ye, Yinyu},
  journal={Computational Management Science},
  year=2015,
  pages = {1--21},
}

@article{WangYuSi16,
  title={Computationally Feasible Near-Optimal Subset Selection for Linear Regression under Measurement Constraints},
  author={Wang, Yining and Yu, Adams Wei and Singh, Aarti},
  journal={arXiv:1601.02068 [stat.ML]},
  year={2016}
}

@article{Warner65,
author = {Stanley Warner},
title = {Randomized response: a survey technique for eliminating evasive
answer bias},
year = 1965,
journal = jasa,
pages = {63--69},
volume = 60,
number = 309,
comment = {
  Early idea on a privacy method for surveying a population when potentially
  invasive questions are asked, as long as all that one cares to know is
  the proportion of a population belonging to some category (as opposed to
  non-marginal statistics of the category).
},
}

@article{WassermanZh10,
author = {Larry Wasserman and Shuheng Zhou},
title = {A statistical framework for differential privacy},
year = 2010,
journal = jasa,
volume = 105,
number = 489,
pages = {375--389},
comment = {
  Analyzes histogram estimators (over the space [0, 1]^d) under the framework
  of differential privacy. Shows a few techniques for achieving privacy:
  one based on simply adding a lower bound \delta > 0 to all histogram
  bins, another based on adding random exponential noise to the bins
  of the histogram, then resampling points from that distribution. This means
  new data Z can be constructed and released, where the distribution of Z
  is close to X (original data) in different metrics. They consider a few
  other mechanisms, including estimation using orthogonal series, where
  resampling is done by sampling from \sum_{j=1}^m (\beta_j + \nu_j) \phi_j(x),
  where \beta_j are the standard estimates and \nu_j are random noise.
  This achieves minimax rates (other sampling schemes sometimes do and
  sometimes do not).
},
}

@inproceedings{WangRoZhSc02,
author=	   	{S. Wang and R. Rosenfeld and Y. Zhao and D. Schuurmans},
title=	   	{The latent maximum entropy principle},
booktitle=      {IEEE International Symposium on Information Theory},
year=		2002
}

@inproceedings{WarmuthLiRa06,
author= {M. Warmuth and J. Liao and G. Ratsch},
title= {Totally corrective boosting algorithms that maximize the margin},
booktitle= {Proceedings of the 23rd international conference on Machine learning},
year = {2006}
}

@inproceedings{WarmuthGlRa07,
author = {M. Warmuth and K. Glocer and G. Ratsch},
title = {Boosting Algorithms for Maximizing the Soft Margin},
booktitle = nips20,
year = {2007}
}

@inproceedings{WarmuthGlVi08,
author = {M. Warmuth and K. Glocer and S.V.N. Vishwanathan},
title = {Entropy Regularized LPBoost},
booktitle = {Algorithmic Learning Theory (ALT)},
year = {2008}
}


@inproceedings{Watkins87,
author=	   	{Watkins, C.J.C.H.},
title=	   	{Combining Cross--Validation and Search},
booktitle= 	{Progress in Machine Learning--Proceedings of EWSL 87:
	   	2nd European Working Session on Learning},
address=   	{Bled, Yugoslavia},
year=	   	1987,
editor=	   	{Bratko, I. and N. Lavrac},
month=	   	may,
pages=	   	{79--90}
}

@phdthesis{Watkins89,
author=		{C. J. C. H. Watkins},
title=		{Learning from delayed rewards},
school=		{University of Cambridge, England},
year=		1989
}

@article{WatkinsDa92
,author=	{Christopher J. C. H. Watkins and Peter Dayan}
,title=		{Q-learning}
,journal=	ml
,volume=	8
,year=		1992
,pages=		{279--292}
}

@article{WeiTa90,
author = {G. Wei and M. A. Tanner},
title = {A {M}onte {C}arlo implementation of the {EM} algorithm and the
poor man's data augmentation algorithms},
year = 1990,
journal = jasa,
pages = {699--704},
volume = 85,
number = 411,
comment = {Uses Monte Carlo sampling within the E step of the EM algorithm.
Probably related to the Stochastic EM algorithm, but uses multiple samples
in E step rather than 1},
}

@article{WeigendWiPe99,
 author = {A. S. Weigend and E. D. Wiener and J. O. Pedersen},
 title = {Exploiting Hierarchy in Text Categorization},
 journal = {Information Retrieval},
 volume = {1},
 number = {3},
 year = {1999},
 pages = {193--216},
 publisher = {Kluwer Academic Publishers},
 }

@inproceedings{WeinbergerDaLaSmAt09,
author = {Killian Weinberger and Anirban Dasgupta and John Langford
  and Alex Smola and Josh Attenberg},
title = {Feature hashing for large scale multitask learning},
year = 2009,
booktitle = icml09,
}

@article{WeinbergerLeZi92,
  author =       "Marcelo J. Weinberger and Abraham Lempel and Jacob Ziv",
  title =        "A Sequential Algorithm for the Universal Coding of
		  Finite-Memory Sources",
  journal =      ieeeit,
  volume =       "38",
  number =       "3",
  month =        may,
  year =         "1992",
  pages =        "1002--1014"
}

@article{WeinbergerMeFe94,
  author =       "Marcelo J. Weinberger and Neri Merhav and Meir Feder",
  title =        "Optimal Sequential Probability Assignment for Individual Sequences",
  journal =      ieeeit,
  volume =       "40",
  number =       "2",
  month =        mar,
  year =         "1994",
  pages =        "384--396"
}

@article{WeinbergerRiFe95,
  author =       "Marcelo J. Weinberger and Jorma J. Rissanen and Meir Feder",
  title =        "A Universal Finite Memory Source",
journal=	ieeeit,
volume=		{41},
number=		3,
year=		1995,
pages=		{643-652}
}

@article{WeinbergerSe97
,author =       {Marcelo J. Weinberger and Gadiel Seroussi}
,title=         {Sequential prediction and ranking in universal
                  context modeling and data compression}
}

@book{Weiss95,
  title={Large deviations for performance analysis},
  author={Weiss, Alan and Shwartz, Adam},
  year=1995,
  publisher={Chapman and Hall, Boca Raton}
}

@article{WeissApDaJoOlGoHa99,
	author = {S. M. Weiss and C. Apte and F. J. Damerau and
		D. E. Johnson and F. J. Oles and T. Goetz and T. Hampp},
	title = {Maximizing Text-Mining Performance},
	journal = {IEEE Intelligent Systems},
	year = 1999
}

@article{WenocurDu81,
author=   	{Wenocur, R. S. and R. M. Dudley},
title=    	{Some Special {V}apnik-{C}hervonenkis Classes},
journal=  	{Discrete Mathematics},
year=     	1981,
volume=   	33,
pages=    	{313--318},
comment=  	{Shows VC dimension of half-spaces in n dimensions is n.}
}


@inproceedings{WestonWa99,
author = 	{J. Weston and C. Watkins},
title = 	{Support Vector Machines for Multi-Class
                 Pattern Recognition},
booktitle = 	esann99,
month =         apr,
year = 		1999
}


@article{WestonElScTi03,
   author = {Weston, J. and A. Elisseeff and B. Sch\"olkopf and M. Tipping},
   title = {Use of the Zero-Norm with Linear Models and Kernel Methods},
   year = {2003},
   volume = {3},
   publisher = {MIT Press},
   pages = {1439-1461},
   journal = {Journal of Machine Learning Research}
}

@inproceedings{WestonBoBo05,
author = 	{J. Weston and A. Bordes and L. Bottou},
title = 	{Online (and Offline) on an Even Tighter Budget},
booktitle = 	{Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics},
year = 		{2005},
pages= {413--420}

}


@article{White89,
author=		{Halbert White},
title=		{Learning in Artificial Neural Networks: A Statistical
		 Perspective},
journal=	{Neural Computation},
volume=		1,
number=		4,
pages=		{425--464},
year=		1989
}

@article{Whitney35,
author = {Hassler Whitney},
title = {A function not constant on a connected set of critical points},
year = 1935,
journal = {Duke Mathematical Journal},
volume = 1,
number = 4,
pages = {514--517},
comment = {Shows that there are functions whose critical values have
full measure. That is, if $D = \{x : \nabla f(x) = 0\}$, then it is
possible that $f(D) = [0, 1]$ or something. This can happen if 
$f : \R^n \to \R$ is $C^m$ for some $m < n$. Otherwise, Sard's theorem
shows this cannot happen. See also van Dijk's bachelor's thesis ``On the
sets of critical points and critical values,'' Leiden University Mathematical
Institute}
}

@book{Whitt02,
  title={Stochastic Process Limits: An Introduction to Stochastic Process Limits and Their Application to Queues},
  author={Whitt, Ward},
  year=2002,
  publisher={Springer Science \& Business Media}
}

@article{WidrowGuMa73
,author=	{Bernard Widrow and Narendra K. Gupta and Sidhartha Maitra}
,title=		{Punish/reward: Learning with a critic in adaptive
		 threshold systems}
,journal=	{IEEE Transactions on Systems, Man, and Cybernetics}
,volume=	{SMC-3}
,number=	5
,month=		sep
,year=		1973
,pages=		{455--465}
}

@article{WieselHe12,
author = {Ami Wiesel and Alfred O. Hero},
title = {Distributed Covariance Estimation in {G}aussian
   Graphical Models},
year = 2012,
journal = ieeesp,
volume = 60,
number = 1,
}

@article{WidrowHo60,
author = 	{B.~Widrow and M.~E.~Hoff},
title = 	{Adaptive Switching Circuits},
journal =	{1960 IRE WESCON Convention Record},
publisher = 	{IRE},
year = 		1960,
pages = 	{96--104},
note = 		{Reprinted in {\sl Neurocomputing} (MIT Press, 1988).}
}

@techreport{WileyTe85,
author=   	{Wiley, R. Paul and Robert R. Tenney},
title=    	{Performace Evaluation of Stochastic Timed Decision-Free
		Petri Nets},
institution=  	{MIT Laboratory for Information and Decision Sciences},
year=     	1985,
month=    	Mar,
number=   	{LIDS-P-1443},
comment=  	{Interesting model for a stochastic system.}
}

@article{Wilf68,
author=		{Herbert S. Wilf},
title=		{Hadamard determinants, {M}\"obius functions, and the
		 chromatic number of a graph},
journal=	bams,
volume=		74,
number=		5,
month=		sep,
year=		1968,
pages=		{960--964}
}

@article{Wilf84,
author=		{Herbert S. Wilf},
title=		{Backtrack:  An {$O(1)$} expected time graph coloring
		algorithm},
journal=	{Information Processing Letters},
volume=		18,
number=		3,
month=		mar,
year=		1984,
pages=		{119--121}
}


@Book{Wilkinson65,
	author =   "J.H. Wilkinson",
	title =    "The Algebric Eigenvalue Problem",
	publisher =    "Claderon Press, Oxford",
	year =     1965
}

@inproceedings{Willems94
,author=	{F. M. J. Willems}
,title=		{Extensions to the context tree weighting method}
,booktitle=	{Proceedings of the IEEE International Symposium on
		 Information Theory}
,year=		1994
,pages=		{387}
}

@inproceedings{WillemsShTj93
,author=	{F. M. J. Willems and Y. M. Shtarkov and Tj. J. Tjalkens}
,title=		{Context tree weighting: a sequential universal source
		 coding procedure for {FSMX} sources}
,booktitle=	{Proceedings of the IEEE International Symposium on
		 Information Theory}
,year=		1993
,pages=		{59}
}

@article{WillemsShTj95
,author=	{F. M. J. Willems and Y. M. Shtarkov and T. J. Tjalkens}
,title=		{The context tree weighting method: basic properties}
,journal=	ieeeit
,volume=	{41}
,number=	3
,year=		1995
,pages=		{653-664}
}

@article{WillemsShTj96
,author=	{F. M. J. Willems and Y. M. Shtarkov and T. J. Tjalkens}
,title=		{Context weighting for general finite-context sources}
,journal=	ieeeit
,year=		1996
}

@incollection{Williams98,
author = 	 {C. K. I. Williams},
booktitle = 	 {Learning and Inference in Graphical Models},
editor =         {M. I. Jordan},
title = 	 {Prediction with Gaussian Processes: From Linear Regression to Linear Prediction and Beyond},
publisher = 	 {Kluwer Academic Press},
pages =          {599--622},
year = 	         {1998}
}

@article{WilliamsonVeRe16,
author = {Robert C. Williamson and Elodie Vernet and Mark D. Reid},
title = {Composite Multiclass Losses},
year = 2016,
journal = jmlr,
volume = {to appear},
}

@inproceedings{Wilson85,
author=   	{Wilson, Stewart W.},
title=    	{Knowledge Growth in an Artificial Animal},
booktitle= 	{Proceedings of an International Conference on Genetic
		Algorithms and their Applications},
year=	  	1985,
month=    	Jul,
pages=    	{16--23},
comment=  	{Empirical results for a `critter' wandering around in the
		woods trying to find food, using a genetic algorithm a la
		Holland to learn general situation/action rules.}
}

@article{Wilson04,
author = {D. B. Wilson},
title = {Mixing times of lozenge tiling and card shuffling {M}arkov chains},
year = 2004,
journal = aoap,
volume = 14,
number = 1,
pages = {274--325},
comment = {A long paper using Fourier analysis and coupling arguments to
  bound mixing times. One consequence (Section 6) is that the random
  transposition chain for sampling from a total order obeying a partial order
  has mixing time n^3 \log(n / \epsilon)},
}

@article{Wing06,
author = {Jeannette M. Wing},
title = {Computational Thinking},
year = 2006,
journal = cacm,
volume = 49,
number = 3,
pages = {33--35},
}

@unpublished{WinklerZu??
,author=	{Peter Winkler and David Zuckerman}
,title=		{Multiple cover time}
}

@incollection{Winston75,
author = 	{Winston, Patrick H.},
title = 	{Learning Structural Descriptions from Examples},
booktitle = 	{The Psychology of Computer Vision},
publisher = 	{McGraw-Hill},
year = 		1975,
address = 	{New York},
editor = 	{Winston, Patrick H.}
}

@article{Witten77,
author = 	{Witten, Ian H.},
title = 	{An Adaptive Optimal Controller for Discrete-Time
		Markov Environments},
journal = 	infctrl,
year = 		1977,
volume = 	34,
pages = 	{286--295},
comment = 	{Controller sees state of environment at each instant, and
		 gets reward from that state.  Uses discounted expectation
		 of future reward to guide action selection.}
}

@article{Witten77b
,author=	{Ian H. Witten}
,title=		{Exploring, modelling and controlling discrete
		 sequential environments}
,year=		1977
}

@article{WoodsSoPrDoBoCl93,
  title={Comparative evaluation of pattern recognition techniques for
                  detection of microcalcifications in mammography},
  author={Woods, Kevin S and Doss, Christopher C and Bowyer, Kevin W
                  and Solka, Jeffrey L and Priebe, Carey E and
                  KEGELMEYER JR, W PHILIP},
  journal={International Journal of Pattern Recognition and Artificial
                  Intelligence},
  volume=7,
  number=06,
  pages={1417--1436},
  year=1993,
  publisher={World Scientific},
  comment={Data link:
                  http://odds.cs.stonybrook.edu/mammography-dataset,
                  heavyly imbalanced dataset (only 2.5 percent of the data
                  are positive) with n = 11183 and d = 6}
}

@inproceedings{WoodworthSr16,
 Author = {Woodworth, Blake E and Srebro, Nati},
 Booktitle = nips29,
 Title = {Tight complexity bounds for optimizing composite objectives},
 Year = {2016},
 Pages = {3639--3647},
}

@article{WoodworthSr17,
	author =  {Woodworth, Blake E and Srebro, Nati},
	title = {Lower Bound for Randomized First Order Convex Optimization},
	journal = {arXiv:1709.03594 [math.OC]},
	year = 2017,
}

@article{Wozabal12,
  title={A framework for optimization under ambiguity},
  author={Wozabal, David},
  journal={Annals of Operations Research},
  volume=193,
  number=1,
  pages={21--47},
  year=2012,
  publisher={Springer}
}

@article{Wright93,
author = {Stephen J. Wright},
title = {Identifiable surfaces in constrained optimization},
year = 1993,
journal = sicon,
volume = 31,
number = 4,
pages = {1063--1079},
comment = {Shows how constraints may be identified under a linear
  independence constraint qualification, which is required for
  uniqueness of Lagrange multipliers.
  In particular, shows that under appropriate conditions, the normal
  cone $N_S(x)$ to the surface S can be roughly open. If $\nabla F(x^*)$
  is in the relative interior of $N_S(x^*)$, then eventually projected
  gradient steps lie in the interior of the outward normal cone $N_S(x^*)$
  so that projections lie in $S$. (i.e. finite identification)
  Moreover, under appropriate conditions,
  convergence is locally quadratic if the Hessian restricted to the
  tangent $T_S(x^*)$ is strongly convex and we use a Newton-like projected
  gradient method.},
}

@inproceedings{WrightGoRi97,
	author = "J. H. Wright and A. L. Gorin and G. Riccardi",
	title = "Automatic acquisition of salient grammar fragments
		for call-type classification",
	booktitle = "Proceedings of the 5th European Conference
            on Speech Communication and Technology",
	year = 1997,
	pages = "1419--1422"
}

@inproceedings{WrightNoFi08,
title = {Sparse Reconstruction by Separable Approximation},
author = {S. Wright and R. Nowak and M. Figueiredo},
year = 2008,
booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},
pages = {3373--3376},
}

@article{WrightNoFi09,
title = {Sparse Reconstruction by Separable Approximation},
author = {S. Wright and R. Nowak and M. Figueiredo},
year = 2009,
journal = {IEEE Transactions on Signal Processing},
volume = 57,
number = 7,
pages = {2479--2493},
}

@InProceedings{WolfSh03,
  author = 	 {L. Wolf and A. Shashua},
  title = 	 {Direct Feature Selection with Implicit Inference},
  booktitle = 	 iccv,
  year =	 2003,
}

@article{Wu83,
    author = {C.F.J. Wu},
    title = {On the convergence properties of the {EM} algorithm},
    journal = {Annals of Statistics},
    volume = {11},
    year = {1983},
    pages = {95--103}
}

@article{WuScBa06,
author = {M.~Wu and B.~{Sch\"olkopf} and G.~Bakir},
title = {A Direct Method for Building Sparse Kernel Learning Algorithms},
journal = jmlr,
volume = 7,
year = 2006,
pages = {603--624}
}

@article{WuSh04,
author = {Wei Biao Wu and Xiaofeng Shao},
title = {Limit theorems for iterated random functions},
year = 2004,
journal = {Journal of Applied Probability},
volume = 41,
pages = {425--436},
comment = { Gives a nice argument for convergence of iterated random functions
  of the form $X_n = F_{\theta_n}(X_{n-1})$, where $\theta_i$ are an i.i.d.
  sequence and the $X_i$ are initialized somehow. Under an assumption of
  geometric decay of distances $X_n(x) = F_{\theta_n} ... F_{\theta_1}(x)$
  and $X_n(y)$, uses a backward process (converging a.s. to some random
  variable) to get convergence in distribution of associated Markov chain.
  Gives central limit theorems (and uniform variants) by showing a sequence
  of $g(X_{n-l}, ..., X_n)$ has a Martingale structure. Does not
  show \emph{what} distributions are or formulae for variance, but that
  is non-trivial.},
}

@article{Wyner72,
author=		{Wyner, A. D.},
title=		{An upper bound on the entropy series},
journal= 	infctrl,
volume=		20,
year=		1972,
pages=		{176--181}
}

@article{Wyner78,
author = {A.~D. Wyner},
title = {A definition of conditional mutual information for arbitrary
ensembles},
year = 1978,
journal = infctrl,
volume = 38,
number = 1,
pages = {51--59},
}

@inproceedings{XiaLiWaZhLi08,
author = {F. Xia and T. Y. Liu and J. Wang and W. Zhang and H. Li},
title = {Listwise approach to learning to rank -- theory and algorithm},
booktitle = icml08,
year = 2008,
}

@inproceedings{XiaLiLi09,
author = {F. Xia and T. Y. Liu and H. Li},
title = {Top-$k$ consistency of learning to rank methods},
booktitle = nips22,
year = 2009,
}

@article{XiaoBoKi07,
title = "Distributed average consensus with least-mean-square deviation",
journal = "Journal of Parallel and Distributed Computing",
volume = "67",
number = "1",
pages = "33--46",
year = "2007",
author = "L. Xiao and S. Boyd and S. J. Kim",
}

@inproceedings{Xiao09,
author = {L. Xiao},
title = {Dual averaging methods for regularized stochastic learning and online optimization},
year = 2009,
booktitle = nips22,
}

@article{Xiao10,
author = {Lin Xiao},
title = {Dual averaging methods for regularized stochastic learning and
         online optimization},
year = 2010,
journal = jmlr,
volume = 11,
pages = {2543--2596},
}

@inproceedings{XingNgJoRu03,
	author = "E. Xing and A.Y. Ng and M. Jordan and S. Russell",
	title = "Distance metric learning, with application to clustering with
		side-information",
	booktitle = nips15,
	year = 2003
}

@inproceedings{XuCaMa09_nips,
  title={Robust regression and Lasso},
  author={Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  booktitle=nips21,
  pages={1801--1808},
  year=2009
}

@article{XuCaMa09,
  title={Robustness and regularization of support vector machines},
  author={Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  journal={Journal of Machine Learning Research},
  volume=10,
  pages={1485--1510},
  year=2009,
  publisher={JMLR. org}
}

@article{XuCaMa12,
  title={A distributional interpretation of robust optimization},
  author={Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  journal={Mathematics of Operations Research},
  volume=37,
  number=1,
  pages={95--110},
  year=2012,
  publisher={INFORMS}
}

@article{XueYe00,
  title={An efficient algorithm for minimizing a sum of p-norms},
  author={Xue, Guoliang and Ye, Yinyu},
  journal=siopt,
  volume=10,
  number=2,
  pages={551--579},
  year=2000,
  publisher={SIAM}
}

@article{YakowitzSP68,
author=		{S. J. Yakowitz and J. D. Spragins},
title=		{On the identifiability of finite mixtures},
journal=       {The Annals of Mathematical Statistics},
volume=		39,
year=		1968,
pages=		{258--263}
}

@inproceedings{Yamanishi90,
author=		{Kenji Yamanishi},
title=		{A Learning Criterion for Stochastic Rules},
booktitle=	colt90,
month=    	Aug,
year=     	1990,
pages=		{67--81},
note=		{To appear, {\it Machine Learning}}
}

@article{Yamanishi92,
author=		{Kenji Yamanishi},
title=		{Learning Nonparametric Densities in Terms of Finite
		 Dimensional Parametric Hypotheses},
journal=	{IEICE Transactions: D Information and Systems},
volume=		{E75D},
number=		4,
year=		1992,
pages=		{459--469}
}

@article{Yamanishi92b,
author=		{Kenji Yamanishi},
title=		{A Learning Criterion for Stochastic Rules},
journal=	ml,
volume=		9,
number=		{2/3},
year=		1992,
month=		jul,
pages=		{165--203}
}

@article{Yamanishi95
,author=	{Kenji Yamanishi}
,title=		{Probably almost discriminitive learning}
,year=		1995
,journal=	ml
}

@article{Yamanishi95b
,author=	{Kenji Yamanishi}
,title=		{A loss bound model for on-line stochastic prediction
		algorithms}
,journal=	infcomp
,volume=	119
,number=	1
,year=		1995
,pages=		{39-54}
}

@inproceedings{Yang94
,author=	{Yiming Yang}
,title=		{Expert network: effective and efficient learning from
		 human decisions in text categorization and retrieval}
,booktitle= sigir94
,pages= {13--22}
,year= 1994
}

@article{Yang99,
	Author = {Yiming Yang},
	Title = {An evaluation of statistical approaches to text categorization},
	Journal = {Information Retrieval},
	year = 1999,
	note = "to appear"
}

@article{YangBa99,
author = {Y. Yang and A. Barron},
title = {Information-theoretic determination of minimax rates of convergence},
year = 1999,
volume = 27,
number = 5,
journal = aos,
pages = {1564--1599},
}

@article{YangCh94,
	Author = "Y. Yang and C. G. Chute",
	Title = "An example-based mapping method for text classification
		and retrieval",
	Journal = "ACM Transactions on Information Systems",
	volume = 12,
	number = 3,
	year = 1994,
        pages= {253-277}
}

@inproceedings{YangYiReMa16,
  title={Weighted SGD for ℓ p regression with randomized preconditioning},
  author={Yang, Jiyan and Chow, Yin-Lam and R{\'e}, Christopher and Mahoney, Michael W},
  booktitle={Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={558--569},
  year=2016,
  organization={Society for Industrial and Applied Mathematics}
}

@inproceedings{Yao79,
  title={Some complexity questions related to distributive computing (Preliminary Report)},
  author={Andrew Chi-Chih Yao},
  booktitle=stoc79,
  pages={209--213},
  year={1979},
  organization={ACM}
}

@inproceedings{Yao82,
author = 	{Andrew C. Yao},
title = 	{Theory and Applications of Trapdoor Functions},
booktitle = 	focs82,
year = 		{1982},
pages = 	{80--91}
}

@unpublished{Young87p,
author=   	{Neal Young},
title=    	{Private communication} ,
note=     	{},
year=     	1987
}

@InProceedings{Young95,
  author = 	 {Neal Young},
  title = 	 {Randomized rounding without solving the linear program},
  booktitle = 	 {Proceedings of the Sixth Annual ACM-SIAM Symposium
		  on Discrete Algorithms},
  year =	 1995,
  pages =	 {170-178}
}

@unpublished{Young9?
,author=	{Neal Young}
,title=		{Randomized rounding without solving the linear
		 program, part two}
}

@article{Young96,
	Author = "S. Young",
	Title = "A Review of Large-Vocabulary Continuous Speech Recognition",
	Journal = "IEEE Signal Processing Mag.",
	year = 1996,
	month=Sep,
	pages= {45--57}
}

@inproceedings{YousefianNeSh10,
author = {F. Yousefian and A. Nedic and U. Shanbhag},
title = {Convex nondifferentiable stochastic optimization: a local
randomized smoothing technique},
booktitle = {Proceedings of IEEE American Control Conference},
year = 2010,
pages = {4875--4880},
}

@article{YousefianNeSh12,
author = {Farzad Yousefian and Angelia Nedi\'c and Uday V. Shanbhag},
title = {On stochastic gradient and subgradient methods with
 adaptive steplength sequences},
journal = {Automatica},
year = 2012,
pages = {56--67},
volume = 48,
}

@article{Yu94,
author = {Bin Yu},
title = {Rates of convergence for empirical processes of stationary
mixing sequences},
year = 1994,
journal = aop,
volume = 22,
number = 1,
pages = {94--116},
comment = {Early work on applying empirical process theory in the
                  context of dependent data; uses metric entropy
                  conditions to get rates of convergence for
                  estimators based on the mixing times of different
                  stochastic processes. Hong's addendum: Gives a rate
                  for a functional CLT type theorem with slower than
                  parametric rate for beta-mixing (absolutely regular)
                  sequences under bounds on metric entropy. Shows that
                  there is a deterioration in the rate for slowly
                  mixing sequences.  In particular, this happens for
                  beta_n = n^{-r} with 0 <= r < 1. If r > 1,
                  ArconesYu94 shows a Donsker theorem.}
}

@incollection{Yu97,
author = {Bin Yu},
title = {Assouad, {F}ano, and {L}e {C}am},
year = 1997,
booktitle = {Festschrift for Lucien Le Cam},
publisher = {Springer-Verlag},
pages = {423--435},
comment = {Nice explanation of some differences between Fano's inequality,
Le Cam's, and Assouad's techniques for lower bounds, along with applications
to density estimation. Reduces density estimation to identification of
biases of several coins, which is a standard technique.
I should try to understand Le Cam and Assouad better.},
}

@article{YueBrKlJo12,
author = {Yisong Yue and Josef Broder and Robert Kleinberg and
Thorsten Joachims},
title = {The $K$-armed dueling bandits problem},
journal = {Journal of Computer and System Sciences, Special Issue for COLT 2009},
pages = {1538--1566},
year = 2012,
}

@article{YueHi99,
  title={Robust designs for fitting linear models with misspecification},
  author={Rong-Xian Yue and Fred J. Hickernell},
  journal={Statistica Sinica},
  pages={1053--1069},
  year={1999},
}

@inproceedings{YuhJyeMa00,
	author = "Yuh-Jye Lee and O. L. Mangasarian",
	title = "{RSVM}: Reduced Support Vector Machines",
	booktitle = "SIAM International Conference on Data Mining",
	year = 2001
}


@article{Zadeh65,
author=		{L. A. Zadeh},
title=		{Fuzzy Sets},
year=		1965,
month=		jun,
journal=	infctrl,
number=		3,
volume=		8,
pages=		{338--353}
}

@INPROCEEDINGS{ZadroznyLaAb03,
author={Zadrozny, B. and Langford, J. and Abe, N.}, 
booktitle={Third IEEE International Conference on Data Mining (ICDM)},
title={Cost-sensitive learning by cost-proportionate example weighting}, 
year={2003}, 
pages={435--442}, 
keywords={cost-benefit analysis;learning (artificial intelligence);pattern classification;sampling methods;support vector machines;classification algorithm;cost-proportionate example weighting;cost-proportionate rejection sampling;cost-sensitive learning algorithms;support vector machines;Boosting;Classification algorithms;Computer crime;Costing;Costs;Data mining;High performance computing;Machine learning;Medical diagnosis;Sampling methods}, 
}

@inproceedings{ZahariaChFrShSt10,
author = {Matei Zaharia and Mosharaf Chowdhury and
   Michael J. Franklin and Scott Shenker and Ion Stoica},
title = {Spark: Cluster Computing with Working Sets},
year = 2010,
booktitle = {HotCloud}
}

@inproceedings{ZahariaChDaDaMaMcFrShSt12,
author = {Matei Zaharia and Mosharaf Chowdhury and Tathagata Das and
 Ankur Dave and Justin Ma and
Murphy McCauley and Michael J. Franklin and Scott Shenker and Ion Stoica},
title = {Resilient Distributed Datasets: A Fault-Tolerant Abstraction for
In-Memory Cluster Computing},
year = 2012,
booktitle = {Ninth USENIX Symposium on Networked Systems Design
 and Implementation},
}

@InProceedings{Zarantonello71,
  author = 	 {E. H. Zarantonello},
  title = 	 {Projections on Convex Sets in Hilbert Space and Spectral
                 Theory},
  OPTcrossref =  {},
  OPTkey = 	 {},
  booktitle =    {Contributions to Nonlinear Functional Analysis},
  pages = 	 {237--424},
  year = 	 {1971},
  editor = 	 {E. H. Zarantonello},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  OPTmonth = 	 {},
  OPTorganization = {},
  publisher =    {Academic Press},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@Article{Zhang03,
  author = 	 {T. Zhang},
  title = 	 {Sequential greedy approximation for certain convex optimization problems},
  journal = 	 {IEEE Transaction on Information Theory},
  year = 	 {2003},
  volume = 	 {49},
  pages = 	 {682--691}
}

@inproceedings{ZhangChLi16,
author = {Huishuai Zhang and Yuejie Chi and Yingbin Liang},
title = {Provable Non-convex Phase Retrieval with Outliers:
Median Truncated {W}irtinger Flow},
year = 2016,
booktitle = icml16,
}

@article{ZhangDuWa12,
author = {Yuchen Zhang and John C.\ Duchi and Martin J.\ Wainwright},
title = {Communication-Efficient Algorithms for Statistical Optimization},
journal = {arXiv:1209.4129 [stat.ML]},
year = {2012},
url = {http://arxiv.org/abs/1209.4129},
}

@inproceedings{ZhangDuJoWa13_nips,
author = {Yuchen Zhang and John C.\ Duchi and Michael I.\ Jordan
and Martin J.\ Wainwright},
title = {Information-theoretic lower bounds for distributed estimation
  with communication constraints},
booktitle = nips26,
year = {2013},
}

@inproceedings{ZhangDuWa12_nips,
author = {Yuchen Zhang and John C.\ Duchi and Martin J.\ Wainwright},
title = {Communication-Efficient Algorithms for Statistical Optimization},
booktitle = nips25,
year = {2012},
}

@article{ZhangDuWa13_kernel,
author = {Yuchen Zhang and John C.\ Duchi and Martin J.\ Wainwright},
title = {Divide and Conquer Kernel Ridge Regression:
  A Distributed Algorithm with Minimax Optimal Rates},
journal = {arXiv:1305.5029 [math.ST]},
year = 2013,
comment = {url = {http://arxiv.org/abs/1305.5029}},
}

@article{ZhangDuWa15,
author = {Yuchen Zhang and John C.\ Duchi and Martin J.\ Wainwright},
title = {Divide and Conquer Kernel Ridge Regression:
  A Distributed Algorithm with Minimax Optimal Rates},
journal = jmlr,
year = 2015,
volume = {16},
pages = {3299−-3340},
}

@inproceedings{ZhangDuWa13_colt,
author = {Yuchen Zhang and John C.\ Duchi and Martin J.\ Wainwright},
title = {Divide and Conquer Kernel Ridge Regression},
year = 2013,
booktitle = colt13,
}

@article{ZhangDuWa13,
author = {Yuchen Zhang and John C.\ Duchi and Martin J.\ Wainwright},
title = {Communication-Efficient Algorithms for Statistical Optimization},
journal = jmlr,
volume = 14,
pages = {3321--3363},
year = {2013},
}

@inproceedings{ZhangDuWa12_cdc,
author = {Yuchen Zhang and John C.\ Duchi and Martin J.\ Wainwright},
title = {Communication-Efficient Algorithms for Statistical Optimization},
booktitle = cdc2012,
year = {2012},
}

@article{ZhangOles03,
	author = {T.~Zhang and F.~J.~Oles},
	title = {Text categorization based on regularized linear
		classification methods},
	journal = {Information Retrieval},
	volume = 4,
	pages = {5--31},
	year = 2001
}

@inproceedings{ZhangWaJo14,
author = {Yuchen Zhang and Martin J. Wainwright and Michael I. Jordan},
title = {Lower bounds on the performance of polynomial-time
algorithms for sparse linear regression},
year = 2014,
booktitle = colt14,
}

@InProceedings{Zhang04,
  author = 	 {T. Zhang},
  title = 	 {Solving Large Scale Linear Prediction Problems Using Stochastic Gradient Descent Algorithms},
  booktitle = icml04,
  year = 	 {2004}
}

@article{Zhang04a,
author = {T. Zhang},
title = {Statistical Analysis of Some Multi-Category Large Margin Classification Methods},
journal = {Journal of Machine Learning Research},
volume = 5,
year = 2004,
pages = {1225--1251},
comment = {Provides a framework for showing Fisher consistency of surrogate
methods for loss minimization, though only in the finite # of labels case},
}

@article{Zhang04b,
author = {T. Zhang},
title = {Statistical behavior and consistency of classification methods based
         on convex risk minimization},
journal = aos,
volume = 32,
year = 2004,
pages = {56--85},
}

@InProceedings{Zhang05,
  author = 	 {T. Zhang},
  title = 	 {Data Dependent Concentration Bounds for Sequential Prediction Algorithms},
  booktitle =  colt05,
  year = 	 {2005},
  pages = {173--187}
}


@article{Zhang05b,
author = {Tong Zhang},
title = {Learning bounds for kernel regression using effective
  data dimensionality},
year = 2005,
journal = {Neural Computation},
volume = 17,
number = 9,
pages = {2077--2098},
comment = {Shows that the convergence rate of RKHS-based estimators is
  controlled by the "effective dimensionality" of the problem. This is defined
  by $D_\lambda = \tr((\Sigma + \lambda I)^{-1} \Sigma)$, where
  $\Sigma$ is the expectation of the outer product of the kernel evaluator
  (i.e. if $\xi_x = K(x, \cdot)$, then $\Sigma = \E[\xi_x \otimes \xi_x]$).
  Equivalently, $\Sigma$ can be taken as the matrix of eigenvalues of the
  kernel operator. The bias-variance tradeoff is shown to scale as
  $\lambda + D_\lambda / n$, where $n$ is the number of samples.

  The proof techniques require the loss to basically look like a regression
  loss (strongly convex and smooth), and then argue that the corresponding
  empirical covariance matrices concentrate at rates dependent on
  $D_\lambda$.
},
}

@InProceedings{Zhang08,
	author = "T.~Zhang",
	title = "Adaptive Forward-Backward Greedy Algorithm for Sparse
		Learning with Linear Models",
	booktitle = nips21,
	year = 2008
}

@inproceedings{ZhangLeJo16,
  title={$\ell_1$-regularized neural networks are improperly
   learnable in polynomial time},
  author={Zhang, Yuchen and Lee, Jason D. and Jordan, Michael I.},
  booktitle=icml16,
  pages={993--1001},
  year={2016}
}

@article{ZhangLiQi12,
author = {Xinzhen Zhang and Chen Ling and Liqun Qi},
title = {The best rank-1 approximation of a symmetric
  tensor and related spherical optimization problems},
journal = simat,
year = 2012,
volume = 33,
number = 3,
pages = {806--821},
}

@article{ZhangLiWa16,
  title={Convexified Convolutional Neural Networks},
  author={Zhang, Yuchen and Liang, Percy and Wainwright, Martin J.},
  journal={arXiv:1609.01000 [stat.ML]},
  year={2016}
}

@article{ZhangLiWuZh08,
author = {H. Zhang and H. Liu and Y. Wu and J. Zhu},
title = {Variable selection for the multi-category {SVM} via adaptive sup-norm
         regularization},
journal = {Electronic Journal of Statistics},
volume = 2,
pages = {1149-1167},
year = 2008,
}

@article{ZhangYu05,
  author = 	 {T. Zhang and B. Yu},
  title = 	 {Boosting with early stopping: Convergence and Consistency},
  journal = 	 {The Annals of Statistics},
  year = 	 {2005},
  volume = 	 {33},
  pages = 	 {1538-1579}
}


@techreport{ZhaoRoYu06,
author = {P. Zhao and G. Rocha and B. Yu},
title = {Grouped and hierarchical model selection through composite absolute
         penalties},
year = 2006,
institution = {Statistics Department, University of California Berkeley},
number = 703,
}

@article{ZhaoRoYu09,
author = {P. Zhao and G. Rocha and B. Yu},
title = {The composite absolute penalties family for grouped and hierarchical
variable selection},
year = 2009,
journal = aos,
volume = 37,
number = 6,
pages = {3468--3497},
}

@article{ZhaoYu06,
author = {P. Zhao and B. Yu},
title = {On model selection consistency of {L}asso},
year = 2006,
journal = {Journal of Machine Learning Research},
volume = 7,
pages = {2541-2567},
}

@article{ZhaoZh14,
  title={Accelerating minibatch stochastic gradient descent using stratified sampling},
  author={Zhao, Peilin and Zhang, Tong},
  journal={arXiv:1405.3080 [stat.ML]},
  year=2014
}

@inproceedings{ZhaoZh15,
  title={Stochastic optimization with importance sampling},
  author={Zhao, Peilin and Zhang, Tong},
  booktitle=icml15,
  year=2015
}

@InProceedings{ZhengMoWa17,
  title = 	 {Collect at Once, Use Effectively: Making Non-interactive Locally Private Learning Possible},
  author = 	 {Kai Zheng and Wenlong Mou and Liwei Wang},
  booktitle = 	 icml17,
  pages = 	 {4130--4139},
  year = 	 {2017},
}

@article{Zhou02,
  title={The covering number in learning theory},
  author={Zhou, Ding-Xuan},
  journal={Journal of Complexity},
  volume=18,
  number=3,
  pages={739--767},
  year=2002,
  publisher={Elsevier},
  comment={Gives bounds on covering numbers of kernel
                  classes. Proposition 1 covers the special case of
                  Gaussian (RBF) kernels. The log metric entropy
                  depends exponentially in the dimension.}
}

@article{Zhou03,
  title={Capacity of reproducing kernel spaces in learning theory},
  author={Zhou, Ding-Xuan},
  journal={IEEE Transactions on Information Theory},
  volume=49,
  number=7,
  pages={1743--1752},
  year=2003,
  publisher={IEEE},
  comment={Shows lower bound estimates on covering numbers of unit
                  balls in a RKHS and gives an embedding of a
                  sufficiently smooth RKHS into a Sobolev space.  The
                  lower bound on the log metric entropy depends
                  exponentially in the dimension. See also Zhou02,
                  Kuhn11.}
}

@article{ZhouHu14,
  title={Gradient-based adaptive stochastic search for non-differentiable optimization},
  author={Zhou, Enlu and Hu, Jiaqiao},
  journal={IEEE Transactions on Automatic Control},
  volume=59,
  number=7,
  pages={1818--1832},
  year=2014,
  publisher={IEEE},
  comment={Proposes a novel model-based algorithm by using a new
                  surrogate distribution. Gives consistency and rate
                  of convergence to the global optimum but requires
                  polynomially growing sample sizes.}
}

@article{ZhouLaWa09,
author = {Shuheng Zhou and John Lafferty and Larry Wasserman},
title = {Compressed regression},
year = 2009,
journal = ieeeit,
volume = 55,
number = 2,
pages = {846--866},
comment = {
Shows how to maintain some privacy (in a different notion than differential)
when solving high-dimensional linear regression problems. Uses a random
matrix to transform data from n to $m \ll n$ examples in the same number
of dimensions; under some constraints this still yields sparsistency and
persistency. Shows that with some sampling matrices, it is possible to
achieve mutual information per-entry (i.e. the average mutual information
normalized by $np$) decreasing as $m/n$. (Their analyses require $m = log(np)$
or $m = log^2(np)$ for sparsistency/persistency, respectively.)
No notion of whether privacy could be made better/more optimal for different
sampling matrices. Does give privacy between data revealed to statistician
and the data itself, though.
},
}

@inproceedings{ZhouLiWa09,
author = {Shuheng Zhou and Katrina Ligett and Larry Wasserman},
title = {Differential privacy with compression},
year = 2009,
booktitle = {Proceedings of the 2009 IEEE International Symposium on
Information Theory},
comment = {
  Shows that PCA can be solved even after a perturbation of data of the form
  $X' = \Phi X$, where $\Phi$ is an $m\times n$ matrix of i.i.d.\ normals
  and $m \le n$. Differential privacy can be achieved in this model, but
  not clear if results are sharp. Also somewhat badly written.
  One nice thing is that data only needs to be released one time, so after
  the perturbation, many problems may be solved.
},
}

@inproceedings{ZhuChDuLa16,
title = {Local Minimax Complexity of Stochastic Convex Optimization},
author = {Yuancheng Zhu and Sabyasachi Chatterjee and John Duchi
   and John Lafferty},
year = 2016,
booktitle = nips29,
}

@inproceedings{ZhuLa14,
  title={Quantized estimation of Gaussian sequence models in Euclidean balls},
  author={Zhu, Yuancheng and Lafferty, John},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3662--3670},
  year=2014
}

@article{ZhuLa15,
  title={Quantized Nonparametric Estimation},
  author={Zhu, Yuancheng and Lafferty, John},
  journal={arXiv preprint arXiv:1503.07368},
  year=2015
}

@article{ZienRaMiScMu00,
   author = {Zien, A. and R\"{a}tsch G. and S. Mika and B. Sch\"olkopf and
	T.  Lengauer and K.-R. M\"{u}ller},
   title = {Engineering Support Vector Machine Kernels That Recognize
	Translation Initiation Sites.},
   year = {2000},
   volume = {16},
   pages = {799-807},
   number = {9},
   journal = {Bioinformatics}
}

@inproceedings{Zinkevich03,
 author = {Martin Zinkevich},
 title = "Online Convex Programming and Generalized Infinitesimal
		Gradient Ascent",
 booktitle = icml03,
 year = 2003,
 comment = {Simple, clear proof that online gradient descent achieves a
  regret bound of O(\sqrt{T}). Analysis is quite similar to that used
  in Boyd's lecture notes on the subgradient method as well as the
  Robust Stochastic Approximation paper by Nemirovski et al.
},
}

@inproceedings{ZinkevichSmWeLi10,
author = {Martin A. Zinkevich and Alex Smola and Markus Weimer and Lihong Li},
booktitle = nips23,
year = {2010},
title = {{Parallelized Stochastic Gradient Descent}},
coment = {Available online at \url{http://martin.zinkevich.org/publications/nips2010.pdf}},
abstract =
 {With the increase in available data parallel machine learning has become an
   in- creasingly pressing problem. In this paper we present the first
   parallel stochastic gradient descent algorithm including a detailed
   analysis and experimental evi- dence. Unlike prior work on parallel
   optimization algorithms 5, 7 our variant comes with parallel acceleration
   guarantees and it poses no overly tight latency constraints, which might
   only be available in the multicore setting. Our analysis introduces a
   novel proof technique contractive mappings to quantify the speed of
   convergence of parameter distributions to their asymptotic limits. As a
   side effect this answers the question of how quickly stochastic gradient
   descent algorithms reach the asymptotically normal regime 1, 8.},
}

@inproceedings{Zippel79,
author=		{Richard Zippel},
title=		{Probabilistic Algorithms for Sparse Polynomials},
booktitle=	eurosam79,
month=		jun,
year=		1979,
publisher=	{Springer-Verlag},
pages=		{216--226}
}

@article{Zippel90,
author=		{Richard Zippel},
title=		{Interpolating Polynomials from their Values},
journal=	symcomp,
year=		1990,
volume=		9,
pages=		{375--403}
}

@Article{Ziv78,
  author = 	 {J. Ziv},
  title = 	 {Coding Theorems for Individual Sequences},
  journal = 	 {IEEE Transactions on Information Theory},
  year = 	 1978,
  volume =	 24,
  number =	 4,
  month =	 {July},
  pages =	 {405--412}
}

@Article{ZivLempel78,
  author = 	 {J. Ziv and A. Lempel},
  title = 	 {Compression of Individual Sequences via Variable Rate Coding},
  journal = 	 {IEEE Transactions on Information Theory},
  year = 	 1978,
  volume =	 24,
  pages =	 {530--536}
}

@article{ZouHa05,
author = {Hui Zou and Trevor Hastie},
title = {Regularization and variable selection via the
elastic net},
year = 2005,
journal = jrssb,
volume = 67,
number = 2,
pages = {301--320},
}

@inproceedings{ZollmanVeOcPo08,
author = {Andreas Zollmann and Ashish Venugopal and Franz Josef Och
and Jay Ponte},
title = {A systematic comparison of phrase-based, hierarchical and
 syntax-augmented statistical {MT}},
year = 2008,
booktitle = {Proceedings of the 22nd International Conference on Computational
 Linguistics (COLING)},
}

@article{ZubkovSe13,
  title={A complete proof of universal inequalities for the distribution function of the binomial law},
  author={Zubkov, AM and Serov, AA},
  journal={Theory of Probability \& Its Applications},
  volume=57,
  number=3,
  pages={539--544},
  year=2013,
  publisher={SIAM}
}


