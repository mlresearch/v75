@article{raginsky2017non,
  title={Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis},
  author={Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
  journal={arXiv preprint arXiv:1702.03849},
  year={2017}
}
@article{zhang2017hitting,
  title={A Hitting Time Analysis of Stochastic Gradient Langevin Dynamics},
  author={Zhang, Yuchen and Liang, Percy and Charikar, Moses},
  journal={arXiv preprint arXiv:1702.05575},
  year={2017}
}
@article{brunick2013mimicking,
  title={Mimicking an It{\^o} process by a solution of a stochastic differential equation},
  author={Brunick, Gerard and Shreve, Steven and others},
  journal={The Annals of Applied Probability},
  volume={23},
  number={4},
  pages={1584--1628},
  year={2013},
  publisher={Institute of Mathematical Statistics}
}
@article{jin2017escape,
  title={How to Escape Saddle Points Efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  journal={arXiv preprint arXiv:1703.00887},
  year={2017}
}
@article{hardt2015train,
  title={Train faster, generalize better: Stability of stochastic gradient descent},
  author={Hardt, Moritz and Recht, Benjamin and Singer, Yoram},
  journal={arXiv preprint arXiv:1509.01240},
  year={2015}
}
@inproceedings{lin2016optimal,
  title={Optimal Learning for Multi-pass Stochastic Gradient Methods},
  author={Lin, Junhong and Rosasco, Lorenzo},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4556--4564},
  year={2016}
}
@inproceedings{lin2016generalization,
  title={Generalization properties and implicit regularization for multiple passes SGM},
  author={Lin, Junhong and Camoriano, Raffaello and Rosasco, Lorenzo},
  booktitle={International Conference on Machine Learning},
  pages={2340--2348},
  year={2016}
}
@article{li2015dynamics,
  title={Dynamics of stochastic gradient algorithms},
  author={Li, Qianxiao and Tai, Cheng and Weinan, E},
  journal={arXiv preprint arXiv:1511.06251},
  year={2015}
}
@article{li2017batch,
  title={Batch Size Matters: A Diffusion Approximation Framework on Nonconvex Stochastic Gradient Descent},
  author={Li, Chris Junchi and Li, Lei and Qian, Junyang and Liu, Jian-Guo},
  journal={arXiv preprint arXiv:1705.07562},
  year={2017}
}
@article{mei2016landscape,
  title={The landscape of empirical risk for non-convex losses},
  author={Mei, Song and Bai, Yu and Montanari, Andrea},
  journal={arXiv preprint arXiv:1607.06534},
  year={2016}
}
@inproceedings{su2014differential,
  title={A differential equation for modeling Nesterov’s accelerated gradient method: Theory and insights},
  author={Su, Weijie and Boyd, Stephen and Candes, Emmanuel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2510--2518},
  year={2014}
}
@article{wibisono2016variational,
  title={A variational perspective on accelerated methods in optimization},
  author={Wibisono, Andre and Wilson, Ashia C and Jordan, Michael I},
  journal={Proceedings of the National Academy of Sciences},
  pages={201614734},
  year={2016},
  publisher={National Acad Sciences}
}
@inproceedings{ge2015escaping,
  title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle={Conference on Learning Theory},
  pages={797--842},
  year={2015}
}
@article{bubeck2015sampling,
  title={Sampling from a log-concave distribution with Projected Langevin Monte Carlo},
  author={Bubeck, S{\'e}bastien and Eldan, Ronen and Lehec, Joseph},
  journal={arXiv preprint arXiv:1507.02564},
  year={2015}
}
@article{bonis2015rates,
  title={Rates in the Central Limit Theorem and diffusion approximation via Stein's Method},
  author={Bonis, Thomas},
  journal={arXiv preprint arXiv:1506.06966},
  year={2015}
}
@inproceedings{germain2016pac,
  title={PAC-Bayesian theory meets Bayesian inference},
  author={Germain, Pascal and Bach, Francis and Lacoste, Alexandre and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1884--1892},
  year={2016}
}
@article{elisseeff2005stability,
  title={Stability of randomized learning algorithms},
  author={Elisseeff, Andre and Evgeniou, Theodoros and Pontil, Massimiliano},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Jan},
  pages={55--79},
  year={2005}
}
@article{nagapetyan2017true,
  title={The True Cost of Stochastic Gradient Langevin Dynamics},
  author={Nagapetyan, Tigran and Duncan, Andrew B and Hasenclever, Leonard and Vollmer, Sebastian J and Szpruch, Lukasz and Zygalakis, Konstantinos},
  journal={arXiv preprint arXiv:1706.02692},
  year={2017}
}
@inproceedings{london2016generalization,
  title={Generalization bounds for randomized learning with application to stochastic gradient descent},
  author={London, Ben},
  booktitle={NIPS Workshop on Optimizing the Optimizers},
  year={2016}
}
@article{seeger2002pac,
  title={PAC-bayesian generalisation error bounds for gaussian process classification},
  author={Seeger, Matthias},
  journal={Journal of machine learning research},
  volume={3},
  number={Oct},
  pages={233--269},
  year={2002}
}
@article{mcallester2003pac,
  title={PAC-Bayesian stochastic model selection},
  author={McAllester, David A},
  journal={Machine Learning},
  volume={51},
  number={1},
  pages={5--21},
  year={2003},
  publisher={Springer}
}
@article{dalalyan2012sparse,
  title={Sparse regression learning by aggregation and Langevin Monte-Carlo},
  author={Dalalyan, Arnak S and Tsybakov, Alexandre B},
  journal={Journal of Computer and System Sciences},
  volume={78},
  number={5},
  pages={1423--1443},
  year={2012},
  publisher={Elsevier}
}
@article{harvey2017nearly,
  title={Nearly-tight VC-dimension bounds for piecewise linear neural networks},
  author={Harvey, Nick and Liaw, Chris and Mehrabian, Abbas},
  journal={arXiv preprint arXiv:1703.02930},
  year={2017}
}
@article{chen2016statistical,
  title={Statistical Inference for Model Parameters in Stochastic Gradient Descent},
  author={Chen, Xi and Lee, Jason D and Tong, Xin T and Zhang, Yichen},
  journal={arXiv preprint arXiv:1610.08637},
  year={2016}
}
@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}

@article{rakhlin2005stability,
  title={Stability results in learning theory},
  author={Rakhlin, Alexander and Mukherjee, Sayan and Poggio, Tomaso},
  journal={Analysis and Applications},
  volume={3},
  number={04},
  pages={397--417},
  year={2005},
  publisher={World Scientific}
}
@article{markowich2000trend,
  title={On the trend to equilibrium for the Fokker-Planck equation: an interplay between physics and functional analysis},
  author={Markowich, Peter A and Villani, C{\'e}dric},
  journal={Mat. Contemp},
  volume={19},
  pages={1--29},
  year={2000}
}
@incollection{risken1996fokker,
  title={Fokker-Planck equation},
  author={Risken, Hannes},
  booktitle={The Fokker-Planck Equation},
  pages={63--95},
  year={1996},
  publisher={Springer}
}

@article{gyongy1986mimicking,
  title={Mimicking the one-dimensional marginal distributions of processes having an It{\^o} differential},
  author={Gy{\"o}ngy, Istv{\'a}n},
  journal={Probability theory and related fields},
  volume={71},
  number={4},
  pages={501--516},
  year={1986},
  publisher={Springer}
}

@article{bousquet2002stability,
  title={Stability and generalization},
  author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
  journal={Journal of Machine Learning Research},
  volume={2},
  number={Mar},
  pages={499--526},
  year={2002}
}

@inproceedings{mcallester1999pac,
  title={PAC-Bayesian model averaging},
  author={McAllester, David A},
  booktitle={Proceedings of the twelfth annual conference on Computational learning theory},
  pages={164--170},
  year={1999},
  organization={ACM}
}
@article{csiszar2004information,
  title={Information theory and statistics: A tutorial},
  author={Csisz{\'a}r, Imre and Shields, Paul C and others},
  journal={Foundations and Trends{\textregistered} in Communications and Information Theory},
  volume={1},
  number={4},
  pages={417--528},
  year={2004},
  publisher={Now Publishers, Inc.}
}
@inproceedings{wei2017early,
  title={Early stopping for kernel boosting algorithms: A general analysis with localized complexities},
  author={Wei, Yuting and Yang, Fanny and Wainwright, Martin J},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6067--6077},
  year={2017}
}
@techreport{zhang2017theory,
  title={Theory of Deep Learning III: Generalization Properties of SGD},
  author={Zhang, Chiyuan and Liao, Qianli and Rakhlin, Alexander and Sridharan, Karthik and Miranda, Brando and Golowich, Noah and Poggio, Tomaso},
  year={2017},
  institution={Center for Brains, Minds and Machines (CBMM)}
}
@article{ye2017langevin,
  title={Langevin Dynamics with Continuous Tempering for Training Deep Neural Networks},
  author={Ye, Nanyang and Zhu, Zhanxing and Mantiuk, Rafal K},
  journal={arXiv preprint arXiv:1703.04379},
  year={2017}
}
@article{chaudhari2016entropy,
  title={Entropy-SGD: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann},
  journal={arXiv preprint arXiv:1611.01838},
  year={2016}
}
@article{neelakantan2015adding,
  title={Adding gradient noise improves learning for very deep networks},
  author={Neelakantan, Arvind and Vilnis, Luke and Le, Quoc V and Sutskever, Ilya and Kaiser, Lukasz and Kurach, Karol and Martens, James},
  journal={arXiv preprint arXiv:1511.06807},
  year={2015}
}
@article{bartlett2017spectrally,
  title={Spectrally-normalized margin bounds for neural networks},
  author={Bartlett, Peter and Foster, Dylan J and Telgarsky, Matus},
  journal={arXiv preprint arXiv:1706.08498},
  year={2017}
}
@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}
@article{wu2017towards,
  title={Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes},
  author={Wu, Lei and Zhu, Zhanxing and Weinan, E},
  journal={arXiv preprint arXiv:1706.10239},
  year={2017}
}
@article{pensia2018generalization,
  title={Generalization Error Bounds for Noisy, Iterative Algorithms},
  author={Pensia, Ankit and Jog, Varun and Loh, Po-Ling},
  journal={arXiv preprint arXiv:1801.04295},
  year={2018}
}
@inproceedings{xu2017information,
  title={Information-theoretic analysis of generalization capability of learning algorithms},
  author={Xu, Aolin and Raginsky, Maxim},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2521--2530},
  year={2017}
}
@article{dalalyan2017theoretical,
  title={Theoretical guarantees for approximate sampling from smooth and log-concave densities},
  author={Dalalyan, Arnak S},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={79},
  number={3},
  pages={651--676},
  year={2017},
  publisher={Wiley Online Library}
}
@article{cheng2017convergence,
  title={Convergence of Langevin MCMC in KL-divergence},
  author={Cheng, Xiang and Bartlett, Peter},
  journal={arXiv preprint arXiv:1705.09048},
  year={2017}
}
@article{cheng2017underdamped,
  title={Underdamped Langevin MCMC: A non-asymptotic analysis},
  author={Cheng, Xiang and Chatterji, Niladri S and Bartlett, Peter L and Jordan, Michael I},
  journal={arXiv preprint arXiv:1707.03663},
  year={2017}
}
@article{gross1975logarithmic,
  title={Logarithmic sobolev inequalities},
  author={Gross, Leonard},
  journal={American Journal of Mathematics},
  volume={97},
  number={4},
  pages={1061--1083},
  year={1975},
  publisher={JSTOR}
}