\section{Proof of Lemma \ref{thm:additive}}
\label{sec:compositionproof}
Before proving Lemma \ref{thm:additive}, we first show a simple claim about compositions with truncation.
\begin{claim}
\label{lm:truncation}
Suppose the distribution $\calD$ is semi-uniform. We have $\property_{\calD}^t(d,\alpha)\subseteq\property_{\calD}(d,\alpha)\subseteq\property_{\calD}^t(d,\alpha+\frac{d}{tm})$.
\end{claim}
\begin{proof}
$\property_{\calD}^t(d,\alpha)\subseteq\property_{\calD}(d,\alpha)$ is obvious. To see $\property_{\calD}(d,\alpha)\subseteq\property_{\calD}^t(d,\alpha+\frac{d}{tm})$, we note that for any $g\in\property(d)$, for each $i$ such that $k_i>t$, substituting a function in $\calC_i^0$ for $g|_{X_i}$ causes at most a $\frac{1}{m}$ increase in the distance from $f\in\property_\calD(d,\alpha)$ to $g$. An easy observation that $|\{i:k_i>t\}|\leq\frac{d}{t}$ given $\sum\limits_{i=1}^mk_i\leq d$ completes the proof. 
\end{proof}

\begin{proof}(of Lemma \ref{thm:additive})
The algorithm first picks indices $1\leq i_1<i_2<\cdots i_l\leq m$ uniformly at random for $l=O(\frac{1}{\epsilon\mu^2}+\frac{1}{\epsilon^2})$. Then the algorithm asks for $O(\frac{Nm}{l})$ unlabeled examples to make sure with probability at least $\frac{11}{12}$, there are at least $N$ examples lying in $\bigcup\limits_{j=1}^lX_{i_j}$. These examples can be treated as drawn independently at random according to $\calD_{\mathbf i}$, where $\mathbf i=(i_1,i_2,\cdots,i_l)$. Finally, the algorithm calls the oracle to approximate the distance from $f$ to $\property^{t}((1+\frac{\mu}{2})\lambda l)$ truncated by $t=\frac{4\lambda}{\epsilon}$ on distribution $\calD_{\mathbf i}$ up to an additive error $\frac{\epsilon}{2}$ using these unlabeled examples and outputs what the oracle outputs. 

The correctness of the algorithm follows from the following two lemmas (with proofs in the appendices) and the Union Bound.
\end{proof}

\begin{lemma}
\label{lm:in}
Suppose $t=\frac{4\lambda}{m}$. If $f\in\property_{\calD}(\lambda m,\alpha)$, then choosing $l=O(\frac{1}{\epsilon\mu^2}+\frac{1}{\epsilon^2})$ is enough to make sure that with probability at least $\frac{5}{6}$, $f\in\property^{t}_{\calD_{\mathbf i}}((1+\frac{\mu}{2})\lambda l,\alpha+\frac{\epsilon}{2})$.
\end{lemma}

\begin{lemma}
\label{lm:notin}
Suppose $t=\frac{4\lambda}{m}$. If $f\notin\property_{\calD}((1+\mu)\lambda m,\alpha)$, then choosing $l=O(\frac{1}{\epsilon\mu^2}+\frac{1}{\epsilon^2})$ is enough to make sure that with probability at least $\frac{5}{6}$, $f\notin\property^{t}_{\calD_{\mathbf i}}((1+\frac{\mu}{2})\lambda l,\alpha-\frac{\epsilon}{2})$.
\end{lemma}


\begin{proof}(of Lemma \ref{lm:in})

By the choice of truncation $t=\frac{4\lambda}{\epsilon}$, according to Claim \ref{lm:truncation}, we know $f\in\property^t_{\calD}(\lambda m,\alpha+\frac{\epsilon}{4})$. Suppose $\dist_{\calD}(f,g)\leq \alpha+\frac{\epsilon}{4}$ for some $g\in\property^t(\lambda m)$. According to the Multiplicative Chernoff Bound for sampling without replacement, choosing $l=O(\frac{1}{\epsilon\mu^2})$ is enough to make sure that with probability at least $\frac{11}{12}$, $\exists g'$ s.t.\ $g'\in\property^{t}((1+\frac{\mu}{2})\lambda l)$ and $\dist_{\calD_{\mathbf i}}(g,g')=0$.\footnote{$g'$ is chosen such that $g'|_{X_{i}}\in\calC_{i}^0$ for all $i\notin \{i_1,i_2,\cdots,i_l\}$ and $g'|_{X_{i}}=g|_{X_{i}}$ for all $i\in\{i_1,i_2,\cdots,i_l\}$. The fact that the $k_i$'s of $g$ are bounded between 0 and $t=\frac{4\lambda}{\epsilon}$ allows us to use the Multiplicative Chernoff Bound.} According to the Chernoff Bound for sampling without replacement, choosing $l=O(\frac{1}{\epsilon^2})$ is enough to make sure that with probability at least $\frac{11}{12}$, $\dist_{\calD_{\mathbf i}}(f,g)\leq\alpha+\frac{\epsilon}{2}$. By the Union Bound, these two events happen at the same time with probability at least $\frac{5}{6}$, and in this case, $f\in\property^{t}_{\calD_{\mathbf i}}((1+\frac{\mu}{2})\lambda l,\alpha+\frac{\epsilon}{2})$. 
\end{proof}

\begin{proof}(of Lemma \ref{lm:notin})
According to Claim \ref{lm:truncation}, we know $f\notin\property^t_{\calD}((1+\mu)\lambda m,\alpha)$. Therefore, by definition, there exists $g\in\property^t((1+\mu)\lambda m)$ with the following two properties:\footnote{E.g., choose $g$ to be the closest or approximately-closest function in the class to $f$.  Note that $\property^t((1+\mu)\lambda m)$ can't be empty, because $\property^t((1+\mu)\lambda m)\supseteq\property^t(0)=\property(0)\neq\emptyset$.}
\begin{enumerate}
\item $\dist_{\calD}(f,g)>\alpha$;
\item $\forall g'\in \property^t((1+\mu)\lambda m),\dist_{\calD}(f,g')>\dist_{\calD}(f,g)-\frac{\epsilon}{4}\cdot\frac{l}{m}$.
\end{enumerate}
Suppose $g|_{X_i}\in\calC_{i}^{k_i}$ for $k_i\leq t=\frac{4\lambda}{\epsilon}$ satisfying $k:=\sum\limits_{i=1}^mk_i\leq(1+\mu)\lambda m$. We enlarge $k_i$ to $k'_i\in[k_i,t]$ to make sure that $k':=\sum\limits_{i=1}^mk'_i=(1+\mu)\lambda m$.\footnote{$k'_i$ doesn't have to be an integer. Also note that $mt=\frac{4\lambda}{\epsilon}\cdot m>4\lambda m>(1+\mu)\lambda m$.} According to the Multiplicative Chernoff Bound for sampling without replacement, choosing $l=O(\frac{1}{\epsilon\mu^2})$ is enough to make sure that with probability at least $\frac{11}{12}$, $\sum\limits_{j=1}^lk'_{i_j}\geq (1+\frac{\mu}{2})\lambda l$.

Now suppose it's the case that $\sum\limits_{j=1}^lk'_{i_j}\geq (1+\frac{\mu}{2})\lambda l$. Then, according to the second property of $g$, we know $$\forall g'\in\property^{t}((1+\frac{\mu}{2})\lambda l),\dist_{\calD_{\mathbf i}}(f,g')> \dist_{\calD_{\mathbf i}}(f,g)-\frac{\epsilon}{4}.$$ Otherwise, we can swap $g'$ for $g$ on $\bigcup\limits_{j=1}^lX_{i_j}$ causing a violation of the second property of $g$.

Finally, according to the Chernoff Bound for sampling without replacement, choosing $l=O(\frac{1}{\epsilon^2})$ is enough to make sure that with probability at least $\frac{11}{12}$, $\dist_{\calD_{\mathbf i}}(f,g)>\alpha-\frac{\epsilon}{4}$. Therefore, by the Union Bound, with probability at least $\frac{5}{6}$, $$\forall g'\in\property^{t}((1+\frac{\mu}{2})\lambda l),\dist_{\calD_{\mathbf i}}(f,g')> \dist_{\calD_{\mathbf i}}(f,g)-\frac{\epsilon}{4}>\alpha-\frac{\epsilon}{2},$$ a completion of the proof.
\end{proof}

