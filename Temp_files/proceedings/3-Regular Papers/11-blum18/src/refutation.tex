\section{Tolerant Passive Testing Implies Refutation}
\label{sec:refutation}
In this section, we consider a class $\calC$ over domain $X$ with VC-dimension $d$. We are going to build a refutation algorithm (see Section \ref{subsec:passive} for definition) with margin $\epsilon\in(0,\frac 12)$ for a distribution $\calD$ by calling a tolerant passive tester over arbitrary unknown distributions with sample complexity $s$ as oracle.

\begin{lemma}
There exist universal positive constants $c_1,c_2$ satisfying the following property. Assume $\calD$ satisfies that with probability at least $\frac {11}{12}$ no point appears twice in an $s'$-sized i.i.d.\ sample from $\calD$ for $s'=\lceil\max\{\frac{{c_1}d}{\epsilon^2}\log\frac1\epsilon,c_2s\}\rceil$. Suppose there exists a tolerant passive tester $\calA$ for $\calC$ over arbitrary unknown distribution with threshold $\alpha=\frac 12-\frac{3\epsilon}4$, margin $\frac\epsilon 2$ and sample complexity $s$. Then there exists a refutation algorithm $\calB$ for $\calC$ over $\calD$ with margin $\epsilon$ and sample complexity $c_2s$.
\end{lemma}
\begin{proof}
Algorithm $\calB$ first obtains a $c_2s$-sized sample $S$ of example label pairs $\{(x_i,y_i)\}$ and declares failure if there exists $y_i\neq y_j$ for $x_i=x_j$. If the algorithm does not declare a failure, it then treat $y_i=f(x_i)$ for some function $f$ and calls $\calA$ to distinguish whether $f$ is $\alpha$-close to $\calC$ or $f$ is $(\alpha+\frac\epsilon 2)$-far from $\calC$ using sample $S$. Here, the success probability of $\calA$ is boosted to at least $\frac{11}{12}$ by repeating $c_2$ times. $\calB$ accepts if $\calA$ accepts and $\calB$ rejects if $\calA$ rejects.

%To show the correctness of the algorithm, we first enlarge $S$ to a $\lceil\frac{{c_1}d}{\epsilon^2}\log\frac1\epsilon\rceil$-sized sample $S'$. With probability at least $\frac 56$, all the $x_i$ are distinct. 

Now, we show the correctness of the algorithm. We first consider the case that every $(x_i,y_i)$ is i.i.d.\ from a distribution $\calD'$ with marginal on $X$ being $\calD$ and $\exists g\in\calC,\Pr_{(x',y')\sim\calD}[g(x')\neq y']\leq\frac 12-\epsilon$. We enlarge $S$ to an $s'$-sized sample $S'$. Equivalently, we can imagine $S'$ is chosen i.i.d.\ from $\calD'$ first and $S$ is an i.i.d.\ sample from the uniform distribution $\calU$ over $S'$. With probability at least $\frac {11}{12}$, all the $x_i$ in $S'$ are distinct. For every $x\in X$, we define $\error(x)=\Pr_{(x',y')\sim\calD'}[g(x')\neq y'|x'=x]$ and we have $\mathbb E_{x\sim\calD}[\error(x)]\leq\frac 12-\epsilon$. According to the Chernoff Bound, with probability at least $\frac{11}{12}$, $\mathbb E_{x\sim \calU}[\error(x)]\leq\frac 12-\frac {7\epsilon}8$. By the Union Bound, with probability at least $\frac 56$, all $x_i$ in $S'$ are distinct \emph{and} $\mathbb E_{x\sim \calU}[\error(x)]\leq\frac 12-\frac {7\epsilon}8$. Conditioned on that, every $y_i$ is independent from others and thus by the Chernoff Bound, with probability at least $\frac {11}{12}$ we have $\Pr_{(x,y)\sim \calU}[g(x)\neq y]\leq\frac 12-\frac {3\epsilon}4$. If we unwrap the conditional probability of at least $\frac 56$, we know with probability at least $\frac 56\cdot\frac{11}{12}$ that 
\begin{enumerate}
\item all $x_i$ in $S'$ are distinct;
\item $\Pr_{(x,y)\sim \calU}[g(x)\neq y]\leq\alpha$.
\end{enumerate}
Now, if we sample $S$ i.i.d.\ from $\calU$ and feed it to $\calA$, we know $\calA$ accepts with probability at least $\frac{11}{12}$. Therefore, $\calB$ accepts with probability at least $\frac{5}{6}\cdot\frac{11}{12}\cdot\frac{11}{12}\geq \frac 23$.

Next, we consider the case that every $y_i$ is i.i.d.\ uniformly chosen from $\{0,1\}$. Again, we enlarge $S$ to an $s'$-sized sample $S'$ and imagine $S'$ is chosen i.i.d.\ from $\calD'$ first and $S$ is an i.i.d.\ sample from the uniform distribution $\calU$ over $S'$. With probability at least $\frac {11}{12}$, all the $x_i$ in $S'$ are distinct. Conditioned on that, by the Chernoff Bound, for any function $g$, we have $\Pr_{(x,y)\sim\calU}[g(x)\neq y]\geq \frac 12-\frac\epsilon 4=\alpha+\frac\epsilon 2$ with probability at least $1-e^{-\epsilon^2s'/8}= 1-\epsilon^{c'd/8}$ for some $c'\geq c_1$ satisfying $s'=\frac{c'd}{\epsilon^2}\log\frac 1\epsilon$. By Sauer's Lemma, the number of different $g$ over the chosen $x_i$ in $S'$ is at most $(\frac{es'}{d})^d=(\frac{c'e}{\epsilon^2}\log\frac{1}{\epsilon})^d$. Note that when $c_1$ is sufficiently large, we always have $\epsilon^{c'd/8}\cdot (\frac{c'e}{\epsilon^2}\log\frac{1}{\epsilon})^d\leq \frac 16$. Therefore, by the Union Bound, with probability at least $\frac 56$, we have $\forall g\in\calC,\Pr_{(x,y)\sim\calU}[g(x)\neq y]\geq\alpha+\frac\epsilon 2$. If we unwrap the conditional probability of at least $\frac{11}{12}$, we know with probability at least $\frac{11}{12}\cdot \frac{5}{6}$ that
\begin{enumerate}
\item all $x_i$ in $S'$ are distinct;
\item $\forall g\in\calC,\Pr_{(x,y)\sim\calU}[g(x)\neq y]\geq\alpha+\frac\epsilon 2$.
\end{enumerate}
Again, if we sample $S$ i.i.d.\ from $\calU$ and feed it to $\calA$, we know $\calA$ rejects with probability at least $\frac{11}{12}$. Therefore, $\calB$ rejects with probability at least $\frac{5}{6}\cdot\frac{11}{12}\cdot\frac{11}{12}\geq \frac 23$.
\end{proof}