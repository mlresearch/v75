\section{Tolerant Testing for Gaussian Surface Area}
\label{sec:surface}
\begin{theorem}
Given any $\eta,\epsilon>0$, there is a ($1+\eta,\epsilon$)-bi-criteria tolerant tester with the following properties. Given active access to a function $f:\mathbb{R}^n\rightarrow\{0,1\}$ over the standard Gaussian distribution and a Gaussian surface area upper bound $S$, the algorithm makes $n^{O(\poly(\eta^{-1},\epsilon^{-1}))}$ queries to an unlabeled sample of size [[TO BE SPECIFIED]] that outputs $\hat \alpha$ such that
\begin{enumerate}
\item $\forall \alpha$ satisfying $f$ is $\alpha$-close to the class of concepts with Gaussian surface area at most $S$, it holds that $\hat\alpha\leq \alpha+\epsilon$.
\item $\forall \alpha$ satisfying $f$ is $\alpha$-far from the class of concepts with Gaussian surface area at most $(1+\eta)S$, it holds that $\hat\alpha>\alpha-\epsilon$.
\end{enumerate}
Note that the query complexity is independent of $S$, in contrast to the $n^{\Omega(S^2)}$ queries needed for learning, even with the ability of making membership queries \citep{KOS08}.
\end{theorem}

\begin{proof}
If $S\leq\frac{2}{\epsilon}$, agnostic learning for the class of concepts with Gaussian surface area at most $S$ can be done using $n^{O(S^2/\epsilon^2)}=n^{O(\epsilon^{-4})}$ random labeled examples, up to an additive error $\frac{\epsilon}{2}$. Suppose agnostic learning for $f$ gives the 
\end{proof}


