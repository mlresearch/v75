%!TEX root = paper.tex
The now apply our techniques to the \emph{bandit multiclass} problem. This problem, first studied by \citet{kakade2008efficient}, considers the protocol of online multiclass learning in \pref{sec:prelims} with nature choosing $y_t \in [K]$ in each round, but with the added twist of bandit feedback: in each round, the learner predicts a class $\yh_t \sim p_t$ and receives feedback only on whether the prediction was correct or not, i.e. $\ind[\hy_t \neq y_t]$. The goal is to minimize regret with respect to a reference class of linear predictors, using some appropriate surrogate loss function for the 0-1 loss. 

\citet{kakade2009complexity} used the multiclass hinge loss $\ell_\text{hinge}(W, (x_t, y_t)) = \max_{k \in [K] \setminus \{y_t\}}[1 + \tri*{W_k, x_t} - \tri*{W_{y_t}, x_t}]_+$ and gave an algorithm based on the multiclass Perceptron algorithm achieving $O(n^{2/3})$ regret. For a Lipschitz continuous surrogate loss function, running the EXP4 algorithm \citep{auer2002nonstochastic} on a suitable discretization of the space of all linear predictors obtains $\tilde{O}(\sqrt{n})$ regret, albeit very inefficiently, i.e. with exponential dependence on the dimension. 
In COLT 2009, \citet{abernethyR09a} posed the open problem of obtaining an {\em efficient} algorithm for the problem with $O(\sqrt{n})$ regret. Specifically, they suggested the multiclass logistic loss as an appropriate surrogate loss function for the problem. \citet{hazan2011newtron} solved the open problem and obtained an algorithm, Newtron,  based on the Online Newton Step algorithm \citep{hazan2007logarithmic} with $\tilde{O}(\sqrt{n})$ regret for the case when norm of the linear predictors scales at most logarithmically in $n$. \citet{beygelzimerOZ17} also solved the open problem presenting a different algorithm called SOBA. SOBA is analyzed using a different family of surrogate loss functions parameterized by a scalar $\eta \in [0, 1]$ with $\eta = 0$ corresponding to the hinge loss and $\eta = 1$ corresponding to the squared hinge loss. For all values of $\eta \in [0, 1]$, SOBA simultaneously obtains relative bound mistake bounds of $\tilde{O}(\frac{1}{\eta}\sqrt{n})$ with the comparator's loss measured with respect to the corresponding loss function. 

Now we present an algorithm, OBAMA (for {\em Online Bandit Aggregation Multiclass Algorithm}), depicted in \pref{alg:bandit_multiclass} in \pref{app:bandit_multiclass_proofs}, that obtains an $\tilde{O}(\sqrt{n})$ relative mistake bound for the multiclass logistic loss, thus providing another solution to the open problem of \citet{abernethyR09a}. The mistake bound of OBAMA trumps that of Newtron, since both algorithms rely on the same loss function, and OBAMA obtains an $\tilde{O}(\sqrt{n})$ relative mistake bound on a larger range of parameter values compared to Newtron. While SOBA also has an $\tilde{O}(\sqrt{n})$ relative mistake bound, the two bounds are incomparable since they are relative to the comparator's loss measured using different loss functions.

\begin{theorem}
\label{thm:bandit_multiclass}
There is a setting of the smoothing parameter $\mu$ such that OBAMA enjoys the following mistake bound:
\[ 
\sum_{t=1}^{n}\ind\brk*{\yh_t\neq{}y_t}\leq\inf_{W \in \cW} \sum_{t=1}^n \ell(Wx_t, y_t) + O\left(\min\left\{dK^2e^{2BR}\log\prn*{\tfrac{BRn}{dK} + e},\ \sqrt{dK^2\log(\tfrac{BRn}{dK} + e)n}\right\}\right).
\]
\end{theorem}
This bound significantly improves upon that of Newtron~\citep{hazan2011newtron},
which is of order $O(dK^3\min\{\exp(BR)\log(n), BRn^{\frac{2}{3}}\})$ under the same setting and surrogate loss. The proof of \pref{thm:bandit_multiclass} appears in \pref{app:bandit_multiclass_proofs}.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
