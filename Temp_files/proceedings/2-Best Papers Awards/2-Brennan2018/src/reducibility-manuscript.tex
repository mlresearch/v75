\documentclass[11pt]{article}

% PACKAGES
\usepackage[colorlinks, linkcolor=blue, citecolor=blue]{hyperref}            
\usepackage{color}
\usepackage{graphicx,subfigure,amsmath,amssymb,amsfonts,bm,epsfig,epsf,url,dsfont}
\usepackage{amsthm}
\usepackage{tikz}
%\usepackage{times}
\usepackage{bbm}      
\usepackage{booktabs}
\usepackage{cases}
\usepackage{fullpage}
\usepackage[small,bf]{caption}
\usepackage{natbib}
\usepackage[top=1in,bottom=1in,left=1in,right=1in]{geometry}
\usepackage{fancybox}

% FILE INPUTS
\input{macros}

\setcounter{tocdepth}{2}

\begin{document}

\title{Reducibility and Computational Lower Bounds for Problems with Planted Sparse Structure}

\author{Matthew Brennan\thanks{Massachusetts Institute of Technology; brennanm@mit.edu.}
\and 
Guy Bresler\thanks{Massachusetts Institute of Technology; guy@mit.edu}
\and
Wasim Huleihel\thanks{Massachusetts Institute of Technology; wasimh@mit.edu}}
\date{\today}

\maketitle

\begin{abstract}
Recently, research in unsupervised learning has gravitated towards exploring statistical-computational gaps induced by sparsity. A line of work initiated in \cite{berthet2013complexity} has aimed to explain these gaps through reductions to conjecturally hard problems from complexity theory. However, the delicate nature of average-case reductions has limited the development of techniques and often led to weaker hardness results that only apply to algorithms robust to different noise distributions or that do not need to know the parameters of the problem. We introduce several new techniques to give a web of average-case reductions showing strong computational lower bounds based on the planted clique conjecture. Our new lower bounds include:
\begin{itemize}
\item \textbf{Planted Independent Set:} We show tight lower bounds for detecting a planted independent set of size $k$ in a sparse Erd\H{o}s-R\'{e}nyi graph of size $n$ with edge density $\tilde{\Theta}(n^{-\alpha})$.
\item \textbf{Planted Dense Subgraph:} If $p > q$ are the edge densities inside and outside of the community, we show the first lower bounds for the general regime $q = \tilde{\Theta}(n^{-\alpha})$ and $p - q = \tilde{\Theta}(n^{-\gamma})$ where $\gamma \ge \alpha$, matching the lower bounds predicted in \cite{chen2016statistical}. Our lower bounds apply to a deterministic community size $k$, resolving a question raised in \cite{hajek2015computational}.
\item \textbf{Biclustering:} We show strong lower bounds for Gaussian biclustering as a simple hypothesis testing problem to detect a uniformly at random planted flat $k \times k$ submatrix.
\item \textbf{Sparse Rank-1 Submatrix:} We show that detection in the sparse spiked Wigner model is often harder than biclustering, and are able to obtain two different tight lower bounds for these problems with different reductions from planted clique.
\item \textbf{Sparse PCA:} We give a reduction between rank-1 submatrix and sparse PCA to obtain tight lower bounds in the less sparse regime $k \gg \sqrt{n}$, when the spectral algorithm is optimal over the SDP. We give an alternate reduction recovering the lower bounds of \cite{berthet2013complexity, gao2017sparse} in the simple hypothesis testing variant of sparse PCA. We also observe a subtlety in the complexity of sparse PCA that arises when the planted vector is biased.
\item \textbf{Subgraph Stochastic Block Model:} We introduce a model where two small communities are planted in an Erd\H{o}s-R\'{e}nyi graph of the same average edge density and give tight lower bounds yielding different hard regimes than planted dense subgraph.
\end{itemize}

Our results demonstrate that, despite the delicate nature of average-case reductions, using natural problems as intermediates can often be beneficial, as is the case in worst-case complexity. Our main technical contribution is to introduce a set of techniques for average-case reductions that: (1) maintain the level of signal in an instance of a problem; (2) alter its planted structure; and (3) map two initial high-dimensional distributions simultaneously to two target distributions approximately under total variation. We also give algorithms matching our lower bounds and identify the information-theoretic limits of the models we consider.
\end{abstract}

\pagebreak

\tableofcontents

\pagebreak

\input{intro-sections}

\input{lifting}

\input{pds-and-reflection-cloning}

\input{random-rotations}

\input{algorithms-and-info-limits}

\input{final-sections}

\bibliography{GB_BIB.bib}
\bibliographystyle{alpha}

\pagebreak

\end{document}
