\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{berthet2013complexity}
\citation{chen2016statistical}
\citation{hajek2015computational}
\citation{berthet2013complexity,gao2017sparse}
\jmlr@workshop{31st Annual Conference on Learning Theory}
\jmlr@title{Reducibility and Computational Lower Bounds}{Reducibility and Computational Lower Bounds for\\ Problems with Planted Sparse Structure}
\jmlr@author{\Name {Matthew Brennan} \Email {brennanm@mit.edu}\\ \addr Department of EECS, MIT \AND \Name {Guy Bresler} \Email {guy@mit.edu}\\ \addr Department of EECS, MIT \AND \Name {Wasim Huleihel} \Email {wasimh@mit.edu} \\ \addr RLE, MIT }{\Name {Matthew Brennan} \Email {brennanm@mit.edu}\\ \addr Department of EECS, MIT \AND \Name {Guy Bresler} \Email {guy@mit.edu}\\ \addr Department of EECS, MIT \AND \Name {Wasim Huleihel} \Email {wasimh@mit.edu} \\ \addr RLE, MIT }
\newlabel{jmlrstart}{{}{48}{}{Doc-Start}{}}
\citation{berthet2013complexity}
\citation{ma2015computational}
\citation{cai2015computational}
\citation{hajek2015computational}
\citation{wang2016average}
\citation{wang2016statistical,gao2017sparse}
\citation{barak2016nearly}
\citation{krauthgamer2015semidefinite,ma2015sum,hopkins2017power}
\citation{feldman2012statistical,feldman2015complexity}
\citation{Barak2017}
\citation{bogdanov2006average}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{49}{section.0.1}}
\citation{berthet2013complexity,wang2016statistical,cai2015computational}
\citation{ma2015computational,gao2017sparse}
\citation{hajek2015computational}
\citation{berthet2013complexity}
\citation{gao2017sparse}
\citation{balakrishnan2017computationally,li2017robust}
\citation{chen2016statistical}
\citation{hajek2015computational}
\citation{ma2015computational}
\citation{berthet2013complexity}
\citation{gao2017sparse}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graph of average-case reductions for detection problems showing tight statistical-computational gaps given the planted clique conjecture.\relax }}{51}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:web}{{1}{51}{Graph of average-case reductions for detection problems showing tight statistical-computational gaps given the planted clique conjecture.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Formulations}{52}{section.0.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Detection and Recovery Problems}{52}{subsection.0.2.1}}
\@writefile{toc}{\contentsline {paragraph}{Detection.}{52}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Recovery.}{53}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Computational Model.}{53}{section*.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Problems}{53}{subsection.0.2.2}}
\newlabel{ss:formulations}{{2.2}{53}{Problems}{subsection.0.2.2}{}}
\citation{hajek2015computational}
\citation{hajek2015computational}
\citation{chen2016statistical}
\citation{cai2015computational}
\@writefile{toc}{\contentsline {paragraph}{Planted Clique and Independent Set.}{54}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{Planted Dense Subgraph.}{54}{section*.7}}
\@writefile{toc}{\contentsline {paragraph}{Subgraph Stochastic Block Model.}{55}{section*.8}}
\@writefile{toc}{\contentsline {paragraph}{Biclustering.}{55}{section*.9}}
\@writefile{toc}{\contentsline {paragraph}{Rank-1 Submatrix and Sparse Spiked Wigner.}{55}{section*.10}}
\@writefile{toc}{\contentsline {paragraph}{Sparse PCA.}{56}{section*.11}}
\@writefile{toc}{\contentsline {paragraph}{Biased Sparse PCA.}{56}{section*.12}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Summary of Results}{56}{section.0.3}}
\citation{berthet2013optimal}
\citation{gao2017sparse}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Types of hardness regimes by $\text  {SNR}$ in Theorem \ref  {lem:2a}. \textsc  {Type I} and \textsc  {Type III} each have two variants A and B depending on the Easy regime when $k \ll n^{1/2}$.\relax }}{57}{figure.caption.13}}
\newlabel{fig:types}{{2}{57}{Types of hardness regimes by $\text {SNR}$ in Theorem \ref {lem:2a}. \textsc {Type I} and \textsc {Type III} each have two variants A and B depending on the Easy regime when $k \ll n^{1/2}$.\relax }{figure.caption.13}{}}
\newlabel{lem:2a}{{3}{57}{Informal Main Theorem}{theorem.0.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Classification of regimes for each problem as in Theorem \ref  {lem:2a}. For each problem, $k$ is in the regime $k = \mathaccentV {tilde}07E{\Theta }(n^{\beta })$ where $\beta \in (0, 1)$ is a constant.\relax }}{58}{figure.caption.14}}
\newlabel{fig:classification}{{3}{58}{Classification of regimes for each problem as in Theorem \ref {lem:2a}. For each problem, $k$ is in the regime $k = \tilde {\Theta }(n^{\beta })$ where $\beta \in (0, 1)$ is a constant.\relax }{figure.caption.14}{}}
\citation{hajek2015computational}
\citation{ma2015computational}
\citation{hajek2015computational}
\citation{ma2015computational}
\@writefile{toc}{\contentsline {section}{\numberline {4}Techniques}{59}{section.0.4}}
\@writefile{toc}{\contentsline {paragraph}{Distributional Lifting.}{59}{section*.15}}
\@writefile{toc}{\contentsline {paragraph}{Rejection Kernels.}{59}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{Reflection Cloning.}{59}{section*.17}}
\citation{gao2017sparse}
\citation{berthet2013complexity}
\bibdata{GB_BIB}
\bibcite{abbe2017community}{{1}{2017}{{Abbe}}{{}}}
\bibcite{abbe2015detection}{{2}{2015}{{Abbe and Sandon}}{{}}}
\bibcite{abbe2016exact}{{3}{2016}{{Abbe et~al.}}{{Abbe, Bandeira, and Hall}}}
\bibcite{alon1998finding}{{4}{1998}{{Alon et~al.}}{{Alon, Krivelevich, and Sudakov}}}
\bibcite{alon2007testing}{{5}{2007}{{Alon et~al.}}{{Alon, Andoni, Kaufman, Matulef, Rubinfeld, and Xie}}}
\bibcite{alon2011inapproximability}{{6}{2011}{{Alon et~al.}}{{Alon, Arora, Manokaran, Moshkovitz, and Weinstein}}}
\bibcite{ames2011nuclear}{{7}{2011}{{Ames and Vavasis}}{{}}}
\bibcite{amini2009high}{{8}{2009}{{Amini and Wainwright}}{{}}}
\@writefile{toc}{\contentsline {paragraph}{Random Rotations and Sparse PCA.}{60}{section*.18}}
\bibcite{applebaum2010public}{{9}{2010}{{Applebaum et~al.}}{{Applebaum, Barak, and Wigderson}}}
\bibcite{arias2014community}{{10}{2014}{{Arias-Castro et~al.}}{{Arias-Castro, Verzelen, et~al.}}}
\bibcite{arora2009computational}{{11}{2009}{{Arora and Barak}}{{}}}
\bibcite{arora2011computational}{{12}{2011}{{Arora et~al.}}{{Arora, Barak, Brunnermeier, and Ge}}}
\bibcite{atserias2018clique}{{13}{2018}{{Atserias and Razborov}}{{}}}
\bibcite{austrin2013inapproximability}{{14}{2013}{{Austrin et~al.}}{{Austrin, Braverman, and Chlamt{\'a}c}}}
\bibcite{awasthi2015label}{{15}{2015}{{Awasthi et~al.}}{{Awasthi, Charikar, Lai, and Risteski}}}
\bibcite{balakrishnan2011statistical}{{16}{2011}{{Balakrishnan et~al.}}{{Balakrishnan, Kolar, Rinaldo, Singh, and Wasserman}}}
\bibcite{balakrishnan2017computationally}{{17}{2017}{{Balakrishnan et~al.}}{{Balakrishnan, Du, Li, and Singh}}}
\bibcite{balcan2013finding}{{18}{2013}{{Balcan et~al.}}{{Balcan, Borgs, Braverman, Chayes, and Teng}}}
\bibcite{baldin2018optimal}{{19}{2018}{{Baldin and Berthet}}{{}}}
\bibcite{bandeira2018notes}{{20}{2018}{{Bandeira et~al.}}{{Bandeira, Perry, and Wein}}}
\bibcite{banks2018information}{{21}{2018}{{Banks et~al.}}{{Banks, Moore, Vershynin, Verzelen, and Xu}}}
\bibcite{Barak2017}{{22}{2017}{{Barak}}{{}}}
\bibcite{barak2016nearly}{{23}{2016}{{Barak et~al.}}{{Barak, Hopkins, Kelner, Kothari, Moitra, and Potechin}}}
\bibcite{benaych2011eigenvalues}{{24}{2011}{{Benaych-Georges and Nadakuditi}}{{}}}
\bibcite{berthet2013complexity}{{25}{2013{a}}{{Berthet and Rigollet}}{{}}}
\bibcite{berthet2013optimal}{{26}{2013{b}}{{Berthet and Rigollet}}{{}}}
\bibcite{bhaskar2016hardness}{{27}{2016}{{Bhaskar et~al.}}{{Bhaskar, Cheng, Ko, and Swamy}}}
\bibcite{bhaskara2010detecting}{{28}{2010}{{Bhaskara et~al.}}{{Bhaskara, Charikar, Chlamtac, Feige, and Vijayaraghavan}}}
\bibcite{bhattiprolu2017sum}{{29}{2017}{{Bhattiprolu et~al.}}{{Bhattiprolu, Guruswami, and Lee}}}
\bibcite{birnbaum2013minimax}{{30}{2013}{{Birnbaum et~al.}}{{Birnbaum, Johnstone, Nadler, and Paul}}}
\bibcite{bogdanov2006worst}{{31}{2006}{{Bogdanov and Trevisan}}{{}}}
\bibcite{bogdanov2006average}{{32}{2006}{{Bogdanov et~al.}}{{Bogdanov, Trevisan, et~al.}}}
\bibcite{butucea2013detection}{{33}{2013}{{Butucea and Ingster}}{{}}}
\bibcite{caiwu2018}{{34}{2018}{{Cai and Wu}}{{}}}
\bibcite{cai2013sparse}{{35}{2013}{{Cai et~al.}}{{Cai, Ma, Wu, et~al.}}}
\bibcite{cai2015computational}{{36}{2015{a}}{{Cai et~al.}}{{Cai, Liang, and Rakhlin}}}
\bibcite{cai2015optimal}{{37}{2015{b}}{{Cai et~al.}}{{Cai, Ma, and Wu}}}
\bibcite{candogan2018finding}{{38}{2018}{{Candogan and Chandrasekaran}}{{}}}
\bibcite{capitaine2009largest}{{39}{2009}{{Capitaine et~al.}}{{Capitaine, Donati-Martin, F{\'e}ral, et~al.}}}
\bibcite{chan2016approximability}{{40}{2016}{{Chan et~al.}}{{Chan, Papailliopoulos, and Rubinstein}}}
\bibcite{chandrasekaran2013computational}{{41}{2013}{{Chandrasekaran and Jordan}}{{}}}
\bibcite{charikar2018finding}{{42}{2018}{{Charikar et~al.}}{{Charikar, Naamad, and Wu}}}
\bibcite{chen2015incoherence}{{43}{2015}{{Chen}}{{}}}
\bibcite{chen2016statistical}{{44}{2016}{{Chen and Xu}}{{}}}
\bibcite{chlamtac2012everywhere}{{45}{2012}{{Chlamtac et~al.}}{{Chlamtac, Dinitz, and Krauthgamer}}}
\bibcite{chlamtavc2017minimizing}{{46}{2017}{{Chlamt{\'a}{\v {c}} et~al.}}{{Chlamt{\'a}{\v {c}}, Dinitz, and Makarychev}}}
\bibcite{chlamtac2018sherali}{{47}{2018}{{{Chlamt{\'a}{\v c}} and {Manurangsi}}}{{}}}
\bibcite{coja2003finding}{{48}{2003}{{Coja-Oghlan}}{{}}}
\bibcite{coja2015independent}{{49}{2015}{{Coja-Oghlan and Efthymiou}}{{}}}
\bibcite{daniely2016complexity}{{50}{2016}{{Daniely and Shalev-Shwartz}}{{}}}
\bibcite{daniely2014average}{{51}{2014}{{Daniely et~al.}}{{Daniely, Linial, and Shalev-Shwartz}}}
\bibcite{dekel2014finding}{{52}{2014}{{Dekel et~al.}}{{Dekel, Gurel-Gurevich, and Peres}}}
\bibcite{deshpande2014sparse}{{53}{2014}{{Deshpande and Montanari}}{{}}}
\bibcite{deshpande2015finding}{{54}{2015{a}}{{Deshpande and Montanari}}{{}}}
\bibcite{deshpande2015improved}{{55}{2015{b}}{{Deshpande and Montanari}}{{}}}
\bibcite{diaconis1987dozen}{{56}{1987}{{Diaconis and Freedman}}{{}}}
\bibcite{diakonikolas2016statistical}{{57}{2016}{{Diakonikolas et~al.}}{{Diakonikolas, Kane, and Stewart}}}
\bibcite{dughmi2014hardness}{{58}{2014}{{Dughmi}}{{}}}
\bibcite{eickmeyer2012approximating}{{59}{2012}{{Eickmeyer et~al.}}{{Eickmeyer, Hansen, and Verbin}}}
\bibcite{feige2002relations}{{60}{2002}{{Feige}}{{}}}
\bibcite{feige2000finding}{{61}{2000}{{Feige and Krauthgamer}}{{}}}
\bibcite{feige2003probable}{{62}{2003}{{Feige and Krauthgamer}}{{}}}
\bibcite{feige2005finding}{{63}{2005}{{Feige and Ofek}}{{}}}
\bibcite{feige2010finding}{{64}{2010}{{Feige and Ron}}{{}}}
\bibcite{feldman2012statistical}{{65}{2012}{{Feldman et~al.}}{{Feldman, Grigorescu, Reyzin, Vempala, and Xiao}}}
\bibcite{feldman2013statistical}{{66}{2013}{{Feldman et~al.}}{{Feldman, Grigorescu, Reyzin, Vempala, and Xiao}}}
\bibcite{feldman2015complexity}{{67}{2015}{{Feldman et~al.}}{{Feldman, Perkins, and Vempala}}}
\bibcite{feral2007largest}{{68}{2007}{{F{\'e}ral and P{\'e}ch{\'e}}}{{}}}
\bibcite{gamarnik2014limits}{{69}{2014}{{Gamarnik and Sudan}}{{}}}
\bibcite{gao2017sparse}{{70}{2017}{{Gao et~al.}}{{Gao, Ma, and Zhou}}}
\bibcite{hajek2016achieving}{{71}{2016{a}}{{Hajek et~al.}}{{Hajek, Wu, and Xu}}}
\bibcite{hajek2016information}{{72}{2016{b}}{{Hajek et~al.}}{{Hajek, Wu, and Xu}}}
\bibcite{hajek2015computational}{{73}{2015}{{Hajek et~al.}}{{Hajek, Wu, and Xu}}}
\bibcite{hardt2014computational}{{74}{2014}{{Hardt et~al.}}{{Hardt, Meka, Raghavendra, and Weitz}}}
\bibcite{hazan2011hard}{{75}{2011}{{Hazan and Krauthgamer}}{{}}}
\bibcite{hirahara2017average}{{76}{2017}{{Hirahara and Santhanam}}{{}}}
\bibcite{hopkins2017efficient}{{77}{2017}{{Hopkins and Steurer}}{{}}}
\bibcite{hopkins2016integrality}{{78}{2016}{{Hopkins et~al.}}{{Hopkins, Kothari, Potechin, Raghavendra, and Schramm}}}
\bibcite{hopkins2017power}{{79}{2017}{{Hopkins et~al.}}{{Hopkins, Kothari, Potechin, Raghavendra, Schramm, and Steurer}}}
\bibcite{jerrum1992large}{{80}{1992}{{Jerrum}}{{}}}
\bibcite{johnstoneSparse04}{{81}{2004}{{Johnstone and Lu}}{{}}}
\bibcite{juels2000hiding}{{82}{2000}{{Juels and Peinado}}{{}}}
\bibcite{koiran2014hidden}{{83}{2014}{{Koiran and Zouzias}}{{}}}
\bibcite{kolar2011minimax}{{84}{2011}{{Kolar et~al.}}{{Kolar, Balakrishnan, Rinaldo, and Singh}}}
\bibcite{kothari2017sum}{{85}{2017}{{Kothari et~al.}}{{Kothari, Mori, O'Donnell, and Witmer}}}
\bibcite{krauthgamer2015semidefinite}{{86}{2015}{{Krauthgamer et~al.}}{{Krauthgamer, Nadler, and Vilenchik}}}
\bibcite{levin1986average}{{87}{1986}{{Levin}}{{}}}
\bibcite{li2017robust}{{88}{2017}{{Li}}{{}}}
\bibcite{ma2015sum}{{89}{2015}{{Ma and Wigderson}}{{}}}
\bibcite{ma2013sparse}{{90}{2013}{{Ma}}{{}}}
\bibcite{ma2015computational}{{91}{2015}{{Ma and Wu}}{{}}}
\bibcite{massart2007concentration}{{92}{2007}{{Massart}}{{}}}
\bibcite{massoulie2014community}{{93}{2014}{{Massouli{\'e}}}{{}}}
\bibcite{mcsherry2001spectral}{{94}{2001}{{McSherry}}{{}}}
\bibcite{minder2009small}{{95}{2009}{{Minder and Vilenchik}}{{}}}
\bibcite{montanari2015finding}{{96}{2015}{{Montanari}}{{}}}
\bibcite{montanari2015limitation}{{97}{2015}{{Montanari et~al.}}{{Montanari, Reichman, and Zeitouni}}}
\bibcite{mossel2012stochastic}{{98}{2012}{{Mossel et~al.}}{{Mossel, Neeman, and Sly}}}
\bibcite{mossel2013proof}{{99}{2013}{{Mossel et~al.}}{{Mossel, Neeman, and Sly}}}
\bibcite{mossel2014consistency}{{100}{2014}{{Mossel et~al.}}{{Mossel, Neeman, and Sly}}}
\bibcite{paul2007asymptotics}{{101}{2007}{{Paul}}{{}}}
\bibcite{peche2006largest}{{102}{2006}{{P{\'e}ch{\'e}}}{{}}}
\bibcite{perry2016statistical}{{103}{2016{a}}{{Perry et~al.}}{{Perry, Wein, and Bandeira}}}
\bibcite{perry2016optimality}{{104}{2016{b}}{{Perry et~al.}}{{Perry, Wein, Bandeira, and Moitra}}}
\bibcite{pitman1997some}{{105}{1997}{{Pitman}}{{}}}
\bibcite{raghavendra2015tight}{{106}{2015}{{Raghavendra and Schramm}}{{}}}
\bibcite{rahman2017local}{{107}{2017}{{Rahman et~al.}}{{Rahman, Virag, et~al.}}}
\bibcite{shabalin2009finding}{{108}{2009}{{Shabalin et~al.}}{{Shabalin, Weigman, Perou, Nobel, et~al.}}}
\bibcite{shah2016feeling}{{109}{2016}{{Shah et~al.}}{{Shah, Balakrishnan, and Wainwright}}}
\bibcite{shen2013consistency}{{110}{2013}{{Shen et~al.}}{{Shen, Shen, and Marron}}}
\bibcite{vershynin2010introduction}{{111}{2010}{{Vershynin}}{{}}}
\bibcite{verzelen2015community}{{112}{2015}{{Verzelen et~al.}}{{Verzelen, Arias-Castro, et~al.}}}
\bibcite{vu2005spectral}{{113}{2005}{{Vu}}{{}}}
\bibcite{vu2012minimax}{{114}{2012}{{Vu and Lei}}{{}}}
\bibcite{wang2016average}{{115}{2016{a}}{{Wang et~al.}}{{Wang, Berthet, and Plan}}}
\bibcite{wang2016statistical}{{116}{2016{b}}{{Wang et~al.}}{{Wang, Berthet, and Samworth}}}
\bibcite{yu1997assouad}{{117}{1997}{{Yu}}{{}}}
\bibcite{zhang2017tensor}{{118}{2017}{{Zhang and Xia}}{{}}}
\bibcite{zhang2014lower}{{119}{2014}{{Zhang et~al.}}{{Zhang, Wainwright, and Jordan}}}
\bibstyle{alpha}
\@writefile{toc}{\contentsline {section}{\numberline {A}Preliminaries}{70}{section.0.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Figure for the Main Theorem}{70}{subsection.0.A.1}}
\newlabel{sec:figmain}{{A.1}{70}{Figure for the Main Theorem}{subsection.0.A.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Parameter regimes by problem plotted as signal vs. sparsity. Sparsity is $k = \mathaccentV {tilde}07E{\Theta }(n^{\beta })$. First labels characterize detection and second labels characterize exact recovery. Recovery is not considered for $\textsc  {SSBM}$ and weak recovery is considered for $\textsc  {SPCA}$ and $\textsc  {BSPCA}$. In Easy (E) regimes, there is a polynomial-time algorithm. In Hard (H) regimes, the PC or PDS conjecture implies there is no polynomial-time algorithm. In Impossible (I) regimes, the task is information-theoretically impossible. Hardness in black regions is open.\relax }}{70}{figure.caption.22}}
\newlabel{fig:diagrams}{{4}{70}{Parameter regimes by problem plotted as signal vs. sparsity. Sparsity is $k = \tilde {\Theta }(n^{\beta })$. First labels characterize detection and second labels characterize exact recovery. Recovery is not considered for $\textsc {SSBM}$ and weak recovery is considered for $\textsc {SPCA}$ and $\textsc {BSPCA}$. In Easy (E) regimes, there is a polynomial-time algorithm. In Hard (H) regimes, the PC or PDS conjecture implies there is no polynomial-time algorithm. In Impossible (I) regimes, the task is information-theoretically impossible. Hardness in black regions is open.\relax }{figure.caption.22}{}}
\citation{berthet2013complexity}
\citation{krauthgamer2015semidefinite}
\citation{berthet2013complexity}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Algorithms for sparse PCA with $d = \Theta (n)$, $k = \mathaccentV {tilde}07E{\Theta }(n^\beta )$ and $\theta = \mathaccentV {tilde}07E{\Theta }(n^{-\alpha })$. Lines represent the strongest guarantees of each algorithm. The line marked as previous reductions shows the strongest previously known planted clique lower bounds for sparse PCA when $k \lesssim \sqrt  {n}$. No planted clique lower bounds were known for $k \gg \sqrt  {n}$.\relax }}{71}{figure.caption.23}}
\newlabel{fig:algsspca}{{5}{71}{Algorithms for sparse PCA with $d = \Theta (n)$, $k = \tilde {\Theta }(n^\beta )$ and $\theta = \tilde {\Theta }(n^{-\alpha })$. Lines represent the strongest guarantees of each algorithm. The line marked as previous reductions shows the strongest previously known planted clique lower bounds for sparse PCA when $k \lesssim \sqrt {n}$. No planted clique lower bounds were known for $k \gg \sqrt {n}$.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Hardness Results from an Algorithmic Perspective}{71}{subsection.0.A.2}}
\citation{berthet2013complexity}
\citation{gao2017sparse}
\citation{zhang2014lower,hardt2014computational,chan2016approximability}
\citation{bandeira2018notes}
\citation{chandrasekaran2013computational}
\citation{alon1998finding}
\citation{feige2000finding,mcsherry2001spectral,feige2010finding,ames2011nuclear,dekel2014finding,deshpande2015finding,chen2016statistical}
\citation{alon2007testing}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Prior Work}{72}{subsection.0.A.3}}
\citation{coja2015independent,gamarnik2014limits,rahman2017local}
\citation{feige2005finding}
\citation{coja2003finding}
\citation{chen2016statistical}
\citation{arias2014community,butucea2013detection,verzelen2015community,hajek2015computational}
\citation{chen2016statistical,hajek2016information,montanari2015finding,candogan2018finding}
\citation{hajek2015computational}
\citation{bhaskara2010detecting}
\citation{chlamtac2012everywhere,chlamtavc2017minimizing}
\citation{chlamtac2018sherali}
\citation{abbe2017community}
\citation{mossel2012stochastic,mossel2013proof,massoulie2014community}
\citation{mossel2014consistency,hajek2016achieving,abbe2016exact}
\citation{abbe2015detection}
\citation{butucea2013detection,ma2015computational,montanari2015limitation}
\citation{shabalin2009finding,kolar2011minimax,balakrishnan2011statistical,cai2015computational,chen2016statistical,hajek2016information}
\citation{ma2015computational}
\citation{cai2015computational}
\@writefile{toc}{\contentsline {paragraph}{Planted Clique and Independent Set.}{73}{section*.24}}
\@writefile{toc}{\contentsline {paragraph}{Planted Dense Subgraph and Community Detection.}{73}{section*.25}}
\@writefile{toc}{\contentsline {paragraph}{Biclustering and the Spiked Wigner Model.}{73}{section*.26}}
\citation{peche2006largest,feral2007largest,capitaine2009largest,benaych2011eigenvalues}
\citation{montanari2015limitation,perry2016statistical,perry2016optimality}
\citation{perry2016statistical,perry2016optimality,banks2018information}
\citation{hopkins2017power}
\citation{johnstoneSparse04}
\citation{amini2009high,ma2013sparse,cai2013sparse,berthet2013optimal,berthet2013complexity,shen2013consistency,krauthgamer2015semidefinite,deshpande2014sparse,wang2016statistical}
\citation{amini2009high,vu2012minimax,berthet2013optimal,birnbaum2013minimax,cai2013sparse,wang2016statistical,cai2015optimal}
\citation{ma2015sum}
\citation{berthet2013complexity}
\citation{berthet2013optimal}
\citation{gao2017sparse}
\citation{wang2016statistical}
\citation{levin1986average}
\citation{bogdanov2006worst}
\citation{arora2009computational}
\citation{bogdanov2006average}
\citation{alon2007testing}
\citation{ma2015computational,cai2015computational,caiwu2018}
\citation{hajek2015computational}
\citation{wang2016average,koiran2014hidden}
\citation{chen2015incoherence}
\citation{hirahara2017average}
\citation{berthet2013optimal,berthet2013complexity,wang2016statistical,gao2017sparse}
\citation{juels2000hiding,applebaum2010public}
\citation{Barak2017}
\citation{alon2011inapproximability}
\citation{minder2009small,hazan2011hard,austrin2013inapproximability}
\citation{dughmi2014hardness,bhaskar2016hardness}
\citation{eickmeyer2012approximating}
\citation{shah2016feeling}
\citation{balcan2013finding}
\citation{arora2011computational}
\citation{baldin2018optimal}
\citation{charikar2018finding}
\citation{awasthi2015label}
\citation{daniely2014average}
\citation{daniely2016complexity}
\citation{feige2002relations}
\citation{zhang2017tensor}
\@writefile{toc}{\contentsline {paragraph}{Sparse PCA.}{74}{section*.27}}
\@writefile{toc}{\contentsline {paragraph}{Average-Case Reductions.}{74}{section*.28}}
\citation{jerrum1992large}
\citation{montanari2015limitation}
\citation{krauthgamer2015semidefinite}
\citation{chen2016statistical}
\citation{deshpande2015improved,raghavendra2015tight,hopkins2016integrality,barak2016nearly}
\citation{ma2015sum}
\citation{hopkins2017power}
\citation{bhattiprolu2017sum}
\citation{kothari2017sum}
\citation{feige2003probable}
\citation{chlamtac2018sherali}
\citation{feldman2013statistical}
\citation{feldman2015complexity}
\citation{diakonikolas2016statistical}
\citation{atserias2018clique}
\citation{hopkins2017efficient}
\@writefile{toc}{\contentsline {paragraph}{Lower Bounds for Classes of Algorithms.}{75}{section*.29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Notation}{75}{subsection.0.A.4}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Densifying Planted Clique and Planted Independent Set}{76}{section.0.B}}
\newlabel{s:lifting}{{B}{76}{Densifying Planted Clique and Planted Independent Set}{section.0.B}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Detecting Planted Generalized Diagonals}{76}{subsection.0.B.1}}
\newlabel{lem:4a}{{4}{76}{Detecting Planted Generalized Diagonals}{theorem.0.B.4}{}}
\citation{pitman1997some}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Planted Clique Lifting}{77}{subsection.0.B.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Planted clique lifting procedure in Lemma \ref  {lem:4b}.\relax }}{78}{figure.caption.30}}
\newlabel{fig:pclifting}{{6}{78}{Planted clique lifting procedure in Lemma \ref {lem:4b}.\relax }{figure.caption.30}{}}
\newlabel{lem:4b}{{5}{78}{Planted Clique Lifting}{theorem.0.B.5}{}}
\newlabel{lem:4c}{{6}{80}{Planted Clique Lifting}{theorem.0.B.6}{}}
\citation{ma2015computational}
\citation{gao2017sparse}
\@writefile{toc}{\contentsline {section}{\numberline {C}Rejection Kernels and Distributional Lifting}{81}{section.0.C}}
\newlabel{s:rejection}{{C}{81}{Rejection Kernels and Distributional Lifting}{section.0.C}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Rejection Kernels}{81}{subsection.0.C.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Rejection kernel in Lemma \ref  {lem:5zz}\relax }}{82}{figure.caption.31}}
\newlabel{fig:rej-kernel}{{7}{82}{Rejection kernel in Lemma \ref {lem:5zz}\relax }{figure.caption.31}{}}
\newlabel{lem:5zz}{{7}{82}{Rejection Kernels}{theorem.0.C.7}{}}
\newlabel{lem:5a}{{8}{85}{Rejection Kernels}{theorem.0.C.8}{}}
\newlabel{lem:5b}{{9}{86}{Rejection Kernels}{theorem.0.C.9}{}}
\newlabel{lem:5c}{{10}{87}{Rejection Kernels}{theorem.0.C.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Distributional Lifting}{89}{subsection.0.C.2}}
\newlabel{lem:5cc}{{11}{90}{Distributional Lifting}{theorem.0.C.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Distributional lifting procedure in Theorem \ref  {lem:5cc}.\relax }}{91}{figure.caption.32}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Poisson lifting procedure in Lemma \ref  {lem:6a}.\relax }}{95}{figure.caption.33}}
\newlabel{fig:pois}{{9}{95}{Poisson lifting procedure in Lemma \ref {lem:6a}.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Planted Dense Subgraph and Biclustering}{95}{section.0.D}}
\newlabel{s:pds}{{D}{95}{Planted Dense Subgraph and Biclustering}{section.0.D}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.1}Poisson Lifting and Lower Bounds for Low-Density PDS}{95}{subsection.0.D.1}}
\newlabel{app:F.1}{{D.1}{95}{Poisson Lifting and Lower Bounds for Low-Density PDS}{subsection.0.D.1}{}}
\newlabel{lem:6a}{{12}{95}{Poisson Lifting}{theorem.0.D.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Gaussian lifting procedure in Lemma \ref  {lem:6b}.\relax }}{98}{figure.caption.34}}
\newlabel{fig:gaussian}{{10}{98}{Gaussian lifting procedure in Lemma \ref {lem:6b}.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.2}Gaussian Lifting and Lower Bounds for High-Density PDS and BC}{98}{subsection.0.D.2}}
\newlabel{lem:6b}{{14}{98}{Gaussian Lifting}{theorem.0.D.14}{}}
\newlabel{thm:gauss-hard}{{15}{100}{Gaussian Lifting and Lower Bounds for High-Density PDS and BC}{theorem.0.D.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Reduction to biclustering in Lemma \ref  {lem:bc}.\relax }}{101}{figure.caption.35}}
\newlabel{fig:bc}{{11}{101}{Reduction to biclustering in Lemma \ref {lem:bc}.\relax }{figure.caption.35}{}}
\newlabel{lem:bc}{{16}{101}{Gaussian Lifting and Lower Bounds for High-Density PDS and BC}{theorem.0.D.16}{}}
\newlabel{thm:bc}{{17}{103}{Gaussian Lifting and Lower Bounds for High-Density PDS and BC}{theorem.0.D.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Reduction to biclustering recovery in Lemma \ref  {lem:bcrec}.\relax }}{104}{figure.caption.36}}
\newlabel{fig:bcrec}{{12}{104}{Reduction to biclustering recovery in Lemma \ref {lem:bcrec}.\relax }{figure.caption.36}{}}
\newlabel{lem:bcrec}{{18}{104}{Gaussian Lifting and Lower Bounds for High-Density PDS and BC}{theorem.0.D.18}{}}
\newlabel{thm:bcrec}{{19}{105}{Gaussian Lifting and Lower Bounds for High-Density PDS and BC}{theorem.0.D.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Reduction to the general regime of planted dense subgraph in Lemma \ref  {lem:gpds}.\relax }}{107}{figure.caption.37}}
\newlabel{fig:bc}{{13}{107}{Reduction to the general regime of planted dense subgraph in Lemma \ref {lem:gpds}.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.3}Lower Bounds for General PDS}{107}{subsection.0.D.3}}
\newlabel{lem:gpds}{{20}{107}{Lower Bounds for General PDS}{theorem.0.D.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Reflection Cloning and Subgraph Stochastic Block Model}{110}{section.0.E}}
\newlabel{s:reflection}{{E}{110}{Reflection Cloning and Subgraph Stochastic Block Model}{section.0.E}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.1}Reflecting Cloning and Rank-1 Submatrix}{110}{subsection.0.E.1}}
\newlabel{lem:refc}{{22}{110}{Reflection Cloning}{theorem.0.E.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Reflection cloning procedure in Lemma \ref  {lem:refc}.\relax }}{111}{figure.caption.38}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Reduction to rank-1 submatrix in Lemma \ref  {lem:ros}.\relax }}{114}{figure.caption.39}}
\newlabel{fig:ros}{{15}{114}{Reduction to rank-1 submatrix in Lemma \ref {lem:ros}.\relax }{figure.caption.39}{}}
\newlabel{lem:ros}{{23}{114}{Reflecting Cloning and Rank-1 Submatrix}{theorem.0.E.23}{}}
\newlabel{thm:ros}{{24}{115}{Reflecting Cloning and Rank-1 Submatrix}{theorem.0.E.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.2}Sparse Spiked Wigner Matrix}{116}{subsection.0.E.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Reduction to sparse spiked Wigner matrix in Lemma \ref  {lem:ssw}.\relax }}{117}{figure.caption.40}}
\newlabel{fig:ssw}{{16}{117}{Reduction to sparse spiked Wigner matrix in Lemma \ref {lem:ssw}.\relax }{figure.caption.40}{}}
\newlabel{lem:ssw}{{25}{117}{Sparse Spiked Wigner Matrix}{theorem.0.E.25}{}}
\newlabel{thm:ssw}{{26}{119}{Sparse Spiked Wigner Matrix}{theorem.0.E.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Reduction to the subgraph stochastic block model in Lemma \ref  {lem:ssbm}.\relax }}{120}{figure.caption.41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {E.3}Subgraph Stochastic Block Model}{120}{subsection.0.E.3}}
\newlabel{lem:ssbm}{{27}{121}{Subgraph Stochastic Block Model}{theorem.0.E.27}{}}
\newlabel{thm:SSBMguar}{{28}{123}{Subgraph Stochastic Block Model}{theorem.0.E.28}{}}
\citation{berthet2013complexity}
\citation{gao2017sparse}
\citation{diaconis1987dozen}
\citation{diaconis1987dozen}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Random rotation procedure in Lemma \ref  {lem:randrot}.\relax }}{125}{figure.caption.42}}
\newlabel{fig:randrot}{{18}{125}{Random rotation procedure in Lemma \ref {lem:randrot}.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Random Rotations and Sparse PCA}{125}{section.0.F}}
\newlabel{s:rotations}{{F}{125}{Random Rotations and Sparse PCA}{section.0.F}{}}
\newlabel{lem:randrot}{{30}{125}{Random Rotation}{theorem.0.F.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Reductions to $\textsc  {SPCA}_D$ when $k \gtrsim \sqrt  {n}$ and $k \lesssim \sqrt  {n}$ in Lemmas \ref  {lem:hsspca} and \ref  {lem:lsspca} and reduction to $\textsc  {SPCA}_{R}$ in Theorem \ref  {thm:spcarec}.\relax }}{127}{figure.caption.43}}
\newlabel{fig:randrot}{{19}{127}{Reductions to $\textsc {SPCA}_D$ when $k \gtrsim \sqrt {n}$ and $k \lesssim \sqrt {n}$ in Lemmas \ref {lem:hsspca} and \ref {lem:lsspca} and reduction to $\textsc {SPCA}_{R}$ in Theorem \ref {thm:spcarec}.\relax }{figure.caption.43}{}}
\newlabel{lem:hsspca}{{31}{127}{Random Rotations and Sparse PCA}{theorem.0.F.31}{}}
\newlabel{lem:lsspca}{{32}{128}{Random Rotations and Sparse PCA}{theorem.0.F.32}{}}
\newlabel{thm:spca}{{33}{129}{Random Rotations and Sparse PCA}{theorem.0.F.33}{}}
\newlabel{thm:spcarec}{{35}{131}{Random Rotations and Sparse PCA}{theorem.0.F.35}{}}
\citation{butucea2013detection}
\citation{butucea2013detection}
\citation{hajek2015computational}
\citation{hajek2015computational}
\citation{hajek2015computational}
\@writefile{toc}{\contentsline {section}{\numberline {G}Algorithms and Information-Theoretic Thresholds}{132}{section.0.G}}
\newlabel{s:info}{{G}{132}{Algorithms and Information-Theoretic Thresholds}{section.0.G}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {G.1}Biclustering, Planted Dense Subgraph and Independent Set}{132}{subsection.0.G.1}}
\@writefile{toc}{\contentsline {paragraph}{Information-Theoretic Lower Bounds.}{132}{section*.44}}
\citation{hajek2015computational}
\citation{hajek2015computational}
\citation{hajek2015computational}
\citation{hajek2016information}
\citation{hajek2016information}
\citation{hajek2016information}
\citation{hajek2016information}
\newlabel{lem:hgm}{{38}{133}{Lemma 14 in \cite {hajek2015computational}}{theorem.0.G.38}{}}
\newlabel{thm:infbcrec}{{40}{133}{Corollary 2 in \cite {hajek2016information}}{theorem.0.G.40}{}}
\newlabel{eqn:gaussweak}{{2}{133}{Corollary 2 in \cite {hajek2016information}}{equation.0.G.2}{}}
\citation{hajek2016information}
\citation{hajek2016information}
\citation{hajek2016information}
\citation{hajek2016information}
\newlabel{thm:bicexact}{{41}{134}{Corollary 4 in \cite {hajek2016information}}{theorem.0.G.41}{}}
\newlabel{eqn:gaussexact}{{3}{134}{Corollary 4 in \cite {hajek2016information}}{equation.0.G.3}{}}
\newlabel{eqn:bernweak}{{4}{134}{Corollary 1 in \cite {hajek2016information}}{equation.0.G.4}{}}
\newlabel{thm:pdsexact}{{43}{134}{Corollary 3 in \cite {hajek2016information}}{theorem.0.G.43}{}}
\newlabel{eqn:bernexact}{{5}{134}{Corollary 3 in \cite {hajek2016information}}{equation.0.G.5}{}}
\citation{butucea2013detection}
\citation{butucea2013detection}
\citation{hajek2015computational}
\@writefile{toc}{\contentsline {paragraph}{Information-Theoretically Optimal Algorithms.}{136}{section*.45}}
\newlabel{thm:pdsdet}{{46}{136}{Information-Theoretically Optimal Algorithms}{theorem.0.G.46}{}}
\citation{chen2016statistical}
\citation{chen2016statistical}
\citation{ma2015computational}
\citation{ma2015computational}
\citation{chen2016statistical}
\citation{chen2016statistical}
\citation{chen2016statistical}
\citation{chen2016statistical}
\citation{chen2016statistical}
\@writefile{toc}{\contentsline {paragraph}{Polynomial-Time Algorithms.}{138}{section*.46}}
\citation{cai2015optimal}
\citation{cai2015optimal}
\@writefile{toc}{\contentsline {subsection}{\numberline {G.2}Rank-1 Submatrix, Sparse Spiked Wigner and Subgraph SBM}{139}{subsection.0.G.2}}
\@writefile{toc}{\contentsline {paragraph}{Information-Theoretic Lower Bounds.}{139}{section*.47}}
\newlabel{lem:hgmw}{{52}{139}{Lemma 1 in \cite {cai2015optimal}}{theorem.0.G.52}{}}
\newlabel{thm:sswinf}{{53}{139}{Information-Theoretic Lower Bounds}{theorem.0.G.53}{}}
\citation{hajek2016information}
\citation{chen2016statistical}
\citation{cai2015computational}
\@writefile{toc}{\contentsline {paragraph}{Information-Theoretically Optimal Algorithms.}{141}{section*.48}}
\newlabel{lem:rossearch}{{54}{141}{Information-Theoretically Optimal Algorithms}{theorem.0.G.54}{}}
\citation{vershynin2010introduction}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Exhaustive search algorithm for sparse rank-1 submatrix recovery in Theorem \ref  {lem:rossearch}.\relax }}{142}{figure.caption.49}}
\citation{vershynin2010introduction}
\@writefile{toc}{\contentsline {paragraph}{Polynomial-Time Algorithms.}{147}{section*.50}}
\citation{cai2015computational}
\citation{cai2015computational}
\citation{cai2015computational}
\citation{cai2015computational}
\citation{cai2015computational}
\citation{cai2015computational}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Algorithm for sparse rank-1 submatrix recovery from \cite  {cai2015computational} and in Theorem \ref  {thm:rosrec}.\relax }}{148}{figure.caption.51}}
\newlabel{fig:rosspectral}{{21}{148}{Algorithm for sparse rank-1 submatrix recovery from \cite {cai2015computational} and in Theorem \ref {thm:rosrec}.\relax }{figure.caption.51}{}}
\newlabel{thm:rosrec}{{58}{148}{Polynomial-Time Algorithms}{theorem.0.G.58}{}}
\citation{cai2015computational}
\citation{vershynin2010introduction}
\citation{vu2005spectral}
\citation{berthet2013optimal}
\citation{cai2015optimal}
\citation{cai2015optimal}
\citation{berthet2013optimal}
\citation{berthet2013optimal}
\citation{cai2015optimal}
\citation{cai2015optimal}
\@writefile{toc}{\contentsline {subsection}{\numberline {G.3}Sparse PCA and Biased Sparse PCA}{151}{subsection.0.G.3}}
\@writefile{toc}{\contentsline {paragraph}{Information-Theoretic Lower Bounds.}{151}{section*.52}}
\newlabel{thm:cmw15}{{61}{151}{Proposition 2 in \cite {cai2015optimal}}{theorem.0.G.61}{}}
\newlabel{lem:chispca}{{62}{151}{Lemma 7 in \cite {cai2015optimal}}{theorem.0.G.62}{}}
\citation{wang2016statistical}
\citation{wang2016statistical}
\citation{massart2007concentration}
\citation{yu1997assouad}
\citation{berthet2013complexity}
\citation{wang2016statistical}
\citation{berthet2013complexity}
\citation{berthet2013complexity}
\@writefile{toc}{\contentsline {paragraph}{Information-Theoretically Optimal Algorithms.}{154}{section*.53}}
\citation{wang2016statistical}
\newlabel{thm:weakrecspca}{{69}{155}{Information-Theoretically Optimal Algorithms}{theorem.0.G.69}{}}
\newlabel{thm:bspcadet}{{70}{156}{Information-Theoretically Optimal Algorithms}{theorem.0.G.70}{}}
\citation{berthet2013complexity}
\citation{berthet2013complexity}
\citation{berthet2013complexity}
\citation{berthet2013complexity}
\citation{wang2016statistical}
\citation{wang2016statistical}
\citation{wang2016statistical}
\citation{wang2016statistical}
\citation{wang2016statistical}
\@writefile{toc}{\contentsline {paragraph}{Polynomial-Time Algorithms.}{157}{section*.54}}
\newlabel{thm:spcasdp}{{72}{157}{Theorem 5 in \cite {wang2016statistical}}{theorem.0.G.72}{}}
\citation{vershynin2010introduction}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces SDP algorithm for weak $\ell _2$ estimation in sparse PCA from \cite  {wang2016statistical} and in Theorem \ref  {thm:spcasdp}.\relax }}{158}{figure.caption.55}}
\newlabel{fig:spcasdp}{{22}{158}{SDP algorithm for weak $\ell _2$ estimation in sparse PCA from \cite {wang2016statistical} and in Theorem \ref {thm:spcasdp}.\relax }{figure.caption.55}{}}
\newlabel{thm:spectralspca}{{74}{158}{Polynomial-Time Algorithms}{theorem.0.G.74}{}}
\citation{krauthgamer2015semidefinite}
\citation{krauthgamer2015semidefinite}
\citation{krauthgamer2015semidefinite}
\citation{paul2007asymptotics}
\citation{paul2007asymptotics}
\citation{krauthgamer2015semidefinite}
\@writefile{toc}{\contentsline {section}{\numberline {H}Detection-Recovery Reductions}{160}{section.0.H}}
\newlabel{s:detectionrecovery}{{H}{160}{Detection-Recovery Reductions}{section.0.H}{}}
\newlabel{lem:pdscloning}{{76}{160}{Detection-Recovery Reductions}{theorem.0.H.76}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Cloning procedures in Lemmas \ref  {lem:pdscloning} and \ref  {lem:gausscloning}.\relax }}{161}{figure.caption.56}}
\newlabel{lem:gausscloning}{{77}{161}{Detection-Recovery Reductions}{theorem.0.H.77}{}}
\citation{vershynin2010introduction}
\@writefile{toc}{\contentsline {paragraph}{Biclustering.}{162}{section*.57}}
\@writefile{toc}{\contentsline {paragraph}{Sparse Spiked Wigner and Rank-1 Submatrix.}{162}{section*.58}}
\@writefile{toc}{\contentsline {paragraph}{Planted Independent Set and Planted Dense Subgraph.}{162}{section*.59}}
\@writefile{toc}{\contentsline {paragraph}{Sparse PCA and Biased Sparse PCA.}{163}{section*.60}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Future Directions}{164}{section.0.I}}
\newlabel{s:future}{{I}{164}{Future Directions}{section.0.I}{}}
\newlabel{jmlrend}{{I}{164}{end of Reducibility and Computational Lower Bounds}{section*.61}{}}
