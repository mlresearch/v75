---
title: Time-Space Tradeoffs for Learning Finite Functions from Random Evaluations,
  with Applications to Polynomials
abstract: We develop an extension of recent analytic methods for  obtaining time-space
  tradeoff lower bounds for problems of learning  from uniformly random labelled examples.  With
  our methods we can obtain bounds for learning concept classes of finite functions
  from random evaluations even when the sample space of random inputs can be significantly
  smaller than the concept class of functions and the function values can be from
  an arbitrary finite set. At the core of our results, we reduce the time-space complexity
  of learning from random evaluations to the question of how much the corresponding
  evaluation matrix amplifies the 2-norms of “almost uniform” probability distributions.
  To analyze the latter, we formulate it as a semidefinite program, and we analyze
  its dual.   In order to handle function values from arbitrary finite sets, we apply
  this norm amplification analysis to complex matrices. As applications that follow
  from our new techniques, we show that any algorithm that learns $n$-variate  polynomial
  functions of degree at most $d$ over $\mathbb{F}_2$ with success at least $2^{-O(n)}$
  from evaluations on randomly chosen inputs either requires space $Ω(nm/d)$ or $2^{Ω(n/d)}$
  time where $m=(n/d)^{Θ(d)}$ is the dimension of the space of such polynomials.   These
  bounds are asymptotically optimal for polynomials of arbitrary constant degree since
  they match the tradeoffs achieved by natural learning algorithms for the problems.
  We extend these results to learning polynomials of degree at most $d$ over any odd
  prime field $\mathbb{F}_p$ where we show that $Ω((mn/d)\log p)$ space or time $p^{Ω(n/d)}$
  is required. To derive our bounds for learning polynomials over finite fields, we
  show that an analysis of the dual of the corresponding semidefinite program follows
  from an understanding of the distribution of the bias of all degree $d$ polynomials
  with respect to uniformly random inputs.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: beame18a
month: 0
tex_title: Time-Space Tradeoffs for Learning Finite Functions from Random Evaluations,
  with Applications to Polynomials
firstpage: 843
lastpage: 856
page: 843-856
order: 843
cycles: false
bibtex_author: Beame, Paul and Oveis Gharan, Shayan and Yang, Xin
author:
- given: Paul
  family: Beame
- given: Shayan
  family: Oveis Gharan
- given: Xin
  family: Yang
date: 2018-06-29
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 6
  - 29
pdf: http://proceedings.mlr.press/v75/beame18a/beame18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
