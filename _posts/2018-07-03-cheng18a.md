---
title: 'Underdamped Langevin MCMC: A non-asymptotic analysis'
abstract: We study the underdamped Langevin diffusion when the log of the target distribution
  is smooth and strongly concave. We present a MCMC algorithm based on its discretization
  and show that it achieves $\varepsilon$ error (in 2-Wasserstein distance) in $\mathcal{O}(\sqrt{d}/\varepsilon)$
  steps. This is a significant improvement over the best known rate for overdamped
  Langevin MCMC, which is $\mathcal{O}(d/\varepsilon^2)$ steps under the same smoothness/concavity
  assumptions. The underdamped Langevin MCMC scheme can be viewed as a version of
  Hamiltonian Monte Carlo (HMC) which has been observed to outperform overdamped Langevin
  MCMC methods in a number of application areas. We provide quantitative rates that
  support this empirical wisdom.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cheng18a
month: 0
tex_title: 'Underdamped Langevin MCMC: A non-asymptotic analysis'
firstpage: 300
lastpage: 323
page: 300-323
order: 300
cycles: false
bibtex_author: Cheng, Xiang and Chatterji, Niladri S. and Bartlett, Peter L. and Jordan,
  Michael I.
author:
- given: Xiang
  family: Cheng
- given: Niladri S.
  family: Chatterji
- given: Peter L.
  family: Bartlett
- given: Michael I.
  family: Jordan
date: 2018-07-03
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
pdf: http://proceedings.mlr.press/v75/cheng18a/cheng18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
