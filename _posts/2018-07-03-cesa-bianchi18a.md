---
title: Nonstochastic Bandits with Composite Anonymous Feedback
abstract: 'We investigate a nonstochastic bandit setting in which the loss of an action
  is not immediately charged to the player, but rather spread over at most d consecutive
  steps in an adversarial way. This implies that the instantaneous loss observed by
  the player at the end of each round is a sum of as many as d loss components of
  previously played actions. Hence, unlike the standard bandit setting with delayed
  feedback, here the player cannot observe the individual delayed losses, but only
  their sum. Our main contribution is a general reduction transforming a standard
  bandit algorithm into one that can operate in this harder setting. We also show
  how the regret of the transformed algorithm can be bounded in terms of the regret
  of the original algorithm. Our reduction cannot be improved in general: we prove
  a lower bound on the regret of any bandit algorithm in this setting that matches
  (up to log factors) the upper bound obtained via our reduction. Finally, we show
  how our reduction can be extended to more complex bandit settings, such as combinatorial
  linear bandits and online bandit convex optimization.'
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cesa-bianchi18a
month: 0
tex_title: Nonstochastic Bandits with Composite Anonymous Feedback
firstpage: 750
lastpage: 773
page: 750-773
order: 750
cycles: false
bibtex_author: Cesa-Bianchi, Nicol\`o and Gentile, Claudio and Mansour, Yishay
author:
- given: Nicol√≤
  family: Cesa-Bianchi
- given: Claudio
  family: Gentile
- given: Yishay
  family: Mansour
date: 2018-07-03
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
pdf: http://proceedings.mlr.press/v75/cesa-bianchi18a/cesa-bianchi18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
