---
title: 'A Data Prism: Semi-verified learning in the small-alpha regime'
abstract: We consider a simple model of unreliable or crowdsourced data where there
  is an underlying set of $n$ binary variables, each “evaluator” contributes a (possibly
  unreliable or adversarial) estimate of the values of some subset of $r$ of the variables,
  and the learner is given the true value of a \emph{constant} number of variables.   We
  show that, provided an $α$-fraction of the evaluators are “good” (either correct,
  or with independent noise rate $p < 1/2$), then the true values of a $(1-\eps)$
  fraction of the $n$ underlying variables can be deduced as long as $r > \log_{2-2p}(1/α)$.
  For example, if the fraction of “good” evaluators is larger than $1/16$ and there
  is no noise in their responses, then accurate recovery is possible provided each
  worker evaluates a random set of $4$ items.  This result is optimal in that if $r
  ≤\log_{2-2p}(1/α)$ the large dataset can contain no information.   This setting
  can be viewed as an instance of the  \emph{semi-verified} learning model introduced
  by Charikar, Steinhardt, and Valiant, which explores the tradeoff between the number
  of items evaluated by each worker and the fraction of “good” evaluators. In the
  standard adversarial setting, our algorithm requires $\tilde{O}\left(n^{\log_{2-2p}(1/α)}\right)$
  evaluators. However, the algorithm runs in near linear time, $\tilde{O}_{r,\eps}(n)$,
  and hence would require only a near-linear number of evaluations in the weaker model
  in which the adversary’s responses to each $r$-tuple of items are independent of
  the set of evaluations collected.  These settings and results can also be viewed
  as examining a general class of semi-adversarial CSPs with a planted assignment.
  This extreme parameter regime, where the fraction of reliable data is small (inverse
  exponential in the amount of data provided by each source), is relevant to a number
  of practical settings.  For example, the setting where you collect a dataset on
  customer preferences, with each customer specifying preferences for a small (constant)
  number of items, and the goal is to ascertain the preferences of a specific demographic
  of interest.   Our results show that this large dataset (which lacks demographic
  information) can be leveraged together with the preferences of the demographic of
  interest for a \emph{constant} (polynomial in $1/α$ but independent of $n$), number
  of randomly selected items, to recover an accurate estimate of the entire set of
  preferences, even if the  fraction of the original dataset contributed by the demographic
  of interest is inverse exponential in the number of preferences supplied by each
  customer.   In this sense, our results can be viewed as a “data prism” allowing
  one to extract the behavior of specific cohorts from a large, mixed, dataset.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: meister18a
month: 0
tex_title: 'A Data Prism: Semi-verified learning in the small-alpha regime'
firstpage: 1530
lastpage: 1546
page: 1530-1546
order: 1530
cycles: false
bibtex_author: Meister, Michela and Valiant, Gregory
author:
- given: Michela
  family: Meister
- given: Gregory
  family: Valiant
date: 2018-06-29
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 6
  - 29
pdf: http://proceedings.mlr.press/v75/meister18a/meister18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
