---
title: Near-Optimal Sample Complexity Bounds for Maximum Likelihood Estimation of
  Multivariate Log-concave Densities
abstract: We study the problem of learning multivariate log-concave densities with
  respect to a global loss function. We obtain the first upper bound on the sample
  complexity of the maximum likelihood estimator (MLE) for a log-concave density on
  $\mathbb{R}^d$, for all $d ≥4$. Prior to this work, no finite sample upper bound
  was known for this estimator in more than $3$ dimensions. In more detail, we prove
  that for any $d ≥1$ and $ε>0$, given  $\tilde{O}_d((1/ε)^{(d+3)/2})$ samples drawn
  from an unknown log-concave density $f_0$ on $\mathbb{R}^d$, the MLE outputs a hypothesis
  $h$ that with high probability is $ε$-close to $f_0$, in squared Hellinger loss.
  A sample complexity lower bound of $\Omega_d((1/ε)^{(d+1)/2})$ was previously known
  for any learning algorithm that achieves this guarantee. We thus establish that
  the sample complexity of the log-concave MLE is near-optimal, up to an $\tilde{O}(1/ε)$
  factor.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: carpenter18a
month: 0
tex_title: Near-Optimal Sample Complexity Bounds for Maximum Likelihood Estimation
  of Multivariate Log-concave Densities
firstpage: 1234
lastpage: 1262
page: 1234-1262
order: 1234
cycles: false
bibtex_author: Carpenter, Timothy and Diakonikolas, Ilias and Sidiropoulos, Anastasios
  and Stewart, Alistair
author:
- given: Timothy
  family: Carpenter
- given: Ilias
  family: Diakonikolas
- given: Anastasios
  family: Sidiropoulos
- given: Alistair
  family: Stewart
date: 2018-07-03
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
pdf: http://proceedings.mlr.press/v75/carpenter18a/carpenter18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
