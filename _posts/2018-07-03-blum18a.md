---
title: Active Tolerant Testing
abstract: In this work, we show that for a nontrivial hypothesis class $\mathcal C$,
  we can estimate the distance of a target function $f$ to $\mathcal C$ (estimate
  the error rate of the best $h\in \mathcal C$) using substantially fewer labeled
  examples than would be needed to actually {\em learn} a good $h \in \mathcal C$.   Specifically,
  we show that for the class $\mathcal C$ of unions of $d$ intervals on the line,
  in the active learning setting in which we have access to a pool of unlabeled examples
  drawn from an arbitrary underlying distribution $\mathcal D$, we can estimate the
  error rate of the best $h \in \mathcal C$ to an additive error $\epsilon$ with a
  number of label requests that is {\em independent of $d$} and depends only on $\epsilon$.  In
  particular, we make $O(\frac{1}{\epsilon^6}\log \frac{1}{\epsilon})$ label queries
  to an unlabeled pool of size $O(\frac{d}{\epsilon^2}\log \frac{1}{\epsilon})$.  This
  task of estimating the distance of an unknown $f$ to a given class $\mathcal C$  is
  called {\em tolerant testing} or {\em distance estimation} in the testing literature,
  usually studied in a membership query model and with respect to the uniform distribution.  Our
  work extends that of Balcan et al. (2012) who solved the {\em non}-tolerant testing
  problem for this class (distinguishing the zero-error case from the case that the
  best hypothesis in the class has error greater than $\epsilon$).   We also consider
  the related problem of estimating the performance of a given learning algorithm
  $\mathcal A$ in this setting.  That is, given a large pool of unlabeled examples
  drawn from distribution $\mathcal D$, can we, from only a few label queries, estimate
  how well $\mathcal A$ would perform if the entire dataset were labeled and given
  as training data to $\mathcal A$?   We focus on $k$-Nearest Neighbor style algorithms,
  and also show how our results can be applied to the problem of hyperparameter tuning
  (selecting the best value of $k$ for the given learning problem).
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: blum18a
month: 0
tex_title: Active Tolerant Testing
firstpage: 474
lastpage: 497
page: 474-497
order: 474
cycles: false
bibtex_author: Blum, Avrim and Hu, Lunjia
author:
- given: Avrim
  family: Blum
- given: Lunjia
  family: Hu
date: 2018-07-03
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
pdf: http://proceedings.mlr.press/v75/blum18a/blum18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
