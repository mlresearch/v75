---
title: Size-Independent  Sample Complexity of Neural Networks
abstract: We study the sample complexity of learning neural networks, by  providing
  new bounds on their Rademacher complexity assuming norm constraints  on the parameter
  matrix of each layer. Compared to previous work, these  complexity bounds have improved
  dependence on the network depth, and under some  additional assumptions, are fully
  independent of the network size (both depth  and width). These results are derived
  using some novel techniques, which may be  of independent interest.
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: golowich18a
month: 0
tex_title: Size-Independent  Sample Complexity of Neural Networks
firstpage: 297
lastpage: 299
page: 297-299
order: 297
cycles: false
bibtex_author: Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad
author:
- given: Noah
  family: Golowich
- given: Alexander
  family: Rakhlin
- given: Ohad
  family: Shamir
date: 2018-07-03
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
pdf: http://proceedings.mlr.press/v75/golowich18a/golowich18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
