---
title: Calibrating Noise to Variance in Adaptive Data Analysis
abstract: " Datasets are often used multiple times and each successive analysis may
  depend on the outcome of previous analyses. Standard techniques for ensuring generalization
  and statistical validity do not account for this adaptive dependence. A recent line
  of work studies the challenges that arise from such adaptive data reuse by considering
  the problem of answering a sequence of “queries” about the data distribution where
  each query may depend arbitrarily on answers to previous queries. The strongest
  results obtained for this problem rely on differential privacy – a strong notion
  of algorithmic stability with the important property that it “composes” well when
  data is reused. However the notion is rather strict, as it requires stability under
  replacement of an arbitrary data element. The simplest algorithm is to add Gaussian
  (or Laplace) noise to distort the empirical answers. However, analysing this technique
  using differential privacy yields suboptimal accuracy guarantees when the queries
  have low variance. Here we propose a relaxed notion of stability based on KL divergence
  that also composes adaptively. We show that our notion of stability implies a bound
  on the mutual information between the dataset and the output of the algorithm and
  then derive new generalization guarantees implied by bounded mutual information.
  We demonstrate that a simple and natural algorithm based on adding noise scaled
  to the standard deviation of the query provides our notion of stability. This implies
  an algorithm that can answer statistical queries about the dataset with substantially
  improved accuracy guarantees for low-variance queries. The only previous approach
  that provides such accuracy guarantees is based on a more involved differentially
  private median-of-means algorithm and its analysis exploits stronger “group” stability
  of the algorithm. "
section: Regular Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
id: feldman18a
month: 0
tex_title: Calibrating Noise to Variance in Adaptive Data Analysis
firstpage: 535
lastpage: 544
page: 535-544
order: 535
cycles: false
bibtex_author: Feldman, Vitaly and Steinke, Thomas
author:
- given: Vitaly
  family: Feldman
- given: Thomas
  family: Steinke
date: 2018-07-03
address: 
publisher: PMLR
container-title: Proceedings of the 31st  Conference On Learning Theory
volume: '75'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
pdf: http://proceedings.mlr.press/v75/feldman18a/feldman18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
